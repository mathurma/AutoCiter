<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
<front>
<journal-meta><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id><journal-id journal-id-type="pmc">ploscomp</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS Computational Biology</journal-title></journal-title-group><issn pub-type="ppub">1553-734X</issn><issn pub-type="epub">1553-7358</issn><publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="publisher-id">09-PLCB-RA-0267R2</article-id><article-id pub-id-type="doi">10.1371/journal.pcbi.1000456</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline"><subject>Computational Biology/Computational Neuroscience</subject><subject>Neuroscience/Theoretical Neuroscience</subject></subj-group></article-categories><title-group><article-title>Towards Reproducible Descriptions of Neuronal Network Models</article-title><alt-title alt-title-type="running-head">Towards Reproducible Model Descriptions</alt-title></title-group><contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Nordlie</surname><given-names>Eilen</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Gewaltig</surname><given-names>Marc-Oliver</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Plesser</surname><given-names>Hans Ekkehard</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff4"><sup>4</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
</contrib-group><aff id="aff1"><label>1</label><addr-line>Department of Mathematical Sciences and Technology, Norwegian University of Life Sciences, Aas, Norway</addr-line>       </aff><aff id="aff2"><label>2</label><addr-line>Honda Research Institute Europe GmbH, Offenbach, Germany</addr-line>       </aff><aff id="aff3"><label>3</label><addr-line>Center for Biomedical Computing, Simula Research Laboratory, Lysaker, Norway</addr-line>       </aff><aff id="aff4"><label>4</label><addr-line>RIKEN Brain Science Institute, Wako-shi, Saitama, Japan</addr-line>       </aff><contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Friston</surname><given-names>Karl J.</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group><aff id="edit1">University College London, United Kingdom</aff><author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">hans.ekkehard.plesser@umb.no</email></corresp>
<fn fn-type="con"><p>Wrote the paper: EN M-OG HEP. Conceived the idea and approach: EN M-OG HEP. Performed the literature search: M-OG HEP. Analyzed the data: EN. </p></fn>
<fn fn-type="conflict"><p>EN and HEP are paid employees of the Norwegian University of Life Sciences. M-OG is a paid employee of Honda Research Institute Europe GmbH.</p></fn></author-notes><pub-date pub-type="collection"><month>8</month><year>2009</year></pub-date><pub-date pub-type="epub"><day>7</day><month>8</month><year>2009</year></pub-date><volume>5</volume><issue>8</issue><elocation-id>e1000456</elocation-id><history>
<date date-type="received"><day>17</day><month>3</month><year>2009</year></date>
<date date-type="accepted"><day>1</day><month>7</month><year>2009</year></date>
</history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2009</copyright-year><copyright-holder>Nordlie et al</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract>
<p>Progress in science depends on the effective exchange of ideas among scientists. New ideas can be assessed and criticized in a meaningful manner only if they are formulated precisely. This applies to simulation studies as well as to experiments and theories. But after more than 50 years of neuronal network simulations, we still lack a clear and common understanding of the role of computational models in neuroscience as well as established practices for describing network models in publications. This hinders the critical evaluation of network models as well as their re-use.</p>
<p>We analyze here 14 research papers proposing neuronal network models of different complexity and find widely varying approaches to model descriptions, with regard to both the means of description and the ordering and placement of material. We further observe great variation in the graphical representation of networks and the notation used in equations. Based on our observations, we propose a <italic>good model description practice</italic>, composed of guidelines for the organization of publications, a checklist for model descriptions, templates for tables presenting model structure, and guidelines for diagrams of networks. The main purpose of this <italic>good practice</italic> is to trigger a debate about the communication of neuronal network models in a manner comprehensible to humans, as opposed to machine-readable model description languages.</p>
<p>We believe that the <italic>good model description practice</italic> proposed here, together with a number of other recent initiatives on data-, model-, and software-sharing, may lead to a deeper and more fruitful exchange of ideas among computational neuroscientists in years to come. We further hope that work on standardized ways of describing—and thinking about—complex neuronal networks will lead the scientific community to a clearer understanding of high-level concepts in network dynamics, and will thus lead to deeper insights into the function of the brain.</p>
</abstract><abstract abstract-type="summary"><title>Author Summary</title>
<p>Scientists make precise, testable statements about their observations and models of nature. Other scientists can then evaluate these statements and attempt to reproduce or extend them. Results that cannot be reproduced will be duly criticized to arrive at better interpretations of experimental results or better models. Over time, this discourse develops our joint scientific knowledge. A crucial condition for this process is that scientists can describe their own models in a manner that is precise and comprehensible to others. We analyze in this paper how well models of neuronal networks are described in the scientific literature and conclude that the wide variety of manners in which network models are described makes it difficult to communicate models successfully. We propose a <italic>good model description practice</italic> to improve the communication of neuronal network models.</p>
</abstract><funding-group><funding-statement>EN and HEP are grateful to Honda Research Institute Europe GmbH and to the Research Council of Norway (Grant 178892/V30 eNeuro) for financial support. Honda Research Institute Europe participated in this research through the co-authorship of M-OG. The Norwegian University of Life Sciences, the Honda Research Institute Europe GmbH and the Research Council of Norway had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="18"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>Science advances human knowledge through learned discourse based on mutual criticism of ideas and observations. This discourse depends on the unambiguous specification of hypotheses and experimental procedures—otherwise any criticism could be diverted easily. Moreover, communication among scientists will be effective only if a publication evokes in a reader the same ideas as the author had in mind upon writing <xref ref-type="bibr" rid="pcbi.1000456-Gopen1">[1]</xref>.</p>
<p>Scientific disciplines have over time developed a range of abstract notations, specific terminologies and common practices for describing methods and results. These have lifted scientific discourse from handwaving arguments about sloppily ascertained observations to precise and falsifiable reasoning about facts established at a well-defined level of certainty. Well chosen notation and systematization, from Linné's classification of flora and fauna, via the periodic system of the elements to Feynman diagrams have widened the minds of scientists and continue to induce new discoveries.</p>
<p>Matrix notation provides an illustrative example of the power of notation. Consider a system of three differential equations<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000456.e001" xlink:type="simple"/><label>(1)</label></disp-formula>Defining <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000456.e002" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000456.e003" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000456.e004" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000456.e005" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000456.e006" xlink:type="simple"/></inline-formula>, etc., we can write this more compactly as<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000456.e007" xlink:type="simple"/><label>(2)</label></disp-formula>Introducing matrix notation simplifies this further to<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000456.e008" xlink:type="simple"/><label>(3)</label></disp-formula>with multiple advantages: the equation is much more compact, since the summing operation is hidden, as well as the system size; most importantly, the equation is essentially reduced to a simple multiplication. This invites further exploration.</p>
<p>From the study of one-dimensional differential equations, we know that<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000456.e009" xlink:type="simple"/><label>(4)</label></disp-formula>has the solution<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000456.e010" xlink:type="simple"/><label>(5)</label></disp-formula>Comparing the shape of Eq. 4 to Eq. 3 immediately suggests the following solution to Eq. 3<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000456.e011" xlink:type="simple"/><label>(6)</label></disp-formula>with the formal definition<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000456.e012" xlink:type="simple"/><label>(7)</label></disp-formula>This formal solution can be made rigorous, and underlies the exact integration method <xref ref-type="bibr" rid="pcbi.1000456-Rotter1">[2]</xref>. It is hard to see how the inspiration to write down a solution such as Eq. 3 might have arisen from the original form of the differential equations in Eq. 1.</p>
<p>Note that even though the notion and notation of vectors and matrices is more abstract and, thus, more compact than the original formulation of Eq. 1, it does not lose any detail. The variables <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000456.e013" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000456.e014" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000456.e015" xlink:type="simple"/></inline-formula> from the original system Eq. 1 are still present, not as separate entities, but as components of the vector <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000456.e016" xlink:type="simple"/></inline-formula>. The specific combinations of additions and multiplications are embedded in the multiplication rule for vectors. To arrive at the concise notation of Eq. 2 we must introduce the new mathematical concept of vector spaces. This example illustrates how scientific notation progresses together with scientific concepts.</p>
<p>Computational neuroscience lags behind mathematics and other fields of science in standardization, expressiveness and power of notation. We assess here the current scientific practice of describing computational models of the brain. We focus on network models built from large numbers of rather simple neurons with an aim to test hypotheses on aspects of brain function. Specifically, we study 14 papers chosen mainly from visual neuroscience <xref ref-type="bibr" rid="pcbi.1000456-Brunel1">[3]</xref>–<xref ref-type="bibr" rid="pcbi.1000456-Wielaard1">[16]</xref>; see <xref ref-type="table" rid="pcbi-1000456-t001">Table 1</xref> for a brief summary of the models. Our selection of papers is by no means comprehensive, although we have attempted to cover past as well as current work, and to include a range of different approaches to the description of neuronal network models.</p>
<table-wrap id="pcbi-1000456-t001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000456.t001</object-id><label>Table 1</label><caption>
<title>Papers analyzed in this study.</title>
</caption><!--===== Grouping alternate versions of objects =====--><alternatives><graphic id="pcbi-1000456-t001-1" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000456.t001" xlink:type="simple"/><table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" colspan="1" rowspan="1">Reference</td>
<td align="left" colspan="1" rowspan="1">Abbr.</td>
<td align="left" colspan="1" rowspan="1">Description</td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Brunel <xref ref-type="bibr" rid="pcbi.1000456-Brunel1">[3]</xref></td>
<td align="left" colspan="1" rowspan="1">B</td>
<td align="left" colspan="1" rowspan="1">Unordered network of two populations of integrate-and-fire neurons with current-injecting synapses; random external input.</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Destexhe et al. <xref ref-type="bibr" rid="pcbi.1000456-Destexhe1">[4]</xref></td>
<td align="left" colspan="1" rowspan="1">D</td>
<td align="left" colspan="1" rowspan="1">One-dimensional network with two layers of point neurons with several ionic currents and conductance based synapses.</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Haeusler and Maass <xref ref-type="bibr" rid="pcbi.1000456-Haeusler1">[5]</xref></td>
<td align="left" colspan="1" rowspan="1">HM</td>
<td align="left" colspan="1" rowspan="1">Unordered six-population model of Hodgkin-Huxley-type neurons with conductance-based synapses with short-term dynamics.</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Hayot and Tranchina <xref ref-type="bibr" rid="pcbi.1000456-Hayot1">[6]</xref></td>
<td align="left" colspan="1" rowspan="1">HT</td>
<td align="left" colspan="1" rowspan="1">Two-dimensional network with three populations of firing-rate neurons; spatiotemporally patterned input.</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Hillenbrand and van Hemmen <xref ref-type="bibr" rid="pcbi.1000456-Hillenbrand1">[7]</xref></td>
<td align="left" colspan="1" rowspan="1">HvH</td>
<td align="left" colspan="1" rowspan="1">Model of corticogeniculate loops that tests if the visual cortex controls the spatiotemporal structure of cortical receptive fields via feedback to the lateral geniculate nucleus.</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Izhikevich and Edelman <xref ref-type="bibr" rid="pcbi.1000456-Izhikevich1">[8]</xref></td>
<td align="left" colspan="1" rowspan="1">IE</td>
<td align="left" colspan="1" rowspan="1">“Whole brain” model covering several brain areas, each composed of layered two-dimensional networks of oscillator neurons with plastic, conductance-based synapses.</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Kirkland and Gerstein <xref ref-type="bibr" rid="pcbi.1000456-Kirkland1">[9]</xref></td>
<td align="left" colspan="1" rowspan="1">KG</td>
<td align="left" colspan="1" rowspan="1">Two-dimensional model of three layers of integrate-and-fire neurons with conductance-based synapses driven by spatiotemporally pattered stimuli.</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Lumer et al. <xref ref-type="bibr" rid="pcbi.1000456-Lumer1">[10]</xref></td>
<td align="left" colspan="1" rowspan="1">L</td>
<td align="left" colspan="1" rowspan="1">Two-dimensional model of ten layers, with two neuron populations per layer; integrate-and-fire neurons with conductance-based synapses.</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Mariño et al. <xref ref-type="bibr" rid="pcbi.1000456-Mario1">[11]</xref></td>
<td align="left" colspan="1" rowspan="1">M</td>
<td align="left" colspan="1" rowspan="1">Two-dimensional model of two layers of Hodgkin-Huxley-type neurons with conductance-based synapses.</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Saam and Eckhorn <xref ref-type="bibr" rid="pcbi.1000456-Saam1">[12]</xref></td>
<td align="left" colspan="1" rowspan="1">SE</td>
<td align="left" colspan="1" rowspan="1">Two-dimensional model of two layers of pulse-coding neurons.</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Tao et al. <xref ref-type="bibr" rid="pcbi.1000456-Tao1">[13]</xref></td>
<td align="left" colspan="1" rowspan="1">TA</td>
<td align="left" colspan="1" rowspan="1">Two-dimensional two-layer model of integrate-and-fire neurons with conductance based synapses.</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Troyer et al. <xref ref-type="bibr" rid="pcbi.1000456-Troyer1">[14]</xref></td>
<td align="left" colspan="1" rowspan="1">TR</td>
<td align="left" colspan="1" rowspan="1">Two-dimensional network model with two populations of conductance-based integrate-and-fire neurons.</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Vogels and Abbott <xref ref-type="bibr" rid="pcbi.1000456-Vogels1">[15]</xref></td>
<td align="left" colspan="1" rowspan="1">VA</td>
<td align="left" colspan="1" rowspan="1">Unordered and one-dimensional networks of integrate-and-fire neurons.</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Wielaard and Sajda <xref ref-type="bibr" rid="pcbi.1000456-Wielaard1">[16]</xref></td>
<td align="left" colspan="1" rowspan="1">WS</td>
<td align="left" colspan="1" rowspan="1">Two-dimensional two-layer model of integrate-and-fire neurons with conductance based synapses.</td>
</tr>
</tbody>
</table></alternatives><table-wrap-foot><fn id="nt101"><p>The table gives a brief overview of the type of model studied and assigns an abbreviation to each paper for reference in other tables.</p></fn></table-wrap-foot></table-wrap>
<p>A central motivation for our work is that sharing of materials, methods, and data in the life sciences has received increased attention in recent years, to a large part driven by developments in molecular biology. The UPSIDE (<italic>uniform principle for sharing integral data and materials expeditiously</italic>) doctrine proposed by the <italic>Committee on Responsibilities of Authorship in the Biological Sciences</italic> of the National Academies of Science (USA) defines the most comprehensive set of rules for data sharing <xref ref-type="bibr" rid="pcbi.1000456-Committee1">[17]</xref> and has been adopted by several leading journals <xref ref-type="bibr" rid="pcbi.1000456-Marshall1">[18]</xref>,<xref ref-type="bibr" rid="pcbi.1000456-Public1">[19]</xref>. Sharing of experimental data has received increasing attention in the neurosciences recently <xref ref-type="bibr" rid="pcbi.1000456-Liu1">[20]</xref>–<xref ref-type="bibr" rid="pcbi.1000456-Gardner1">[23]</xref>.</p>
<p>Sejnowski et al. <xref ref-type="bibr" rid="pcbi.1000456-Sejnowski1">[24]</xref> gave a fine account of the role of modeling in neuroscience 20 years ago, when computational neuroscience as a field just “took off”. They characterized models as “provisional framework[s] for organizing possible ways of thinking about the nervous system.” Since then, modeling activity has multiplied, but reflection about the modeling process has hardly kept up.</p>
<p>Computational neuroscientists are only now beginning to pay increasing attention to the role of models and simulations, as well as preconditions for the successful exchange of models, as witnessed by recent workshops <xref ref-type="bibr" rid="pcbi.1000456-Cannon1">[25]</xref>,<xref ref-type="bibr" rid="pcbi.1000456-Djurfeldt1">[26]</xref>, collaborative reviews of simulation software <xref ref-type="bibr" rid="pcbi.1000456-Brette1">[27]</xref>, and the development of software providing common interfaces <xref ref-type="bibr" rid="pcbi.1000456-Gleeson1">[28]</xref>,<xref ref-type="bibr" rid="pcbi.1000456-Davison1">[29]</xref> and run-time interaction of simulations on different simulators <xref ref-type="bibr" rid="pcbi.1000456-Ekeberg1">[30]</xref>. Most of these discussions have been rather technical, though, and little attention has been paid to the intellectual gain as part of the modeling process or to the issue of how to convey models and simulations best in scientific publications. Researchers in ecology, systems biology and physiome modeling appear to be significantly ahead in these issues <xref ref-type="bibr" rid="pcbi.1000456-Peck1">[31]</xref>–<xref ref-type="bibr" rid="pcbi.1000456-Nickerson1">[37]</xref>. Indeed, De Schutter <xref ref-type="bibr" rid="pcbi.1000456-DeSchutter1">[38]</xref> recently suggested that computational neuroscience has much to learn from systems biology.</p>
<sec id="s1a">
<title>The nature of neuronal network models</title>
<p>Philosophers of science have yet to develop a robust definition and interpretation of models and simulations <xref ref-type="bibr" rid="pcbi.1000456-Frigg1">[39]</xref>–<xref ref-type="bibr" rid="pcbi.1000456-Kppers1">[42]</xref>. Most of that debate focuses on models in physics, but Peck <xref ref-type="bibr" rid="pcbi.1000456-Peck1">[31]</xref> gives an interesting review of models and simulations in ecology, while Aumann <xref ref-type="bibr" rid="pcbi.1000456-Aumann1">[32]</xref> thoroughly discusses requirements of successful modeling of ecological systems; Wooley and Lin <xref ref-type="bibr" rid="pcbi.1000456-Wooley1">[43]</xref> give an overview of modeling and simulation in biology. The only comparable assessment of the role of models and simulations in computational neuroscience is part of a book chapter by Clark and Eliasmith <xref ref-type="bibr" rid="pcbi.1000456-Clark1">[44]</xref>. A recent appraisal of the role of models in neuroscience <xref ref-type="bibr" rid="pcbi.1000456-Lappi1">[45]</xref>–<xref ref-type="bibr" rid="pcbi.1000456-Rusanen1">[47]</xref>, based on a general reappraisal of the role of computational models by Humphreys <xref ref-type="bibr" rid="pcbi.1000456-Humphreys1">[48]</xref>, has mostly focused on connectionist models.</p>
<p>We shall not attempt to provide a general analysis of models and simulations in computational neuroscience here. Our aim is more practical: to promote standards for the description of neuronal network models in the literature, to further sharing of knowledge and facilitate critique. Thus, our focus is narrower yet than that of Eliasmith and Anderson <xref ref-type="bibr" rid="pcbi.1000456-Eliasmith1">[49]</xref>, Ch. 1.5, who proposed a “Methodology” of neural engineering. For our purposes, we adopt a quite restricted working definition of a model:</p>
<disp-quote>
<p> A neuronal network model is an explicit and specific hypothesis about the structure and microscopic dynamics of (a part of) the nervous system.</p>
</disp-quote>
<p>Several aspects of this definition deserve note:</p>
<list list-type="bullet"><list-item>
<p>The model must be <italic>explicit</italic>, i.e., all aspects of the model must be specified.</p>
</list-item><list-item>
<p>The model must be <italic>specific</italic>, i.e., all aspects must be defined so detailed that they can be implemented unequivocally.</p>
</list-item><list-item>
<p>The model specifies the <italic>structure</italic> (placement and type of network elements; source, target and type of connections) and <italic>dynamics of components</italic> (ion channels, membrane potential, spike generation and propagation).</p>
</list-item><list-item>
<p>The model does <italic>not</italic> describe the dynamics of the model as a whole, which is an emerging property of the model.</p>
</list-item></list>
<p>The model is first of all a mental model formed in the brain of a researcher. It is her hypothesis about the function of a part of the brain. Heinrich Hertz expressed this idea first in his textbook “Prinzipien der Mechanik” in 1894:</p>
<disp-quote>
<p>“We make for ourselves internal images or symbols of the external objects, and we make them in such a way that the consequences of the images that are necessary in thought are always images of the consequences of the depicted objects that are necessary in nature Once we have succeeded in deriving from accumulated previous experience images with the required property, we can quickly develop from them, as if from models, the consequences that in the external world will occur only over an extended period or as a result of our own intervention.” (cited from <xref ref-type="bibr" rid="pcbi.1000456-Hartmann1">[40]</xref>).</p>
</disp-quote>
<p>Scientific progress depends critically on the ability of neuroscientists to communicate models, i.e., hypotheses, among each other: When Anna presents her model to Bob and Charlie—will both build the same mental model in their minds as Anna? Or will some nuances be lost, some aspects interpreted differently, some parts misunderstood? Only a precise, unambiguous notation for models will allow Anna, Bob and Charlie to discuss their individual understandings of the model and thus to truly share models. Efficient communication dictates that scientists should use a common notation to describe their models, as it is demanding to thoroughly acquaint ourselves with any advanced notation.</p>
<p>It is tempting to consider implementations of neuronal network models in a specific simulator software as a sufficient model description, as it is explicit, specific and describes structure and dynamics. We believe this to be a fallacy. Implementations come most often in the form of scripts or computer programs, which tend to be difficult to reverse engineer: It is simply not possible to infer the overall network structure from the bits and pieces of a large script. Secondly, most simulation scripts rely on properties hidden in a simulator, which may even change as a simulator evolves over time. Translating a given implementation first to a mental model and then to a second simulator software for independent testing, opens for errors in both translation steps. We believe that while scientific productivity benefits from sharing simulation code through repositories such as ModelDB <xref ref-type="bibr" rid="pcbi.1000456-Hines1">[50]</xref> and standard languages such as NeuroML <xref ref-type="bibr" rid="pcbi.1000456-Goddard1">[51]</xref>, implementations do not fill the need for precise human-readable model descriptions in the scientific literature. Based on experiences in systems biology, Wimalaratne et al. <xref ref-type="bibr" rid="pcbi.1000456-Wimalaratne1">[36]</xref> stress that it is crucial to identify biophysical concepts as logical abstractions in order to create meaningful and re-usable model implementations.</p>
<p>It is also worth mentioning that the translation of a mathematical model into a computer program is lossy and irreversible. The translation is lossy due to the finite precisions of computers. For example, most real numbers cannot be represented on a computer. This is obviously problematic in the analysis of chaotic systems where small errors have a big influence on the state trajectories of the system. The translation is generally not reversible, because the commonly used programming languages are not accessible to formal analysis. It is generally not even possible to prove that a function, implemented in a common language such as C++, is correct. In some cases, one may even have to add equations to models in the computer implementation to preserve stability and obtain results in agreement with experimental observation <xref ref-type="bibr" rid="pcbi.1000456-Kppers1">[42]</xref>,<xref ref-type="bibr" rid="pcbi.1000456-Kppers2">[52]</xref>.</p>
<p>While mathematical model descriptions can be treated with formal methods, their computer implementations generally cannot. This means that if we want to validate the claims about a model, we must start from the description in the scientific publication. If we start from the model implementation of the authors, we can <italic>never</italic> refute that the model may be faulty or doing something entirely different than what was claimed in the publication. Taking a given implementation of a model or hypothesis and simply executing it again does <italic>not</italic> constitute independent testing, nor does it fulfill the criterion of <italic>falsifiability</italic>: the same program run twice should yield identical results.</p>
</sec></sec><sec id="s2">
<title>Methods</title>
<p>We shall now sketch key aspects of neuronal network model descriptions: what is described where and by what means in the computational neuroscience literature? This will introduce the conceptual framework for the subsequent analysis of the papers given in <xref ref-type="table" rid="pcbi-1000456-t001">Table 1</xref>.</p>
<sec id="s2a">
<title>Components of model descriptions</title>
<p>A complete model description must cover at least the following three components: (i) The <italic>network architecture</italic>, i.e., the composition of the network from areas, layers, or neuronal sub-populations. (ii) The <italic>network connectivity</italic>, describing how neurons are connected among each other in the network. In most cases, connectivity will be given as a set of rules for generating the connections. (iii) The <italic>neuron and synapse models</italic> used in the network model, usually given by differential equations for the membrane potential and synaptic currents or conductances, rules for spike generation and post-spike reset. Model descriptions should also contain information about (iv) the <italic>input (stimuli)</italic> applied to the model and (v) the <italic>data recorded</italic> from the model, just as papers in experimental neuroscience do, since a reproduction of the simulations would otherwise become impossible.</p>
</sec><sec id="s2b">
<title>Means of model descriptions</title>
<p>Neuronal network models are usually described by a combination of five means: prose (text), equations, figures, tables and pseudocode. We shall discuss these in turn.</p>
<p><italic>Prose</italic> is a powerful means of communicating ideas, intentions and reasons. It is flexible and, if used carefully, precise. Unfortunately, prose can easily—often unintentionally—become ambiguous. Previous knowledge and ideas in the mind of the reader will shape the reader's understanding of a textual description of a model and may lead to misunderstandings. Prose that strives to be strictly unambiguous and provide all required detail, on the other hand, will often be difficult to read.</p>
<p><italic>Mathematical notation (equations)</italic> is compact and unambiguous. Suitably chosen notation compresses complex relationships in concise expressions, which allow for further manipulation in our mind, as illustrated by the matrix exponentiation in the <xref ref-type="sec" rid="s1">Introduction</xref>. The now common mathematical notation emerged alongside the great scientific achievements of Newton, Leibniz and others between the 17<sup>th</sup> and 19<sup>th</sup> century <xref ref-type="bibr" rid="pcbi.1000456-Cajori1">[53]</xref>,<xref ref-type="bibr" rid="pcbi.1000456-Wikipedia1">[54]</xref>. Unfortunately, not all mathematical notation is understood easily, and variations in notation, as is common in computational neuroscience (cf. <xref ref-type="table" rid="pcbi-1000456-t002">Table 2</xref>), can present serious obstacles to effective communication.</p>
<table-wrap id="pcbi-1000456-t002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000456.t002</object-id><label>Table 2</label><caption>
<title>Membrane potential equations for some papers using conductance-based neurons.</title>
</caption><!--===== Grouping alternate versions of objects =====--><alternatives><graphic id="pcbi-1000456-t002-2" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000456.t002" xlink:type="simple"/><table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/></colgroup>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Destexhe et al. <xref ref-type="bibr" rid="pcbi.1000456-Destexhe1">[4, Eq. 2]</xref></td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000456.e017" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Lumer et al. <xref ref-type="bibr" rid="pcbi.1000456-Lumer1">[10]</xref></td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000456.e018" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Tao et al. <xref ref-type="bibr" rid="pcbi.1000456-Tao1">[13, Eq. 1]</xref></td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000456.e019" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Vogels and Abbott <xref ref-type="bibr" rid="pcbi.1000456-Vogels1">[15, Eq. 2]</xref></td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000456.e020" xlink:type="simple"/></inline-formula></td>
</tr>
</tbody>
</table></alternatives><table-wrap-foot><fn id="nt102"><label/><p>The model by Destexhe et al. is a Hodgkin-Huxley style neuron, all others are integrate-and-fire neurons.</p></fn></table-wrap-foot></table-wrap>
<p><italic>Figures</italic> communicate the architecture and connectivity of network models well, since vision is the dominating sense in most humans. Most readers will first scan the figures in a paper to get an overview of what the paper is about, using figure captions as a guide, and read the full text of the paper only later. Thus, figures and captions will shape the initial idea a reader forms about a neuronal network model, and the ideas thus established may be difficult to correct through textual description. Specifying complex networks precisely in figures can be difficult, and disciplines depending strongly on exact diagrams, such as mechanical and electrical engineering, have developed precise standards for such diagrams (see, e.g., <xref ref-type="bibr" rid="pcbi.1000456-Shannon1">[55]</xref>). Systems biologists have yet to arrive at a definite standard for depicting their models, but they at least have an open debate about graphical representations <xref ref-type="bibr" rid="pcbi.1000456-Kohn1">[56]</xref>–<xref ref-type="bibr" rid="pcbi.1000456-Blinov1">[59]</xref>.</p>
<p><italic>Tables</italic> are a useful means of organizing data, especially model parameters. Data presented in table form is far more accessible than data dispersed throughout a text, facilitating, e.g., comparisons of parameter choices between different papers and proof-reading of simulation scripts against papers.</p>
<p><italic>Pseudocode</italic> is often used to present algorithms in concise, human readable form, without resorting to a specific programming language. It will be an efficient means of communication only if the pseudocode notation is sufficiently well established to be unambiguous.</p>
</sec><sec id="s2c">
<title>Placement of model descriptions</title>
<p>The placement of model descriptions within a scientific publication depends on the focus of the paper and the journal it is published in. Traditionally, model descriptions were either given in the <italic>body text</italic> of a paper, or in an <italic>appendix</italic>. It has now become common to give only brief model overviews in the paper itself, and to relegate detailed model descriptions to <italic>supplementary material</italic> published online, or even to place simulation code online in community <italic>repositories</italic> such as ModelDB.</p>
</sec></sec><sec id="s3">
<title>Results</title>
<p>We will now analyze model descriptions in the 14 papers listed in <xref ref-type="table" rid="pcbi-1000456-t001">Table 1</xref>. We study the placement of model descriptions in publications first, followed by a general discussion of the means of description used. We will then investigate in more detail how specific aspects of models are described. Finally, we propose a <italic>good model description practice</italic>.</p>
<sec id="s3a">
<title>Placement of description</title>
<p><xref ref-type="fig" rid="pcbi-1000456-g001">Figure 1</xref> summarizes the placement of the description of architecture, connectivity and neuron and synapse models, respectively, across all papers; for details, see <xref ref-type="supplementary-material" rid="pcbi.1000456.s001">Tables S1</xref>, <xref ref-type="supplementary-material" rid="pcbi.1000456.s002">S2</xref> and <xref ref-type="supplementary-material" rid="pcbi.1000456.s003">S3</xref> in the Supporting files. All papers present at least an overview of the model they investigate in the main body of the paper. Details are frequently provided in supplementary material available online, especially in more recent papers; appendices are used to a lesser degree. Model descriptions in some papers are incomplete in the sense that the authors refer to other publications for details of neuronal dynamics in particular.</p>
<fig id="pcbi-1000456-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000456.g001</object-id><label>Figure 1</label><caption>
<title>Placement of description in papers surveyed.</title>
<p>Bar graphs show the percentage of papers describing (from top to bottom) model architecture, model connectivity and neuronal dynamics in the body text of the paper, the appendix, and in supplementary material. Many papers spread descriptions over several locations and are thus counted in several categories. For detailed data, see supporting material <xref ref-type="supplementary-material" rid="pcbi.1000456.s001">Tables S1</xref>, <xref ref-type="supplementary-material" rid="pcbi.1000456.s002">S2</xref> and <xref ref-type="supplementary-material" rid="pcbi.1000456.s003">S3</xref>.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000456.g001" xlink:type="simple"/></fig>
<p>Within the body text of the paper, model descriptions were placed in the “Methods” sections in 10 of the 14 papers surveyed, even though the neuronal network model is in itself a product of significant scientific analysis and synthesis <xref ref-type="bibr" rid="pcbi.1000456-Aumann1">[32]</xref>. As such, it would rather belong in the “Results” section of a paper. Whether the placement of the model description in the “Methods” section genuinely reflects the way in which authors perceive their models, or rather is a consequence of editorial policies shaped by “wet” neuroscience, is not clear at present. It is interesting to note in this context that papers in theoretical physics generally do not follow the strict “methods-results-discussion” pattern.</p>
<p>We would like to point out two interesting aspects of the placement of model descriptions. First, the text of a paper manuscript, including the appendix, undergoes thorough peer review and copy editing, ensuring high standards in content and presentation. It is not, at present, clear whether all material published as supplementary material receives the same scrutiny in the review process; it is often not copy-edited to the same standards as the paper proper. Second, source code published in community repositories represents an implementation of a model, not the model itself <xref ref-type="bibr" rid="pcbi.1000456-Kppers2">[52]</xref>. It can thus serve only as a service to the community to facilitate code-reuse, but not to communicate the content of the model proper.</p>
<p>Incidentally, none of the 14 papers surveyed here describes re-use of neuronal models available in repositories, such as ModelDB <xref ref-type="bibr" rid="pcbi.1000456-Hines1">[50]</xref>. Nor does any paper mention that the source code for the model implemented in the paper was made available to the community, even though models from several papers are at present available from ModelDB <xref ref-type="bibr" rid="pcbi.1000456-Destexhe1">[4]</xref>,<xref ref-type="bibr" rid="pcbi.1000456-Haeusler1">[5]</xref>,<xref ref-type="bibr" rid="pcbi.1000456-Vogels1">[15]</xref>. In recent years, though, there appears to be a slowly growing trend to explicitly reference and re-use existing models from ModelDB; see <ext-link ext-link-type="uri" xlink:href="http://senselab.med.yale.edu/modeldb/prm.asp" xlink:type="simple">http://senselab.med.yale.edu/modeldb/prm.asp</ext-link> for an up-to-date list (Michael Hines, personal communication).</p>
</sec><sec id="s3b">
<title>Means of model descriptions</title>
<p><xref ref-type="fig" rid="pcbi-1000456-g002">Figure 2</xref> shows that equations are mostly used to describe the dynamics of model neurons, while connections are most often presented in a combination of prose and figures, occasionally in form of pseudocode. We will review the quality of these descriptions in detail below. <xref ref-type="table" rid="pcbi-1000456-t003">Table 3</xref> shows how parameters are presented in papers. It regrettably indicates that too few authors make parameters easily accessible in tables.</p>
<fig id="pcbi-1000456-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000456.g002</object-id><label>Figure 2</label><caption>
<title>Use of different means of description in papers surveyed.</title>
<p>Bar graphs show the percentage of papers describing (from top to bottom) model architecture, model connectivity and neuronal dynamics using prose, equations, figures, tables, and references. Many papers combine several means for one purpose and are thus counted in several categories. For detailed data, see supporting material <xref ref-type="supplementary-material" rid="pcbi.1000456.s001">Tables S1</xref>, <xref ref-type="supplementary-material" rid="pcbi.1000456.s002">S2</xref>, <xref ref-type="supplementary-material" rid="pcbi.1000456.s003">S3</xref>.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000456.g002" xlink:type="simple"/></fig><table-wrap id="pcbi-1000456-t003" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000456.t003</object-id><label>Table 3</label><caption>
<title>Presentation of parameters.</title>
</caption><!--===== Grouping alternate versions of objects =====--><alternatives><graphic id="pcbi-1000456-t003-3" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000456.t003" xlink:type="simple"/><table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" colspan="1" rowspan="1">All</td>
<td align="left" colspan="1" rowspan="1">Most</td>
<td align="left" colspan="1" rowspan="1">Some</td>
<td align="left" colspan="1" rowspan="1">None</td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">—</td>
<td align="left" colspan="1" rowspan="1">IE, KG, L, SE</td>
<td align="left" colspan="1" rowspan="1">HM</td>
<td align="left" colspan="1" rowspan="1">B, D, HT, HvH, M, TA, TR, VA, WS</td>
</tr>
</tbody>
</table></alternatives><table-wrap-foot><fn id="nt103"><label/><p>The table shows the papers presenting all, most, some or none of their parameters in tables. See <xref ref-type="table" rid="pcbi-1000456-t001">Table 1</xref> for paper abbreviations.</p></fn></table-wrap-foot></table-wrap>
<p>Network model descriptions in the literature show no consistent order of description. Among the papers surveyed here, six begin with a description of the neuron models and then proceed to network architecture, seven papers use the opposite order, while one paper mixes the description of neurons and network. We find the latter option least useful to the reader.</p>
<p>Authors differ greatly in their efforts to anchor their models in empirical data. Destexhe et al. <xref ref-type="bibr" rid="pcbi.1000456-Destexhe1">[4]</xref> go to great lengths to justify the design of their neuron and synapse models with respect to the neurophysiological literature. They thus provide the <italic>synthesis document</italic> proposed by Aumann <xref ref-type="bibr" rid="pcbi.1000456-Aumann1">[32]</xref> as the basis of any modeling effort. Unfortunately for those readers who want to investigate the resulting model, though, model description and justification are tightly intertwined in the terse methods section, making it quite demanding to extract the model description as such.</p>
<p>Among all papers surveyed here, only Destexhe et al. <xref ref-type="bibr" rid="pcbi.1000456-Destexhe1">[4]</xref> and Izhikevich and Edelman <xref ref-type="bibr" rid="pcbi.1000456-Izhikevich1">[8]</xref> show responses of individual synaptic conductances and individual neurons to test stimuli, while all other authors only show responses of the entire network. This means that researchers who attempt to re-implement a model and find themselves unable to reproduce the results from a paper, will not be able to find out whether problems arise from neuron model implementations or from a wrong network setup.</p>
<p>We will now analyze in detail which difficulties arise in describing a network model, considering in turn network architecture, connectivity, and neuron models, and point out examples of good descriptions.</p>
</sec><sec id="s3c">
<title>Network architecture</title>
<p>Descriptions of network architecture become challenging as network complexity increases. Networks with a small number of populations, random connectivity and no spatial structure are easily described in a few lines of prose, as in Brunel's paper <xref ref-type="bibr" rid="pcbi.1000456-Brunel1">[3]</xref>. A combination of prose and simple figures is usually sufficient to describe architecture of networks composed from a small number of one- or two-dimensional layers of individual neurons; examples are Destexhe et al. <xref ref-type="bibr" rid="pcbi.1000456-Destexhe1">[4]</xref> and Kirkland and Gerstein <xref ref-type="bibr" rid="pcbi.1000456-Kirkland1">[9]</xref>.</p>
<p>Complex models spanning several brain areas with detailed spatial, layered, and functional substructure, such as Lumer et al. <xref ref-type="bibr" rid="pcbi.1000456-Lumer1">[10]</xref> and Izhikevich and Edelman <xref ref-type="bibr" rid="pcbi.1000456-Izhikevich1">[8]</xref>, are more challenging to describe. Authors generally adopt a top-down approach, giving first an overview of the brain areas involved, before detailing the structure of the individual areas. In models of systems with clearly defined signal flow, areas are often visited in the predominant order of signal flow <xref ref-type="bibr" rid="pcbi.1000456-Hayot1">[6]</xref>,<xref ref-type="bibr" rid="pcbi.1000456-Hillenbrand1">[7]</xref>,<xref ref-type="bibr" rid="pcbi.1000456-Troyer1">[14]</xref>, while others present the more complex cortical structures before descending to subcortical structures <xref ref-type="bibr" rid="pcbi.1000456-Izhikevich1">[8]</xref>,<xref ref-type="bibr" rid="pcbi.1000456-Lumer1">[10]</xref>.</p>
<p>The most detailed explicit model studied here is the thalamocortical model presented by Lumer et al. <xref ref-type="bibr" rid="pcbi.1000456-Lumer1">[10]</xref>. The description of the cortical areas in this model (Vp and Vs), while complete, lacks in our opinion the clarity desirable of a good model description, and may thus help to identify rules for ideal model descriptions. For one, discussions on model design and properties are embedded in the model description, e.g., the reduction of a total of 32 “combinations of response selectivities” to just two included in the model, and a comparison of the number of neurons in the model to that found in animals. We believe that design decisions and model review should be kept separate from the model description proper for the sake of clarity, since they are independent intellectual endeavours <xref ref-type="bibr" rid="pcbi.1000456-Aumann1">[32]</xref>. Second, Lumer et al. mix different views of their layer architecture without providing sufficient guidance to the reader. They begin by describing the Vp layer as a grid of 8×8 macro-units, with two “selectivities within a macro-unit”, each containing “a collection of 5×5 topographic elements, each of which corresponded to a contiguous location in retinal space”, before proceeding to state that “[t]opographic elements in Vp were organized in maps of 40×40 elements for each of the two modeled orientation selectivities.” We find it difficult to interpret this description unambiguously. We are in particular in doubt about the localization of macro-units and topographic elements in retinal space. In our view, the most parsimonious interpretation is as follows: 5×5 topographic elements placed in each of 8×8 macro-units result in a grid of 40×40 topographic elements.” This interpretation is sketched in <xref ref-type="fig" rid="pcbi-1000456-g003">Fig. 3</xref>.</p>
<fig id="pcbi-1000456-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000456.g003</object-id><label>Figure 3</label><caption>
<title>Interpretation of Lumer <xref ref-type="bibr" rid="pcbi.1000456-Lumer1">[10]</xref> model architecture.</title>
<p>The most parsimonious interpretation of the description of the primary visual cortical area Vp given by Lumer <italic>et al</italic>, is as two layers of 40×40 topographic elements, representing horizontal and vertical orientations, respectively.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000456.g003" xlink:type="simple"/></fig>
<p>Another interesting aspect is that model composition is often described from a perspective orthogonal to the description of connections. Lumer et al. <xref ref-type="bibr" rid="pcbi.1000456-Lumer1">[10]</xref>, e.g., present the primary thalamus and cortex as grids of 40×40 topographical units, each containing an excitatory and an inhibitory neuron (thalamus) and a microcolumn composed of 10 neurons organized in three laminae (cortex). Connections are then described by looking at this architecture from an orthogonal perspective: Thalamus is described as two layers, one of excitatory and one of inhibitory neurons, while cortex is split into six layers, one of excitatory and one of inhibitory neurons for each of the three laminae in the model. We believe that it may be more sensible to base the model description on the perspective used in defining connections, as connectivity is the central aspect of a network model.</p>
<p>Izhikevich and Edelman <xref ref-type="bibr" rid="pcbi.1000456-Izhikevich1">[8]</xref> present a significantly more complex model, covering the entire human cortex and thalamus. Concerning the spatial placement, they only state that “[n]euronal bodies are allocated randomly on the cortical surface, whose coordinates were obtained from anatomical MRI.” No further information is given on how MRI measurements were converted to neuron densities in space. Thus, even if one had access to MRI data of the human brain, it would be difficult to reproduce the neuron distribution investigated by Izhikevich and Edelman. In such cases it would be advantageous to either use datasets available from community databases or to make data available to others.</p>
<p>Figures of network architecture vary widely between papers. We will discuss them in the following section together with connections.</p>
</sec><sec id="s3d">
<title>Connections</title>
<p>Describing the connections well is the most challenging task in presenting a neuronal network model. For networks with random connections and no spatial structure, connectivity is easily described in a few sentences <xref ref-type="bibr" rid="pcbi.1000456-Brunel1">[3]</xref>. Haeusler and Maass <xref ref-type="bibr" rid="pcbi.1000456-Haeusler1">[5]</xref> additionally represent connection strengths and probabilities in a figure; this works well for their six-population model. If yet more populations were involved, such a figure would soon become cluttered, and it becomes more useful to present connection parameters in tables , cf. supplementary material in ref. <xref ref-type="bibr" rid="pcbi.1000456-Izhikevich1">[8]</xref>. Even in these simple networks, care must be taken to specify details:</p>
<list list-type="bullet"><list-item>
<p>May neurons connect to themselves?</p>
</list-item><list-item>
<p>May there be multiple connections between any pair of neurons?</p>
</list-item><list-item>
<p>Are connection targets chosen at random for a fixed sender neuron (divergent connection), senders chosen at random for fixed target (convergent connection), or are sender and receiver chosen at random for each connection?</p>
</list-item></list>
<p>Few authors are explicit on all these points, although these choices may have significant consequences for network dynamics (Tom Tetzlaff, personal communication; see also Kriener et al. <xref ref-type="bibr" rid="pcbi.1000456-Kriener1">[60]</xref>).</p>
<p>Models incorporating spatial structure have more complex connection patterns, which we will call <italic>topographic</italic> connections, since they usually describe the spatial distribution of connection targets relative to the spatial location of the sending neuron, i.e., connections are typically described as divergent connections. In most cases, connections have a random component: they are created with a certain probability. In simple cases, such as Kirkland and Gerstein <xref ref-type="bibr" rid="pcbi.1000456-Kirkland1">[9]</xref>, connections are made to neurons in a rectangular mask with equal probability. In more complex models, connection probability depends on the relative locations of the neurons that are candidates for a connection, e.g., <xref ref-type="bibr" rid="pcbi.1000456-Lumer1">[10]</xref>,<xref ref-type="bibr" rid="pcbi.1000456-Mario1">[11]</xref>. Unfortunately, few authors provide the equations for these probability functions; Mariño et al. <xref ref-type="bibr" rid="pcbi.1000456-Mario1">[11]</xref> is a laudable exception. It is somewhat paradoxical if papers present long tables of parameters for these connection probability functions, but do not provide the equation into which these parameters enter.</p>
<p>Mariño et al. <xref ref-type="bibr" rid="pcbi.1000456-Mario1">[11]</xref> are the only authors who explicitly discuss self-connections (in their supplementary material), and as far as we can see, no authors have discussed whether multiple connections between any two neurons may be created. Another neglected issue is precisely how probabilistic connections are created. The following approach seems to be implied: For each pair of neurons from the sender and target population, a connection is created if a random number is smaller than the connection probability for the pair. But one might equally well determine the total number of connections to be made first, and then distribute the connections according to the spatial probability profile <xref ref-type="bibr" rid="pcbi.1000456-Potjans1">[61]</xref>. Such schemes offer significant performance gains <xref ref-type="bibr" rid="pcbi.1000456-Plesser1">[62]</xref>. A complete specification of the connection algorithm should thus be given.</p>
<p>Among the papers surveyed, Izhikevich and Edelman <xref ref-type="bibr" rid="pcbi.1000456-Izhikevich1">[8]</xref> has by far the most complex connectivity and the authors go to great lengths to present gray-matter connectivity in figures, tables, and prose. Alas, some information appears to be missing: It is not clear from the text exactly how connections are distributed within the axonal spans, and how they are distributed across dendritic compartments of neurons with more than one compartment in a cortical layer. We have also been unable to find specific information on how synaptic weights and delays were assigned to connections. Finally, no details are provided about the white-matter (long-range) connections, which were based on diffusion-tensor imaging (DTI) data. Without access to the DTI data it is thus impossible to re-implement the model presented.</p>
<p>Paper authors draw network diagrams in quite different ways, both in the overall style of their diagrams and in use of symbols. <xref ref-type="fig" rid="pcbi-1000456-g004">Figure 4</xref> shows network diagrams of a model loosely based on Einevoll and Plesser <xref ref-type="bibr" rid="pcbi.1000456-Einevoll1">[63]</xref>, Fig. 3, drawn in the style of three of the papers surveyed here. The diagram in the style of Hayot and Tranchina <xref ref-type="bibr" rid="pcbi.1000456-Hayot1">[6]</xref> (<xref ref-type="fig" rid="pcbi-1000456-g004">Fig. 4A</xref>) gives a reduced but clear overview of the overall architecture of the model; it provides no details. The style of Haeusler and Maass <xref ref-type="bibr" rid="pcbi.1000456-Haeusler1">[5]</xref> (<xref ref-type="fig" rid="pcbi-1000456-g004">Fig. 4B</xref>) carries most information, with weights and probabilities shown next to connection lines, and line widths proportional to the product of weight and probability. <xref ref-type="fig" rid="pcbi-1000456-g004">Figure 4C</xref>, which imitates the style of Lumer et al. <xref ref-type="bibr" rid="pcbi.1000456-Lumer1">[10]</xref>, is rather illustrative: it provides no quantitative information and the structure of the connectivity is less prominent than in the other two figures; on the other hand, it is the only figure hinting at the spatial structure of the network. Interestingly, all three diagram styles use different ways of marking excitatory and inhibitory connections: bars vs circles, black vs red, and arrows vs bars. Indeed, bars at the end of connection lines mark excitatory connections in Hayot and Tranchina's style, but inhibitory connections in the style of Lumer et al, nicely illustrating the lack of standards in the field.</p>
<fig id="pcbi-1000456-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000456.g004</object-id><label>Figure 4</label><caption>
<title>Diagram styles for network models.</title>
<p>Diagrams of a model of the thalamocortical pathway drawn using diagram styles from (A) Hayot and Tranchina <xref ref-type="bibr" rid="pcbi.1000456-Hayot1">[6]</xref>, Fig. 2, (B) Haeusler and Maass <xref ref-type="bibr" rid="pcbi.1000456-Haeusler1">[5]</xref>, Fig. 1, and (C) Lumer et al. <xref ref-type="bibr" rid="pcbi.1000456-Lumer1">[10]</xref>, Fig. 1. Numbers on arrows in B mark connection weight and probability of connection, while line width represents the product of the two. In C, open circles show excitatory, filled circles inhibitory neurons. The model depicted is loosely based on Einevoll and Plesser <xref ref-type="bibr" rid="pcbi.1000456-Einevoll1">[63, Fig. 3]</xref>, but the differentiation into two cortical layers, each with excitatory and inhibitory subpopulations, in B and C, as well as the connection weights and probabilities, have been added here for the purpose of illustration.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000456.g004" xlink:type="simple"/></fig>
<p>Izhikevich and Edelman <xref ref-type="bibr" rid="pcbi.1000456-Izhikevich1">[8]</xref> have illustrated their brain model using diagrams presenting significantly more detail than in the diagrams shown in our <xref ref-type="fig" rid="pcbi-1000456-g004">Fig. 4</xref>. Unfortunately, we cannot reproduce Figures 2 and 8 from the supplementary material of the paper by Izhikevich and Edelman here due to copyright issues; the figures are available on the internet at <ext-link ext-link-type="uri" xlink:href="http://www.pnas.org/content/105/9/3593.figures-only" xlink:type="simple">http://www.pnas.org/content/105/9/3593.figures-only</ext-link> and <ext-link ext-link-type="uri" xlink:href="http://www.pnas.org/content/105/9/3593/suppl/DC1" xlink:type="simple">http://www.pnas.org/content/105/9/3593/suppl/DC1</ext-link>, respectively. Their diagrams, though, provide so much detail of interest to the re-implementer, that the reader will have difficulty to form a clear conceptual model from the diagram. This is in many ways the curse of complex models as the following analogy may illustrate: when a physicist or electrical engineer sees a diagram of an RLC circuit, she will intuitively “see” the circuit oscillate. When presented with the complete wiring diagram for a modern analog radio receiver, though, it is hardly likely she will “hear the music”. The figure in the style of Haeusler and Maass <xref ref-type="bibr" rid="pcbi.1000456-Haeusler1">[5]</xref> takes a middle ground. Since the individual populations are homogeneous, they can be represented by one circle each, with annotated lines providing information about connection structure <italic>and</italic> parameters. By marking connection strength through line width and differentiating excitation and inhibition by line color, the figure appeals quite directly to our intuition. It is clear, though, that any further populations would increase the complexity of the diagram to the point of illegibility.</p>
<p>There is no established standard for the order in which connections within a network are described. Some authors proceed from local connectivity (e.g., intracortical intralaminar) towards global connectivity <xref ref-type="bibr" rid="pcbi.1000456-Lumer1">[10]</xref>. Others rather follow the signal flow through the network, from retina via LGN to cortex, e.g., Kirkland and Gerstein <xref ref-type="bibr" rid="pcbi.1000456-Kirkland1">[9]</xref>, Hayot and Tranchina <xref ref-type="bibr" rid="pcbi.1000456-Hayot1">[6]</xref>, and Troyer et al. <xref ref-type="bibr" rid="pcbi.1000456-Troyer1">[14]</xref>.</p>
</sec><sec id="s3e">
<title>Neuron and synapse models</title>
<p>Neuron and synapse models are commonly described by a mixture of prose and equations, cf. <xref ref-type="fig" rid="pcbi-1000456-g002">Fig. 2</xref>; tables are used inconsistently to present parameters, see <xref ref-type="table" rid="pcbi-1000456-t003">Table 3</xref>. Some authors do not provide complete model specifications in their paper, but rely heavily <xref ref-type="bibr" rid="pcbi.1000456-Destexhe1">[4]</xref> or even entirely <xref ref-type="bibr" rid="pcbi.1000456-Haeusler1">[5]</xref> on references to earlier work. While the desire to avoid repetition is understandable, we believe that authors here walk a thin line toward incomprehensibility, especially if the models used are spread over three or more publications. Even though the re-use of neuron model implementations provided in repositories such as ModelDB may save effort and contribute to a standardization in the field, none of the papers we studied made use of available model implementations—or the authors failed to point out that they did.</p>
<p><xref ref-type="table" rid="pcbi-1000456-t002">Table 2</xref> shows the membrane potential equations found in several papers and demonstrates that there is a reasonable amount of variation in the way this central equation is written down. There is in particular no widespread agreement on whether to include the membrane capacitance <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000456.e021" xlink:type="simple"/></inline-formula> explicitly in the equation or rather to subsume it in a membrane time constant <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000456.e022" xlink:type="simple"/></inline-formula>. Some authors, such as Tao et al. <xref ref-type="bibr" rid="pcbi.1000456-Tao1">[13]</xref>, even chose to normalize the membrane potential equation by defining <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000456.e023" xlink:type="simple"/></inline-formula>. Yet greater variation is found in the representation of synaptic currents. This means that phrases such as “we use the standard equations for integrate-and-fire neurons”, which are not uncommon in the literature, are essentially meaningless, since there are no established “standard equations” for integrate-and-fire neurons.</p>
<p>Spike generation and detection, including subsequent reset and refractory behavior, are usually described in prose, sometimes with interspersed equations. “<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000456.e024" xlink:type="simple"/></inline-formula> was reset to … <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000456.e025" xlink:type="simple"/></inline-formula>, when it exceeded a threshold of … −51 mV …, at which point a spike was recorded, and relayed …,” is a typical formulation <xref ref-type="bibr" rid="pcbi.1000456-Lumer1">[10]</xref>. Unfortunately, it does not state precisely how threshold crossings are detected, which times are assigned to spikes, or when exactly the reset is executed. All these issues can have significant consequences for network dynamics <xref ref-type="bibr" rid="pcbi.1000456-Hansel1">[64]</xref>–<xref ref-type="bibr" rid="pcbi.1000456-Morrison2">[66]</xref>.</p>
</sec><sec id="s3f">
<title>Good model description practice: a proposal</title>
<p>The previous sections have documented a wide variety of approaches to model descriptions in the literature. We believe that this variety is detrimental to the field, as it makes it difficult to communicate neuronal network models correctly and efficiently. At the same time, we believe that the field of computational neuroscience is too young to establish exacting standards for model descriptions. We will return to this problem and its various causes in the <xref ref-type="sec" rid="s4">discussion</xref>. As a middle road, we propose to establish a <italic>good model description practice</italic> for the scientific literature. We will refer to it as “good practice” below for brevity. Some of our suggestions are motivated by a recent analysis of modeling techniques in ecology <xref ref-type="bibr" rid="pcbi.1000456-Aumann1">[32]</xref>, but see also <xref ref-type="bibr" rid="pcbi.1000456-Eliasmith1">[49]</xref>.</p>
<p>We propose a practice with the following elements:</p>
<list list-type="order"><list-item>
<p><italic>Guidelines for the organization</italic> of a model description in a publication.</p>
</list-item><list-item>
<p><italic>Checklists for model descriptions</italic> helping authors to present all required information in a useful order.</p>
</list-item><list-item>
<p><italic>Templates for tables</italic> describing the essential aspects and components of a model in a compact, easily accessible manner.</p>
</list-item><list-item>
<p><italic>Guidelines for diagrams</italic> visualizing neuronal network models.</p>
</list-item></list>
<p>We will discuss these elements in turn below, followed by more detailed discussions about how to render specific aspects of a network model. As an illustrative example, <xref ref-type="fig" rid="pcbi-1000456-g005">Figures 5</xref> and <xref ref-type="fig" rid="pcbi-1000456-g006">6</xref> provide a concise description of the Brunel <xref ref-type="bibr" rid="pcbi.1000456-Brunel1">[3]</xref> model following the good practice format. A similar description of the Lumer et al. <xref ref-type="bibr" rid="pcbi.1000456-Lumer1">[10]</xref> model is given in <xref ref-type="fig" rid="pcbi-1000456-g007">Figures 7</xref>–<xref ref-type="fig" rid="pcbi-1000456-g008"/><xref ref-type="fig" rid="pcbi-1000456-g009">9</xref>.</p>
<fig id="pcbi-1000456-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000456.g005</object-id><label>Figure 5</label><caption>
<title>Tabular description of Brunel model <xref ref-type="bibr" rid="pcbi.1000456-Brunel1">[3]</xref>.</title>
<p> The model is summarized in panel A and detailed in panels B–F.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000456.g005" xlink:type="simple"/></fig><fig id="pcbi-1000456-g006" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000456.g006</object-id><label>Figure 6</label><caption>
<title>Alternatives for diagrams of simple network models (Brunel <xref ref-type="bibr" rid="pcbi.1000456-Lumer1">[10]</xref>).</title>
<p>(A) Excitatory connections shown by full lines, inhibitory by dashed lines. Lines beginning with open semicircle and ending in filled circle indicate random convergent connections. (B) Double lines represent multiple connections, solid/dashed marks excitatory/inhibitory connections. Multiplicity of connections marked at line ends. (C) Same as B, but inhibitory connections marked with circles on target side instead of dashed lines. (D) Same as C, but displaying explicitly that there are <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000456.e026" xlink:type="simple"/></inline-formula> external Poisson inputs (PG) to each neuron, and single lines are used instead of double lines.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000456.g006" xlink:type="simple"/></fig><fig id="pcbi-1000456-g007" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000456.g007</object-id><label>Figure 7</label><caption>
<title>Tabular description of Lumer et al. model <xref ref-type="bibr" rid="pcbi.1000456-Lumer1">[10]</xref>, part 1.</title>
<p>The model is summarized in panel A and detailed in panels B–I. See <xref ref-type="fig" rid="pcbi-1000456-g008">Figure 8</xref> for panels E–I.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000456.g007" xlink:type="simple"/></fig><fig id="pcbi-1000456-g008" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000456.g008</object-id><label>Figure 8</label><caption>
<title>Tabular description Lumer et al. model <xref ref-type="bibr" rid="pcbi.1000456-Lumer1">[10]</xref>, part 2.</title>
<p>See <xref ref-type="fig" rid="pcbi-1000456-g007">Figure 7</xref> for panels A–D.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000456.g008" xlink:type="simple"/></fig><fig id="pcbi-1000456-g009" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000456.g009</object-id><label>Figure 9</label><caption>
<title>Hierarchy of diagrams of a complex network model (Lumer et al. <xref ref-type="bibr" rid="pcbi.1000456-Lumer1">[10]</xref>).</title>
<p>(A) Overview diagram of connectivity between high-level populations. Excitatory connections are marked by arrows, inhibitory connections by circles. Excitatory and inhibitory populations have been lumped in Tp, while Vp(v) and Vp(h) are composed of three layers of excitatory and inhibitory populations, as detailed in B. (B) Detailed diagram of connectivity within cortical population Vp(v), which is tuned to vertically oriented stimuli. Vp(v) is composed of three cortical layers, each with an excitatory (left) and inhibitory (right) subpopulation. Filled arrows mark excitatory, open circles inhibitory connections. Connections to and from corresponding horizontally tuned cortical populations in Vp(h) are shown as dashed lines; black lines show input from the thalamus. Connections to and from higher cortical areas are not shown. (C) Detailed rendition of connection masks and kernels projecting onto one cortical subpopulation Vp(v)LI(e) from panel B, i.e., the excitatory subpopulation of the infragranular layer of Vp(v). Squares show projection masks, gray shade the probability of a connection (black: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000456.e027" xlink:type="simple"/></inline-formula>). Connections are created by centering the mask about each location in the layer and drawing connections according to the probability distribution. Outgoing arrows indicate projections to other populations. Projection masks are scaled down in size to fit all projections into the layer, and grayscales have been adjusted for visibility. Connections are placed to correspond to the layout of panel B: Connections to and from thalamus are at the bottom, connections to and from Vp(v)LI(i) and Vp(h) to the right and connections to and from Vp(v)LS and Vp(v)L4 at the top.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000456.g009" xlink:type="simple"/></fig>
<p>We would like to stress that we present the good practice here to stimulate the debate on model descriptions within the computational neuroscience community. If it is adopted widely throughout the community, it will provide numerous advantages: authors will have guidelines that will allow them to check their descriptions for completeness and unambiguousness; referees will more easily be able to assess the correctness and quality of a model; and readers will find it easier to comprehend and re-implement a model, and to compare different models.</p>
<sec id="s3f1">
<title>Guidelines for organization</title>
<p>Many journals require authors to organize their manuscript into the sections <italic>Introduction</italic>, <italic>Results</italic>, <italic>Methods</italic>, and <italic>Discussion</italic> and the question arises how modeling papers fit into this framework. We believe that this organization is also appropriate for modeling papers if the meaning of the individual section headings are carefully observed.</p>
<p>Generally, a publication on a computational modeling study should provide the following information:</p>
<list list-type="order"><list-item>
<p><italic>Hypothesis:</italic> a concrete description of the question or problem that the model addresses;</p>
</list-item><list-item>
<p><italic>Model derivation:</italic> a presentation of experimental data that support your hypothesis, your model, or both;</p>
</list-item><list-item>
<p><italic>Model description:</italic> a description of your model, its inputs (stimuli), and its outputs (measured quantities) and all free parameters, according to the good practice proposed below;</p>
</list-item><list-item>
<p><italic>Implementation:</italic> a concise description of the methods used to implement and simulate the model (e.g., details of spike threshold detection, assignment of spike times, time resolution, etc.), as well as a description of all third party tools used, such as simulation software or mathematical packages;</p>
</list-item><list-item>
<p><italic>Model analysis:</italic> a description of all analytical and numerical experiments performed on the model, and the results obtained;</p>
</list-item><list-item>
<p><italic>Model justification:</italic> a presentation of all empirical or theoretical results from the literature that support the results obtained from your model and that were not used to derive the model.</p>
</list-item></list>
<p>We suggest that authors organize their presentation according to these six points where possible. When publishing in a journal that requires a traditional organization of manuscripts into <italic>Introduction</italic>, <italic>Results</italic>, <italic>Methods</italic>, and <italic>Discussion</italic>, we recommend the following structure:</p>
<list list-type="order"><list-item>
<p><italic>Introduction</italic>                       <list list-type="alpha-lower"><list-item>
<p><italic>Hypothesis</italic></p>
</list-item><list-item>
<p><italic>Model derivation</italic></p>
</list-item></list>                   </p>
</list-item><list-item>
<p><italic>Results</italic>                       <list list-type="alpha-lower"><list-item>
<p><italic>Model description</italic></p>
</list-item><list-item>
<p><italic>Model analysis</italic></p>
</list-item></list>                   </p>
</list-item><list-item>
<p><italic>Methods</italic>                       <list list-type="alpha-lower"><list-item>
<p><italic>Implementation</italic></p>
</list-item></list>                   </p>
</list-item><list-item>
<p><italic>Discussion</italic>                       <list list-type="alpha-lower"><list-item>
<p><italic>Model justification</italic></p>
</list-item></list>                   </p>
</list-item></list>
<p>The paper should be written such that readers who are not interested in model derivation and implementation can skip these sections to proceed directly from the model description to the analysis.</p>
<p>Many journals impose strict limits on the length of a paper, making it impossible to provide a full model description along with an elaborate model analysis. In this case, authors should consider to split their manuscript in two (or more) separate manuscripts: One describing the model, and the other describing the model analysis. The model paper should include the full description of the model but with the model analysis section reduced to only that information which is needed to validate the model and its implementation. In the analysis paper, authors can cite the model paper and reduce the model description to a brief outline of the model, using the tables proposed below. This should offer sufficient room to include a full account of the model analysis.</p>
<p>Where a companion paper is infeasible, authors should provide a detailed model description as online supplementary materials, although we see two disadvantages in this case: (i) Supplementary material might not be peer-reviewed according to the same high standards as a separate model paper. (ii) Hiding the model in supplementary material deprives both author and model of the proper credit for the intellectual effort that went into the creation of the model.</p>
<p>Authors should be encouraged to make their model implementation available through community repositories under suitable licensing terms <xref ref-type="bibr" rid="pcbi.1000456-Committee1">[17]</xref>,<xref ref-type="bibr" rid="pcbi.1000456-Stodden1">[67]</xref>, to promote re-use. We expect professionally managed repositories for neuronal network models to emerge that will give equal weight to human comprehensible and machine readable model descriptions, and curate them according to precisely defined quality standards; such efforts are underway in a number of communities <xref ref-type="bibr" rid="pcbi.1000456-Nickerson1">[37]</xref>, <xref ref-type="bibr" rid="pcbi.1000456-Hines1">[50]</xref>, <xref ref-type="bibr" rid="pcbi.1000456-Lloyd1">[68]</xref>–<xref ref-type="bibr" rid="pcbi.1000456-LeNovre2">[70]</xref>. Once such a repository is firmly established for computational neuroscience, papers might reference detailed model descriptions in a repository, instead of including a full description in the paper itself.</p>
</sec><sec id="s3f2">
<title>Checklists for model descriptions</title>
<p>Model descriptions should give the reader a good overview of the overall structure of a model. We suggest a description in prose accompanied by figures. The text should give an introduction to each composite part, i.e., stating the number of parts, their size, and what sub-parts they consist of. We recommend that authors concisely summarize the information for each part in standardized tables (see panel A in <xref ref-type="fig" rid="pcbi-1000456-g005">Figures 5</xref>, <xref ref-type="fig" rid="pcbi-1000456-g007">7</xref>, and <xref ref-type="fig" rid="pcbi-1000456-g008">8</xref>) and quote only the most necessary pieces in the text. We will discuss network diagrams in detail below.</p>
<p>Following the principle that models should be presented <italic>top-down</italic>, we suggest that authors adhere to the following order when describing the parts of their models:</p>
<list list-type="order"><list-item>
<p>Model composition</p>
</list-item><list-item>
<p>Coordinate systems and topology</p>
</list-item><list-item>
<p>Connectivity</p>
</list-item><list-item>
<p>Neurons, synapses, and channels</p>
</list-item><list-item>
<p>Model input, output, and free parameters</p>
</list-item><list-item>
<p>Model validation</p>
</list-item><list-item>
<p>Model implementation</p>
</list-item></list>
<p>Not all parts will apply to all models, but using such a checklist (i) ensures that all necessary information is included in the paper; (ii) allows referees to systematically check that all information is given; and (iii), facilitates the comparison with other models. We will address each of the items in the list below.</p>
<p>Past experience indicates that it is essential to review model descriptions after one has implemented a model <xref ref-type="bibr" rid="pcbi.1000456-Aumann1">[32]</xref>. We strongly suggest that authors carefully compare model description and implementation. This ensures that the description is complete and that any choices made during implementation are duly reflected. If possible (and feasible), one should ask a colleague to re-implement the model based on the description.</p>
<p>The <bold>model composition</bold> are the groups, or populations, of neurons in a network model. Populations are either unordered, such as Brunel <xref ref-type="bibr" rid="pcbi.1000456-Brunel1">[3]</xref> and Haeusler and Maass <xref ref-type="bibr" rid="pcbi.1000456-Haeusler1">[5]</xref>, or ordered, such as the remaining models in <xref ref-type="table" rid="pcbi-1000456-t001">Table 1</xref>.</p>
<p>A good model description should list all populations of the model along with the used neuron model, their properties, their number, and how each population relates to the modeled system. Authors should name each population and use this name consistently throughout the manuscript. Some populations may be selections of neurons from other populations. In this case, authors should give explicit selection rules or equations.</p>
<p>Even for random selections, we recommend that authors explicitly define the actual range of indices used, to avoid formulations such as “we recorded from 50 randomly selected neurons”, when indeed a contiguous range of 50 neurons from an unordered population was chosen <xref ref-type="bibr" rid="pcbi.1000456-Brunel1">[3]</xref>.</p>
<p><bold>Coordinate systems and topologies</bold> describe how individual neurons in a population can be addressed, or selected, and, where applicable, the spatial relationships between neurons. Authors should specify all coordinate systems used, because they are central to defining the connectivity of the network.</p>
<p>The most basic is the <italic>index coordinate system</italic> which numbers each neuron in the population. Index coordinates are often one-dimensional, but if the populations are representing sheets or volumes of nervous tissue, index coordinates may become two-, three-, or even higher dimensional. Index coordinates are <italic>unordered</italic>, because they do not imply a neighborhood relation between any two neurons, nor do they define a distance function (e.g., Brunel <xref ref-type="bibr" rid="pcbi.1000456-Brunel1">[3]</xref>).</p>
<p>Many models have additional coordinate systems, e.g., <italic>anatomical coordinates</italic>, if the coordinates within a population refer to positions in the brain, as in Izhikevich and Edelman <xref ref-type="bibr" rid="pcbi.1000456-Izhikevich1">[8]</xref>, or <italic>logical coordinates</italic>, if the coordinates within a population refer to some logical property, such as stimulus dimensions or response properties, e.g., orientation angle, as in Lumer et al. <xref ref-type="bibr" rid="pcbi.1000456-Lumer1">[10]</xref>. Anatomical or logical coordinates impose a <italic>topology</italic> on the unordered population, because they allow one to measure distances between neurons.</p>
<p>For each coordinate system used, authors should state exactly how the coordinates are mapped to the index coordinates of the population. A good model description should also give explicit expressions for all distance functions used.</p>
<p>The description of the <bold>connectivity</bold> can now build on the defined populations and coordinate systems. To describe the connections we suggest using prose, equations and figure(s). Authors should start with an overview of the connectivity at the level of populations, followed by all information needed to link connectivity at the level of populations to the connections between individual neurons. The following checklist may assist authors in this task:</p>
<list list-type="order"><list-item>
<p>Are all populations of pre- and post-synaptic neurons defined?</p>
</list-item><list-item>
<p>Are all coordinate systems defined which are needed to select pre- and post-synaptic neurons?</p>
</list-item><list-item>
<p>How are pre-synaptic neurons selected from a population?</p>
</list-item><list-item>
<p>How are post-synaptic neurons selected from a population?</p>
</list-item><list-item>
<p>How are boundary effects in topological connections handled?</p>
</list-item><list-item>
<p>If a pair of pre- and post-synaptic neurons can be chosen more than once, is this connection allowed?</p>
</list-item><list-item>
<p>If the same neuron can be selected as pre- and post-synaptic neuron, is this connection allowed?</p>
</list-item><list-item>
<p>How are the parameters (e.g., weight and delay) of a connection determined?</p>
</list-item><list-item>
<p>If random connections are used, provide the algorithm used to select the pre- and post-synaptic neurons and to determine whether a connection is made.</p>
</list-item><list-item>
<p>Are all parameters of the connectivity explained and are their numerical values given?</p>
</list-item></list>
<p>A figure of the connections in addition to the textual description is of great help to the reader. Suggestions for how to draw connection diagrams are given below.</p>
<p>To describe the dynamics of <bold>neurons, synapses, and channels</bold> we suggest a combination of prose and equations. The text should give the overview, the equations the detail, since they are more exact.</p>
<p>It is important to describe how the neuron behaves over time. For spiking models, the description should encompass how the neuron behaves before, during and after a spike is generated, e.g., state the spike threshold, set the refractory period and define if there is a potential reset. Since this part of a neuron model is often algorithmic, pseudo-code or flow-charts may be an effective means of description. There should also be a description of the synapse type and its behavior, and the algorithms for the plasticity should be given.</p>
<p><bold>Model input, output, and free parameters</bold> are important aspects of a model. Models in computational neuroscience mostly attempt to describe systems rather than phenomena. This is shown by the fact that none of the models we investigated explicitly states its input and output variables.</p>
<p>By contrast, models in statistics are built around the concepts of independent variables (stimulus), dependent variables (response), and the free parameters of a system. A model is then a function that maps the independent variables onto the dependent variables, using the free parameters. We find this view helpful, because it makes the scope of a model explicit.</p>
<p>We suggest that authors explicitly list the independent and dependent variables of their model, along with all free parameters. A textual description of the stimuli accompanied by tabulated parameter values will suffice in most cases to recreate the stimuli. In addition, readers will benefit from a figure illustrating non-trivial stimuli, such as Fig. 1 in Hayot and Tranchina <xref ref-type="bibr" rid="pcbi.1000456-Hayot1">[6]</xref>. If the model uses complex stimuli, such as images or sound sequences, authors should make them available online, so that readers can re-implement the model. A good model description should also detail how responses are measured.</p>
<p>The following checklist may help authors to compile all information for the model description. Most of this information is best placed in the tables, suggested below.</p>
<list list-type="order"><list-item>
<p><italic>Model input</italic>                       <list list-type="alpha-lower"><list-item>
<p>Describe the stimulus ensemble;</p>
</list-item><list-item>
<p>Describe which parts of the model are stimulated;</p>
</list-item><list-item>
<p>Describe exactly how the stimulus is applied;</p>
</list-item><list-item>
<p>Describe any scaling or normalization of the stimulus.</p>
</list-item></list>                   </p>
</list-item><list-item>
<p><italic>Model output</italic>                       <list list-type="alpha-lower"><list-item>
<p>Describe which quantities are measured;</p>
</list-item><list-item>
<p>Describe exactly from which parts of the model measurements are taken;</p>
</list-item><list-item>
<p>Describe exactly how measurements are taken (e.g., specify the sampling rate of the measurements);</p>
</list-item><list-item>
<p>Describe how output quantities are computed from the measurements (e.g., firing rates from spike-trains).</p>
</list-item></list>                   </p>
</list-item><list-item>
<p><italic>Free parameters</italic>                       <list list-type="alpha-lower"><list-item>
<p>Describe all free parameters of the model;</p>
</list-item><list-item>
<p>List the chosen values for each parameter.</p>
</list-item></list>                   </p>
</list-item></list>
<p><bold>Model validation</bold> is crucial to the reliability of modeling studies. Authors should provide information that will allow others to systematically test re-implementations of neuronal network models. To this end, they should include, e.g., membrane-potential traces of model neurons in response to current injection and crafted spike trains.</p>
<p>These figures help readers who attempt to re-implement a network model to validate their implementation of the neuron models; Destexhe et al. <xref ref-type="bibr" rid="pcbi.1000456-Destexhe1">[4]</xref> and Izhikevich and Edelman <xref ref-type="bibr" rid="pcbi.1000456-Izhikevich1">[8]</xref> are fine examples in this respect. Unless the model is new, such figures are best placed in the appendix. For models that are well known in the literature, these figures may be put in the supplementary material.</p>
<p>Testing that parts of a model behave as expected is an excellent way of reducing the chance of errors at a later stage, and is also known as <italic>unit testing</italic> <xref ref-type="bibr" rid="pcbi.1000456-Hamill1">[71]</xref>. If performed in stages, unit testing ensures that all components at a given level function properly, such that any difficulties at the next level of integration can be localized to that level. Systems biologists are ahead of neuroscientists in this respect, and have addressed this issue through the development of the SBML Semantic Validation Suite <xref ref-type="bibr" rid="pcbi.1000456-Finney1">[35]</xref>.</p>
<p>Authors should specify the <bold>model implementation</bold>, i.e., list details of the tools and methods that were used to obtain numerical results. The information should be sufficient to allow readers to re-implement the model and its analysis.</p>
<p>The following list may assist authors in compiling the required information:</p>
<list list-type="order"><list-item>
<p>Which software was used to analyze the model?                       <list list-type="alpha-lower"><list-item>
<p>If third party software was used, list the name, version, and provider of the software.</p>
</list-item><list-item>
<p>If self-written software was used, provide sufficient information on the algorithms and numerical methods used, to allow re-implementation.</p>
</list-item><list-item>
<p>Consider making the simulation program/scripts available as supplementary material.</p>
</list-item></list>                   </p>
</list-item><list-item>
<p>Which parameters, such as integration stepsize and accuracy goals, were used?</p>
</list-item><list-item>
<p>Which software was used to analyze and visualize the data obtained from the model?                       <list list-type="alpha-lower"><list-item>
<p>If third party software was used, list the name, version, and provider of the software.</p>
</list-item><list-item>
<p>If self-written software was used, provide sufficient information on the algorithms and numerical methods used, to allow re-implementation.</p>
</list-item><list-item>
<p>Consider making the simulation program/scripts available as supplementary material.</p>
</list-item></list>                   </p>
</list-item><list-item>
<p>Consider making your analysis scripts available as supplementary material.</p>
</list-item></list>
</sec><sec id="s3f3">
<title>Templates for tables</title>
<p>To provide a full description of the network model, we encourage authors to detail each model part. <xref ref-type="fig" rid="pcbi-1000456-g005">Figures 5</xref>, <xref ref-type="fig" rid="pcbi-1000456-g007">7</xref>, and <xref ref-type="fig" rid="pcbi-1000456-g008">8</xref> illustrate how such detailed descriptions may be given in concise form. We invite readers to use these tables as templates for their own publications.</p>
<p>At present, it does not seem possible, or even desirable, to define precisely how these tables should be formed. Indeed, the reader will notice that we describe the connectivity in the Lumer et al. <xref ref-type="bibr" rid="pcbi.1000456-Lumer1">[10]</xref> model in a rather different way than in the Brunel <xref ref-type="bibr" rid="pcbi.1000456-Brunel1">[3]</xref> model. Lacking any widely adopted formalism for the description of connections, we could at present not see any other way of providing descriptions that were at the same time compact and informative. The connection set algebra recently proposed by Djurfeldt <xref ref-type="bibr" rid="pcbi.1000456-Djurfeldt2">[72]</xref> may eventually evolve into a common formalism for connectivity.</p>
<p>For now, we have set up our tables pragmatically as follows:</p>
<list list-type="order"><list-item>
<p>The first table shall always present a concise <italic>Model Summary</italic> based on the <italic>Checklist</italic> proposed above; one may compare it to the “Nutrition facts” box on food packaging. Non-applicable entries in the table shall be kept in the table to make explicit that a model does not have, e.g., topology or synaptic plasticity.</p>
</list-item><list-item>
<p>For each non-empty entry in the <italic>Model Summary</italic>, a table presenting details shall follow.</p>
</list-item><list-item>
<p>These detailed tables shall in themselves be concise and be presented in the same order as the entries in the <italic>Model Summary</italic>.</p>
</list-item><list-item>
<p>The tables shall contain the names (or symbols) used for populations, connections or other model elements in the modeling paper.</p>
</list-item><list-item>
<p>When model components have been obtained from a model repository, or have a precise definition in a relevant online ontology, accession numbers or ontology reference shall be given.</p>
</list-item></list>
<p>The tables proposed here describe the <italic>structure</italic> of the model. In addition, we propose that all <italic>parameters</italic> of a model should be given in tables to make them easily accessible; some authors do this already.</p>
</sec><sec id="s3f4">
<title>Guidelines for diagrams</title>
<p>Diagrams are a powerful way of expressing relations between parts of a model. Authors should use diagrams to illustrate their model structure and to specify relations between the different model parts. A good model description should use at least one diagram, showing the overall structure of the model. Further diagrams can then be given to elaborate on details and different aspects of the model.</p>
<p>Diagrams should be precise representations of a model and its parts. To this end, we must use the graphical vocabulary of shapes, lines and graphical styles to convey as much detail as possible without sacrificing clarity.</p>
<p>To achieve their full potential, diagrams need to follow a common standard, so that readers can perceive and compare diagrams from different publications. We have seen earlier that there are currently no established rules for drawing diagrams of neural network models. At this point, we give some tentative suggestions only, as sketched in <xref ref-type="fig" rid="pcbi-1000456-g006">Fig. 6</xref> (Brunel <xref ref-type="bibr" rid="pcbi.1000456-Brunel1">[3]</xref> model) and <xref ref-type="fig" rid="pcbi-1000456-g009">Fig. 9</xref> (Lumer et al. <xref ref-type="bibr" rid="pcbi.1000456-Lumer1">[10]</xref> model). These figures are based on the following principles:</p>
<list list-type="order"><list-item>
<p>Unordered populations are shown as circles;</p>
</list-item><list-item>
<p>Populations with spatial structure are shown as rectangles;</p>
</list-item><list-item>
<p>Pointed arrowheads represent excitatory, round ones inhibitory connections;</p>
</list-item><list-item>
<p>Arrows beginning/ending outside a population indicate that the arrows represent a set of connections with source/target neurons selected from the population;</p>
</list-item><list-item>
<p>Probabilistic connection patterns are shown as cut-off masks filled with connection probability as grayscale gradient; the pertaining arrows end on the outside of the mask.</p>
</list-item></list>
<p>We will return to the design of network diagrams in the <xref ref-type="sec" rid="s4">discussion</xref>.</p>
</sec></sec></sec><sec id="s4">
<title>Discussion</title>
<p>Communicating neuronal network models in scientific publications is a challenging task. We have demonstrated above that current publication practices are far from ideal. This has two unfortunate consequences: First of all, it hampers the critical, mutual assessment of published models. As a result, there is no tradition in the computational neuroscience community for scientists to cross-examine each others models thoroughly. The validation of models thus typically remains at the level of individual studies and publications, i.e., not as reliable as is desirable. Other fields, in contrast, have established the validity of their central models beyond any reasonable doubt—and with a clear understanding of their limits of viability—such as the central laws of classical and quantum mechanics, electrodynamics and statistical physics. A second unfortunate consequence of present publication practices is that neuronal network models are rarely re-used by others, thus reducing the overall productivity of the computational neuroscience community. This second consequence follows to a large degree from the first, as few scientists would like to re-use models unless their validity was properly established; in addition, the lack of precision in today's model descriptions often makes re-use difficult.</p>
<sec id="s4a">
<title>Network diagrams</title>
<p>The model survey presented here revealed a wide variety of approaches to describing the composition and connectivity of neuronal networks. We believe that this is, at least in part, due to a lack of common high-level concepts for composition and connectivity from a modeling perspective. Developing such high-level concepts describing, e.g., certain types of randomized connectivity patterns, is thus an important task for the computational neuroscience community. The challenge at hand is perhaps best clarified when trying to draw diagrams representing neuronal network models. Such diagrams have two aims: To give the reader an intuitive understanding of model properties central to the dynamics of the model, and to unambiguously provide the necessary detail to allow a reconstruction of a model. In the absence of a mathematical formalism for model specification, diagrams often seem better suited than prose to present unambiguous detail. Simple models, such as that by Brunel <xref ref-type="bibr" rid="pcbi.1000456-Brunel1">[3]</xref>, can be depicted in a single diagram, as illustrated in <xref ref-type="fig" rid="pcbi-1000456-g006">Fig. 6</xref>. The four panels in that figure, though, show that one may choose from a wide variety of styles for such diagrams, and it is not <italic>a priori</italic> clear which style is best. In panels A–C in the figure we propose three ways to differentiate between excitatory and inhibitory connections (line styles and endings) as well as to mark connectivity patterns (line endings, styles, annotations). Panel D differs from the other three in the way the external input is represented. Brunel <xref ref-type="bibr" rid="pcbi.1000456-Brunel1">[3]</xref> states that “[each neuron] receives <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000456.e028" xlink:type="simple"/></inline-formula> connections from excitatory neurons outside the network. External synapses are activated by independent Poisson processes with rate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000456.e029" xlink:type="simple"/></inline-formula>.” This is rendered in detail in panel D, which shows <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000456.e030" xlink:type="simple"/></inline-formula> Poisson generators per modeled neuron. In all other panels, these generators have been collapsed into an external excitatory population <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000456.e031" xlink:type="simple"/></inline-formula> with the implicit assumption that this population contains the correct number of Poisson generators required by the model.</p>
<p>Presenting complex models is even more challenging. In <xref ref-type="fig" rid="pcbi-1000456-g009">Fig. 9</xref>, we present a set of three figures describing the model by Lumer et al. <xref ref-type="bibr" rid="pcbi.1000456-Lumer1">[10]</xref> at three levels of hierarchy: an overall view in panel A, details of the connectivity within the cortical populations tuned to vertical stimuli in panel B, and finally details of projection patterns into a single cortical population in panel C. All figures are simplifications of the full model, since we have left out the secondary thalamic and cortical areas. We are currently pursuing research to identify drawing styles and a hierarchy of diagrams that will be intuitive to a majority of computational neuroscientists and provide the necessary detail. Results will be presented elsewhere.</p>
</sec><sec id="s4b">
<title>Why are standards lacking?</title>
<p>Given the importance of comprehensible and precise model descriptions, it may seem surprising that no standards or good practices have emerged in computational neuroscience to date. Early proposals, such as the Neural Simulation Language <xref ref-type="bibr" rid="pcbi.1000456-Weitzenfeld1">[73]</xref> (see also Eliasmith and Anderson <xref ref-type="bibr" rid="pcbi.1000456-Eliasmith1">[49]</xref>, Ch. 1.5 and Kumar <xref ref-type="bibr" rid="pcbi.1000456-Kumar1">[74]</xref>), have not been accepted widely in the community.</p>
<p>At present, two developments appear promising. NetworkML, which is part of the NeuroML project <xref ref-type="bibr" rid="pcbi.1000456-Gleeson1">[28]</xref>,<xref ref-type="bibr" rid="pcbi.1000456-Goddard1">[51]</xref>, provides a simulator-agnostic XML-based declarative standard for neuron network model descriptions. Simulation code for tools such as Neuron and Genesis can be generated from models defined in NeuroML. PyNN <xref ref-type="bibr" rid="pcbi.1000456-Davison1">[29]</xref>, in contrast, is an imperative scripting language that can control a number of common neuronal network simulators, such as NEST, Neuron, and Brian. One reason why neither NetworkML nor PyNN has yet caught on as a means of widespread model exchange may be that neither of the two languages seems to aim at providing human-comprehensible model descriptions that might be included in publications.</p>
<p>Another reason for the lack of model description standards may be that computational neuroscience has to a large degree been an ancillary science, an appendix of electrophysiology: The vast majority of publications in computational neuroscience compares its modeling results directly to specific sets of experimental data. And even though models have driven the development in some fields of neuroscience <xref ref-type="bibr" rid="pcbi.1000456-Goodhill1">[75]</xref>, very few authors have compared the properties of different models with each other; Erwin et al. <xref ref-type="bibr" rid="pcbi.1000456-Erwin1">[76]</xref> is a notable exception. De Schutter <xref ref-type="bibr" rid="pcbi.1000456-DeSchutter2">[77]</xref> even argues that there currently is a trend away from the investigation of models as such, and back to a one-to-one matching of models to experiments. As long as computational neuroscientists focus on matching their models to specific experiments, rather than either to spar their models against each other, or build their models upon each other, the motivation to use a standard notation is obviously limited.</p>
</sec><sec id="s4c">
<title>Perspectives</title>
<p>We have no doubt that model sharing will increase in computational neuroscience in years to come. This raises the question of what model sharing precisely entails. At the simplest level, models may be shared as simulator code. While this seems convenient at first, it carries significant risk, as any code is likely to contain errors, in particular errors that may surface only once an existing model is used in a different context than the one in which it was originally developed. Indeed, in at least one case, high-profile publications (outside neuroscience), had to be retracted after a subtle programming error was discovered in a widely shared scientific software <xref ref-type="bibr" rid="pcbi.1000456-Miller1">[78]</xref>. Some scientists argue that everyone in a field should use the same, carefully maintained simulation software to avoid such problems, and to make computational science reliable <xref ref-type="bibr" rid="pcbi.1000456-Donoho1">[79]</xref>. We beg to differ: monoculture tends to create more problems than it solves.</p>
<p>Establishing a new publication culture in computational neuroscience will require considerable effort within the community. We hope that the <italic>good model description practice</italic> that we have outlined in the previous section may be a good starting point. We believe in particular that a clear segregation of model derivation, model description, implementation, and model analysis, as proposed above, will make it easier for readers to discern the model as such, compare it to other models, and evaluate its relevance to their own research. The proposed <italic>Checklists for model descriptions</italic> will help to ensure that model descriptions themselves are reasonably complete and follow a common pattern, further improving the communication of models, while the <italic>Templates for tables</italic> invite a standardized presentation of details on various aspects of models; similarly, the <italic>Guidelines for diagrams</italic> should aid authors in illustrating their network models. Since all our proposals are informal, we hope that authors will find it straightforward to apply them when describing their network models, thus establishing a <italic>de facto</italic> standard for model descriptions.</p>
<p>We are optimistic that we are beginning to see changes towards more cooperation within computational neuroscience, as witnessed by several collaborative reports on neuronal network simulations in the last two years <xref ref-type="bibr" rid="pcbi.1000456-Cannon1">[25]</xref>–<xref ref-type="bibr" rid="pcbi.1000456-Brette1">[27]</xref> and the development of tools for the integration of various simulation software <xref ref-type="bibr" rid="pcbi.1000456-Davison1">[29]</xref>,<xref ref-type="bibr" rid="pcbi.1000456-Ekeberg1">[30]</xref>, much helped by the establishment of the International Neuroinformatics Coordinating Facility (INCF) in 2005. The Connection Set Algebra proposed by Djurfeldt <xref ref-type="bibr" rid="pcbi.1000456-Djurfeldt2">[72]</xref> is an encouraging step towards establishing high-level concepts for neuronal network descriptions, i.e., giving us a concise language to talk about our models. There is also much to be learned from model sharing and curation efforts in other communities, such as the IUPS <italic>Physiome</italic> and the European <italic>Virtual physiological human</italic> projects <xref ref-type="bibr" rid="pcbi.1000456-Nickerson1">[37]</xref>,<xref ref-type="bibr" rid="pcbi.1000456-Beard1">[80]</xref>.</p>
<p>In closing, let us return to the power of notation, as exemplified by the matrix notation in the <xref ref-type="sec" rid="s1">introduction</xref>. In July 1924, Werner Heisenberg gave a manuscript full of complicated mathematics to his mentor Max Born, unsure whether it was worth publishing. Born worked through Heisenberg's ideas and realized that what Heisenberg had written down, actually amounted to the matrix mechanics of quantum theory. This insight of Born's unleashed the full power of Heisenberg's ideas and let Born discover the non-commutativity of quantum mechanics <xref ref-type="bibr" rid="pcbi.1000456-Greenspan1">[81]</xref>, p. 125f. We are looking forward to the day when a good formalism will give us deeper insights into the secrets of signal processing in the brain.</p>
</sec></sec><sec id="s5">
<title>Supporting Information</title>
<supplementary-material id="pcbi.1000456.s001" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000456.s001" xlink:type="simple"><label>Table S1</label><caption>
<p>Network architecture description: placement and means. Each table entry gives the number of papers from <xref ref-type="table" rid="pcbi-1000456-t001">Table 1</xref> in main paper using a given means (columns) and location (rows) to describe the network architecture of the model used, with row- and column-wise totals to the right and at the bottom. Most papers combine several modes of description; the “References”-column contains papers that do not give explicit descriptions, but point to published models. The network architecture description is an overview only, and details are left out. That is the reason for why columns “Eqns” and “Tables” are empty here. See <xref ref-type="table" rid="pcbi-1000456-t001">Table 1</xref> in main paper for paper abbreviations.</p>
<p>(0.27 MB PDF)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1000456.s002" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000456.s002" xlink:type="simple"><label>Table S2</label><caption>
<p>Network connectivity description: placement and means. The presentation is the same as in <xref ref-type="supplementary-material" rid="pcbi.1000456.s001">Table S1</xref>.</p>
<p>(0.10 MB PDF)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1000456.s003" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000456.s003" xlink:type="simple"><label>Table S3</label><caption>
<p>Neuron and synapse model description: placement and means. The presentation is the same as in <xref ref-type="supplementary-material" rid="pcbi.1000456.s001">Table S1</xref>.</p>
<p>(0.12 MB PDF)</p>
</caption></supplementary-material></sec></body>
<back>
<ack>
<p>We would like to thank Markus Diesmann and Sven Schrader as well as three anonymous reviewers for stimulating feedback on earlier versions of the manuscript and Kittel Austvoll for help in preparing figures. We are grateful to Mikael Djurfeldt for sharing his Connection Set Algebra manuscript with us prior to publication, and to our colleagues at Ås for feedback on table and figure design.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1000456-Gopen1"><label>1</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Gopen</surname><given-names>GD</given-names></name>
<name name-style="western"><surname>Swan</surname><given-names>JA</given-names></name>
</person-group>             <year>1990</year>             <article-title>The science of scientific writing.</article-title>             <source>American Scientist</source>             <volume>78</volume>             <fpage>550</fpage>             <lpage>558</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Rotter1"><label>2</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Rotter</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Diesmann</surname><given-names>M</given-names></name>
</person-group>             <year>1999</year>             <article-title>Exact digital simulation of time-invariant linear systems with applications to neuronal modeling.</article-title>             <source>Biol Cybern</source>             <volume>81</volume>             <fpage>381</fpage>             <lpage>402</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Brunel1"><label>3</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Brunel</surname><given-names>N</given-names></name>
</person-group>             <year>2000</year>             <article-title>Dynamics of sparsely connected networks of excitatory and inhibitory spiking neurons.</article-title>             <source>J Comput Neurosci</source>             <volume>8</volume>             <fpage>183</fpage>             <lpage>208</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Destexhe1"><label>4</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Destexhe</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Bal</surname><given-names>T</given-names></name>
<name name-style="western"><surname>McCormick</surname><given-names>DA</given-names></name>
<name name-style="western"><surname>Sejnowski</surname><given-names>TJ</given-names></name>
</person-group>             <year>1996</year>             <article-title>Ionic mechanisms underlying synchronized oscillations and propagating waves in a model of ferret thalamic slices.</article-title>             <source>J Neurophysiol</source>             <volume>76</volume>             <fpage>2049</fpage>             <lpage>2070</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Haeusler1"><label>5</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Haeusler</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Maass</surname><given-names>W</given-names></name>
</person-group>             <year>2007</year>             <article-title>A statistical analysis of information-processing properties of laminaspecific cortical microcircuit models.</article-title>             <source>Cereb Cortex</source>             <volume>17</volume>             <fpage>149</fpage>             <lpage>162</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Hayot1"><label>6</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Hayot</surname><given-names>F</given-names></name>
<name name-style="western"><surname>Tranchina</surname><given-names>D</given-names></name>
</person-group>             <year>2001</year>             <article-title>Modeling corticofugal feedback and the sensitivity of lateral geniculate neurons to orientation discontinuity.</article-title>             <source>Vis Neurosci</source>             <volume>18</volume>             <fpage>865</fpage>             <lpage>877</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Hillenbrand1"><label>7</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Hillenbrand</surname><given-names>U</given-names></name>
<name name-style="western"><surname>van Hemmen</surname><given-names>LJ</given-names></name>
</person-group>             <year>2000</year>             <article-title>Spatiotemporal adaptation through corticothalamic loops: A hypothesis.</article-title>             <source>Vis Neurosci</source>             <volume>17</volume>             <fpage>107</fpage>             <lpage>118</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Izhikevich1"><label>8</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Izhikevich</surname><given-names>EM</given-names></name>
<name name-style="western"><surname>Edelman</surname><given-names>GM</given-names></name>
</person-group>             <year>2008</year>             <article-title>Large-scale model of mammalian thalamocortical systems.</article-title>             <source>Proc Natl Acad Sci U S A</source>             <volume>105</volume>             <fpage>3593</fpage>             <lpage>3598</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Kirkland1"><label>9</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kirkland</surname><given-names>KL</given-names></name>
<name name-style="western"><surname>Gerstein</surname><given-names>GL</given-names></name>
</person-group>             <year>1998</year>             <article-title>A model of cortically induced synchronization in the lateral geniculate nucleus of the cat: a role for low-threshold calcium channels.</article-title>             <source>Vision Res</source>             <volume>38</volume>             <fpage>2007</fpage>             <lpage>2022</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Lumer1"><label>10</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Lumer</surname><given-names>ED</given-names></name>
<name name-style="western"><surname>Edelman</surname><given-names>GM</given-names></name>
<name name-style="western"><surname>Tononi</surname><given-names>G</given-names></name>
</person-group>             <year>1997</year>             <article-title>Neural dynamics in a model of the thalamocortical system. I. Layers, loops and the emergence of fast synchronous rhythms.</article-title>             <source>Cereb Cortex</source>             <volume>7</volume>             <fpage>207</fpage>             <lpage>227</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Mario1"><label>11</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Mariño</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Schummers</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Lyon</surname><given-names>DC</given-names></name>
<name name-style="western"><surname>Schwabe</surname><given-names>L</given-names></name>
<name name-style="western"><surname>Beck</surname><given-names>O</given-names></name>
<etal/></person-group>             <year>2005</year>             <article-title>Invariant computations in local cortical networks with balanced excitation and inhibition.</article-title>             <source>Nat Neurosci</source>             <volume>8</volume>             <fpage>194</fpage>             <lpage>201</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Saam1"><label>12</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Saam</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Eckhorn</surname><given-names>R</given-names></name>
</person-group>             <year>2000</year>             <article-title>Lateral spike conduction velocity in the visual cortex affects spatial range of synchronization and receptive field size without visual experience: a learning model with spiking neurons.</article-title>             <source>Biol Cybern</source>             <volume>83</volume>             <fpage>L1</fpage>             <lpage>L9</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Tao1"><label>13</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Tao</surname><given-names>L</given-names></name>
<name name-style="western"><surname>Shelley</surname><given-names>M</given-names></name>
<name name-style="western"><surname>McLaughlin</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Shapley</surname><given-names>R</given-names></name>
</person-group>             <year>2004</year>             <article-title>An egalitarian network model for the emergence of simple and complex cells in visual cortex.</article-title>             <source>Proc Natl Acad Sci U S A</source>             <volume>101</volume>             <fpage>366</fpage>             <lpage>371</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Troyer1"><label>14</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Troyer</surname><given-names>TW</given-names></name>
<name name-style="western"><surname>Krukowski</surname><given-names>AE</given-names></name>
<name name-style="western"><surname>Priebe</surname><given-names>NJ</given-names></name>
<name name-style="western"><surname>Miller</surname><given-names>KD</given-names></name>
</person-group>             <year>1998</year>             <article-title>Contrast-invariant orientation tuning in cat visual cortex: thalamocortical input tuning and correlation-based intracortical connectivity.</article-title>             <source>J Neurosci</source>             <volume>18</volume>             <fpage>5908</fpage>             <lpage>5927</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Vogels1"><label>15</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Vogels</surname><given-names>TP</given-names></name>
<name name-style="western"><surname>Abbott</surname><given-names>LF</given-names></name>
</person-group>             <year>2005</year>             <article-title>Signal propagation and logic gating in networks of integrate-and-fire neurons.</article-title>             <source>J Neurosci</source>             <volume>25</volume>             <fpage>10786</fpage>             <lpage>10795</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Wielaard1"><label>16</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Wielaard</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Sajda</surname><given-names>P</given-names></name>
</person-group>             <year>2007</year>             <article-title>Dependence of response properties on sparse connectivity in a spiking neuron model of the lateral geniculate nucleus.</article-title>             <source>J Neurophysiol</source>             <volume>98</volume>             <fpage>3292</fpage>             <lpage>3308</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Committee1"><label>17</label><element-citation publication-type="other" xlink:type="simple">             <collab xlink:type="simple">Committee on Responsibilities of Authorship in the Biological Sciences, editor</collab>             <year>2003</year>             <source>Sharing Publication-Related Data and Material: Responsibilities of Authorship in the Life Sciences</source>             <publisher-loc>Washington, DC</publisher-loc>             <publisher-name>The National Academies Press</publisher-name>             <comment>Available: <ext-link ext-link-type="uri" xlink:href="http://www.nap.edu/catalog.php?record id=10613" xlink:type="simple">http://www.nap.edu/catalog.php?record id=10613</ext-link>. Accessed 30 June 2009</comment>          </element-citation></ref>
<ref id="pcbi.1000456-Marshall1"><label>18</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Marshall</surname><given-names>E</given-names></name>
</person-group>             <year>2003</year>             <article-title>Science publishing. The UPSIDE of good behavior: make your data freely available.</article-title>             <source>Science</source>             <volume>299</volume>             <fpage>990</fpage>          </element-citation></ref>
<ref id="pcbi.1000456-Public1"><label>19</label><element-citation publication-type="other" xlink:type="simple">             <collab xlink:type="simple">Public Library of Science</collab>             <year>2009</year>             <article-title>PLoS Computational Biology Editorial and Publishing Policies.</article-title>             <comment>Available: <ext-link ext-link-type="uri" xlink:href="http://www.ploscompbiol.org/static/policies.action" xlink:type="simple">http://www.ploscompbiol.org/static/policies.action</ext-link>. Accessed 29 January 2009</comment>          </element-citation></ref>
<ref id="pcbi.1000456-Liu1"><label>20</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Liu</surname><given-names>Y</given-names></name>
<name name-style="western"><surname>Ascoli</surname><given-names>GA</given-names></name>
</person-group>             <year>2007</year>             <article-title>Value added by data sharing: long-term potentiation of neuroscience research. A commentary on the 2007 SfN Satellite Symposium on data sharing.</article-title>             <source>Neuroinformatics</source>             <volume>5</volume>             <fpage>143</fpage>             <lpage>145</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Teeters1"><label>21</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Teeters</surname><given-names>JL</given-names></name>
<name name-style="western"><surname>Harris</surname><given-names>KD</given-names></name>
<name name-style="western"><surname>Millman</surname><given-names>KJ</given-names></name>
<name name-style="western"><surname>Olshausen</surname><given-names>BA</given-names></name>
<name name-style="western"><surname>Sommer</surname><given-names>FT</given-names></name>
</person-group>             <year>2008</year>             <article-title>Data sharing for computational neuroscience.</article-title>             <source>Neuroinformatics</source>             <volume>6</volume>             <fpage>47</fpage>             <lpage>55</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Horn1"><label>22</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Horn</surname><given-names>JDV</given-names></name>
<name name-style="western"><surname>Ball</surname><given-names>CA</given-names></name>
</person-group>             <year>2008</year>             <article-title>Domain-specific data sharing in neuroscience: what do we have to learn from each other?</article-title>             <source>Neuroinformatics</source>             <volume>6</volume>             <fpage>117</fpage>             <lpage>121</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Gardner1"><label>23</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Gardner</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Akil</surname><given-names>H</given-names></name>
<name name-style="western"><surname>Ascoli</surname><given-names>GA</given-names></name>
<name name-style="western"><surname>Bowden</surname><given-names>DM</given-names></name>
<name name-style="western"><surname>Bug</surname><given-names>W</given-names></name>
<etal/></person-group>             <year>2008</year>             <article-title>The neuroscience information framework: a data and knowledge environment for neuroscience.</article-title>             <source>Neuroinformatics</source>             <volume>6</volume>             <fpage>149</fpage>             <lpage>160</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Sejnowski1"><label>24</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Sejnowski</surname><given-names>TJ</given-names></name>
<name name-style="western"><surname>Koch</surname><given-names>C</given-names></name>
<name name-style="western"><surname>Churchland</surname><given-names>PS</given-names></name>
</person-group>             <year>1988</year>             <article-title>Computational neuroscience.</article-title>             <source>Science</source>             <volume>241</volume>             <fpage>1299</fpage>             <lpage>1306</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Cannon1"><label>25</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Cannon</surname><given-names>RC</given-names></name>
<name name-style="western"><surname>Gewaltig</surname><given-names>MO</given-names></name>
<name name-style="western"><surname>Gleeson</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Bhalla</surname><given-names>US</given-names></name>
<name name-style="western"><surname>Cornelis</surname><given-names>H</given-names></name>
<etal/></person-group>             <year>2007</year>             <article-title>Interoperability of neuroscience modeling software: Current status and future directions.</article-title>             <source>Neuroinformatics</source>             <volume>5</volume>             <fpage>127</fpage>             <lpage>138</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Djurfeldt1"><label>26</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Djurfeldt</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Lansner</surname><given-names>A</given-names></name>
</person-group>             <year>2007</year>             <article-title>1st INCF workshop on large-scale modeling of the nervous system.</article-title>             <source>Nature Precedings</source>             <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/npre.2007.262.1" xlink:type="simple">10.1038/npre.2007.262.1</ext-link>. Available: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/npre.2007.262.1" xlink:type="simple">http://dx.doi.org/10.1038/npre.2007.262.1</ext-link>. Accessed 30 June 2009</comment>          </element-citation></ref>
<ref id="pcbi.1000456-Brette1"><label>27</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Brette</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Rudolph</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Carnevale</surname><given-names>T</given-names></name>
<name name-style="western"><surname>Hines</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Beeman</surname><given-names>D</given-names></name>
<etal/></person-group>             <year>2007</year>             <article-title>Simulation of networks of spiking neurons: A review of tools and strategies.</article-title>             <source>J Comput Neurosci</source>             <volume>23</volume>             <fpage>349</fpage>             <lpage>398</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Gleeson1"><label>28</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Gleeson</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Crook</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Barnes</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Silver</surname><given-names>A</given-names></name>
</person-group>             <year>2008</year>             <article-title>Interoperable model components for biologically realistic single neuron and network models implemented in NeuroML.</article-title>             <source>Frontiers in Neuroinformatics. Conference Abstract: Neuroinformatics 2008</source>             <publisher-loc>Stockholm</publisher-loc>             <publisher-name>International Neuroinformatics Coordinating Facility</publisher-name>             <comment>Available: <ext-link ext-link-type="uri" xlink:href="http://frontiersin.org/conferences/individual abstract listing.php?conferid=2&amp;pap=491&amp;ind abs=1&amp;pg=5" xlink:type="simple">http://frontiersin.org/conferences/individual abstract listing.php?conferid=2&amp;pap=491&amp;ind abs=1&amp;pg=5</ext-link>. Accessed 30 June 2009</comment>          </element-citation></ref>
<ref id="pcbi.1000456-Davison1"><label>29</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Davison</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Brüderle</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Eppler</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Kremkow</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Muller</surname><given-names>E</given-names></name>
<etal/></person-group>             <year>2008</year>             <article-title>PyNN: a common interface for neuronal network simulators.</article-title>             <source>Front Neuroinform</source>             <volume>2</volume>             <fpage>11</fpage>          </element-citation></ref>
<ref id="pcbi.1000456-Ekeberg1"><label>30</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Ekeberg</surname><given-names>Ö</given-names></name>
<name name-style="western"><surname>Djurfeldt</surname><given-names>M</given-names></name>
</person-group>             <year>2008</year>             <article-title>MUSIC—multisimulation coordinator: Request for comments.</article-title>             <source>Nature Preceedings</source>             <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/npre.2008.1830.1" xlink:type="simple">http://dx.doi.org/10.1038/npre.2008.1830.1</ext-link>. Available: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/npre.2008.1830.1" xlink:type="simple">10.1038/npre.2008.1830.1</ext-link>. Accessed 30 June 2009</comment>          </element-citation></ref>
<ref id="pcbi.1000456-Peck1"><label>31</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Peck</surname><given-names>SL</given-names></name>
</person-group>             <year>2004</year>             <article-title>Simulation as experiment: a philosophical reassessment for biological modeling.</article-title>             <source>TRENDS in Ecology and Evolution</source>             <volume>19</volume>             <fpage>530</fpage>             <lpage>534</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Aumann1"><label>32</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Aumann</surname><given-names>CA</given-names></name>
</person-group>             <year>2007</year>             <article-title>A methodology for developing simulation models of complex systems.</article-title>             <source>Ecological Modelling</source>             <volume>202</volume>             <fpage>385</fpage>             <lpage>396</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Lander1"><label>33</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Lander</surname><given-names>AD</given-names></name>
</person-group>             <year>2004</year>             <article-title>A calculus of purpose.</article-title>             <source>PLoS Biol</source>             <volume>2</volume>             <fpage>e164</fpage>          </element-citation></ref>
<ref id="pcbi.1000456-Reeves1"><label>34</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Reeves</surname><given-names>GT</given-names></name>
<name name-style="western"><surname>Fraser</surname><given-names>SE</given-names></name>
</person-group>             <year>2009</year>             <article-title>Biological systems from an engineer's point of view.</article-title>             <source>PLoS Biol</source>             <volume>7</volume>             <fpage>e21</fpage>          </element-citation></ref>
<ref id="pcbi.1000456-Finney1"><label>35</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Finney</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Hucka</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Bornstein</surname><given-names>BJ</given-names></name>
<name name-style="western"><surname>Keating</surname><given-names>SM</given-names></name>
<name name-style="western"><surname>Shapiro</surname><given-names>BE</given-names></name>
<etal/></person-group>             <year>2006</year>             <article-title>Software infrastructure for effective communication and reuse of computational models.</article-title>             <person-group person-group-type="editor">
<name name-style="western"><surname>Szallasi</surname><given-names>Z</given-names></name>
<name name-style="western"><surname>Stelling</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Periwal</surname><given-names>V</given-names></name>
</person-group>             <source>System Modeling in Cellular Biology: From Concepts to Nuts and Bolts</source>             <publisher-loc>Cambridge, MA</publisher-loc>             <publisher-name>MIT Press</publisher-name>             <fpage>355</fpage>             <lpage>378</lpage>             <comment>chapter 17</comment>          </element-citation></ref>
<ref id="pcbi.1000456-Wimalaratne1"><label>36</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Wimalaratne</surname><given-names>SM</given-names></name>
<name name-style="western"><surname>Halstead</surname><given-names>MDB</given-names></name>
<name name-style="western"><surname>Lloyd</surname><given-names>CM</given-names></name>
<name name-style="western"><surname>Cooling</surname><given-names>MT</given-names></name>
<name name-style="western"><surname>Crampin</surname><given-names>EJ</given-names></name>
<etal/></person-group>             <year>2009</year>             <article-title>Facilitating modularity and reuse: Guidelines for structuring CellML 1.1 models by isolating common biophysical concepts.</article-title>             <source>Exp Physiol</source>             <volume>94</volume>             <fpage>472</fpage>             <lpage>485</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Nickerson1"><label>37</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Nickerson</surname><given-names>DP</given-names></name>
<name name-style="western"><surname>Buist</surname><given-names>ML</given-names></name>
</person-group>             <year>2009</year>             <article-title>A physiome standards-based model publication paradigm.</article-title>             <source>Philos Transact A Math Phys Eng Sci</source>             <volume>367</volume>             <fpage>1823</fpage>             <lpage>1844</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-DeSchutter1"><label>38</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>De Schutter</surname><given-names>E</given-names></name>
</person-group>             <year>2008</year>             <article-title>Why are computational neuroscience and systems biology so separate?</article-title>             <source>PLoS Comput Biol</source>             <volume>4</volume>             <fpage>78</fpage>          </element-citation></ref>
<ref id="pcbi.1000456-Frigg1"><label>39</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Frigg</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Hartmann</surname><given-names>S</given-names></name>
</person-group>             <year>2008</year>             <article-title>Models in science.</article-title>             <person-group person-group-type="editor">
<name name-style="western"><surname>Zalta</surname><given-names>EN</given-names></name>
</person-group>             <publisher-name>The Stanford Encyclopedia of Philosophy, Metaphysics Research Lab, Stanford University</publisher-name>             <comment>Available: <ext-link ext-link-type="uri" xlink:href="http://plato.stanford.edu/archives/fall2008/entries/models-science/" xlink:type="simple">http://plato.stanford.edu/archives/fall2008/entries/models-science/</ext-link>. Accessed 30 June 2009</comment>          </element-citation></ref>
<ref id="pcbi.1000456-Hartmann1"><label>40</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Hartmann</surname><given-names>S</given-names></name>
</person-group>             <year>1996</year>             <article-title>The world as a process: Simulations in the natural and social sciences.</article-title>             <person-group person-group-type="editor">
<name name-style="western"><surname>Hegselmann</surname><given-names>R</given-names></name>
<etal/></person-group>             <source>Simulation and Modelling in the Social Sciences from the Philosophy of Science Point of View</source>             <publisher-loc>Dordrecht</publisher-loc>             <publisher-name>Kluwer, Theory and Decision Library</publisher-name>             <fpage>77</fpage>             <lpage>100</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Winsberg1"><label>41</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Winsberg</surname><given-names>E</given-names></name>
</person-group>             <year>2003</year>             <article-title>Simulated experiments: Methodology for a virtual world.</article-title>             <source>Philosophy of Science</source>             <volume>70</volume>             <fpage>105</fpage>             <lpage>125</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Kppers1"><label>42</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Küppers</surname><given-names>G</given-names></name>
<name name-style="western"><surname>Lenhard</surname><given-names>J</given-names></name>
</person-group>             <year>2005</year>             <article-title>Computersimulationen: Modellierungen 2. Ordnung.</article-title>             <source>Journal for General Philosophy of Science</source>             <volume>36</volume>             <fpage>305</fpage>             <lpage>329</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Wooley1"><label>43</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="editor">
<name name-style="western"><surname>Wooley</surname><given-names>JC</given-names></name>
<name name-style="western"><surname>Lin</surname><given-names>HS</given-names></name>
</person-group>             <year>2005</year>             <source>Catalyzing Inquiry at the Interface of Computing and Biology</source>             <publisher-loc>Washington, DC</publisher-loc>             <publisher-name>The National Academies Press</publisher-name>             <comment>Available: <ext-link ext-link-type="uri" xlink:href="http://www.nap.edu/catalog/11480.html" xlink:type="simple">http://www.nap.edu/catalog/11480.html</ext-link>. Accessed 30 June 2009</comment>          </element-citation></ref>
<ref id="pcbi.1000456-Clark1"><label>44</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Clark</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Eliasmith</surname><given-names>C</given-names></name>
</person-group>             <year>2000</year>             <article-title>Philosophical issues in brain theory and connectionism.</article-title>             <person-group person-group-type="editor">
<name name-style="western"><surname>Arbib</surname><given-names>M</given-names></name>
</person-group>             <source>Handbook of Brain Theory and Neural Networks</source>             <publisher-loc>Cambridge, MA</publisher-loc>             <publisher-name>MIT Press</publisher-name>             <fpage>886</fpage>             <lpage>888</lpage>             <comment>Second edition</comment>          </element-citation></ref>
<ref id="pcbi.1000456-Lappi1"><label>45</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Lappi</surname><given-names>O</given-names></name>
</person-group>             <year>2007</year>             <article-title>Computational templates, neural network dynamics, and symbolic logic.</article-title>             <fpage>1226</fpage>             <lpage>1230</lpage>             <comment>In: Proc. International Joint Conference on Neural Networks IJCNN 2007</comment>             <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1109/IJCNN.2007.4371133" xlink:type="simple">10.1109/IJCNN.2007.4371133</ext-link></comment>          </element-citation></ref>
<ref id="pcbi.1000456-Knuuttila1"><label>46</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Knuuttila</surname><given-names>T</given-names></name>
<name name-style="western"><surname>Rusanen</surname><given-names>AM</given-names></name>
<name name-style="western"><surname>Honkela</surname><given-names>T</given-names></name>
</person-group>             <year>2007</year>             <article-title>Self-organizing maps as traveling computational templates.</article-title>             <fpage>1231</fpage>             <lpage>1236</lpage>             <comment>In: Proc. International Joint Conference on Neural Networks IJCNN 2007</comment>             <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1109/IJCNN.2007.4371134" xlink:type="simple">10.1109/IJCNN.2007.4371134</ext-link></comment>          </element-citation></ref>
<ref id="pcbi.1000456-Rusanen1"><label>47</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Rusanen</surname><given-names>AM</given-names></name>
<name name-style="western"><surname>Ylikoski</surname><given-names>P</given-names></name>
</person-group>             <year>2007</year>             <article-title>Neural network templates and their interpretation.</article-title>             <fpage>2683</fpage>             <lpage>2688</lpage>             <comment>In: Proc. International Joint Conference on Neural Networks IJCNN 2007</comment>             <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1109/IJCNN.2007.4371382" xlink:type="simple">10.1109/IJCNN.2007.4371382</ext-link></comment>          </element-citation></ref>
<ref id="pcbi.1000456-Humphreys1"><label>48</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Humphreys</surname><given-names>P</given-names></name>
</person-group>             <year>2004</year>             <source>Extending Ourselves: Computational Science, Empiricism, and Scientific Method.</source>             <publisher-name>Oxford University Press</publisher-name>          </element-citation></ref>
<ref id="pcbi.1000456-Eliasmith1"><label>49</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Eliasmith</surname><given-names>C</given-names></name>
<name name-style="western"><surname>Anderson</surname><given-names>CH</given-names></name>
</person-group>             <year>2004</year>             <source>Neural Engineering: Computation, Representation, and Dynamics in Neurobiological Systems</source>             <publisher-loc>Cambridge, MA</publisher-loc>             <publisher-name>MIT Press</publisher-name>          </element-citation></ref>
<ref id="pcbi.1000456-Hines1"><label>50</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Hines</surname><given-names>ML</given-names></name>
<name name-style="western"><surname>Morse</surname><given-names>T</given-names></name>
<name name-style="western"><surname>Migliore</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Carnevale</surname><given-names>NT</given-names></name>
<name name-style="western"><surname>Shepherd</surname><given-names>GM</given-names></name>
</person-group>             <year>2004</year>             <article-title>ModelDB: A database to support computational neuroscience.</article-title>             <source>J Comput Neurosci</source>             <volume>17</volume>             <fpage>7</fpage>             <lpage>11</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Goddard1"><label>51</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Goddard</surname><given-names>NH</given-names></name>
<name name-style="western"><surname>Hucka</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Howell</surname><given-names>F</given-names></name>
<name name-style="western"><surname>Cornelis</surname><given-names>H</given-names></name>
<name name-style="western"><surname>Shankar</surname><given-names>K</given-names></name>
<etal/></person-group>             <year>2001</year>             <article-title>Towards NeuroML: model description methods for collaborative modelling in neuroscience.</article-title>             <source>Philos Trans R Soc Lond B Biol Sci</source>             <volume>356</volume>             <fpage>1209</fpage>             <lpage>1228</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Kppers2"><label>52</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Küppers</surname><given-names>G</given-names></name>
<name name-style="western"><surname>Lenhard</surname><given-names>J</given-names></name>
</person-group>             <year>2005</year>             <article-title>Validation of simulation: Patterns in the social and natural sciences.</article-title>             <source>Journal of Artificial Societies and Social Simulation</source>             <volume>8</volume>             <fpage>3</fpage>             <comment>Available: <ext-link ext-link-type="uri" xlink:href="http://jasss.soc.surrey.ac.uk/8/4/3.html" xlink:type="simple">http://jasss.soc.surrey.ac.uk/8/4/3.html</ext-link>. Accessed 30 June 2009</comment>          </element-citation></ref>
<ref id="pcbi.1000456-Cajori1"><label>53</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Cajori</surname><given-names>F</given-names></name>
</person-group>             <year>1993</year>             <source>A History of Mathematical Notations: Two Volumes Bound as One</source>             <publisher-loc>New York</publisher-loc>             <publisher-name>Dover Publications</publisher-name>          </element-citation></ref>
<ref id="pcbi.1000456-Wikipedia1"><label>54</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Wikipedia</surname></name>
</person-group>             <year>2008</year>             <article-title>History of mathematical notation — Wikipedia, the free encyclopedia.</article-title>             <comment>Available: <ext-link ext-link-type="uri" xlink:href="http://en.wikipedia.org/wiki/History" xlink:type="simple">http://en.wikipedia.org/wiki/History</ext-link> of mathematical notation. Accessed 20 October 2008</comment>          </element-citation></ref>
<ref id="pcbi.1000456-Shannon1"><label>55</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Shannon</surname><given-names>CE</given-names></name>
</person-group>             <year>1940</year>             <article-title>A symbolic analysis of relay and switching circuits.</article-title>             <comment>Master's thesis, Massachusetts Institute of Technology. Dept. of Electrical Engineering</comment>          </element-citation></ref>
<ref id="pcbi.1000456-Kohn1"><label>56</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kohn</surname><given-names>KW</given-names></name>
<name name-style="western"><surname>Aladjem</surname><given-names>MI</given-names></name>
</person-group>             <year>2006</year>             <article-title>Circuit diagrams for biological networks.</article-title>             <source>Mol Syst Biol</source>             <volume>2</volume>             <fpage>2006.0002</fpage>          </element-citation></ref>
<ref id="pcbi.1000456-Kitano1"><label>57</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kitano</surname><given-names>H</given-names></name>
<name name-style="western"><surname>Funahashi</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Matsuoka</surname><given-names>Y</given-names></name>
<name name-style="western"><surname>Oda</surname><given-names>K</given-names></name>
</person-group>             <year>2005</year>             <article-title>Using process diagrams for the graphical representation of biological networks.</article-title>             <source>Nat Biotechnol</source>             <volume>23</volume>             <fpage>961</fpage>             <lpage>966</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Kohn2"><label>58</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kohn</surname><given-names>KW</given-names></name>
<name name-style="western"><surname>Aladjem</surname><given-names>MI</given-names></name>
<name name-style="western"><surname>Weinstein</surname><given-names>JN</given-names></name>
<name name-style="western"><surname>Pommier</surname><given-names>Y</given-names></name>
</person-group>             <year>2006</year>             <article-title>Molecular interaction maps of bioregulatory networks: a general rubric for systems biology.</article-title>             <source>Mol Biol Cell</source>             <volume>17</volume>             <fpage>1</fpage>             <lpage>13</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Blinov1"><label>59</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Blinov</surname><given-names>ML</given-names></name>
<name name-style="western"><surname>Yang</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Faeder</surname><given-names>JR</given-names></name>
<name name-style="western"><surname>Hlavacek</surname><given-names>WS</given-names></name>
</person-group>             <year>2006</year>             <article-title>Depicting signaling cascades.</article-title>             <source>Nat Biotechnol</source>             <volume>24</volume>             <fpage>137</fpage>             <lpage>138</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Kriener1"><label>60</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kriener</surname><given-names>B</given-names></name>
<name name-style="western"><surname>Tetzlaff</surname><given-names>T</given-names></name>
<name name-style="western"><surname>Aertsen</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Diesmann</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Rotter</surname><given-names>S</given-names></name>
</person-group>             <year>2008</year>             <article-title>Correlations and population dynamics in cortical networks.</article-title>             <source>Neural Comput</source>             <volume>20</volume>             <fpage>2185</fpage>             <lpage>2226</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Potjans1"><label>61</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Potjans</surname><given-names>TC</given-names></name>
<name name-style="western"><surname>Diesmann</surname><given-names>M</given-names></name>
</person-group>             <year>2008</year>             <article-title>Data-driven structure representation for large-scale models of layered cortical networks. In: Frontiers in Neuroinformatics. Conference Abstract: Neuroinformatics 2008. doi:10.3389/conf.neuro.11.2008.01.087. Available: <ext-link ext-link-type="uri" xlink:href="http://frontiersin.org/conferences/individual abstract listing.php?conferid=2&amp;pap=407&amp;ind abs=1&amp;pg=7" xlink:type="simple">http://frontiersin.org/conferences/individual abstract listing.php?conferid=2&amp;pap=407&amp;ind abs=1&amp;pg=7</ext-link>. Accessed 30 June 2009</article-title>          </element-citation></ref>
<ref id="pcbi.1000456-Plesser1"><label>62</label><mixed-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Plesser</surname><given-names>HE</given-names></name>
<name name-style="western"><surname>Austvoll</surname><given-names>K</given-names></name>
</person-group>             <year>2009</year>             <article-title>Efficient probabilistic wiring of spatial neuronal network using walker's alias method.</article-title> <!--===== Restructure page-count as size[@units="page"] =====--><size units="page">1277</size> (T26-1C).              <comment>In: Proceedings of the Eighth Göttingen Meeting of the German Neuroscience Society. Neurowissenschaftliche Gesellschaft</comment>             <comment>Available: <ext-link ext-link-type="uri" xlink:href="http://www.nwg-goettingen.de/2009/upload/abstracts pdf/T26-1C.pdf" xlink:type="simple">http://www.nwg-goettingen.de/2009/upload/abstracts pdf/T26-1C.pdf</ext-link>. Accessed 30 June 2009</comment>          </mixed-citation></ref>
<ref id="pcbi.1000456-Einevoll1"><label>63</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Einevoll</surname><given-names>GT</given-names></name>
<name name-style="western"><surname>Plesser</surname><given-names>HE</given-names></name>
</person-group>             <year>2002</year>             <article-title>Linear mechanistic models for the dorsal lateral geniculate nucleus of cat probed using drifting grating stimuli.</article-title>             <source>Network-Comp Neural</source>             <volume>13</volume>             <fpage>503</fpage>             <lpage>530</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Hansel1"><label>64</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Hansel</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Mato</surname><given-names>G</given-names></name>
<name name-style="western"><surname>Meunier</surname><given-names>C</given-names></name>
<name name-style="western"><surname>Neltner</surname><given-names>L</given-names></name>
</person-group>             <year>1998</year>             <article-title>On numerical simulations of integrate-and-fire neural networks.</article-title>             <source>Neural Comput</source>             <volume>10</volume>             <fpage>467</fpage>             <lpage>483</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Morrison1"><label>65</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Morrison</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Straube</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Plesser</surname><given-names>HE</given-names></name>
<name name-style="western"><surname>Diesmann</surname><given-names>M</given-names></name>
</person-group>             <year>2007</year>             <article-title>Exact subthreshold integration with continuous spike times in discrete time neural network simulations.</article-title>             <source>Neural Comput</source>             <volume>19</volume>             <fpage>47</fpage>             <lpage>79</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Morrison2"><label>66</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Morrison</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Diesmann</surname><given-names>M</given-names></name>
</person-group>             <year>2008</year>             <article-title>Maintaining causality in discrete time neuronal network simulations.</article-title>             <person-group person-group-type="editor">
<name name-style="western"><surname>Beim Graben</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Zhou</surname><given-names>C</given-names></name>
<name name-style="western"><surname>Thiel</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Kuhrts</surname><given-names>J</given-names></name>
</person-group>             <source>Lectures in Supercomputational Neuroscience: Dynamics in Complex Brain Networks</source>             <publisher-loc>Berlin und Heidelberg</publisher-loc>             <publisher-name>Springer-Verlag</publisher-name>             <fpage>267</fpage>             <lpage>278</lpage>             <comment>chapter 10</comment>          </element-citation></ref>
<ref id="pcbi.1000456-Stodden1"><label>67</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Stodden</surname><given-names>V</given-names></name>
</person-group>             <year>2009</year>             <article-title>The legal framework for reproducible scientific research: Licensing and copyright.</article-title>             <source>Computing in Science &amp; Engineering</source>             <volume>11</volume>             <fpage>35</fpage>             <lpage>40</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Lloyd1"><label>68</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Lloyd</surname><given-names>CM</given-names></name>
<name name-style="western"><surname>Lawson</surname><given-names>JR</given-names></name>
<name name-style="western"><surname>Hunter</surname><given-names>PJ</given-names></name>
<name name-style="western"><surname>Nielsen</surname><given-names>PF</given-names></name>
</person-group>             <year>2008</year>             <article-title>The CellML model repository.</article-title>             <source>Bioinformatics</source>             <volume>24</volume>             <fpage>2122</fpage>             <lpage>2123</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-LeNovre1"><label>69</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Le Novère</surname><given-names>N</given-names></name>
<name name-style="western"><surname>Finney</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Hucka</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Bhalla</surname><given-names>US</given-names></name>
<name name-style="western"><surname>Campagne</surname><given-names>F</given-names></name>
<etal/></person-group>             <year>2005</year>             <article-title>Minimum information requested in the annotation of biochemical models (MIRIAM).</article-title>             <source>Nat Biotechnol</source>             <volume>23</volume>             <fpage>1509</fpage>             <lpage>1515</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-LeNovre2"><label>70</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Le Novère</surname><given-names>N</given-names></name>
<name name-style="western"><surname>Bornstein</surname><given-names>B</given-names></name>
<name name-style="western"><surname>Broicher</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Courtot</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Donizelli</surname><given-names>M</given-names></name>
<etal/></person-group>             <year>2006</year>             <article-title>BioModels Database: a free, centralized database of curated, published, quantitative kinetic models of biochemical and cellular systems.</article-title>             <source>Nucleic Acids Res</source>             <volume>34</volume>             <fpage>D689</fpage>             <lpage>D691</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Hamill1"><label>71</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Hamill</surname><given-names>P</given-names></name>
</person-group>             <year>2004</year>             <source>Unit Test Frameworks</source>             <publisher-loc>Sebastopol, CA</publisher-loc>             <publisher-name>O'Reilly Media, Inc</publisher-name>          </element-citation></ref>
<ref id="pcbi.1000456-Djurfeldt2"><label>72</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Djurfeldt</surname><given-names>M</given-names></name>
</person-group>             <year>2009</year>             <article-title>The connection-set algebra—a novel formalism for the representation of connectivity structure in neuronal network models.</article-title>             <comment>Submitted</comment>          </element-citation></ref>
<ref id="pcbi.1000456-Weitzenfeld1"><label>73</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Weitzenfeld</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Arbib</surname><given-names>MA</given-names></name>
<name name-style="western"><surname>Alexander</surname><given-names>A</given-names></name>
</person-group>             <year>2002</year>             <source>The Neural Simulation Language: A System for Brain Modeling</source>             <publisher-loc>Cambridge, MA</publisher-loc>             <publisher-name>MIT Press</publisher-name>          </element-citation></ref>
<ref id="pcbi.1000456-Kumar1"><label>74</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kumar</surname><given-names>R</given-names></name>
</person-group>             <year>2001</year>             <article-title>A neural net compiler system for hierarchical organization.</article-title>             <source>ACM SIGPLAN Notices</source>             <volume>36</volume>             <fpage>26</fpage>             <lpage>36</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Goodhill1"><label>75</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Goodhill</surname><given-names>GJ</given-names></name>
</person-group>             <year>2007</year>             <article-title>Contributions of theoretical modeling to the understanding of neural map development.</article-title>             <source>Neuron</source>             <volume>56</volume>             <fpage>301</fpage>             <lpage>311</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Erwin1"><label>76</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Erwin</surname><given-names>E</given-names></name>
<name name-style="western"><surname>Obermayer</surname><given-names>K</given-names></name>
<name name-style="western"><surname>Schulten</surname><given-names>K</given-names></name>
</person-group>             <year>1995</year>             <article-title>Models of orientation and ocular dominance columns in the visual cortex: A critical comparison.</article-title>             <source>Neural Comput</source>             <volume>7</volume>             <fpage>425</fpage>             <lpage>468</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-DeSchutter2"><label>77</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>De Schutter</surname><given-names>E</given-names></name>
</person-group>             <year>2008</year>             <article-title>Reviewing multi-disciplinary papers: a challenge in neuroscience?</article-title>             <source>Neuroinformatics</source>             <volume>6</volume>             <fpage>253</fpage>             <lpage>255</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Miller1"><label>78</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Miller</surname><given-names>G</given-names></name>
</person-group>             <year>2006</year>             <article-title>Scientific publishing. a scientist's nightmare: software problem leads to five retractions.</article-title>             <source>Science</source>             <volume>314</volume>             <fpage>1856</fpage>             <lpage>1857</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Donoho1"><label>79</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Donoho</surname><given-names>DL</given-names></name>
<name name-style="western"><surname>Maleki</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Rahman</surname><given-names>IU</given-names></name>
<name name-style="western"><surname>Shahram</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Stodden</surname><given-names>V</given-names></name>
</person-group>             <year>2009</year>             <article-title>15 years of reproducible research in computational harmonic analysis.</article-title>             <source>Computing in Science &amp; Engineering</source>             <volume>11</volume>             <fpage>8</fpage>             <lpage>18</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Beard1"><label>80</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Beard</surname><given-names>DA</given-names></name>
<name name-style="western"><surname>Britten</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Cooling</surname><given-names>MT</given-names></name>
<name name-style="western"><surname>Garny</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Halstead</surname><given-names>MDB</given-names></name>
<etal/></person-group>             <year>2009</year>             <article-title>CellML metadata standards, associated tools and repositories.</article-title>             <source>Philos Transact A Math Phys Eng Sci</source>             <volume>367</volume>             <fpage>1845</fpage>             <lpage>1867</lpage>          </element-citation></ref>
<ref id="pcbi.1000456-Greenspan1"><label>81</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Greenspan</surname><given-names>NT</given-names></name>
</person-group>             <year>2005</year>             <source>The End of the Certain World: The Life and Science of Max Born</source>             <publisher-loc>Chichester</publisher-loc>             <publisher-name>John Wiley &amp; Sons</publisher-name>          </element-citation></ref>
</ref-list>

</back>
</article>
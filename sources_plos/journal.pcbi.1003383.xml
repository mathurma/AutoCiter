<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id><journal-title-group>
<journal-title>PLoS Computational Biology</journal-title></journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-13-00562</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1003383</article-id>
<article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Biology</subject><subj-group><subject>Computational biology</subject><subj-group><subject>Computational neuroscience</subject><subj-group><subject>Circuit models</subject></subj-group></subj-group></subj-group><subj-group><subject>Neuroscience</subject><subj-group><subject>Computational neuroscience</subject><subject>Learning and memory</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Mathematics</subject><subj-group><subject>Nonlinear dynamics</subject></subj-group><subj-group><subject>Statistics</subject><subj-group><subject>Statistical methods</subject></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Forward and Backward Inference in Spatial Cognition</article-title>
<alt-title alt-title-type="running-head">Forward and Backward Inference in Navigation</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Penny</surname><given-names>Will D.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Zeidman</surname><given-names>Peter</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Burgess</surname><given-names>Neil</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib>
</contrib-group>
<aff id="aff1"><label>1</label><addr-line>Wellcome Trust Centre for Neuroimaging, University College, London, London, United Kingdom</addr-line></aff>
<aff id="aff2"><label>2</label><addr-line>Institute for Cognitive Neuroscience, University College, London, London, United Kingdom</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Gutkin</surname><given-names>Boris S.</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group>
<aff id="edit1"><addr-line>École Normale Supérieure, College de France, CNRS, France</addr-line></aff>
<author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">w.penny@ucl.ac.uk</email></corresp>
<fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn>
<fn fn-type="con"><p>Conceived and designed the experiments: WDP. Performed the experiments: WDP. Analyzed the data: WDP. Contributed reagents/materials/analysis tools: WDP. Wrote the paper: WDP PZ NB.</p></fn>
</author-notes>
<pub-date pub-type="collection"><month>12</month><year>2013</year></pub-date>
<pub-date pub-type="epub"><day>12</day><month>12</month><year>2013</year></pub-date>
<volume>9</volume>
<issue>12</issue>
<elocation-id>e1003383</elocation-id>
<history>
<date date-type="received"><day>4</day><month>4</month><year>2013</year></date>
<date date-type="accepted"><day>23</day><month>10</month><year>2013</year></date>
</history>
<permissions>
<copyright-year>2013</copyright-year>
<copyright-holder>Penny et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple"><license-p>This is an open-access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions>
<abstract>
<p>This paper shows that the various computations underlying spatial cognition can be implemented using statistical inference in a single probabilistic model. Inference is implemented using a common set of ‘lower-level’ computations involving forward and backward inference over time. For example, to estimate where you are in a known environment, forward inference is used to optimally combine location estimates from path integration with those from sensory input. To decide which way to turn to reach a goal, forward inference is used to compute the likelihood of reaching that goal under each option. To work out which environment you are in, forward inference is used to compute the likelihood of sensory observations under the different hypotheses. For reaching sensory goals that require a chaining together of decisions, forward inference can be used to compute a state trajectory that will lead to that goal, and backward inference to refine the route and estimate control signals that produce the required trajectory. We propose that these computations are reflected in recent findings of pattern replay in the mammalian brain. Specifically, that theta sequences reflect decision making, theta flickering reflects model selection, and remote replay reflects route and motor planning. We also propose a mapping of the above computational processes onto lateral and medial entorhinal cortex and hippocampus.</p>
</abstract>
<abstract abstract-type="summary"><title>Author Summary</title>
<p>The ability of mammals to navigate is well studied, both behaviourally and in terms on the underlying neurophysiology. Navigation is a well studied topic in computational fields such as machine learning and signal processing. However, studies in computational neuroscience, which draw together these findings, have mainly focused on specific navigation tasks such as spatial localisation. In this paper, we propose a single probabilistic model which can support multiple tasks, from working out which environment you are in, to computing a sequence of motor commands that will take you to a sensory goal, such as being warm or viewing a particular object. We describe how these tasks can be implemented using a common set of lower level algorithms that implement ‘forward and backward inference over time’. We relate these algorithms to recent findings in animal electrophysiology, where sequences of hippocampal cell activations are observed before, during or after a navigation task, and these sequences are played either forwards or backwards. Additionally, one function of the hippocampus that is preserved across mammals is that it integrates spatial and non-spatial information, and we propose how the forward and backward inference algorithms naturally map onto this architecture.</p>
</abstract>
<funding-group><funding-statement>This work was supported by a core grant [number 091593/Z/10/Z] from the Wellcome Trust: <ext-link ext-link-type="uri" xlink:href="http://www.wellcome.ac.uk" xlink:type="simple">www.wellcome.ac.uk</ext-link>. NB is funded by the Wellcome Trust and EU FP7 SpaceCog, and PZ is funded by The Brain Research Trust. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="22"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>This paper describes a dynamic Bayesian model of spatial cognition. Here we define spatial cognition as including the tasks of localisation (estimating where you are in a known environment), sensory imagery (constructing a virtual scene), decision making (deciding which way to turn to reach a goal), model selection (working out which environment you are in) and motor planning (computing a sequence of motor commands that will lead to a sensory goal). We show that all of these tasks can be implemented using statistical inference in a single probabilistic model. We note that the above formulation is slightly different to previous definitions by OKeefe and Nadel <xref ref-type="bibr" rid="pcbi.1003383-OKeefe1">[1]</xref>, Gallistel <xref ref-type="bibr" rid="pcbi.1003383-Gallistel1">[2]</xref>, and Redish <xref ref-type="bibr" rid="pcbi.1003383-Redish1">[3]</xref> which stress the capacity of determining and performing a path from a current position towards a desired location.</p>
<p>The model has hidden states comprising speed, direction and allocentric location, control variables comprising change in direction and speed, and sensory states representing olfactory, somatosensory and visual information. The model describes the dynamical evolution of hidden states, and provides a mapping from hidden to sensory states. Inference in the model is then implemented using a common set of ‘lower-level’ computations involving forward and backward inference over time. We propose that these computations are reflected in recent empirical findings of pattern replay in the mammalian brain <xref ref-type="bibr" rid="pcbi.1003383-Gupta1">[4]</xref>, <xref ref-type="bibr" rid="pcbi.1003383-Buhry1">[5]</xref>. Specifically, we propose that theta sequences reflect decision making, theta flickering reflects model selection, and remote replay reflects route and motor planning. Our use of the terms ‘forward’ and ‘backward’ here relate to time and should not be confused with the direction of message passing in a cortical hierarchy <xref ref-type="bibr" rid="pcbi.1003383-Mumford1">[6]</xref>.</p>
<p>Our approach falls into the general category of ‘map-based’ or ‘model-based’ planning <xref ref-type="bibr" rid="pcbi.1003383-OKeefe1">[1]</xref>, <xref ref-type="bibr" rid="pcbi.1003383-Tolman1">[7]</xref>–<xref ref-type="bibr" rid="pcbi.1003383-Hasselmo1">[10]</xref>, or ‘model-based decision making’ <xref ref-type="bibr" rid="pcbi.1003383-vanderMeer1">[11]</xref>. The term ‘model-based’ refers to making and updating a representation of the world (such as a cognitive map). This is to be contrasted, for example, with ‘model-free’ approaches in which agents merely react to stimuli, after having previously learnt stimulus-response mappings through extensive exposure to an environment <xref ref-type="bibr" rid="pcbi.1003383-Sutton1">[12]</xref>.</p>
<p>More generally, agents will use a variety of navigation strategies depending on their cognitive capabilities and familiarity with an environment. Spatial decisions can, for example, be classified <xref ref-type="bibr" rid="pcbi.1003383-Arleo1">[13]</xref> as being cue-guided (eg. move towards the red house), stimulus triggered (eg. turn left at the red house), route based (turn left at the red house then right at the blue house). There is a good deal of evidence showing that the brain has multiple decision making or control systems, each with its own strengths and weaknesses <xref ref-type="bibr" rid="pcbi.1003383-White1">[14]</xref>–<xref ref-type="bibr" rid="pcbi.1003383-Lengyel1">[16]</xref>.</p>
<p>The usefulness of model-based planning is most apparent after an agent has sufficient experience to learn a model of an environment and when, subsequently, local changes to that environment are made which affect the optimal route to a goal <xref ref-type="bibr" rid="pcbi.1003383-Daw1">[15]</xref>. In statistical terms, these would be referred to as nonstationarities. For spatial models this could be, for example, a hole appearing in a wall enabling an agent to take a shortcut, or a new object appearing preventing an agent taking a habitual route. Another strength of model-based control is that it can reduce learning time. Tse et al. <xref ref-type="bibr" rid="pcbi.1003383-Tse1">[17]</xref>, for example, studied decision making in rats and found that learning required fewer trials when it occurred against a background of prior knowledge. This allows new information to be assimilated into an existing schema or model.</p>
<p>The model-based versus model-free distinction has become important for the study of decision making in general as the underlying neuroanatomical differences are being delineated <xref ref-type="bibr" rid="pcbi.1003383-vanderMeer1">[11]</xref>, <xref ref-type="bibr" rid="pcbi.1003383-Daw1">[15]</xref>. Khamassi and Humphries <xref ref-type="bibr" rid="pcbi.1003383-Khamassi1">[18]</xref> argue that, due to the shared underlying neuroanatomy, spatial navigation strategies that were previously described as being either place-driven or cue-driven are better thought of as being model-based versus model-free. Daw et al. <xref ref-type="bibr" rid="pcbi.1003383-Daw1">[15]</xref> propose that arbitration between model-based and model-free controllers is based on the relative uncertainty of the decisions and more recently, Pezzulo et al. <xref ref-type="bibr" rid="pcbi.1003383-Pezzulo1">[19]</xref> have embedded both types of decision making systems into a single ‘mixed instrumental controller’.</p>
<p>This paper describes the computations underlying spatial cognition, initially, at a rather abstract level of manipulations of probability densities and then employs vector and matrix representations of variables and connectivities. Although we later on go on to describe how our model relates to underlying neuronal implementations, the model itself is not specified at a neuronal level. This style of modelling has many precedents in the literature. For example, Bousquet et al. <xref ref-type="bibr" rid="pcbi.1003383-Bousquet1">[20]</xref> have conceived of the hippocampus as a Kalman filter. This requires that the hippocampus has an ‘observation model’ relating hidden states (places specified in allocentric coordinates) to sensory cues, and a dynamic model relating previous to current state via path integration. Kalman filtering then refers to the forward inference algorithm that combines path integral estimates of state with current sensory cues to provide optimal updates of the agent's location. The main function of Kalman filtering in this context is therefore one of localisation. One of the key points of this paper is that if an agent has taken the trouble to construct a ‘dynamic model’ and an ‘observation model’ then they can be used for more than just localisation; the same models, when combined with additional inference steps, can also be used for model selection, decision making and motor planning and to construct sensory imagery.</p>
<p>Other statistical treatments of hippocampal function address the issue of context learning <xref ref-type="bibr" rid="pcbi.1003383-Fuhs1">[21]</xref>. Here, a context is defined in statistical terms as a stationary distribution of experiences. The problem of context learning is then reduced to one of clustering together an agent's experiences into a finite number of contexts. This is addressed through the use of Hidden Markov Models (HMMs) and it is shown how this perspective explains experimental findings in rat navigation concerning sequence and reversal learning and place-cell remapping. Johnson et al. <xref ref-type="bibr" rid="pcbi.1003383-Johnson1">[22]</xref> provide a normative statistical model of exploratory behaviour called Information Foraging (IF). ‘Passive IF’ describes the temporal distribution of an agent's sampling process (eg. spending longer investigating novel versus familiar objects) whereas ‘Directed IF’ describes its spatial distribution (eg. where it should move to next). Additionally, IF is conceived to apply both to the environment and the agent's memory of the environment. Directed IF proposes a common hippocampal substrate for constructive memory (eg. scene construction), vicarious trial and error behaviour, model-based facilitation of memory performance, and memory consolidation. The IF framework samples spatial locations, or episodic memories using an information theoretic criterion. To compute this criterion it is necessary for the agent to possess an observation model of the sort described in our article below. A further statistical treatment of hippocampal function comprises a two-stage processing model of memory formation in the entorhinal-hippocampal loop <xref ref-type="bibr" rid="pcbi.1003383-Lorincz1">[23]</xref>. The first stage, which is proposed to take place during theta activity, allows hippocampus to temporally decorrelate and sparsify its input, and develop representations based on an Independent Component Analysis. The second stage, which is proposed to take place during Sharp Wave Ripples <xref ref-type="bibr" rid="pcbi.1003383-Buzsaki1">[24]</xref>, allows hippocampus to replay these new representations to neocortex where long term memories are held to be instantiated.</p>
<p>This paper is concerned with computational processes underlying spatial cognition and we describe how the underlying computations may be instantiated in hippocampus and associated brain regions. The hippocampal formation is, however, implicated in a much broader array of functions <xref ref-type="bibr" rid="pcbi.1003383-Andersen1">[25]</xref>, such as episodic memory, that our model does not address. Indeed one of the key differences between our approach and some other models of spatial cognition <xref ref-type="bibr" rid="pcbi.1003383-Hasselmo1">[10]</xref>, <xref ref-type="bibr" rid="pcbi.1003383-Lengyel1">[16]</xref> is that the approach we describe has no episodic component. Specifically, the sequences that are generated in our model are the result of online computation rather than memory recall. However, as we highlight in the <xref ref-type="sec" rid="s4">discussion</xref>, the interactions between episodic memory and the computations we describe would be especially interesting to examine in future work.</p>
<p>The paper is structured as follows. The computer simulations in this paper describe an agent acting in a simple two-dimensional environment. This environment produces visual, somatosensory and olfactory cues as described in the methods section on the ‘Environmental Model’. The agent then develops its own model of the environment as described in the ‘Probabilistic Model’ section. This describes the two elements of the model (i) a dynamical model describing the evolution of hidden states and (ii) a mapping from hidden states to sensory states. The section on ‘Spatial Cognition as Statistical Inference’ then describes how the various tasks of localisation, decision making (and sensory imagery), model selection and motor planning can be described in probabilistic terms. The section on ‘Forward and Backward Inference’ describes the common set of forward and backward recursions for estimating the required probability densities. The section on ‘<xref ref-type="sec" rid="s3">Results</xref>’ describes an implementation of the above algorithms and provides some numerical results. The <xref ref-type="sec" rid="s4">discussion</xref> section on ‘Neuronal Implementation’ then describes our proposal for how these algorithms are implemented in the brain and how functional connectivity among a candidate set of brain regions changes as a function of task. We conclude with a discussion of how the above computations might relate to pattern replay and what are the specific predictions of our model.</p>
</sec><sec id="s2" sec-type="methods">
<title>Methods</title>
<p>In what follows matrices are written in upper case bold type and vectors in lower case bold. Scalars are written in upper or lower case plain type. We use <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e001" xlink:type="simple"/></inline-formula> to denote a multivariate Gaussian density over the random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e002" xlink:type="simple"/></inline-formula> having mean <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e003" xlink:type="simple"/></inline-formula> and covariance <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e004" xlink:type="simple"/></inline-formula>. <xref ref-type="table" rid="pcbi-1003383-t001">Table 1</xref> provides a list of all the symbols used in the main text.</p>
<table-wrap id="pcbi-1003383-t001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003383.t001</object-id><label>Table 1</label><caption>
<title>Description of mathematical symbols used in the main text.</title>
</caption><alternatives><graphic id="pcbi-1003383-t001-1" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003383.t001" xlink:type="simple"/>
<table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/></colgroup>
<tbody>
<tr>
<td colspan="2" align="left" rowspan="1"><bold>Environmental Model</bold></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e005" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">Scaling of olfactory source</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e006" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">Allocentric location of olfactory source</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e007" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">Spatial diffusion of olfactory source</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e008" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">Sequence of sensory states from environmental model</td>
</tr>
<tr>
<td colspan="2" align="left" rowspan="1"><bold>Sensory State Variables</bold></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e009" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">Olfactory, somatosensory and visual states</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e010" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">Sensory state (comprising <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e011" xlink:type="simple"/></inline-formula>)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e012" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">Sequence of sensory states up to time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e013" xlink:type="simple"/></inline-formula> (observations or goals)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e014" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">Sensory noise</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e015" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">Variance of olfactory noise</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e016" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">Variance of somatosensory noise</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e017" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">Covariance of visual noise</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e018" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">Sensory noise covariance (blkdiag(<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e019" xlink:type="simple"/></inline-formula>))</td>
</tr>
<tr>
<td colspan="2" align="left" rowspan="1"><bold>Control Variables</bold></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e020" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">Control signal (virtual input or motor efference copy)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e021" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">Sequence of control signals up to time index <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e022" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e023" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">Estimate of control signal from backward inference</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e024" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">Uncertainty in est. of control signal from backward inference</td>
</tr>
<tr>
<td colspan="2" align="left" rowspan="1"><bold>Hidden State Variables</bold></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e025" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">Allocentric location comprising <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e026" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e027" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e028" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">Speed</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e029" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">Direction of heading</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e030" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">Hidden state (comprising <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e031" xlink:type="simple"/></inline-formula>) at time step <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e032" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e033" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">Hidden state sequence up to time index <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e034" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e035" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">Flow term describing change of state wrt. previous state</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e036" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">Flow term describing change of state wrt. input</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e037" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">Hidden state noise</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e038" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">Hidden state noise covariance</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e039" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">State estimate from path integration (forward inference)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e040" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">State estimate based on Bayes rule (forward inference)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e041" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">State estimate from backward inference</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e042" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">Covariance of state estimate from path integration</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e043" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">Covariance of state estimate from Bayes rule (forward inference)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e044" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">Covariance of state estimate from backward inference</td>
</tr>
<tr>
<td colspan="2" align="left" rowspan="1"><bold>Agent's Observation Model</bold></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e045" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">Model of environment i</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e046" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e047" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e048" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">Agent's predictions of olfactory, somatosensory and visual state</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e049" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">Agent's predictions of sensory state</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e050" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">Local linearisation of observation model</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e051" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">Precision of head direction cells</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e052" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">Output of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e053" xlink:type="simple"/></inline-formula>th head direction cell</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e054" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">Output of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e055" xlink:type="simple"/></inline-formula>th spatial basis function</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e056" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e057" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e058" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">Weights in agent's olfactory, somatosensory and visual models</td>
</tr>
</tbody>
</table>
</alternatives></table-wrap><sec id="s2a">
<title>Environmental Model</title>
<p>Computer simulations are implemented in Matlab (R2012a, The MathWorks, Inc.) and are based on an agent navigating in a simple 2D environment depicted in <xref ref-type="fig" rid="pcbi-1003383-g001">Figure 1</xref>. The location of the agent is specified using orthogonal allocentric coordinates <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e059" xlink:type="simple"/></inline-formula> and its direction of heading (clockwise from positive <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e060" xlink:type="simple"/></inline-formula>) is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e061" xlink:type="simple"/></inline-formula>. The environment contains two inner walls and four boundary walls. The agent is equipped with a touch sensor that detects the minimum Euclidian distance to a wall, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e062" xlink:type="simple"/></inline-formula>. It is also equipped with a nose that detects olfactory input, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e063" xlink:type="simple"/></inline-formula>. In this paper we consider a single olfactory source located at allocentric coordinates <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e064" xlink:type="simple"/></inline-formula>. We assume this source diffuses isotropically with scale parameter <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e065" xlink:type="simple"/></inline-formula> so that olfactory input at location <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e066" xlink:type="simple"/></inline-formula> is given by an exponential function<disp-formula id="pcbi.1003383.e067"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003383.e067" xlink:type="simple"/><label>(1)</label></disp-formula>All of the simulations use a single olfactory source with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e068" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e069" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e070" xlink:type="simple"/></inline-formula>. More realistic environments with multiple olfactory sources and turbulence <xref ref-type="bibr" rid="pcbi.1003383-Jacobs1">[26]</xref> are beyond the scope of this paper.</p>
<fig id="pcbi-1003383-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003383.g001</object-id><label>Figure 1</label><caption>
<title>Model of environment.</title>
<p>Allocentric representation (left panel) and egocentric view (right panel). The agent (white triangle) is at allocentric location <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e071" xlink:type="simple"/></inline-formula> and oriented at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e072" xlink:type="simple"/></inline-formula> degrees (clockwise relative to the positive <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e073" xlink:type="simple"/></inline-formula> axis). The environment contains two inner walls and four boundary walls. The agent is equipped with whiskers that detect the minimum Euclidian distance to a wall, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e074" xlink:type="simple"/></inline-formula>. It is also equipped with a nose that detects the signal from an olfactory source placed at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e075" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e076" xlink:type="simple"/></inline-formula> in the south-west corner of the maze (white circle). The agent also has a retina that is fixed in orientation and always aligned with the direction of heading, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e077" xlink:type="simple"/></inline-formula>. The retina provides one-dimensional visual input, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e078" xlink:type="simple"/></inline-formula> (displayed as a one-dimensional image in the right panel), from −45 to +45 degrees of visual angle around <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e079" xlink:type="simple"/></inline-formula> and comprising <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e080" xlink:type="simple"/></inline-formula> pixels.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003383.g001" position="float" xlink:type="simple"/></fig>
<p>The agent is also equipped with a retina that is aligned with the direction of heading. The retina provides one-dimensional visual input, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e081" xlink:type="simple"/></inline-formula>, from −45 to +45 degrees of visual angle around <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e082" xlink:type="simple"/></inline-formula> and comprises <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e083" xlink:type="simple"/></inline-formula> pixels. The retina provides information about the ‘colour’ of the walls within its field of view. In our simulations ‘colour’ is a scalar variable which we have displayed using colormaps for ease of visualisation. The scalar values corresponding to the various walls are 0.14 (north border), 0.29 (east border), 0.43 (south border), 0.57 (west border), 0.71 (west wall), 0.86 (east wall). These map onto the colours shown in <xref ref-type="fig" rid="pcbi-1003383-g001">Figure 1</xref> using Matlab's default colour map. Although classical laboratory navigation tasks do not involve walls with different colours, they employ extra-maze cues which enable experimental subjects to localize themselves. For the sake of simplicity, here we provide such visual information to the simulated agent by variation of wall colour.</p>
<p>The environmental model of retinal input takes the values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e084" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e085" xlink:type="simple"/></inline-formula> and produces <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e086" xlink:type="simple"/></inline-formula> using calculations based on the two-dimensional geometrical relation of the agent with the environment. This uses a simple ray-tracing algorithm. The agent then has its own predictive model of retinal input, described in the ‘vision’ section below, which predicts <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e087" xlink:type="simple"/></inline-formula> from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e088" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e089" xlink:type="simple"/></inline-formula> using a basis set expansion. The agent has similar models of olfactory and somatosensory input (see ‘Olfaction’ and ‘Touch’ below). Overall, the environmental model produces the signals <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e090" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e091" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e092" xlink:type="simple"/></inline-formula> which form the sensory inputs to the agent's spatial cognition model (see next section). We write this as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e093" xlink:type="simple"/></inline-formula> to denote sensory signals from the environment. For a sequence of signals we write <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e094" xlink:type="simple"/></inline-formula>. These sensory inputs are surrogates for the compact codes produced by predictive coding in sensory cortices <xref ref-type="bibr" rid="pcbi.1003383-McNaughton1">[27]</xref>. We emphasise that the agent has its own model of sensory input (an ‘observation model’) which is distinct from the environmental input itself. The agent's observation model is learnt from exposure to the environment.</p>
</sec><sec id="s2b">
<title>Probabilistic Model</title>
<p>We investigate agents having a model comprising two parts (i) a dynamical model and (ii) an observation model. The dynamical model describes how the agent's internal state, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e095" xlink:type="simple"/></inline-formula> is updated from the previous time step <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e096" xlink:type="simple"/></inline-formula> and motor efference copy <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e097" xlink:type="simple"/></inline-formula>. The observation model is a mapping from hidden states <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e098" xlink:type="simple"/></inline-formula> to sensory states <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e099" xlink:type="simple"/></inline-formula>. Our probabilistic model falls into the general class of discrete-time nonlinear state-space models<disp-formula id="pcbi.1003383.e100"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003383.e100" xlink:type="simple"/><label>(2)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e101" xlink:type="simple"/></inline-formula> is a control input, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e102" xlink:type="simple"/></inline-formula> is state noise and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e103" xlink:type="simple"/></inline-formula> is sensory noise. The noise components are Gaussian distributed with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e104" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e105" xlink:type="simple"/></inline-formula>. This is a Nonlinear Dynamical System (NDS) with inputs and hidden variables. We consider a series of time points <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e106" xlink:type="simple"/></inline-formula> and denote sequences of sensory states, hidden states, and controls using <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e107" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e108" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e109" xlink:type="simple"/></inline-formula>. These are also referred to as trajectories. The above equations implicitly specify the state transition probability density <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e110" xlink:type="simple"/></inline-formula> and the observation probability density <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e111" xlink:type="simple"/></inline-formula>. This latter probability depends on the agent's model of its environment, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e112" xlink:type="simple"/></inline-formula>. Together these densities comprise the agent's generative model, as depicted in <xref ref-type="fig" rid="pcbi-1003383-g002">Figure 2</xref> (top left).</p>
<fig id="pcbi-1003383-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003383.g002</object-id><label>Figure 2</label><caption>
<title>Generative model for spatial cognition.</title>
<p>The agent's dynamical model is embodied in the red arrows, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e113" xlink:type="simple"/></inline-formula>, and its observation model in the blue arrows, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e114" xlink:type="simple"/></inline-formula>. All of the agent's spatial computations are based on statistical inference in this same probabilistic generative model. The computations are defined by what variables are known (gray shading) and what the agent wishes to estimate. <bold>Sensory Imagery</bold> Given a known initial state, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e115" xlink:type="simple"/></inline-formula>, and virtual motor commands <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e116" xlink:type="simple"/></inline-formula>, the agent can generate sensory imagery <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e117" xlink:type="simple"/></inline-formula>. <bold>Decision Making</bold> Given initial state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e118" xlink:type="simple"/></inline-formula>, a sequence of putative motor commands <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e119" xlink:type="simple"/></inline-formula> (eg. left turn), and sensory goals <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e120" xlink:type="simple"/></inline-formula>, an agent can compute the likelihood of attaining those goals given <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e121" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e122" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e123" xlink:type="simple"/></inline-formula>. This computation requires a single sweep of forward inference. The agent can then repeat this for a second putative motor sequence (eg. right turn), and decide which turn to take based on the likelihood ratio. <bold>Model Selection</bold> Here, the agent has made observations <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e124" xlink:type="simple"/></inline-formula> and computes the likelihood ratio under two different models of the environment. <bold>Planning</bold> can be formulated as estimation of a density over actions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e125" xlink:type="simple"/></inline-formula> given current state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e126" xlink:type="simple"/></inline-formula> and desired sensory states, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e127" xlink:type="simple"/></inline-formula>. This requires a forward sweep to compute the hidden states that are commensurate with the goals, and a backward sweep to compute the motor commands that will produce the required hidden state trajectory.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003383.g002" position="float" xlink:type="simple"/></fig><sec id="s2b1">
<title>Path integration</title>
<p>During spatial localisation, an agent's current location can be computed using path integration. This takes the previous location, direction of heading, velocity and elapsed time and uses them to compute current position, by integrating the associated differential equation. We assume that the agent is in receipt of a control signal <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e128" xlink:type="simple"/></inline-formula> which delivers instructions to change direction, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e129" xlink:type="simple"/></inline-formula>, and speed, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e130" xlink:type="simple"/></inline-formula>. During navigation, for example, these signals will correspond to motor efference copy. Later we will show how these control signals can be inferred by conditioning on desirable future events (i.e. how the agent performs planning). For the moment we assume the controls are known. The dynamical model is<disp-formula id="pcbi.1003383.e131"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003383.e131" xlink:type="simple"/><label>(3)</label></disp-formula>Here the state variables are two orthogonal axes of allocentric location, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e132" xlink:type="simple"/></inline-formula>, speed <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e133" xlink:type="simple"/></inline-formula> and direction <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e134" xlink:type="simple"/></inline-formula> (clockwise angle relative to the positive <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e135" xlink:type="simple"/></inline-formula> axis). Motion is also subject to frictional forces as defined by the constant <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e136" xlink:type="simple"/></inline-formula>. We set <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e137" xlink:type="simple"/></inline-formula>. We can write a state vector <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e138" xlink:type="simple"/></inline-formula>. The control signals <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e139" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e140" xlink:type="simple"/></inline-formula> change the agent's speed and direction. We can write<disp-formula id="pcbi.1003383.e141"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003383.e141" xlink:type="simple"/><label>(4)</label></disp-formula>which can be integrated to form a discrete-time representation<disp-formula id="pcbi.1003383.e142"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003383.e142" xlink:type="simple"/><label>(5)</label></disp-formula>using local linearisation as described in <xref ref-type="supplementary-material" rid="pcbi.1003383.s001">Text S1</xref>. If the deterministic component of the dynamics is originally described using differential equations, the flow terms <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e143" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e144" xlink:type="simple"/></inline-formula> can be computed as shown in <xref ref-type="supplementary-material" rid="pcbi.1003383.s001">Text S1</xref>. Here <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e145" xlink:type="simple"/></inline-formula> describes how the current hidden state depends on the previous hidden state, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e146" xlink:type="simple"/></inline-formula> how it depends on the previous input. An example of using the above equations for implementing path integration is described in the ‘Sensory Imagery’ simulation section below. Errors in path integration, perhaps due to inaccuracies in the representation of time or in local linearisation, can also be included, i.e.<disp-formula id="pcbi.1003383.e147"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003383.e147" xlink:type="simple"/><label>(6)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e148" xlink:type="simple"/></inline-formula> is a random variable. This corresponds to a locally linearised version of <xref ref-type="disp-formula" rid="pcbi.1003383.e100">equation 2</xref>. For the results in this paper we used a local regression method, due to Schaal et al. <xref ref-type="bibr" rid="pcbi.1003383-Schaal1">[28]</xref>, to compute <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e149" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e150" xlink:type="simple"/></inline-formula> as this resulted in more robust estimates. This is described in <xref ref-type="supplementary-material" rid="pcbi.1003383.s001">Text S1</xref>.</p>
</sec><sec id="s2b2">
<title>Multisensory input</title>
<p>We consider agents with sensory states, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e151" xlink:type="simple"/></inline-formula> having olfactory, somatosensory and visual components. Sensory states will typically be low-dimensional codes that index richer multimodal representations in sensory cortices. During navigation and model selection these will correspond to inputs from the environmental model, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e152" xlink:type="simple"/></inline-formula>. During decision making and motor planning these will correspond to internally generated sensory goals. The agent associates hidden states with sensory states using the mapping <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e153" xlink:type="simple"/></inline-formula>, a nonlinear function of the state variables. We have<disp-formula id="pcbi.1003383.e154"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003383.e154" xlink:type="simple"/><label>(7)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e155" xlink:type="simple"/></inline-formula> is zero-mean Gaussian noise with covariance <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e156" xlink:type="simple"/></inline-formula>. During localisation and model selection <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e157" xlink:type="simple"/></inline-formula> corresponds to the agent's prediction of its sensory input, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e158" xlink:type="simple"/></inline-formula> specifies the covariance of the prediction errors. These predictions can be split into modality-specific components <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e159" xlink:type="simple"/></inline-formula> with associated prediction errors having (co-)variances <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e160" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e161" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e162" xlink:type="simple"/></inline-formula>. <xref ref-type="disp-formula" rid="pcbi.1003383.e154">Equation 7</xref> defines the likelihood<disp-formula id="pcbi.1003383.e163"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003383.e163" xlink:type="simple"/><label>(8)</label></disp-formula>We assume the different modalities are independent given the state so that<disp-formula id="pcbi.1003383.e164"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003383.e164" xlink:type="simple"/><label>(9)</label></disp-formula>where<disp-formula id="pcbi.1003383.e165"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003383.e165" xlink:type="simple"/><label>(10)</label></disp-formula>so that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e166" xlink:type="simple"/></inline-formula>. We now describe the agent's model for generating the predictions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e167" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e168" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e169" xlink:type="simple"/></inline-formula>. Olfactory input is predicted using a basis set<disp-formula id="pcbi.1003383.e170"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003383.e170" xlink:type="simple"/><label>(11)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e171" xlink:type="simple"/></inline-formula> is the number of basis functions, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e172" xlink:type="simple"/></inline-formula> is the location, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e173" xlink:type="simple"/></inline-formula> are parameters of the olfactory model. Here we use a local basis function representation where<disp-formula id="pcbi.1003383.e174"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003383.e174" xlink:type="simple"/></disp-formula>is the response of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e175" xlink:type="simple"/></inline-formula>th basis cell. Following Foster et al. <xref ref-type="bibr" rid="pcbi.1003383-Foster1">[29]</xref> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e176" xlink:type="simple"/></inline-formula> may be viewed as an idealised place cell output, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e177" xlink:type="simple"/></inline-formula> is the spatial location of the centre of cell i's place field, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e178" xlink:type="simple"/></inline-formula> its breadth. We assume that the parameters governing the location and width of these cells have been set in a previous learning phase. In this paper we used <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e179" xlink:type="simple"/></inline-formula> and the centres of the place fields <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e180" xlink:type="simple"/></inline-formula> were arranged to form a 10-by-10 grid in allocentric space. The same set of cells were used as a basis for predicting olfactory, somatosensory and visual input.</p>
<p>The parameters <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e181" xlink:type="simple"/></inline-formula> will have to be learnt for each new environment. For the results in this paper they are learnt using a regression approach, which assumes knowledge of the agent's location. More generally, they will have to be learnt without such knowledge and on a slower time scale than (or after learning of) the place cell centres and widths. This is perfectly feasible but beyond the scope of the current paper. We return to this issue in the <xref ref-type="sec" rid="s4">discussion</xref>.</p>
<p>In the agent's model, somatosensory input is predicted using a basis set<disp-formula id="pcbi.1003383.e182"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003383.e182" xlink:type="simple"/><label>(12)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e183" xlink:type="simple"/></inline-formula> are the parameters of the somatosensory model. Here we envisage that processing in somatosensory cortex is sufficiently sophisticated to deliver a signal <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e184" xlink:type="simple"/></inline-formula> that is the minimum distance to a physical boundary. If the agent had whiskers, a simple function of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e185" xlink:type="simple"/></inline-formula> would correspond to the amount of whisker-related neural activity. More sophisticated generative models of somatosensory input would have a directional, and perhaps a dynamic component. But this is beyond the scope of the current paper.</p>
<p>The agent's retina is aligned with the direction of heading, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e186" xlink:type="simple"/></inline-formula>. The retina provides one-dimensional visual input, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e187" xlink:type="simple"/></inline-formula>, from −45 to +45 degrees of visual angle around <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e188" xlink:type="simple"/></inline-formula> and comprising <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e189" xlink:type="simple"/></inline-formula> pixels. An example of retinal input is shown in the right panel of <xref ref-type="fig" rid="pcbi-1003383-g001">Figure 1</xref>. The agent's prediction of this visual input is provided by a weighted conjunction of inputs from populations of place/grid and head direction cells. The head direction cells are defined as<disp-formula id="pcbi.1003383.e190"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003383.e190" xlink:type="simple"/><label>(13)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e191" xlink:type="simple"/></inline-formula> is the preferred angle of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e192" xlink:type="simple"/></inline-formula>th basis function and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e193" xlink:type="simple"/></inline-formula> defines the range of angles to which it is sensitive. The output for retinal angle <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e194" xlink:type="simple"/></inline-formula> is given simply by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e195" xlink:type="simple"/></inline-formula>. Visual input at retinal angle <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e196" xlink:type="simple"/></inline-formula> is then predicted to be<disp-formula id="pcbi.1003383.e197"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003383.e197" xlink:type="simple"/><label>(14)</label></disp-formula>This sort of conjunctive representation is widely used to provide transformations among coordinate systems and, for sensorimotor transforms, is thought to be supported by parietal cortex <xref ref-type="bibr" rid="pcbi.1003383-Pouget1">[30]</xref>. The above mapping is adaptable and can be optimised by choosing appropriate weights <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e198" xlink:type="simple"/></inline-formula> and these will have to be learnt for each new environment.</p>
<p>It is a gross simplification to predict retinal input, or egocentric views, with a single stage of computation as in the above equation. More realistic models of this process <xref ref-type="bibr" rid="pcbi.1003383-Becker1">[31]</xref>, <xref ref-type="bibr" rid="pcbi.1003383-Byrne1">[32]</xref> propose separate representations of the spatial and textural components of landmarks, with bilateral connectivity to cells in a parietal network which effect a transform between allocentric and egocentric coordinates. Egocentric view cells are then also connected to this parietal network. This level of detail is omitted from our current model, as our aim is to focus on temporal dynamics.</p>
<p>Overall, the agent's model of multisensory input has parameters <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e199" xlink:type="simple"/></inline-formula>. For each new environment, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e200" xlink:type="simple"/></inline-formula>, the agent has a separate set of parameters. Experiments on rats have found that changes to the environment cause changes in the pattern of firing of place cells <xref ref-type="bibr" rid="pcbi.1003383-Bostock1">[33]</xref>, <xref ref-type="bibr" rid="pcbi.1003383-Leutgeb1">[34]</xref>. This could happen in our model if the cells fire at rates <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e201" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e202" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e203" xlink:type="simple"/></inline-formula> and the parameters <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e204" xlink:type="simple"/></inline-formula> are updated to reflect changes in sensory features. In the simulations that follow the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e205" xlink:type="simple"/></inline-formula> parameters are set using a separate learning phase prior to spatial cognition. More detailed models of this learning process propose that cells in the dentate gyrus select which CA3 cells will be engaged for encoding a new environment <xref ref-type="bibr" rid="pcbi.1003383-Kali1">[35]</xref>. Connections from EC to selected CA3 cells are then updated to learn the relevant place-landmark associations.</p>
</sec></sec><sec id="s2c">
<title>Spatial Cognition as Statistical Inference</title>
<p>This section describes, initially at the level of manipulations of probability densities, how the various computations underlying spatial cognition can be implemented. It then describes a practical algorithm based on local linearisation. If an agent has a probabilistic model of its environment, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e206" xlink:type="simple"/></inline-formula>, then the various tasks that together comprise spatial cognition are optimally implemented using statistical inference in that model. These inferences will be optimal in the sense of maximising likelihood. The various tasks - localisation, imagery, decision making, model selection and planning - all rely on the same statistical model. They are differentiated by what variables are known and what the agent wishes to compute. This is depicted in the panels in <xref ref-type="fig" rid="pcbi-1003383-g002">Figure 2</xref> where shaded circles denote known quantities. Additionally, for each task, the information entering the system may be of a different nature. For example, for imagery, the inputs, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e207" xlink:type="simple"/></inline-formula>, are virtual motor commands and for localisation they are motor efference copies. Similarly, during localisation and model selection the agent receives inputs from sensory cortices. For the simulations in this paper these come from the environmental model, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e208" xlink:type="simple"/></inline-formula>. However, during decision making and motor planning these inputs do not derive from the agent's environment but are generated internally and correspond to the agent's goals <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e209" xlink:type="simple"/></inline-formula>.</p>
<sec id="s2c1">
<title>Localisation</title>
<p>The use of dynamic models with hidden states for spatial localisation is well established in the literature <xref ref-type="bibr" rid="pcbi.1003383-Bousquet1">[20]</xref>, <xref ref-type="bibr" rid="pcbi.1003383-Oore1">[36]</xref>, <xref ref-type="bibr" rid="pcbi.1003383-DurrantWhyte1">[37]</xref>. Estimation of spatial location requires motor efference copy <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e210" xlink:type="simple"/></inline-formula>, and sensory input <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e211" xlink:type="simple"/></inline-formula>. The initial location <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e212" xlink:type="simple"/></inline-formula> may be known or specified with some degree of uncertainty. Forward inference over states (in time) can then be used to optimally combine probabilistic path integration with sensory input to estimate location. This produces the density <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e213" xlink:type="simple"/></inline-formula>. A Gaussian approximation to this density based on a local linearisation is described below in the section on forward inference over states (see <xref ref-type="disp-formula" rid="pcbi.1003383.e262">equation 24</xref>). The agent's best estimate of its location is then given by the maximum likelihood estimate<disp-formula id="pcbi.1003383.e214"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003383.e214" xlink:type="simple"/><label>(15)</label></disp-formula>We refer to this as a maximum likelihood estimate because there is no distribution over <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e215" xlink:type="simple"/></inline-formula> prior to observing the sequence <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e216" xlink:type="simple"/></inline-formula>. This is commensurate with standard terminology <xref ref-type="bibr" rid="pcbi.1003383-Bishop1">[38]</xref>. However, one could also think of this as a posterior estimate, due to the sequential nature of the estimation process (see below), in that there is a distribution over <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e217" xlink:type="simple"/></inline-formula> prior to the observation at a single time point <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e218" xlink:type="simple"/></inline-formula>. For the Gaussian approximation to this density, we have <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e219" xlink:type="simple"/></inline-formula> where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e220" xlink:type="simple"/></inline-formula> is the mean of the Gaussian.</p>
<p>It is also possible to improve the above estimates retrospectively<disp-formula id="pcbi.1003383.e221"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003383.e221" xlink:type="simple"/><label>(16)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e222" xlink:type="simple"/></inline-formula>. For example, upon leaving an underground metro system and turning left you may not know that you are heading north until you encounter a familiar landmark. You can then use this observation to update your estimate about where you have been previously. Estimation of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e223" xlink:type="simple"/></inline-formula> requires forward and backward inference over hidden states (see <xref ref-type="disp-formula" rid="pcbi.1003383.e285">equation 30</xref>). The Gaussian approximation to this density has mean <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e224" xlink:type="simple"/></inline-formula>, so that under the local linear approximation we have <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e225" xlink:type="simple"/></inline-formula>.</p>
</sec><sec id="s2c2">
<title>Decision making</title>
<p>Given initial state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e226" xlink:type="simple"/></inline-formula>, a sequence of putative motor commands <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e227" xlink:type="simple"/></inline-formula> (eg. left turn), and sensory goals <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e228" xlink:type="simple"/></inline-formula>, an agent can compute the likelihood of attaining those goals, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e229" xlink:type="simple"/></inline-formula>. This computation requires a single sweep (or ‘replay’ - see <xref ref-type="sec" rid="s4">discussion</xref>) of forward inference (see <xref ref-type="disp-formula" rid="pcbi.1003383.e275">equation 29</xref> in the section on ‘Likelihood’ below). The agent can then repeat this for a second putative motor sequence (eg. right turn), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e230" xlink:type="simple"/></inline-formula>, and decide which turn to take based on the likelihood ratio.<disp-formula id="pcbi.1003383.e231"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003383.e231" xlink:type="simple"/><label>(17)</label></disp-formula>Here <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e232" xlink:type="simple"/></inline-formula> are internally generated task goals rather than sensory input from the environment <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e233" xlink:type="simple"/></inline-formula>. Decisions based on the likelihood ratio are statistically optimal <xref ref-type="bibr" rid="pcbi.1003383-Bishop1">[38]</xref>. In probabilistic models of sequential data the likelihood can be computed by a single forward pass of inference, as described below. We would therefore need two forward passes to compute the LR, one for each putative motor sequence.</p>
<p>This formulation of decision making is based on sets of motor primitives being combined to form actions such as ‘turn left’ or ‘turn right’. This can therefore also be regarded as motor planning (see below) at some higher level. Additionally, the generation of sensory imagery can be viewed as a component of decision making because, to evaluate the likelihood, sensory goals must be compared with sensory predictions from the agent's generative model. In later sections we consider sensory imagery in its own right.</p>
</sec><sec id="s2c3">
<title>Model selection</title>
<p>Given motor efference copy <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e234" xlink:type="simple"/></inline-formula>, and sensory input <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e235" xlink:type="simple"/></inline-formula> the agent computes the likelihood ratio under two different models of the environment. The agent's best estimate of which environment it is in, is given by the maximum likelihood estimate<disp-formula id="pcbi.1003383.e236"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003383.e236" xlink:type="simple"/><label>(18)</label></disp-formula>For consistency with terminology in statistics, we refer to this as model selection. This can be implemented using multiple sweeps of forward inference, one for each potential environment. The likelihood can be computed, for example, for two maze models <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e237" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e238" xlink:type="simple"/></inline-formula> each hypothesising that the agent is in a particular environment. To decide which environment the observations are drawn from one can compute the likelihood ratio<disp-formula id="pcbi.1003383.e239"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003383.e239" xlink:type="simple"/><label>(19)</label></disp-formula>where each probability is computed using <xref ref-type="disp-formula" rid="pcbi.1003383.e275">equation 29</xref> in the section on ‘Likelihood’ below.</p>
</sec><sec id="s2c4">
<title>Motor planning</title>
<p>Given current state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e240" xlink:type="simple"/></inline-formula> and sensory goals, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e241" xlink:type="simple"/></inline-formula>, planning can be formulated as estimation of a density over actions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e242" xlink:type="simple"/></inline-formula>, as depicted in <xref ref-type="fig" rid="pcbi-1003383-g002">Figure 2</xref>. This requires a forward sweep to compute the hidden states that are commensurate with the goals, and a backward sweep to compute the motor commands that will produce the required hidden state trajectory. This is described in the section below on ‘Inference over Inputs’ and can be implemented using <xref ref-type="disp-formula" rid="pcbi.1003383.e315">equations 33</xref> and <xref ref-type="disp-formula" rid="pcbi.1003383.e318">34</xref>. The agent's best estimate of the motor commands needed to attain sensory goals <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e243" xlink:type="simple"/></inline-formula> is given by the maximum likelihood estimate<disp-formula id="pcbi.1003383.e244"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003383.e244" xlink:type="simple"/><label>(20)</label></disp-formula>Here <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e245" xlink:type="simple"/></inline-formula> are internally generated task goals rather than sensory input from the environment <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e246" xlink:type="simple"/></inline-formula>.</p>
</sec></sec><sec id="s2d">
<title>Forward and Backward Inference</title>
<p><xref ref-type="supplementary-material" rid="pcbi.1003383.s002">Text S2</xref> describes how the required probability densities can be computed at the very general level of manipulations of probability densities. However, these operations cannot be implemented exactly. They can only be implemented approximately and there are basically two types of approximate inference methods. These are based either on sampling <xref ref-type="bibr" rid="pcbi.1003383-Doucet1">[39]</xref> or Local Linearization (LL) <xref ref-type="bibr" rid="pcbi.1003383-Einicke1">[40]</xref>. In this paper we adopt an LL approach although this is not without disadvantages. We return to this important issue in the <xref ref-type="sec" rid="s4">discussion</xref>. The following subsections describe the forward and backward inference algorithms under LL assumptions. Readers unfamiliar with statistical inference for dynamical systems models may benefit from textbook material <xref ref-type="bibr" rid="pcbi.1003383-Bishop1">[38]</xref>.</p>
<sec id="s2d1">
<title>Forward inference over hidden states</title>
<p>The problem of estimating the hidden states given current and previous sensory states is solved using Forward Inference. This produces the marginal densities <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e247" xlink:type="simple"/></inline-formula>. Estimation of the state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e248" xlink:type="simple"/></inline-formula> is based <italic>only</italic> on information up to that time point. For Linear Dynamical Systems (LDS), forward inference corresponds to the Kalman Filter, and for nonlinear dynamical systems under LL, forward inference can be instantiated using an Extended Kalman Filter (EKF) <xref ref-type="bibr" rid="pcbi.1003383-Einicke1">[40]</xref>. After local linearisation the state-space model can be written as<disp-formula id="pcbi.1003383.e249"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003383.e249" xlink:type="simple"/><label>(21)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e250" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e251" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e252" xlink:type="simple"/></inline-formula> are Jacobian matrices (see <xref ref-type="supplementary-material" rid="pcbi.1003383.s001">Text S1</xref> and below). There is a long history of applying KFs, EKFs and related state-space models to the problem of localisation <xref ref-type="bibr" rid="pcbi.1003383-Bousquet1">[20]</xref>, <xref ref-type="bibr" rid="pcbi.1003383-Oore1">[36]</xref>. Indeed one of the key implementations of the KF is for solving the localisation problem. These probabilistic algorithms have been used in a formalism known as Simultaneous Localisation and Mapping (SLAM) <xref ref-type="bibr" rid="pcbi.1003383-DurrantWhyte1">[37]</xref>. The goal of SLAM research is to develop an algorithm that would allow an agent to explore and map novel environments.</p>
<p>In the context of localisation, forward inference allows information from path integration and sensory input to be combined in an optimal way. Under a local linear approximation the state estimates are Gaussian<disp-formula id="pcbi.1003383.e253"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003383.e253" xlink:type="simple"/><label>(22)</label></disp-formula>and these quantities can be estimated recursively using an EKF. Here <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e254" xlink:type="simple"/></inline-formula> is the agent's estimate of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e255" xlink:type="simple"/></inline-formula> based only on information up to time index <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e256" xlink:type="simple"/></inline-formula>. The covariance <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e257" xlink:type="simple"/></inline-formula> quantifies the agent's uncertainty about <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e258" xlink:type="simple"/></inline-formula>, again based on information up to that time point. The agent's best estimate of location, based on forward inference, is then given by the first two entries in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e259" xlink:type="simple"/></inline-formula> (the third and fourth entries are speed and direction, see <xref ref-type="disp-formula" rid="pcbi.1003383.e131">equation 3</xref>). The EKF equations can be expressed in two steps. The first is a prediction step<disp-formula id="pcbi.1003383.e260"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003383.e260" xlink:type="simple"/><label>(23)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e261" xlink:type="simple"/></inline-formula> is the state noise covariance defined earlier. During localisation this corresponds to probabilistic path integration. The second is a correction step<disp-formula id="pcbi.1003383.e262"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003383.e262" xlink:type="simple"/><label>(24)</label></disp-formula>where the ‘Kalman Gain’ is<disp-formula id="pcbi.1003383.e263"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003383.e263" xlink:type="simple"/><label>(25)</label></disp-formula>and the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e264" xlink:type="simple"/></inline-formula>th entry in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e265" xlink:type="simple"/></inline-formula> is given by<disp-formula id="pcbi.1003383.e266"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003383.e266" xlink:type="simple"/><label>(26)</label></disp-formula>evaluated at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e267" xlink:type="simple"/></inline-formula>. The correction step provides optimal combination of probabilistic path integration with sensory input. More specifically, probabilistic path integration produces an estimate of the current state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e268" xlink:type="simple"/></inline-formula>. The agent produces a prediction of sensory input <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e269" xlink:type="simple"/></inline-formula> and compares it with actual sensory input <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e270" xlink:type="simple"/></inline-formula>. The final estimate of the current state is then <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e271" xlink:type="simple"/></inline-formula> plus the Kalman gain times the prediction error <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e272" xlink:type="simple"/></inline-formula>. This very naturally follows predictive coding principles, as described below in the section on Neuronal Implementation. Together, the above updates implement an EKF and these recursions are initialised by specifying the initial distribution over hidden states.<disp-formula id="pcbi.1003383.e273"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003383.e273" xlink:type="simple"/><label>(27)</label></disp-formula></p>
</sec><sec id="s2d2">
<title>Likelihood</title>
<p>As described in <xref ref-type="supplementary-material" rid="pcbi.1003383.s002">Text S2</xref>, we can use the predictive densities to compute the likelihood of a data sequence. Under local linearisation the predictive density is given by<disp-formula id="pcbi.1003383.e274"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003383.e274" xlink:type="simple"/><label>(28)</label></disp-formula>The log-likelihood of a sequence of observations is then<disp-formula id="pcbi.1003383.e275"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003383.e275" xlink:type="simple"/><label>(29)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e276" xlink:type="simple"/></inline-formula> is the prediction error. The (log) likelihood of sensory input <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e277" xlink:type="simple"/></inline-formula> can thus be computed using <xref ref-type="disp-formula" rid="pcbi.1003383.e275">equation 29</xref>. The first term in this equation corresponds to an accumulation of sum-squared prediction errors weighted by the inverse variance (precision). During decision making, the likelihood of attaining sensory goals <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e278" xlink:type="simple"/></inline-formula> under a proposed control sequence <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e279" xlink:type="simple"/></inline-formula> is computed using this method. During model selection, the likelihood of sensory observations <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e280" xlink:type="simple"/></inline-formula>, under a proposed model of the environment, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e281" xlink:type="simple"/></inline-formula>, is also computed using this method.</p>
</sec><sec id="s2d3">
<title>Backward inference over hidden states</title>
<p>Forward inference over the states is used to estimate a distribution over <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e282" xlink:type="simple"/></inline-formula> using all observations up to time point <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e283" xlink:type="simple"/></inline-formula>. Backward inference over the states can then be used to improve these estimates by using observations up to time point <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e284" xlink:type="simple"/></inline-formula> i.e. future observations. The resulting estimates are therefore retrospective. An example of when this retrospective updating is beneficial is when the observation of a new landmark disambiguates where you have previously been located. For locally linear systems, Backward Inference over states is implemented using<disp-formula id="pcbi.1003383.e285"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003383.e285" xlink:type="simple"/><label>(30)</label></disp-formula>Here, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e286" xlink:type="simple"/></inline-formula> is the optimal state estimate given all sensory data up to time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e287" xlink:type="simple"/></inline-formula>. Intuitively, the state estimate based on data up to time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e288" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e289" xlink:type="simple"/></inline-formula>, is improved upon based on state estimates at future time points (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e290" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e291" xlink:type="simple"/></inline-formula>). The resulting sequence <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e292" xlink:type="simple"/></inline-formula> will provide more accurate state estimates than those based on purely forward inference, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e293" xlink:type="simple"/></inline-formula>.</p>
<p>The above formulae are known as the ‘gamma recursions’ (see <xref ref-type="supplementary-material" rid="pcbi.1003383.s002">Text S2</xref>). An alternative algorithm for computing <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e294" xlink:type="simple"/></inline-formula>, based on the ‘beta recursions’, requires storage of the data sequence <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e295" xlink:type="simple"/></inline-formula> and so is not an online algorithm. The gamma recursions may therefore have a simpler neuronal implementation (see below).</p>
<p>The above recursions depend on a number of quantities from forward inference. These are <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e296" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e297" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e298" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e299" xlink:type="simple"/></inline-formula>. The gamma recursions are initialised with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e300" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e301" xlink:type="simple"/></inline-formula>. For an LDS the above equations constitute the well-known Rauch-Tung-Striebel (RTS) smoother. Various reparameterisations can be made to remove computation of matrix inverses <xref ref-type="bibr" rid="pcbi.1003383-Briers1">[41]</xref>. A predictive coding interpretation is readily applied to the second row of the above equation. The backward estimate <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e302" xlink:type="simple"/></inline-formula> is equal to the forward estimate <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e303" xlink:type="simple"/></inline-formula> plus a correction term which is given by a learning rate matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e304" xlink:type="simple"/></inline-formula> times a prediction error. This prediction error is the difference between the estimate of the next state based on the entire data sequence, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e305" xlink:type="simple"/></inline-formula>, minus the prediction of the next state based only on data up to the current time point, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e306" xlink:type="simple"/></inline-formula>.</p>
</sec><sec id="s2d4">
<title>Inference over inputs</title>
<p>This section describes forward and backward inference over hidden states and inputs. If the controls are unknown we can estimate them by computing <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e307" xlink:type="simple"/></inline-formula> where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e308" xlink:type="simple"/></inline-formula> is the current state and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e309" xlink:type="simple"/></inline-formula> are the desired sensory states. This probability can be computed via forward and backward inference in the following locally linearised model<disp-formula id="pcbi.1003383.e310"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003383.e310" xlink:type="simple"/><label>(31)</label></disp-formula>with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e311" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e312" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e313" xlink:type="simple"/></inline-formula>. The initial control values are distributed as<disp-formula id="pcbi.1003383.e314"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003383.e314" xlink:type="simple"/><label>(32)</label></disp-formula>Informally, the forward sweep is necessary to compute the hidden states that are commensurate with sensory goals, and the backward sweep for computing the inputs that will produce the required state trajectory. <xref ref-type="supplementary-material" rid="pcbi.1003383.s003">Text S3</xref> shows how inferences about the unknown controls can be made by creating an augmented state-space model and using the previously described equations for forward and backward inference over the states. The density over estimated inputs is a Gaussian<disp-formula id="pcbi.1003383.e315"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003383.e315" xlink:type="simple"/><label>(33)</label></disp-formula>with mean <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e316" xlink:type="simple"/></inline-formula> and covariance <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e317" xlink:type="simple"/></inline-formula>. In the absence of correlations between inputs and hidden states the backward inference formulae have the simplified form<disp-formula id="pcbi.1003383.e318"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003383.e318" xlink:type="simple"/><label>(34)</label></disp-formula></p>
<p>Effectively, the optimal inputs are estimated using a model-based deconvolution of the desired sensory states.</p>
</sec></sec></sec><sec id="s3">
<title>Results</title>
<p>This section describes computer simulations showing how the agent's model can be used to generate visual imagery, and how inference in that model can implement decision making, model selection and motor planning. Here, ‘model selection’ refers to estimating which model of the environment is most likely given sensory data. An agent would use this to figure out what maze it was in.</p>
<p>In what follows we assume the agent is already equipped with the correct dynamical model <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e319" xlink:type="simple"/></inline-formula>. The first section below describes a preliminary learning phase in which the sensory mapping <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e320" xlink:type="simple"/></inline-formula> is learnt for a given environment <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e321" xlink:type="simple"/></inline-formula>. Once the agent has a dynamical and a sensory mapping it is in effect equipped with a model of its environment which can be thought of as its own virtual reality system. It can then predict the sensory consequences of the control signals it receives.</p>
<p>The degree to which each sensory modality is used in the following simulations is determined by the relative values of observation noise covariance (see <xref ref-type="supplementary-material" rid="pcbi.1003383.s004">Text S4</xref> for details). Here we set <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e322" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e323" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e324" xlink:type="simple"/></inline-formula> (see <xref ref-type="disp-formula" rid="pcbi.1003383.e165">equation 10</xref>). This means that the agent is guided most by olfaction and touch, and least by vision. Note, however, that as there are many more visual than somatosensory or olfactory inputs this differential weighting is perhaps less distinct than it might first appear. All the simulations use <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e325" xlink:type="simple"/></inline-formula> time points with a time step of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e326" xlink:type="simple"/></inline-formula>. The simulations also used a very low level of dynamical noise, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e327" xlink:type="simple"/></inline-formula>, except for the planning example where we used <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e328" xlink:type="simple"/></inline-formula>.</p>
<sec id="s3a">
<title>Sensory Imagery</title>
<p>This section describes a preliminary learning phase in which an agent is exposed to an environment to learn the sensory mapping from states <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e329" xlink:type="simple"/></inline-formula> to observations <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e330" xlink:type="simple"/></inline-formula>. Here the agent is provided with the observations <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e331" xlink:type="simple"/></inline-formula> and also exact knowledge of the hidden states <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e332" xlink:type="simple"/></inline-formula>. More realistic simulations would also require the agent to infer the hidden states <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e333" xlink:type="simple"/></inline-formula> whilst learning. This is in principle straightforward but is beyond the scope of the current paper, as our focus is on temporal dynamics. We return to this point in the <xref ref-type="sec" rid="s4">discussion</xref>.</p>
<p>The olfactory and sensorimotor models use a 10-by-10 grid of basis cells giving 100 cells in all. We assume that the parameters governing the location and width of these cells have been set in a previous learning phase. The weight vectors <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e334" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e335" xlink:type="simple"/></inline-formula> (see <xref ref-type="disp-formula" rid="pcbi.1003383.e170">equations 11</xref> and <xref ref-type="disp-formula" rid="pcbi.1003383.e182">12</xref>) were optimised using least squares regression and 225 training exemplars with uniform spatial sampling. The retinal model used the same number and location of basis cells. It additionally used 32 head direction cells each having a directional precision parameter <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e336" xlink:type="simple"/></inline-formula>. The conjunctive representation comprised 3200 basis cells. The weight vector <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e337" xlink:type="simple"/></inline-formula> (see <xref ref-type="disp-formula" rid="pcbi.1003383.e197">equation 14</xref>) was optimised using least squares and a training set comprising 10,575 exemplars. These were generated from spatial positions taken uniformly throughout the maze. Visual input from the environmental model for multiple directions at each spatial location was used to create the training examples. At the end of this learning phase the agent is exquisitely familiar with the environment.</p>
<p>A trained model can then be used to generate visual imagery. This is implemented by specifying a synthetic control sequence, running path integration and generating predictions from the model. For example, <xref ref-type="fig" rid="pcbi-1003383-g003">Figure 3A</xref> shows a control sequence that is used to generate the ‘north-east’ trajectory shown in <xref ref-type="fig" rid="pcbi-1003383-g003">Figure 3C</xref>. We also generated ‘north-west’, ‘south-west’ and ‘south-east’ trajectories by changing the sign of direction change, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e338" xlink:type="simple"/></inline-formula>, and/or the initial direction, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e339" xlink:type="simple"/></inline-formula>.</p>
<fig id="pcbi-1003383-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003383.g003</object-id><label>Figure 3</label><caption>
<title>Visual imagery.</title>
<p>(A) Control sequence used to generate visual imagery for the ‘north-east’ trajectory. The input signals are acceleration, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e340" xlink:type="simple"/></inline-formula>, and change in direction, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e341" xlink:type="simple"/></inline-formula>. These control signals change the agent's state according to <xref ref-type="disp-formula" rid="pcbi.1003383.e131">equation 3</xref>. (B) The state variables speed <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e342" xlink:type="simple"/></inline-formula> and direction <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e343" xlink:type="simple"/></inline-formula> produced by the control sequence in A. (C) The state variables <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e344" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e345" xlink:type="simple"/></inline-formula> shown as a path (red curve). This is the ‘north-east’ trajectory. The state variable time series in B and C were produced by integrating the dynamics in <xref ref-type="disp-formula" rid="pcbi.1003383.e131">equation 3</xref> using the local linearisation approach of <xref ref-type="disp-formula" rid="pcbi.1003383.e142">equation 5</xref>. (D) Accuracy of visual imagery produced by agent as compared to sensory input that would have been produced by the environmental model. The figure shows the proportion of variance, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e346" xlink:type="simple"/></inline-formula>, explained by the agent's model as a function of retinal angle, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e347" xlink:type="simple"/></inline-formula>. This was computed separately for the north-east (black), north-west (red), south-east (blue) and south-west (green) trajectories. Only activity in the centre of the retina is accurately predicted.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003383.g003" position="float" xlink:type="simple"/></fig>
<p>To quantitatively assess the accuracy of these imagery sequences, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e348" xlink:type="simple"/></inline-formula>, we compared them to the sequence of visual inputs that would have been received from the environmental model, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e349" xlink:type="simple"/></inline-formula>. <xref ref-type="fig" rid="pcbi-1003383-g003">Figure 3D</xref> plots the proportion of variance explained by the agent's model as a function of retinal angle. These plots were computed separately for each trajectory, and show that only activity in the central retina is accurately predicted. This is due to the increased optic flow in peripheral regions of the agent's retina. The asymmetry in <xref ref-type="fig" rid="pcbi-1003383-g003">Figure 3D</xref> is due to the particular spatial arrangement and numerical values of the visual cues. These results suggest that it would be better to have a retina with lower spatial resolution in the periphery.</p>
</sec><sec id="s3b">
<title>Localisation</title>
<p>This simulation shows how an agent can localise itself in an environment. The agent was located centrally and moved according to the south-east trajectory. Its exact path was computed using noiseless path integration and the appropriate environmental inputs were provided to the agent.</p>
<p>In the <xref ref-type="sec" rid="s4">discussion</xref> section below we propose a mapping of the forward and backward inference equations onto the hippocampal-entorhinal complex. We now report the results of two simulations. The first used the standard forward inference updates in <xref ref-type="disp-formula" rid="pcbi.1003383.e260">equations 23</xref> and <xref ref-type="disp-formula" rid="pcbi.1003383.e262">24</xref>. This corresponds to the algorithm that an agent with an intact hippocampus would use. The second, however, had a ‘lesioned hippocampus’ in that only the path integral updates in <xref ref-type="disp-formula" rid="pcbi.1003383.e260">equation 23</xref> were used (we set <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e350" xlink:type="simple"/></inline-formula>). This in effect removed the top down input from hippocampus to MEC (see ‘Localisation’ subsection in the <xref ref-type="sec" rid="s4">discussion</xref>) so that path integral errors are not corrected by sensory input. In both cases the agent's path updates, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e351" xlink:type="simple"/></inline-formula>, were subject to a small amount of noise (with standard deviation 0.01) at each time step.</p>
<p><xref ref-type="fig" rid="pcbi-1003383-g004">Figure 4</xref> shows the results for single and multiple trials. Here, localisation with an intact hippocampus results in better tracking of the agent's location. Localisation accuracy was assessed over multiple trials (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e352" xlink:type="simple"/></inline-formula>) and found to be significantly more accurate with, rather than without, a hippocampus (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e353" xlink:type="simple"/></inline-formula>). The mean localisation error was 60 per cent smaller with a hippocampus.</p>
<fig id="pcbi-1003383-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003383.g004</object-id><label>Figure 4</label><caption>
<title>Localisation.</title>
<p>Left: Representative result from a single trial showing true route computed using noiseless path integration (black curve), localisation with a noisy path integrator and no Hippocampus (blue curve) and localisation with a noisy path integrator and a Hippocampus (red curve). Right: Boxplots of localisation error over trials with medians indicated by red bars, box edges indicating 25th and 75th percentiles, whiskers indicating more extreme points, and outliers plotted as red crosses.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003383.g004" position="float" xlink:type="simple"/></fig>
<p>For the above simulations we disabled somatosensory input by setting <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e354" xlink:type="simple"/></inline-formula>. This was found to be necessary as this input is not a reliable predictor of location (the distance from a boundary is the same at very many locations in an environment).</p>
</sec><sec id="s3c">
<title>Decision Making</title>
<p>This simulation shows how an agent can make a decision about which direction to turn by computing likelihood ratios. To demonstrate this principle, we selected the ‘north-west’ and ‘north-east’ trajectories as two possible control sequences. The sensory goal <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e355" xlink:type="simple"/></inline-formula> was set equal to the sensory input that would be received at the end of the ‘north-east’ trajectory. This goal was set to be identical at all time points <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e356" xlink:type="simple"/></inline-formula>.</p>
<p>The agent's starting location was <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e357" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e358" xlink:type="simple"/></inline-formula> with initial speed set to zero. The log of the likelihood ratio (see <xref ref-type="disp-formula" rid="pcbi.1003383.e274">equation 28</xref>), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e359" xlink:type="simple"/></inline-formula>, for model 1 versus model 2 was then computed at each time step. <xref ref-type="fig" rid="pcbi-1003383-g005">Figure 5</xref> shows the accumulated <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e360" xlink:type="simple"/></inline-formula> as a function of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e361" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e362" xlink:type="simple"/></inline-formula> time points along the trajectory. A <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e363" xlink:type="simple"/></inline-formula> of 3 corresponds to a probability of 95% <xref ref-type="bibr" rid="pcbi.1003383-Green1">[42]</xref>. This indicates that a confident decision can be made early on in the hypothesized trajectories.</p>
<fig id="pcbi-1003383-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003383.g005</object-id><label>Figure 5</label><caption>
<title>Decision making.</title>
<p>The task of decision making is to decide whether to make a left or a right turn (hence the question mark in the above graphic). Top Left: Locations on the route of the ‘left turn’ or north-west trajectory (red curve) Top Right: The markers A, B, C, D and E denote locations on the ‘right turn’ or north-east trajectory corresponding to time points <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e364" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e365" xlink:type="simple"/></inline-formula> respectively. Bottom: The log likelihood ratio (of north-east versus north-west), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e366" xlink:type="simple"/></inline-formula>, as a function of the number of time points along the trajectory.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003383.g005" position="float" xlink:type="simple"/></fig>
<p>The degree to which each sensory modality is used in the above computations is determined by the relative values of observation noise covariances (see <xref ref-type="supplementary-material" rid="pcbi.1003383.s004">Text S4</xref>). These were initially fixed to the values described at the beginning of the simulations section. Whilst a confident decision could soon be reached using the above default values, decomposition of the LR into modality specific terms showed a strong contribution from both olfactory and visual modalities, but a somatosensory contribution that was initially rather noisy. This is due to small idiosyncrasies in the predictions of somatosensory values. We therefore experimented with the level of somatosensory noise covariance. <xref ref-type="fig" rid="pcbi-1003383-g005">Figure 5</xref> was produced using a value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e367" xlink:type="simple"/></inline-formula> which means LR effectively ignores this contribution (although we also have <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e368" xlink:type="simple"/></inline-formula>, there are 20 visual inputs).</p>
</sec><sec id="s3d">
<title>Model Selection</title>
<p>This simulation shows how likelihood ratios can also be used to estimate what environment an agent is located in. We first trained an agent on the maze as described in the imagery section. We refer to this as environment one and the model, described by the set of estimated weights <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e369" xlink:type="simple"/></inline-formula>, as model one. We then trained the agent on a second environment and allowed it to develop a separate model. These are referred to as environment two and model two. The second environment was exactly the same as the first except that the east and west boundary walls had their colours swapped.</p>
<p>We then placed the agent in the first maze and used the ‘north-east’ control trajectory, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e370" xlink:type="simple"/></inline-formula>, and allowed the agent to compute the likelihood of observed data under its two models, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e371" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e372" xlink:type="simple"/></inline-formula>, as described earlier. The log of the likelihood ratio, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e373" xlink:type="simple"/></inline-formula> for model 1 versus model 2 was then computed at each time step. <xref ref-type="fig" rid="pcbi-1003383-g006">Figure 6</xref> shows the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e374" xlink:type="simple"/></inline-formula> as a function of the number of time points along the trajectory.</p>
<fig id="pcbi-1003383-g006" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003383.g006</object-id><label>Figure 6</label><caption>
<title>Model selection.</title>
<p>The task of model selection is for the agent to decide which environment it is in (hence the question mark in the above graphic). Top Left: North-east trajectory in maze 2, Top Right: North-east trajectory in maze 1. The mazes have different coloured east and west walls. The markers on the trajectories (A, B, C, D and E) denote locations corresponding to different time points (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e375" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e376" xlink:type="simple"/></inline-formula>). Bottom: The log likelihood ratio (of maze 1 versus maze 2), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e377" xlink:type="simple"/></inline-formula>, as a function of the number of time points along the trajectory. At <italic>n</italic> = 1000, the LogLR is approximately 3. This allows the agent to infer, with 95% probability, that it is located in maze 1 rather than maze 2.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003383.g006" position="float" xlink:type="simple"/></fig>
<p>The degree to which each sensory modality is used in the above computations is determined by the relative values of observation noise covariances. These were fixed to the values described at the beginning of the simulations section. However, because the only difference between the two models is in their predictions of retinal input (due to the swapping of wall colours), the above computation is driven solely by vision.</p>
<p>For the decision making example, described above, the likelihood of reaching the goal given the two trajectories is also differentiated by the olfactory inputs at the goal location (as the olfactory source is located in the south west corner and diffuses isotropically, there will be weaker input in the north east than north west corner). This explains the scaling differences in the likelihood ratios - decision making is easier, in this example, as it is guided by olfaction as well as vision. This is not generally the case, however, and only occurred here due to the specifics of the environments and goals (same olfactory sources at same locations in both mazes, different olfactory inputs at the two goals).</p>
</sec><sec id="s3e">
<title>Route and Motor Planning</title>
<p>This simulation gives an example of how route and motor planning can be implemented. The agent is placed in maze 1 at starting location <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e378" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e379" xlink:type="simple"/></inline-formula> with initial speed <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e380" xlink:type="simple"/></inline-formula> and direction <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e381" xlink:type="simple"/></inline-formula>. This initial state, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e382" xlink:type="simple"/></inline-formula>, is known with high precision <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e383" xlink:type="simple"/></inline-formula> (see <xref ref-type="disp-formula" rid="pcbi.1003383.e273">equation 27</xref>). The initial distribution over motor controls has mean <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e384" xlink:type="simple"/></inline-formula> and precision <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e385" xlink:type="simple"/></inline-formula> (see <xref ref-type="disp-formula" rid="pcbi.1003383.e314">equation 32</xref>). The covariance of the noise on the motor controls is set to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e386" xlink:type="simple"/></inline-formula> (see <xref ref-type="disp-formula" rid="pcbi.1003383.e310">equation 31</xref>). This specifies that the control signals for changes in acceleration (first element) are expected to be larger than those for direction (second element). For this simulation we augmented the sensory vector <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e387" xlink:type="simple"/></inline-formula> with observations of the agent's speed <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e388" xlink:type="simple"/></inline-formula>.</p>
<p>The sensory goal <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e389" xlink:type="simple"/></inline-formula> is multimodal with components for olfaction, touch, vision and speed. For olfaction, touch and speed we set <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e390" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e391" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e392" xlink:type="simple"/></inline-formula>. The goal is therefore to navigate to the point in space with olfactory code most similar to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e393" xlink:type="simple"/></inline-formula>. The environmental location with this value is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e394" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e395" xlink:type="simple"/></inline-formula>. The observation noise covariance for speed was set to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e396" xlink:type="simple"/></inline-formula>. A second aim is that the distance to the nearest boundary should be close to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e397" xlink:type="simple"/></inline-formula>. A third aim is that the speed should be as near to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e398" xlink:type="simple"/></inline-formula> as possible. That is, the agent should be stationary at the target. The visual component <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e399" xlink:type="simple"/></inline-formula> is set to correspond to an image of the left wall with all ‘yellow’ values. The desired goal trajectory, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e400" xlink:type="simple"/></inline-formula>, is set to be equal to the goal <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e401" xlink:type="simple"/></inline-formula> at all time points.</p>
<p>The degree to which each sensory modality is used in motor planning is determined by the relative values of observation noise covariance. We used the values described at the beginning of the simulations section. This means that motor planning is guided most by olfaction and touch, and least by vision. The estimated hidden states and inputs were then computed as shown in the earlier section on ‘Inference over Inputs’.</p>
<p><xref ref-type="fig" rid="pcbi-1003383-g007">Figure 7</xref> shows the planned route traced out by forward and backward inference. For forward inference we are plotting the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e402" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e403" xlink:type="simple"/></inline-formula> elements of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e404" xlink:type="simple"/></inline-formula> (see <xref ref-type="disp-formula" rid="pcbi.1003383.e262">equation 24</xref>), and for backward inference the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e405" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e406" xlink:type="simple"/></inline-formula> elements of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e407" xlink:type="simple"/></inline-formula> (see <xref ref-type="disp-formula" rid="pcbi.1003383.e285">equation 30</xref>). The paths for backward inference are smoother and more direct. <xref ref-type="fig" rid="pcbi-1003383-g007">Figure 7</xref> also shows the estimated motor control sequence. These sequences correspond to the mean from backward inference, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e408" xlink:type="simple"/></inline-formula>, as described in the section on ‘Inference over Inputs’ (see <xref ref-type="disp-formula" rid="pcbi.1003383.e315">equation 33</xref>).</p>
<fig id="pcbi-1003383-g007" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003383.g007</object-id><label>Figure 7</label><caption>
<title>Route and motor planning.</title>
<p>Right: The figure shows the planned route traced out by forward (red) and backward (green) inference. For forward inference we are plotting the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e409" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e410" xlink:type="simple"/></inline-formula> elements of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e411" xlink:type="simple"/></inline-formula>, and for backward inference the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e412" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e413" xlink:type="simple"/></inline-formula> elements of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e414" xlink:type="simple"/></inline-formula>. The agent is located at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e415" xlink:type="simple"/></inline-formula> (white cross) and the goal is at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e416" xlink:type="simple"/></inline-formula> (white circle). Left: The figure shows the estimated motor control sequence for producing the desired sensory goals. This sequence corresponds to the mean from backward inference, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e417" xlink:type="simple"/></inline-formula>, as described in the theory section on ‘Inference over Inputs’.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003383.g007" position="float" xlink:type="simple"/></fig>
<p>Simple decisions such as ‘turn left’ or ‘turn right’ can be implemented using the ‘decision making’ procedure described in the above section. This is a rudimentary form of planning. The route and motor planning described here is a more powerful approach that we envisage is engaged when the optimal route to a goal involves the chaining together of multiple decisions (eg. ‘turn left’, ‘straight on’, ‘turn right’).</p>
</sec></sec><sec id="s4">
<title>Discussion</title>
<p>This paper has illustrated how the various computations underlying goal-directed spatial cognition can be implemented using statistical inference in a single probabilistic model. This extends previous work which has focussed on single computations such as localisation <xref ref-type="bibr" rid="pcbi.1003383-Bousquet1">[20]</xref> or model selection <xref ref-type="bibr" rid="pcbi.1003383-Fuhs1">[21]</xref>. Here we use a single model, and show that inference based on different combinations of known and unknown variables can additionally implement goal-based planning and decision making, and have shown how a specific implementation based on a continuous state space model and local linearisation can achieve these ends. In what follows we describe a neuronal implementation of our approach and discuss how the underlying forward and backward algorithms may relate to recent empirical findings of pattern replay. We close by describing a number of experimental predictions suggested by the model.</p>
<sec id="s4a">
<title>Neuronal Implementation</title>
<p>This section discusses how and where in the brain the above computational processes might be implemented. Our starting point here is <xref ref-type="fig" rid="pcbi-1003383-g008">Figure 8</xref> which describes a candidate set of brain regions. Entorhinal cortex is partitioned into Lateral (LEC) and Medial (MEC) components, with the latter representing spatial and the former non-spatial information <xref ref-type="bibr" rid="pcbi.1003383-Knierim1">[43]</xref>. The LEC receives substantial input from perirhinal cortex which in turn receives major projections from temporal cortices, whereas the MEC receives substantial input from parahippocampal cortex which in turn receives projections from parietal cortices. The anatomical connectivity supporting this architecture is described in <xref ref-type="fig" rid="pcbi-1003383-g003">Figure 3</xref> of <xref ref-type="bibr" rid="pcbi.1003383-vanStrien1">[44]</xref>. We assume that temporal, parietal, parahippocampal and perirhinal cortices and the machinery that feeds into them, together produce a compact coding of spatial and non-spatial aspects of the agent's environment. These processes are not explicitly modelled in this paper.</p>
<fig id="pcbi-1003383-g008" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003383.g008</object-id><label>Figure 8</label><caption>
<title>Neuronal implementation.</title>
<p>Here <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e418" xlink:type="simple"/></inline-formula> indexes time and we have control signals <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e419" xlink:type="simple"/></inline-formula>, path integral hidden state estimates <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e420" xlink:type="simple"/></inline-formula>, Bayesian state estimates, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e421" xlink:type="simple"/></inline-formula>, non-spatial sensory states, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e422" xlink:type="simple"/></inline-formula> and predictions of non-spatial sensory states <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e423" xlink:type="simple"/></inline-formula>. During <bold>Localisation</bold>, path integration in MEC combines previous state estimates and motor efference copy to produce a new state estimate, with mean <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e424" xlink:type="simple"/></inline-formula> as described in <xref ref-type="disp-formula" rid="pcbi.1003383.e260">equation 23</xref>. Bayesian inference in CA3-CA1 combines path integration with sensory input to get an improved state estimate <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e425" xlink:type="simple"/></inline-formula> as described in <xref ref-type="disp-formula" rid="pcbi.1003383.e262">equation 24</xref>. LEC sends a prediction error signal <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e426" xlink:type="simple"/></inline-formula> to CA3-CA1. The computations underlying ‘sensory imagery’, ‘decision making’ and ‘model selection’ are discussed in the main text in the section on ‘Neural Implementation’. CA: Cornu Ammonis, LEC/MEC: Lateral/Medial Entorhinal cortex.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003383.g008" position="float" xlink:type="simple"/></fig>
<p>Our simple and tentative mapping onto hippocampal neuroanatomy currently does not distinguish between CA3 and CA1, instead we consider a single hippocampal node encompassing the activity of CA3-CA1 place cells. Our model then comprises two hippocampal-entorhinal loops, one spatial and one non-spatial, as shown in <xref ref-type="fig" rid="pcbi-1003383-g008">Figure 8</xref> (top left). The spatial loop proceeds from superficial MEC layers to CA3-CA1, and returns to deep layers of MEC. This partitioning into deep and superficial layers is consistent with known anatomy and previous functional models <xref ref-type="bibr" rid="pcbi.1003383-Mhatre1">[45]</xref>. Anatomically, entorhinal-hippocampal connectivity is more complex with, for example, direct connections from EC layer three to CA1 <xref ref-type="bibr" rid="pcbi.1003383-Witter1">[46]</xref>, and return connections via proximal CA1 (CA1p) and distal Subiculum (SUBd) <xref ref-type="bibr" rid="pcbi.1003383-Jones1">[47]</xref>, but our model does not have this level of detail.</p>
<p>The non-spatial loop proceeds from superficial LEC layers to CA3-CA1, and returns to deep layers of LEC. The sensory states of our spatial model, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e427" xlink:type="simple"/></inline-formula>, are compact codes representing non-spatial information in the superficial layers of LEC. Predictions of these sensory states from the agent's model, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e428" xlink:type="simple"/></inline-formula>, are made via the CA3-CA1 to LEC pathway. In our model, the function of CA3-CA1 is to integrate spatial input from MEC with non-spatial input from LEC. This is consistent with a recent schematic model <xref ref-type="bibr" rid="pcbi.1003383-Manns1">[48]</xref>, where it is argued that this functionality is preserved across mammals.</p>
<p>The mapping from CA3-CA1 to LEC generates the agent's predictions of sensory states, whereas the mapping from LEC to CA3-CA1 implements the (approximate) inverse of this mapping. Together, these recurrent connections constitute the agent's model of its environment, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e429" xlink:type="simple"/></inline-formula>, and different models will be instantiated in different subsets of these connections. That populations of cells in LEC encode sensory prediction errors, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e430" xlink:type="simple"/></inline-formula>, is supported by recent recordings in rats <xref ref-type="bibr" rid="pcbi.1003383-Tsao1">[49]</xref>. This study identified cells that fired at locations where objects had been located on previous trials (high prediction error), but did not respond when the object was actually present (no prediction error).</p>
<sec id="s4a1">
<title>Grid, place and direction cells</title>
<p>Our model assumes that path integration takes place in the Entorhinal Cortex. A number of computational models of the underlying processing have appeared in the literature <xref ref-type="bibr" rid="pcbi.1003383-Mhatre1">[45]</xref>, <xref ref-type="bibr" rid="pcbi.1003383-Conklin1">[50]</xref>, <xref ref-type="bibr" rid="pcbi.1003383-McNaughton2">[51]</xref> and assume that allocentric space, direction and velocity are represented by populations of grid cells. These grid cells were originally discovered in rat Entorhinal Cortex (EC) and represent space using a Fourier-like basis set <xref ref-type="bibr" rid="pcbi.1003383-Hafting1">[52]</xref>. More recently, an fMRI study has found evidence of grid-cell-like representations in human EC <xref ref-type="bibr" rid="pcbi.1003383-Doeller1">[53]</xref>.</p>
<p>Our model also assumes representations of space in CA3-CA1 which we envisage are supported by the activity of place cells. These place cells fire bursts of action potentials when a rat passes through a particular location in their environment <xref ref-type="bibr" rid="pcbi.1003383-OKeefe2">[54]</xref>. Place cells have also been found in humans using intracranial unit recordings <xref ref-type="bibr" rid="pcbi.1003383-Ekstrom1">[55]</xref>, and neuroimaging of human subjects has implicated the hippocampus in navigation <xref ref-type="bibr" rid="pcbi.1003383-Maguire1">[56]</xref> and the representation of spatial location <xref ref-type="bibr" rid="pcbi.1003383-Hassabis1">[57]</xref>. A representation of spatial distance has also been identified in left hippocampus <xref ref-type="bibr" rid="pcbi.1003383-Morgan1">[58]</xref>. Hidden state representations of direction, in our model, are perhaps encoded by head direction cells. These neurons fire in relation to an animal's direction of heading regardless of its current location, and have been found in postsubiculum, retrosplenial cortex, anterior thalamus, striatum and entorhinal cortex <xref ref-type="bibr" rid="pcbi.1003383-Taube1">[59]</xref>. Additionally, directionally modulated grid cells have been found in entorhinal cortex <xref ref-type="bibr" rid="pcbi.1003383-Sargolini1">[60]</xref>.</p>
<p>In summary, the speed, location and direction variables that comprise the agent's hidden state are most likely represented in a highly distributed manner in the brain, using basis representations built on cell types with multiple dependencies. In EC these will be grid cells and in CA3-CA1 these will be place cells. This level of detail is omitted from our model, as our focus is on temporal dynamics.</p>
<p><xref ref-type="fig" rid="pcbi-1003383-g008">Figures 8</xref> and <xref ref-type="fig" rid="pcbi-1003383-g009">9</xref> refer to a ‘prefrontal’ module containing representations of model inputs <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e431" xlink:type="simple"/></inline-formula> which are changes in heading direction and changes in speed. We envisage that this is a distributed circuit involving both cortical and subcortical brain regions. The subcortical regions would include for example those parts of the head direction circuit receiving proprioceptive feedback and motor efference copy <xref ref-type="bibr" rid="pcbi.1003383-Taube1">[59]</xref>.</p>
<fig id="pcbi-1003383-g009" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003383.g009</object-id><label>Figure 9</label><caption>
<title>Motor and route planning.</title>
<p>Route planning can be implemented using <bold>Forward</bold> inference, in which sensory goals are instantiated in LEC (or projections to it), and the recurrent circuitry produces state estimates from path integration <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e432" xlink:type="simple"/></inline-formula>, and Bayesian estimation <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e433" xlink:type="simple"/></inline-formula>, that are consistent with those goals. <bold>Backward</bold> inference takes as input the result of the forward sweep. It produces improved estimates of the hidden states, given by the recursion <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e434" xlink:type="simple"/></inline-formula>, and estimates of control signals given by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e435" xlink:type="simple"/></inline-formula>. We propose that the prediction error <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e436" xlink:type="simple"/></inline-formula> is computed in MEC and propagated to CA3-CA1 for computation of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e437" xlink:type="simple"/></inline-formula> and to prefrontal regions for computation of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e438" xlink:type="simple"/></inline-formula>. See <xref ref-type="disp-formula" rid="pcbi.1003383.e318">equation 34</xref> for more details.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003383.g009" position="float" xlink:type="simple"/></fig></sec><sec id="s4a2">
<title>Localisation</title>
<p>The architecture in <xref ref-type="fig" rid="pcbi-1003383-g008">Figure 8</xref> (top left) assumes that path integration takes place in MEC, as discussed in a recent review <xref ref-type="bibr" rid="pcbi.1003383-McNaughton2">[51]</xref>. MEC contains multi-scale grid cells which provide a basis set representation of allocentric space. In our model of spatial localisation, path integration combines previous state estimates <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e439" xlink:type="simple"/></inline-formula> and motor efference copy <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e440" xlink:type="simple"/></inline-formula> to get a new state estimate, with mean <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e441" xlink:type="simple"/></inline-formula> as described in <xref ref-type="disp-formula" rid="pcbi.1003383.e260">equation 23</xref>.</p>
<p>We assume that networks in CA3-CA1 implement Bayes rule such that location estimates from path integration computed in MEC, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e442" xlink:type="simple"/></inline-formula>, are combined with non-spatial information to form an improved estimate of location, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e443" xlink:type="simple"/></inline-formula>. The new estimate is given by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e444" xlink:type="simple"/></inline-formula> and is described more fully in <xref ref-type="disp-formula" rid="pcbi.1003383.e262">equation 24</xref>. This new estimate is then fed back to MEC to be incorporated into the next iteration of path integration.</p>
<p>A more detailed mapping onto neuroanatomy, which is consistent with our proposal, can be motivated by concerns for how grid and place cells keep in register <xref ref-type="bibr" rid="pcbi.1003383-OKeefe3">[61]</xref>. It has been suggested <xref ref-type="bibr" rid="pcbi.1003383-Sreenivasan1">[62]</xref> that CA1 combines grid cell outputs from MEC with cue information from CA3 place cells. In our model this would correspond to CA3 computing <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e445" xlink:type="simple"/></inline-formula> and CA1 computing <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e446" xlink:type="simple"/></inline-formula>. Region CA1 would then signal <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e447" xlink:type="simple"/></inline-formula> back to MEC, and the CA1 to LEC pathway could compute <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e448" xlink:type="simple"/></inline-formula> using a representation based on place cells in CA1.</p>
<p>The above iterative updates capture the circular nature of estimating position and direction. The activity of head direction cells <xref ref-type="bibr" rid="pcbi.1003383-Taube1">[59]</xref>, for example, is known to be dependent on the identification of landmarks, and on self-motion cues, such as vestibular and proprioceptive cues. Here, we envisage that vestibular cues, proprioceptive cues and self-motion contribute to probabilistic path integration and that forward inference then combines path integration with sensory input regarding landmarks. The relative contribution of path integration and sensory input, during spatial localisation, is discussed in more detail in <xref ref-type="supplementary-material" rid="pcbi.1003383.s004">Text S4</xref>.</p>
<p>The integration of sensory cues with path integral estimates of location has previously been considered in a model by Arleo and Gerstner <xref ref-type="bibr" rid="pcbi.1003383-Arleo2">[63]</xref>. In this model, once the error in path integration has reached a certain level the path integrator is reset using information from sensory cues. This is to be contrasted with the algorithm proposed in this paper and, for example, work by Mhatre et al. <xref ref-type="bibr" rid="pcbi.1003383-Mhatre1">[45]</xref> in which top down predictions from CA1 to MEC continually update path integral information.</p>
<p>A key quantity in the combined estimate of hidden state, in <xref ref-type="disp-formula" rid="pcbi.1003383.e262">equation 24</xref>, is the Kalman gain <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e449" xlink:type="simple"/></inline-formula>. This acts as a multiplier for the prediction errors such that sensory modalities that are more predictive of hidden state have higher gain. By changing the sensory observation noise <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e450" xlink:type="simple"/></inline-formula> one can change elements of the Kalman gain. Indeed, our simulations on localisation showed that it was necessary to increase the somatosensory noise <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e451" xlink:type="simple"/></inline-formula> to the extent that this modality was effectively ignored during localisation (the component of the Kalman gain tended towards zero). In the brain this would be manifested by a modulation of the connection strength between somatosensory LEC and hippocampus.</p>
</sec><sec id="s4a3">
<title>Sensory imagery</title>
<p>During sensory imagery the architecture in <xref ref-type="fig" rid="pcbi-1003383-g008">Figure 8</xref> (top right) is used as the agent's virtual reality engine. The MEC receives virtual motor commands, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e452" xlink:type="simple"/></inline-formula>, from prefrontal cortex, and uses path integration to update states, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e453" xlink:type="simple"/></inline-formula>. The CA3-CA1 to LEC pathway then produces predictions of sensory codes, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e454" xlink:type="simple"/></inline-formula>. This would therefore be consistent with recent findings that the imagination of coherent scenes is hippocampus dependent <xref ref-type="bibr" rid="pcbi.1003383-Hassabis2">[64]</xref>.</p>
<p>The above predictions (and state estimates <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e455" xlink:type="simple"/></inline-formula>) are then (separately) propagated back down cortical hierarchies, creating egocentric sensory imagery in lower-level regions of scene construction networks <xref ref-type="bibr" rid="pcbi.1003383-Hassabis3">[65]</xref>. In the simulations described earlier, we (unrealistically) reduced these multiple stages of processing to a single mapping <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e456" xlink:type="simple"/></inline-formula>.</p>
</sec><sec id="s4a4">
<title>Decision making</title>
<p>During decision making we envisage that the architecture operates as in <xref ref-type="fig" rid="pcbi-1003383-g008">Figure 8</xref> (bottom left). LEC receives sensory goals, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e457" xlink:type="simple"/></inline-formula>, and MEC receives virtual motor commands, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e458" xlink:type="simple"/></inline-formula>, from prefrontal cortex. Sensory goals are then compared with predicted sensory input, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e459" xlink:type="simple"/></inline-formula> from the CA3-CA1 to LEC pathway. The likelihood of the data given the model is then proportional to the sum-squared difference between <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e460" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e461" xlink:type="simple"/></inline-formula> (see <xref ref-type="disp-formula" rid="pcbi.1003383.e275">equation 29</xref>). Previously, Fox and Prescott <xref ref-type="bibr" rid="pcbi.1003383-Fox1">[66]</xref> have proposed that septal regions, or projections to them, represent such accumulated disparities. To compute a likelihood ratio this whole process would have to happen twice, once for virtual motor commands corresponding to a left turn and once for a right turn, as described earlier. This is indicated by the thick line from prefrontal to MEC in <xref ref-type="fig" rid="pcbi-1003383-g008">Figure 8</xref> (bottom left).</p>
<p>Experimental data <xref ref-type="bibr" rid="pcbi.1003383-Johnson2">[67]</xref> shows that, when rats reach decision points, potential routes are explored serially rather than in parallel, which therefore suggests that evidence for a left versus a right turn will be computed serially. To compute log-likelihood ratios it will therefore be necessary to use working memory, as in other delayed discrimination tasks. A possible neural subtrate for this are mutual inhibition circuits that can encode the alternative likelihoods <xref ref-type="bibr" rid="pcbi.1003383-Bogacz1">[68]</xref>, store them and make an appropriate decision <xref ref-type="bibr" rid="pcbi.1003383-Machens1">[69]</xref>.</p>
<p>Although we have modelled sensory goals as being represented in LEC, it may well be the case that they are represented at lower levels of cortical hierarchies. If this is the case, then the discrepancy between sensory goals and predicted sensory input would also occur at lower levels. The coarseness of these representations, and thus their anatomical instantiation, are likely to vary as a function of task requirements.</p>
</sec><sec id="s4a5">
<title>Model selection</title>
<p>During model selection we envisage that the architecture operates as in <xref ref-type="fig" rid="pcbi-1003383-g008">Figure 8</xref> (bottom right). LEC receives observed sensory data, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e462" xlink:type="simple"/></inline-formula>, and MEC receives efference copy, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e463" xlink:type="simple"/></inline-formula>, from prefrontal cortex. Sensory observations are then compared with predicted sensory input, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e464" xlink:type="simple"/></inline-formula>, from the CA3-CA1 to LEC pathway, to produce the prediction error signal <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e465" xlink:type="simple"/></inline-formula>. The likelihood of the data given the model is then proportional to the sum-squared prediction errors as shown in <xref ref-type="disp-formula" rid="pcbi.1003383.e275">equation 29</xref>. As described above for the decision making simulations, these likelihoods may be represented in lower level sensory cortices or as accumulated discrepancy signals projecting to septal regions. Ratios of these likelihoods are used for deciding which environment an agent is in, as described above.</p>
<p>The recurrent connections between CA3-CA1 and LEC (thick lines in <xref ref-type="fig" rid="pcbi-1003383-g008">Figure 8</xref> - bottom right) implement the agent's model of its environment. Different models will be instantiated in different subsets of these connections. To compute likelihood ratios for model selection, the above computations would have to be run twice, once for each model (we propose that this happens in parallel during ‘theta flickering’ - see below). The thick lines in <xref ref-type="fig" rid="pcbi-1003383-g008">Figure 8</xref> indicate that different subsets of these connections will be engaged, corresponding to the different models.</p>
</sec><sec id="s4a6">
<title>Route and motor planning</title>
<p>During route and motor planning we envisage that the underlying neural architecture operates as described in <xref ref-type="fig" rid="pcbi-1003383-g009">Figure 9</xref>. This comprises separate phases of forward and backward inference. During forward inference LEC receives sensory goals, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e466" xlink:type="simple"/></inline-formula>, and the CA3-CA1 to LEC pathway produces predictions, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e467" xlink:type="simple"/></inline-formula>. As there is no input at this stage (virtual or efference copy), MEC state estimates are driven solely by state dynamics <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e468" xlink:type="simple"/></inline-formula> eg. location estimates are updated based on velocity and direction. The entorhinal-hippocampal loop then iteratively updates the hidden state estimates <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e469" xlink:type="simple"/></inline-formula>, using Bayesian estimation, so as to minimise the discrepancy between sensory goals and predictions. The result is a sequence of estimates <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e470" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e471" xlink:type="simple"/></inline-formula> which contains a putative sequence of spatial locations that will lead to the sensory goal.</p>
<p>Backward inference then proceeds using just the spatial loop, as shown in <xref ref-type="fig" rid="pcbi-1003383-g008">Figure 8</xref> (right panel). That sensory goals do not need to be instantiated at this stage is a consequence of using the gamma rather than the beta form of the backward recursions (see <xref ref-type="supplementary-material" rid="pcbi.1003383.s002">Text S2</xref>). In the absence of correlations between inputs and hidden states the update formulae for these backward recursions are straightforward, and given by <xref ref-type="disp-formula" rid="pcbi.1003383.e318">equation 34</xref>. The backward estimates of the hidden states are given by the recursion <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e472" xlink:type="simple"/></inline-formula> and the control signals are estimated as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e473" xlink:type="simple"/></inline-formula>. One possibility is that the prediction error <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e474" xlink:type="simple"/></inline-formula> is computed in MEC and propagated to CA3-CA1 for computation of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e475" xlink:type="simple"/></inline-formula> and to prefrontal regions for computation of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e476" xlink:type="simple"/></inline-formula>, as depicted in <xref ref-type="fig" rid="pcbi-1003383-g009">Figure 9</xref> (right panel). This proposed architecture is consistent with a previous suggestion that, during navigation, cue information is provided by LEC and action information by MEC <xref ref-type="bibr" rid="pcbi.1003383-Lisman1">[70]</xref>.</p>
</sec></sec><sec id="s4b">
<title>Population Codes</title>
<p>As with other proposals that the brain may implement some form of approximate Bayesian inference <xref ref-type="bibr" rid="pcbi.1003383-Penny1">[71]</xref>, to formally test this idea it is necessary to have a proposal for how neural populations represent uncertainty. Ma et al. <xref ref-type="bibr" rid="pcbi.1003383-Ma1">[72]</xref>, for example, have shown how populations of cells can represent probability distributions using probabilistic population codes in which simple linear combinations of firing rates can implement Bayesian inference. Beck at al. <xref ref-type="bibr" rid="pcbi.1003383-Beck1">[73]</xref> have shown how such a scheme can implement Kalman filtering.</p>
<p>As we have locally linearised the dynamic and observation nonlinearities, the forward inference step in this paper closely corresponds to Kalman filtering. It therefore seems plausible that forward inference using EKF can be implemented using similar principles. Thus, although <xref ref-type="disp-formula" rid="pcbi.1003383.e260">equations 23</xref> to <xref ref-type="disp-formula" rid="pcbi.1003383.e266">26</xref> perhaps seem rather removed from neurobiology there may well be a plausible neural implementation.</p>
<p>It has yet to be demonstrated how the gamma recursions underlying backward inference could be implemented using probabilistic population codes. However, given that the gamma recursions comprise an implementation of Bayes rule followed by a marginalisation (see <xref ref-type="supplementary-material" rid="pcbi.1003383.s002">Text S2</xref>) whereas Kalman filtering is a marginalisation followed by Bayes rule (see <xref ref-type="supplementary-material" rid="pcbi.1003383.s002">Text S2</xref>) we imagine a similar instantiation is possible.</p>
<p>The Beck at al. <xref ref-type="bibr" rid="pcbi.1003383-Beck1">[73]</xref> approach assumes that trial-to-trial variability in population firing rates is in a class of distributions from the linear-exponential family. This includes distributions where cells have independent Poisson rates. There is good evidence to suggest that MTL cell firing is not independent and Poisson <xref ref-type="bibr" rid="pcbi.1003383-Fenton1">[74]</xref>, but it is not known if their activity falls into the more general linear-exponential family.</p>
<p>Other proposals as to how the brain might implement Bayesian inference are specific to the hippocampus. One proposal <xref ref-type="bibr" rid="pcbi.1003383-Lengyel2">[75]</xref> suggests that higher certainty is encoded by spike patterns containing more spikes and where the spikes are closer together. If this is true then our perspective makes a number of simple predictions. For example, because backward inference produces higher certainty estimates than forward inference, backward replays should produce burstier spike trains. This should be simple to test using existing data <xref ref-type="bibr" rid="pcbi.1003383-Foster2">[76]</xref>.</p>
</sec><sec id="s4c">
<title>Planning as Inference</title>
<p>An important part of our proposal is that the multiple tasks that together comprise spatial cognition can all be implemented using probabilistic inference in a single model. A caveat here is that our approach is restricted to goal-direction navigation. Whilst the forward inference in nonlinear dynamical systems that gives rise to the EKF algorithm, has a long history in estimates of localisation, there have been no proposals, to our knowledge, that also consider planning. However, in the machine learning literature, similar approaches for solving planning or control problems have been developed under the generic term ‘Planning as Inference’. For example, Attias <xref ref-type="bibr" rid="pcbi.1003383-Attias1">[77]</xref> has proposed that planning problems can be solved using Bayesian inference.</p>
<p>The central idea is to infer the control signals, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e477" xlink:type="simple"/></inline-formula>, conditioned on known initial state, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e478" xlink:type="simple"/></inline-formula> and desired goal states <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e479" xlink:type="simple"/></inline-formula>. Similarly, Toussaint <xref ref-type="bibr" rid="pcbi.1003383-Toussaint1">[78]</xref> describes the estimation of control signals using a Bayesian message passing algorithm which defaults to the classic Linear Quadratic Regulator (LQR) for linear Gaussian dynamics. Proposals have been made regarding how this Planning as Inference framework maps onto neural architectures in the brain <xref ref-type="bibr" rid="pcbi.1003383-Botvinick1">[79]</xref>, <xref ref-type="bibr" rid="pcbi.1003383-Solway1">[80]</xref>.</p>
<p>A key difference to our proposal is that Toussaint solves a closed-loop (feedback) control problem. This finds a mapping from state-space to the optimal action, also known as the ‘policy’. In terms of the underlying generative model in <xref ref-type="fig" rid="pcbi-1003383-g002">Figure 2</xref>, this requires extra links from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e480" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e481" xlink:type="simple"/></inline-formula>. In this paper we solve an open-loop control problem. Our estimated control trajectory <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e482" xlink:type="simple"/></inline-formula> is a set of ballistic commands that cannot be updated in light of future information regarding the state of the system. Nevertheless, these commands can be rapidly computed at arbitrary time scales ‘on the fly’, and this type of control strategy may be sufficient for a compliant motor system.</p>
</sec><sec id="s4d">
<title>Learning</title>
<p>In our simulations the agent learnt to predict sensory input using a pre-developed set of place cells with fixed centres and widths. This allowed us to use a simple regression approach for learning the basis function weights, which is similar to the standard two-stage optimisation process in machine learning. In the first stage basis functions are estimated in an initial unsupervised learning phase (eg. based purely on MEC input), and basis function weights are learnt in a second, supervised learning phase <xref ref-type="bibr" rid="pcbi.1003383-Bishop2">[81]</xref>.</p>
<p>Our simulations also assumed the agent had exact knowledge of its hidden state during learning, whereas more realistic simulations would also require the agent to infer these states. In principle this requires a straightforward implementation of the Expectation-Maximisation (EM) algorithm <xref ref-type="bibr" rid="pcbi.1003383-Bishop1">[38]</xref>, <xref ref-type="bibr" rid="pcbi.1003383-Ghahramani1">[82]</xref> for learning in dynamical systems.</p>
<p>A more powerful alternative which integrates out the dependence on model parameters in the forward and backward passes is Variational Bayes (VB) <xref ref-type="bibr" rid="pcbi.1003383-Beal1">[83]</xref>, <xref ref-type="bibr" rid="pcbi.1003383-Daunizeau1">[84]</xref>. Implementation of these VB schemes would mean that the maximum likelihood approach described in this paper would be replaced by a maximum evidence approach. Agents would implement decision making, model selection and motor planning by maximising the model evidence. Given that VB approximates the model evidence using free energy, the resulting scheme would then be broadly consistent with the Free Energy Principle <xref ref-type="bibr" rid="pcbi.1003383-Friston1">[85]</xref>. A further detail here is that in previous applications of VB <xref ref-type="bibr" rid="pcbi.1003383-Beal1">[83]</xref>, <xref ref-type="bibr" rid="pcbi.1003383-Daunizeau1">[84]</xref>, backward inference was implemented using the beta not the gamma recursions. In this paper we propose that it is the gamma recursions that are implemented in the brain, as they do not require storage of sensory observation sequences.</p>
</sec><sec id="s4e">
<title>Local Linearisation</title>
<p>The forward and backward algorithms are general purpose computations which may be implemented in a number of ways and this paper has focussed on an implementation based on local linearisation. The benefit of this is that the state probability distributions are Gaussian and so may be described with a small number of parameters; means and covariances. Additionally, there are analytic formulae for updating the parameters.</p>
<p>A drawback of the LL approach is that the true probability distributions may be non-Gaussian. One possibility is that the distribution over the agent's location may be multimodal. This will be the case when an agent is placed in a familiar environment at an unknown location where there are multiple locations consistent with sensory data. For this scenario inferential methods based on sampling, such as particle filtering, would be more appropriate <xref ref-type="bibr" rid="pcbi.1003383-DurrantWhyte1">[37]</xref>.</p>
<p>A second concern is that a single iteration of forward and backward inference may not be sufficient to find the controls that maximise the planning likelihood <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e483" xlink:type="simple"/></inline-formula>. It may be possible to improve the estimated controls by running multiple forward and backward replays such that the linearisation takes place around a different and improved trajectory each time. This iterated local linearisation would be analogous to the iterative Local Quadratic Gaussian (iLQG) approach from control theory <xref ref-type="bibr" rid="pcbi.1003383-Li1">[86]</xref>.</p>
<p>This second concern may also be addressed by treating space as discrete rather than continuous. In this perspective the agent is currently located in one of a finite number of ‘bins’ each of which may correspond to the support of a place cell. The optimal trajectory through these bins can then be computed by solving a discrete Bellman equation. Todorov has shown that this corresponds to backward inference in a hidden Markov model <xref ref-type="bibr" rid="pcbi.1003383-Todorov1">[87]</xref>. This computation relies on a recursive high-dimensional update that is perhaps readily suited to the massively recurrent nature of CA3. These computations would be consistent with earlier proposals that the hippocampus itself is suited for solving shortest path problems <xref ref-type="bibr" rid="pcbi.1003383-Muller1">[88]</xref>.</p>
</sec><sec id="s4f">
<title>Open-Loop Control</title>
<p>In regard to motor planning, this paper has described a forward and backward inference procedure which allows an agent to solve an open-loop control problem. This produces a control trajectory that is a set of ballistic commands that cannot be updated in light of future information regarding the state of the system. It is possible to augment the generative model to include extra links from states to actions, so that the agent instead learns a policy - a mapping from states to actions, as in <xref ref-type="bibr" rid="pcbi.1003383-Toussaint1">[78]</xref>. This would then provide a solution to the closed-loop (feedback) control problem.</p>
<p>However, it may be the case that the mammalian brain solves the closed-loop problem in two stages. First, the computational power of recurrent networks in CA3 could be used to implement forward and backward inference to solve the open-loop problem. Estimated trajectories would then be replayed to ventral striatum during quiet wakefulness or slow wave sleep. This is consistent with an earlier model <xref ref-type="bibr" rid="pcbi.1003383-Johnson3">[89]</xref> and the observation of ripple activity propagating to this region <xref ref-type="bibr" rid="pcbi.1003383-Pennartz1">[90]</xref>. These replays would then be used to train up a habitual dorsal striatal decision making system (see <xref ref-type="bibr" rid="pcbi.1003383-vanderMeer1">[11]</xref> for a review of habitual versus flexible/deliberative systems and their anatomy).</p>
<p>This is also consistent with proposals that for known environments, navigational control is gradually transferred from a flexible inferential system to a habitual system based on a hippocampo-striatal mapping <xref ref-type="bibr" rid="pcbi.1003383-White1">[14]</xref>. Such a hippocampo-striatal model has previously been proposed by Foster et al. <xref ref-type="bibr" rid="pcbi.1003383-Foster1">[29]</xref>.</p>
</sec><sec id="s4g">
<title>Cognitive Control</title>
<p>This paper has described how the various aspects of spatial cognition can be implemented using inference in a statistical model. It has not, however, addressed the broader cognitive control issues such as how internally generated goals are produced or when to switch between localisation versus model selection versus decision making modes. A recent computational framework <xref ref-type="bibr" rid="pcbi.1003383-Johnson1">[22]</xref>, called Information Foraging (IF), however, does address some of these issues. This approach requires that agents compute the information that will be gained by making spatial decisions, which in turn requires the agent to have a probabilistic model of its environment. Thus, it would be possible for both IF and the Forward-Backward (FB) model to both use the same underlying probabilistic model, with perhaps IF deciding when to run an iteration of FB.</p>
<p>This paper has proposed how model-based control may be implemented using spatial models implemented in hippocampal circuits. But it has not addressed how the control of decision making is arbitrated between, for example, model-based and model-free controllers. An influential proposal here <xref ref-type="bibr" rid="pcbi.1003383-Daw1">[15]</xref> is that such arbitration is based on the confidence with which each system can make a decision. Thus, model-based and model-free systems can be combined by weighting each decision with their relative confidence. The ‘Mixed Instrumental Controller’ <xref ref-type="bibr" rid="pcbi.1003383-Pezzulo1">[19]</xref> also makes use of both types of decision making system. The model-based system incurs a fixed computational penalty reflecting the fact that model-based decisions require time to reach. If the estimated benefit of a model-based decision does not exceed this penalty then control is given to the model-free controller.</p>
</sec><sec id="s4h">
<title>Theta Sequences and Pattern Replay</title>
<p>The next and final section of this discussion summarises the specific predictions of the model proposed in this paper. To put these predictions in context we now briefly review two sets of empirical findings. These are, firstly, the observations of ‘theta sequences’ <xref ref-type="bibr" rid="pcbi.1003383-Foster3">[91]</xref> which are sequential patterns of place cell firing occurring whilst rats move about in their environment and theta activity is recorded in hippocampus. The second set of observations are, again, sequential patterns of place cell firing but now occurring during sleep or quiet wakefulness and when Sharp Wave Ripples (SWRs) (henceforth ‘ripples’) <xref ref-type="bibr" rid="pcbi.1003383-Buzsaki1">[24]</xref> are recorded in hippocampus.</p>
<p>The phenomenon of phase precession refers to the observation <xref ref-type="bibr" rid="pcbi.1003383-OKeefe4">[92]</xref>, <xref ref-type="bibr" rid="pcbi.1003383-Skaggs1">[93]</xref> that place cells fire at gradually earlier phases of the hippocampal theta rhythm as rats move through their place fields. This is consistent with the notion of ‘theta sequences’ in which place cells fire in sequence within a theta cycle. Theta sequences have since been measured across cell-populations <xref ref-type="bibr" rid="pcbi.1003383-Foster3">[91]</xref>. Additionally, theta sequences which sweep forward in advance of a rat's current location have been observed and are especially noteworthy at decision points in maze navigation. For example Johnson and Redish <xref ref-type="bibr" rid="pcbi.1003383-Johnson2">[67]</xref> recorded the activity of neural ensembles in the dorsal hippocampal CA3 region of awake behaving rats running in a T-maze. They found that as rats reached a decision point, representations swept predominantly forward from the current location, first down the right path and then the left. This activity did not occur in both forward directions simultaneously: the representation first encoded one arm and then the other. Finally, Gupta et al. <xref ref-type="bibr" rid="pcbi.1003383-Gupta1">[4]</xref> have shown that theta sequences represent distances further ahead of a rat during acceleration and further behind during deceleration, and that these sequences represent the environment in ‘chunks’. A key feature of theta sequences is that they are time-compressed, occurring at about 5 to 10 times the speed of actual behaviour <xref ref-type="bibr" rid="pcbi.1003383-Foster3">[91]</xref>, <xref ref-type="bibr" rid="pcbi.1003383-Skaggs1">[93]</xref>, <xref ref-type="bibr" rid="pcbi.1003383-Dragoi1">[94]</xref>. That is, were a rat to run through an environment at a typical speed, it could activate the same sequence of place cells, but would do so 5 to 10 times more slowly.</p>
<p>We now turn to the discussion of ripple activity. In humans, episodic memories are thought to be encoded by the Medial Temporal Lobe (MTL) memory system. Information regarding these memories can then be transferred to neocortex <xref ref-type="bibr" rid="pcbi.1003383-Marr1">[95]</xref>–<xref ref-type="bibr" rid="pcbi.1003383-Mclelland1">[97]</xref> and a proposed mechanism of this transfer is the replay of episodes during later waking or sleep <xref ref-type="bibr" rid="pcbi.1003383-McNaughton1">[27]</xref> so that neocortical synaptic plasticity can then act to strengthen cortico-cortical connections. This replay activity has been observed primarily in rodents using spatial navigation tasks <xref ref-type="bibr" rid="pcbi.1003383-Wilson1">[98]</xref> during ripples in Slow Wave Sleep (SWS) <xref ref-type="bibr" rid="pcbi.1003383-Lee1">[99]</xref> and quiet wakefulness. There is evidence that this pattern replay is related to consolidation and transfer, as disrupting ripples impairs performance in a spatial memory task <xref ref-type="bibr" rid="pcbi.1003383-Girardeau1">[100]</xref>.</p>
<p>Place cell sequences observed during awake ripples have been observed to be played backwards. This is known as reverse replay. Foster and Wilson <xref ref-type="bibr" rid="pcbi.1003383-Foster2">[76]</xref>, for example, recorded from cell ensembles in dorsal CA1 hippocampus in awake behaving rats and detected reverse replays after a rat had run the length of a 1D track. Similar reverse replays that start immediately after navigation have been observed on other 1D tracks <xref ref-type="bibr" rid="pcbi.1003383-Diba1">[101]</xref>, a linear path through a 2D environment <xref ref-type="bibr" rid="pcbi.1003383-Davidson1">[102]</xref>, a 2D open-field environment <xref ref-type="bibr" rid="pcbi.1003383-Csiscvari1">[103]</xref>, and a two choice T-maze <xref ref-type="bibr" rid="pcbi.1003383-Gupta2">[104]</xref>. Place cell sequences observed during awake ripples have also been observed to be played forwards <xref ref-type="bibr" rid="pcbi.1003383-Diba1">[101]</xref>. This is known as forward replay.</p>
<p>Replay activity during ripples is also time-compressed, with sequences being replayed within the duration of a single ripple (50–250 ms). This corresponds to a compression factor of about 15 to 20 relative to the original behaviour <xref ref-type="bibr" rid="pcbi.1003383-Davidson1">[102]</xref>.</p>
<p>The above forward and backward replays are also known as ‘local replays’ or ‘locally initiated replays’ so as to distinguish them from another phenomenon known as ‘remote replay’ or ‘remotely initiated replay’. This occurs when a rat replays an experience of one place whilst being physically located in another. In one experiment <xref ref-type="bibr" rid="pcbi.1003383-Karlsson1">[105]</xref>, rats were exposed to two different environments which had the same physical structure (allocentric layout) but differed in their set of visual cues. Replays of trajectories in one maze were observed whilst the rat was located in the other. Remote replay has also been observed <xref ref-type="bibr" rid="pcbi.1003383-Davidson1">[102]</xref>, <xref ref-type="bibr" rid="pcbi.1003383-Gupta2">[104]</xref> where rats replayed activity corresponding to remote parts of the same environment. As is the case with local replays, remote replays can be forward or backward in time <xref ref-type="bibr" rid="pcbi.1003383-Gupta2">[104]</xref>. In general, replay activity during ripples can be forward or backward, whereas theta sequences are always forward.</p>
<p>Jadhav et al. <xref ref-type="bibr" rid="pcbi.1003383-Jadhav1">[106]</xref> have interrupted awake ripples during performance of a navigation task with alternating goals in a W-shaped maze. Ripple disruption was found to affect decision making on the outbound leg of the task, which required linking of past information with current location. However, it did not affect the inbound leg which required no such memory component therefore providing evidence that awake ripples support spatial working memory.</p>
<p>Finally, Dragoi and Tonegawa <xref ref-type="bibr" rid="pcbi.1003383-Dragoi2">[107]</xref> have observed ‘preplay’ activity. Here, the sequence of place-cell firing during a novel spatial experience occurred on a significant number of occasions during the resting or sleeping period prior to that experience. They propose that this activity organises hippocampal assemblies into dynamical structures ready for subsequent associations with sensory episodes.</p>
</sec><sec id="s4i">
<title>Model predictions</title>
<p>This section summarizes the predictions of our model (the ‘FB model’). We indicate where these predictions are unique to the proposed model and where they are shared by others.</p>
<sec id="s4i1">
<title>The hippocampus optimally combines sensory cues with path integration</title>
<p>This prediction is not unique to the FB model. It is shared for example by the conception of the Hippocampus as a Kalman Filter <xref ref-type="bibr" rid="pcbi.1003383-Bousquet1">[20]</xref>. Evidence for the related hypothesis that humans optimally combine sensory cues with path integration is provided in a behavioural study <xref ref-type="bibr" rid="pcbi.1003383-Nardini1">[108]</xref>. Given behaviorial data on a rat navigating in a simple environment in darkness and then in light, it should be possible to develop a spatial model (mapping location to sensory cues) and then infer the precision of sensory cues with respect to path integral input (ie. how much noisier one is than the other). The principles of such an investigation are the same as for the study of Bayesian sensory integration in other domains eg. visual and haptic (for a review, see <xref ref-type="bibr" rid="pcbi.1003383-Penny1">[71]</xref>).</p>
</sec><sec id="s4i2">
<title>Local changes to an environment will produce hippocampal prediction errors</title>
<p>Local changes to an environment, such as objects being moved or disappearing, will be reflected in greater ‘prediction error’ activity in layer 2 LEC cells. This observation has in fact already been made in the reported activity of ‘trace cells’ in LEC <xref ref-type="bibr" rid="pcbi.1003383-Tsao1">[49]</xref>. This prediction is not unique to the FB model, however. It is common to all predictive coding models which posit that connections from hippocampus to LEC layer 5 convey predictions, and connections from LEC layer 2 convey prediction errors <xref ref-type="bibr" rid="pcbi.1003383-Lorincz1">[23]</xref>. The model in Mhatre et al. <xref ref-type="bibr" rid="pcbi.1003383-Mhatre1">[45]</xref> also has this structure, although only predictions of medial rather than lateral EC are considered. These predictive coding models can be traced back to earlier formulations by Gray and McNaughton <xref ref-type="bibr" rid="pcbi.1003383-Gray1">[109]</xref> (p. 243).</p>
</sec><sec id="s4i3">
<title>Theta sequences during decision making are driven by prefrontal circuits</title>
<p>The FB model predicts that theta sequences during decision making (a la Johnson-Redish <xref ref-type="bibr" rid="pcbi.1003383-Johnson2">[67]</xref>) are driven by activity in prefrontal circuits. Moreover, different populations of neurons will be engaged during left-turn versus right-turn theta sequences. This prediction could be confirmed using cell assembly recordings of prefrontal cortex in rat, or using pattern recognition methods for decoding neuroimaging data in human. This prediction is similar to an earlier proposal <xref ref-type="bibr" rid="pcbi.1003383-Byrne1">[32]</xref> that suggested prefrontal regions signal virtual motor efference copy to a spatial cognition system during sensory imagery.</p>
</sec><sec id="s4i4">
<title>Different populations of CA3/CA1 cells will become active during model selection</title>
<p>It has long been proposed that different environments are encoded using different populations of CA3/CA1 cells. Thus, during model selection, when an agent is trying to figure out which environment it is in, we envisage that these different populations will become active as they compete to explain sensory observations. This has been observed in a recent study by Jezek et al. <xref ref-type="bibr" rid="pcbi.1003383-Jezek1">[110]</xref> who familiarized a rat with two different environments, which had identical allocentric layouts but different sensory cues (wall markings). They were then able to electronically switch the sensory cues. Immediately following these switches, two different populations of CA3 cells flickered on and off until one representation became stable. This is referred to as ‘theta flickering’. The FB perspective on theta flickering is as follows. By using the models developed in the investigation of sensory cue integration (see above), it should be possible to predict how long the flickering period endures. The end of the flickering period will correspond to an above threshold likelihood ratio (see <xref ref-type="fig" rid="pcbi-1003383-g005">Figure 5</xref>). This prediction is not unique to the FB model but would be common to any dynamic Bayesian model of hippocampal activity, such as Kalman or particle filtering <xref ref-type="bibr" rid="pcbi.1003383-Bousquet1">[20]</xref>, <xref ref-type="bibr" rid="pcbi.1003383-Courville1">[111]</xref>.</p>
</sec><sec id="s4i5">
<title>Remote replays are algorithmic and support route and motor planning</title>
<p>The replays observed during ripples are often considered to be of previously experienced sequences from episodic memory. We refer to this as the ‘episodic’ view. In contrast, the FB model predicts that replays are not merely previous experiences played forwards or backwards but are the result of computations (the forward and backward recursions). This perspective, which we might term ‘algorithmic’ rather than ‘episodic’ makes a number of specific predictions.</p>
<list list-type="order"><list-item>
<p>Because the function of remote replay is hypothesised to be planning of spatial and motor trajectories then the interruption of remote replay should result in poorer subsequent navigation performance (speed,accuracy). This prediction is specific to the FB model.</p>
</list-item><list-item>
<p>Backward replays should be similar but not identical to time-reversed forward replays. This is illustrated in <xref ref-type="fig" rid="pcbi-1003383-g007">Figure 7</xref>. More specifically, the backward replays are more direct than the corresponding forward replays. That is, they describe shorter trajectories from beginning to end. This prediction is specific to the FB model.</p>
</list-item><list-item>
<p>The FB model predicts that reverse replays encode location with higher spatial precision than the corresponding forward sequences. Here, decoded locations are computed in a backward replay, and FB predicts that the associated spatial precisions will be higher than for the corresponding forward replay. If spatial precision is reflected in higher density spike trains <xref ref-type="bibr" rid="pcbi.1003383-Lengyel2">[75]</xref> then reverse replays should contain higher density spike trains than the associated forward replay. To our knowledge this prediction is unique to the FB model.</p>
</list-item><list-item>
<p>Forward and backward replays should be paired in that a backward replay starts from the end point of a forward replay. The backward replays must therefore be initiated immediately after completion of the corresponding forward replay. This ‘temporal pairing’ is a key prediction of the FB model but has so far not been reported in the literature.</p>
</list-item></list>
<p>The pairing of forward and backward replays, referred to above, would be evident when the following conditions are satisfied (i) the agent is familiar with the environment, (ii) the optimal route requires a chaining together of decisions, rather than a single decision. This is illustrated for example in <xref ref-type="fig" rid="pcbi-1003383-g007">Figure 7</xref> which depicts route and motor planning. Given that the agent is initially facing south, two decisions have to be made to reach the goal (turn right and continue, rather than eg. turn right then right again). This is to be contrasted, for example, with ‘decision making’ in <xref ref-type="fig" rid="pcbi-1003383-g005">Figure 5</xref>, where a single decision is required to reach the goal. The agent needs to be familiar with the environment for it to have developed a model and planning is then based on this model. The above conditions would be satisfied following minor reconfigurations of a familiar environment, such as blockage of a familiar route <xref ref-type="bibr" rid="pcbi.1003383-Alvernhe1">[112]</xref> or appearance of a shortcut <xref ref-type="bibr" rid="pcbi.1003383-Alvernhe2">[113]</xref>. Having updated its model of the environment, an agent could then use forward and backward replays to plan a new optimal route to goal.</p>
<p>A plausible alternative functional role for remote replay is that it is involved in maintaining a memory representation of paths that have not recently been experienced <xref ref-type="bibr" rid="pcbi.1003383-Buhry1">[5]</xref>, <xref ref-type="bibr" rid="pcbi.1003383-Gupta2">[104]</xref>. For example, reverse replay might provide a mechanism for developing a navigationally complete representation of an environment - one reflecting not only trajectories experienced, but also the corresponding reverse trajectories. There is also evidence, referred to earlier, that replays during awake ripples are involved in spatial working memory <xref ref-type="bibr" rid="pcbi.1003383-Jadhav1">[106]</xref>.</p>
<p>Just as we predict that backward replays will be more direct than preceding forward replays, we also predict that later forward replays will be more direct than preceding forward replays. This is, however, predicated on forward and backward replays being repeated iteratively (see ‘Local Linearisation’ above) and being a signature of route planning. Later forward replays can then become quite different to earlier forward replays and correspond to much more direct paths. This prediction is consistent with recent findings <xref ref-type="bibr" rid="pcbi.1003383-Gupta2">[104]</xref> where novel shortcut trajectories were constructed during replay activity. It is also more generally consistent with recent research <xref ref-type="bibr" rid="pcbi.1003383-Pfeiffer1">[114]</xref> that replay activity is involved in planning and is a predictor of subsequent behaviour.</p>
</sec><sec id="s4i6">
<title>Changes in effective connectivity</title>
<p>We now describe predictions of the FB model that posit a change in effective connectivity from one brain region to another. In humans this can be assessed using functional neuroimaging and measures of effective connectivity <xref ref-type="bibr" rid="pcbi.1003383-Friston2">[115]</xref>, <xref ref-type="bibr" rid="pcbi.1003383-Litvak1">[116]</xref>. These human neuroimaging experiments would use previously developed virtual reality environments. Additionally, it is becoming easier to make simultaneous electrophysiological recordings from multiple brain regions in rats. To our knowledge the following predictions are unique to the FB model.</p>
<p>The FB model predicts that theta sequences during decision making (a la Johnson-Redish <xref ref-type="bibr" rid="pcbi.1003383-Johnson2">[67]</xref>) are driven by populations of neurons in prefrontal circuits. We would therefore expect to see increased effective connectivity from prefrontal to hippocampal regions at decision points. The FB model predicts that task goals during decision making are instantiated by increased connectivity from PFC to LEC. We would therefore also expect an increase in effective connectivity from PFC to LEC during these decisions. Additionally, which way to turn would be based on the computation of a likelihood ratio, which we hypothesise will employ the same PFC machinery as for other delayed discrimination tasks (see earlier section on decision making). We would therefore expect to see increased effective connectivity from hippocampus to PFC during decisions. The above predictions are consistent with recent findings of changes in theta coherence in hippocampal-prefrontal networks <xref ref-type="bibr" rid="pcbi.1003383-Benchenane1">[117]</xref>.</p>
<p>During sensory imagery (and decision making) we expect greater prefrontal to hippocampal connectivity, as virtual efference copy is proposed to drive activity in hippocampus. This proposal has also been made in a previous model of spatial memory and imagery <xref ref-type="bibr" rid="pcbi.1003383-Byrne1">[32]</xref>. During route and motor planning we expect prefrontal to LEC connectivity to be increased so as to instantiate task goals (same as for decision making above). Additionally, we expect MEC to prefrontal connectivity to be increased so that control signals can be estimated from the computed reverse path.</p>
</sec></sec><sec id="s4j">
<title>Conclusion</title>
<p>We have shown that the various computations underlying spatial cognition can be implemented using statistical inference in a single probabilistic model. Inference is implemented using a common set of ‘lower-level’ computations involving forward and backward inference over time. We have proposed a mapping of the above computational processes onto lateral and medial entorhinal cortex and hippocampal regions CA3-CA1. This proposed mapping is consistent with recent findings in rat electrophysiology, and other proposals that one function of the hippocampus that is preserved across mammalian species, is that it integrates spatial and non-spatial information. We have also proposed that these computations are reflected in recent findings of pattern replay in the mammalian brain. Specifically, that theta sequences reflect decision making, theta flickering reflects model selection, and remote replay reflects route and motor planning. Many of the underlying hypotheses can be tested using existing data.</p>
</sec></sec><sec id="s5">
<title>Supporting Information</title>
<supplementary-material id="pcbi.1003383.s001" mimetype="application/pdf" xlink:href="info:doi/10.1371/journal.pcbi.1003383.s001" position="float" xlink:type="simple"><label>Text S1</label><caption>
<p>Contains a description of how to to derive the flow matrices <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e484" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003383.e485" xlink:type="simple"/></inline-formula> using local linearisation of state dynamics originally described using a nonlinear differential equation. This used a ‘local regression’ approach described in <xref ref-type="bibr" rid="pcbi.1003383-Schaal1">[28]</xref>.</p>
<p>(PDF)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1003383.s002" mimetype="application/pdf" xlink:href="info:doi/10.1371/journal.pcbi.1003383.s002" position="float" xlink:type="simple"><label>Text S2</label><caption>
<p>Contains a description of the general formulation of forward and backward inference for state space models, at the level of manipulations of probability densities. It describes two alternative formulations based on (i) the gamma and (ii) the beta recursions <xref ref-type="bibr" rid="pcbi.1003383-Bishop1">[38]</xref>, <xref ref-type="bibr" rid="pcbi.1003383-Beal2">[118]</xref>, <xref ref-type="bibr" rid="pcbi.1003383-Todorov2">[119]</xref>.</p>
<p>(PDF)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1003383.s003" mimetype="application/pdf" xlink:href="info:doi/10.1371/journal.pcbi.1003383.s003" position="float" xlink:type="simple"><label>Text S3</label><caption>
<p>Shows how inference over inputs can be accommodated in the standard state-space framework by using an augmented model where the hidden states are an augmented vector comprising both the original states and the inputs.</p>
<p>(PDF)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1003383.s004" mimetype="application/pdf" xlink:href="info:doi/10.1371/journal.pcbi.1003383.s004" position="float" xlink:type="simple"><label>Text S4</label><caption>
<p>Presents an alternative formulation of <xref ref-type="disp-formula" rid="pcbi.1003383.e262">equation 24</xref> in the main text, showing how the relative contribution of path integration and sensory cues, to the estimation of hidden states, is a function of their relative precision <xref ref-type="bibr" rid="pcbi.1003383-Taube1">[59]</xref>, <xref ref-type="bibr" rid="pcbi.1003383-Abbott1">[120]</xref>.</p>
<p>(PDF)</p>
</caption></supplementary-material></sec></body>
<back>
<ack>
<p>We would like to thank Sven Bestmann for discussions regarding motor planning and Hugo Spiers for discussions about model predictions.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1003383-OKeefe1"><label>1</label>
<mixed-citation publication-type="book" xlink:type="simple">O'Keefe J, Nadel L (1978) The Hippocampus as a Cognitive Map. Oxford University Press.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Gallistel1"><label>2</label>
<mixed-citation publication-type="book" xlink:type="simple">Gallistel CR (1990) The organization of learning. Cambridge: MIT Press.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Redish1"><label>3</label>
<mixed-citation publication-type="book" xlink:type="simple">Redish AD (1999) Beyond the Cognitive Map. Cambridge: MIT Press.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Gupta1"><label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gupta</surname><given-names>A</given-names></name>, <name name-style="western"><surname>van der Meer</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Touretzky</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Redish</surname><given-names>A</given-names></name> (<year>2012</year>) <article-title>Segmentation of spatial experience by hippocampal sequences</article-title>. <source>Nature Neuroscience</source> <volume>15</volume>: <fpage>1032</fpage>–<lpage>1039</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Buhry1"><label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Buhry</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Azizi</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Cheng</surname><given-names>S</given-names></name> (<year>2011</year>) <article-title>Reactivation, replay, and preplay: how it might all fit together</article-title>. <source>Neural Plast</source> <volume>2011</volume>: <fpage>203462</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Mumford1"><label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mumford</surname><given-names>D</given-names></name> (<year>1992</year>) <article-title>On the computational architecture of the neocortex II: the role of corticocortical loops</article-title>. <source>Biological Cybernetics</source> <volume>66</volume>: <fpage>241</fpage>–<lpage>251</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Tolman1"><label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tolman</surname><given-names>E</given-names></name> (<year>1948</year>) <article-title>Cognitive maps in rats and men</article-title>. <source>Psychological Review</source> <volume>55</volume>: <fpage>189</fpage>–<lpage>208</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Keith1"><label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Keith</surname><given-names>J</given-names></name>, <name name-style="western"><surname>McVety</surname><given-names>K</given-names></name> (<year>1988</year>) <article-title>Latent place learning in a novel environment and the influence of prior training in rats</article-title>. <source>Psycho</source> <volume>16</volume>: <fpage>146</fpage>–<lpage>151</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Gaussier1"><label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gaussier</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Revel</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Banquet</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Babeau</surname><given-names>V</given-names></name> (<year>2002</year>) <article-title>From view cells and place cells to cognitive map learning: processing stages of the hippocampal system</article-title>. <source>Biological Cybernetics</source> <volume>86</volume>: <fpage>15</fpage>–<lpage>28</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Hasselmo1"><label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hasselmo</surname><given-names>M</given-names></name> (<year>2005</year>) <article-title>A model of prefrontal cortical mechanisms for goal-directed behavior</article-title>. <source>Journal of Cognitive Neuroscience</source> <volume>17</volume>: <fpage>1115</fpage>–<lpage>1129</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-vanderMeer1"><label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>van-der Meer</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Kurth-Nelson</surname><given-names>Z</given-names></name>, <name name-style="western"><surname>Redish</surname><given-names>AD</given-names></name> (<year>2012</year>) <article-title>Information processing in decision making systems</article-title>. <source>The Neuroscientist</source> <volume>18</volume>: <fpage>342</fpage>–<lpage>359</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Sutton1"><label>12</label>
<mixed-citation publication-type="book" xlink:type="simple">Sutton R, Barto A (1998) Reinforcement Learning: An Introduction. Cambridge: MIT Press.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Arleo1"><label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Arleo</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Rondi-Reig</surname><given-names>L</given-names></name> (<year>2007</year>) <article-title>Multimodal sensory integration and concurrent navigation strategies for spatial cognition in real and artificial organisms</article-title>. <source>Journal of Integrative Neuroscience</source> <volume>6</volume>: <fpage>327</fpage>–<lpage>366</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-White1"><label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>White</surname><given-names>N</given-names></name>, <name name-style="western"><surname>McDonald</surname><given-names>R</given-names></name> (<year>2002</year>) <article-title>Multiple parallel memory systems in the brain of the rat</article-title>. <source>Neurobiology of Learning and Memory</source> <volume>77</volume>: <fpage>125</fpage>–<lpage>184</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Daw1"><label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Daw</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Niv</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name> (<year>2005</year>) <article-title>Uncertainty-based competition between prefrontal and dorsolateral striatal systems for behavioral control</article-title>. <source>Nat Neurosci</source> <volume>8</volume>: <fpage>1704</fpage>–<lpage>1711</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Lengyel1"><label>16</label>
<mixed-citation publication-type="other" xlink:type="simple">Lengyel M, Dayan P (2007) Hippocampal contributions to control: The third way. In: J Platt YS D Koller, Roweis S, editors, Advances in Neural Information Processing Systems.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Tse1"><label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tse</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Langston</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Kakeyama</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Bethus</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Spooner</surname><given-names>P</given-names></name>, <etal>et al</etal>. (<year>2007</year>) <article-title>Schemas and memory consolidation</article-title>. <source>Science</source> <volume>316</volume>: <fpage>76</fpage>–<lpage>82</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Khamassi1"><label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Khamassi</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Humphries</surname><given-names>M</given-names></name> (<year>2012</year>) <article-title>Integrating cortico-limbic-basal ganglia architectures for learning model-based and model-free navigation strategies</article-title>. <source>Frontiers Behavioural Neuroscience</source> <volume>6</volume>: <fpage>79</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Pezzulo1"><label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pezzulo</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Rigoli</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Chersi</surname><given-names>F</given-names></name> (<year>2013</year>) <article-title>The Mixed Instrumental Controller: using Values of Information to combine habitual choice and mental simulation</article-title>. <source>Frontiers in Psychology</source> <volume>4</volume>: <fpage>92</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Bousquet1"><label>20</label>
<mixed-citation publication-type="other" xlink:type="simple">Bousquet O, Balakrishnan K, Honavar V (1998) Is the hippocampus a Kalman filter? In: In Proceedings of the Pacific Symposium on Biocomputing. pp. 655–666.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Fuhs1"><label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fuhs</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Touretzky</surname><given-names>D</given-names></name> (<year>2007</year>) <article-title>Context Learning in the Rodent Hippocampus</article-title>. <source>Neural Computation</source> <volume>19</volume>: <fpage>3173</fpage>–<lpage>3215</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Johnson1"><label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Johnson</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Varberg</surname><given-names>Z</given-names></name>, <name name-style="western"><surname>Benhardus</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Maahs</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Schrater</surname><given-names>P</given-names></name> (<year>2012</year>) <article-title>The hippocampus and exploration: dynamically evolving behavior and neural representations</article-title>. <source>Frontiers in Human Neuroscience</source> <volume>6</volume>: <fpage>216</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Lorincz1"><label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lorincz</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Buzsaki</surname><given-names>G</given-names></name> (<year>2000</year>) <article-title>Two-Phase Computational Model Training Long-Term Memories in the Entorhinal-Hippocampal Region</article-title>. <source>Annals New York Academy of Sciences</source> <volume>911</volume>: <fpage>83</fpage>–<lpage>111</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Buzsaki1"><label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Buzsaki</surname><given-names>G</given-names></name> (<year>1989</year>) <article-title>Two-stage model of memory trace formation: a role for noisy brain states</article-title>. <source>Neuroscience</source> <volume>31</volume>: <fpage>551</fpage>–<lpage>70</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Andersen1"><label>25</label>
<mixed-citation publication-type="book" xlink:type="simple">Andersen P, Morris R, Amaral D, Bliss T, O'Keefe J (2007) The Hippocampus Book. Oxford: Oxford University Press.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Jacobs1"><label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jacobs</surname><given-names>LF</given-names></name> (<year>2012</year>) <article-title>From chemotaxis to the cognitive map: the function of olfaction</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>109 Suppl 1</volume>: <fpage>10693</fpage>–<lpage>10700</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-McNaughton1"><label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>McNaughton</surname><given-names>B</given-names></name> (<year>2010</year>) <article-title>Cortical hierarchies, sleep and the extraction of knowledge from memory</article-title>. <source>Artificial Intelligence</source> <volume>174</volume>: <fpage>205</fpage>–<lpage>214</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Schaal1"><label>28</label>
<mixed-citation publication-type="book" xlink:type="simple">Schaal S (1997) Learning from demonstration. In: Mozer M, Jordan M, Petsche T, editors, Advances in Neural Information Processing Systems 9. Cambridge, MA: MIT Press.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Foster1"><label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Foster</surname><given-names>DJ</given-names></name>, <name name-style="western"><surname>Morris</surname><given-names>RG</given-names></name>, <name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name> (<year>2000</year>) <article-title>A model of hippocampally dependent navigation, using the temporal difference learning rule</article-title>. <source>Hippocampus</source> <volume>10</volume>: <fpage>1</fpage>–<lpage>16</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Pouget1"><label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pouget</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Sejnowski</surname><given-names>T</given-names></name> (<year>1997</year>) <article-title>Spatial transformations in the parietal cortex using basis functions</article-title>. <source>Journal of Cognitive Neuroscience</source> <volume>9</volume>: <fpage>222</fpage>–<lpage>237</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Becker1"><label>31</label>
<mixed-citation publication-type="book" xlink:type="simple">Becker S, Burgess N (2001) Modelling spatial recall, mental imagery and neglect. In: Leen T, Dietterich T, Tresp V, editors, Advances in Neural Information Processing Systems 13. Cambridge: MIT Press.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Byrne1"><label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Byrne</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Becker</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Burgess</surname><given-names>N</given-names></name> (<year>2007</year>) <article-title>Remembering the past and imagining the future: a neural model of spatial memory and imagery</article-title>. <source>Psychol Rev</source> <volume>114</volume>: <fpage>340</fpage>–<lpage>375</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Bostock1"><label>33</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bostock</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Muller</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Kubie</surname><given-names>J</given-names></name> (<year>1991</year>) <article-title>Experience-dependent modifications of hippocampal place cell firing</article-title>. <source>Hippocampus</source> <volume>1</volume>: <fpage>193</fpage>–<lpage>206</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Leutgeb1"><label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Leutgeb</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Leutgeb</surname><given-names>JK</given-names></name>, <name name-style="western"><surname>Barnes</surname><given-names>CA</given-names></name>, <name name-style="western"><surname>Moser</surname><given-names>EI</given-names></name>, <name name-style="western"><surname>McNaughton</surname><given-names>BL</given-names></name>, <etal>et al</etal>. (<year>2005</year>) <article-title>Independent codes for spatial and episodic memory in hippocampal neuronal ensembles</article-title>. <source>Science</source> <volume>309</volume>: <fpage>619</fpage>–<lpage>623</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Kali1"><label>35</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kali</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name> (<year>2000</year>) <article-title>The involvement of recurrent connections in area ca3 in establishing the properties of place fields: a model</article-title>. <source>J Neurosci</source> <volume>20</volume>: <fpage>7463</fpage>–<lpage>7477</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Oore1"><label>36</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Oore</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Hinton</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Dudek</surname><given-names>G</given-names></name> (<year>1997</year>) <article-title>A mobile robot that learns its place</article-title>. <source>Neural Computation</source> <volume>9</volume>: <fpage>683</fpage>–<lpage>699</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-DurrantWhyte1"><label>37</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Durrant-Whyte</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Bailey</surname><given-names>T</given-names></name> (<year>2006</year>) <article-title>Simultaneous localisation and mapping (SLAM): Part i the essential algorithms</article-title>. <source>Robotics and Automation Magazine</source> <volume>13</volume>: <fpage>99</fpage>–<lpage>110</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Bishop1"><label>38</label>
<mixed-citation publication-type="book" xlink:type="simple">Bishop C (2006) Pattern Recognition and Machine Learning. New York: Springer.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Doucet1"><label>39</label>
<mixed-citation publication-type="book" xlink:type="simple">Doucet A, Johansen A (2011) Handbook of nonlinear filtering. Oxford University Press, chapter A tutorial on Particle Filtering and Smoothing: Fifteen years Later.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Einicke1"><label>40</label>
<mixed-citation publication-type="book" xlink:type="simple">Einicke G (2012) Smoothing, Filtering and Prediction - Estimating the past, present and future. New York: InTech.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Briers1"><label>41</label>
<mixed-citation publication-type="other" xlink:type="simple">Briers M, Doucet A, Maskell S (2004) Smoothing algorithms for state-space models. Technical report, Engineering Department, Cambridge University.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Green1"><label>42</label>
<mixed-citation publication-type="book" xlink:type="simple">Green D, Swets J (1966) Signal detection theory and psychophysics. Chichester: John Wiley.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Knierim1"><label>43</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Knierim</surname><given-names>J</given-names></name> (<year>2006</year>) <article-title>Neural representations of location outside the hippocampus</article-title>. <source>Learn Mem</source> <volume>13</volume>: <fpage>405</fpage>–<lpage>415</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-vanStrien1"><label>44</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>van Strien</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Cappaert</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Witter</surname><given-names>M</given-names></name> (<year>2009</year>) <article-title>The anatomy of memory: an interactive overview of the parahippocampal-hippocampal network</article-title>. <source>Nature Reviews Neuroscience</source> <volume>10</volume>: <fpage>272</fpage>–<lpage>282</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Mhatre1"><label>45</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mhatre</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Gorchetchnikov</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Grossberg</surname><given-names>S</given-names></name> (<year>2012</year>) <article-title>Grid cell hexagonal patterns formed by fast self-organized learning within entorhinal cortex</article-title>. <source>Hippocampus</source> <volume>22</volume>: <fpage>320</fpage>–<lpage>334</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Witter1"><label>46</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Witter</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Moser</surname><given-names>E</given-names></name> (<year>2006</year>) <article-title>Spatial representation and the architecture of the entorhinal cortex</article-title>. <source>Trends Neuroscience</source> <volume>29</volume>: <fpage>671</fpage>–<lpage>678</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Jones1"><label>47</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jones</surname><given-names>M</given-names></name>, <name name-style="western"><surname>McHugh</surname><given-names>T</given-names></name> (<year>2011</year>) <article-title>Updating hippocampal representations: CA2 joins the circuit</article-title>. <source>Trends Neurosci</source> <volume>34</volume>: <fpage>526</fpage>–<lpage>535</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Manns1"><label>48</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Manns</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Eichenbaum</surname><given-names>H</given-names></name> (<year>2006</year>) <article-title>Evolution of declarative memory</article-title>. <source>Hippocampus</source> <volume>16</volume>: <fpage>795</fpage>–<lpage>808</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Tsao1"><label>49</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tsao</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Moser</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Moser</surname><given-names>E</given-names></name> (<year>2013</year>) <article-title>Traces of experience in the lateral entorhinal cortex</article-title>. <source>Current Biology</source> <volume>23</volume>: <fpage>1</fpage>–<lpage>7</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Conklin1"><label>50</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Conklin</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Eliasmith</surname><given-names>C</given-names></name> (<year>2005</year>) <article-title>An attractor network model of path integration in the rat</article-title>. <source>Journal of Computational Neuroscience</source> <volume>18</volume>: <fpage>183</fpage>–<lpage>203</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-McNaughton2"><label>51</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>McNaughton</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Battaglia</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Jensen</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Moser</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Moser</surname><given-names>M</given-names></name> (<year>2006</year>) <article-title>Path integration and the neural basis of the ‘cognitive map’</article-title>. <source>Nat Rev Neurosci</source> <volume>7</volume>: <fpage>663</fpage>–<lpage>678</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Hafting1"><label>52</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hafting</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Fyhn</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Molden</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Moser</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Moser</surname><given-names>E</given-names></name> (<year>2005</year>) <article-title>Microstructure of a spatial map in the entorhinal cortex</article-title>. <source>Nature</source> <volume>436</volume>: <fpage>801</fpage>–<lpage>806</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Doeller1"><label>53</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Doeller</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Barry</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Burgess</surname><given-names>N</given-names></name> (<year>2010</year>) <article-title>Evidence for grid cells in a human memory network</article-title>. <source>Nature</source> <volume>463</volume>: <fpage>657</fpage>–<lpage>661</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-OKeefe2"><label>54</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>O' Keefe</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Dostrovsky</surname><given-names>J</given-names></name> (<year>1971</year>) <article-title>The hippocampus as a spatial map. preliminary evidence from unit activity in the freely moving rat</article-title>. <source>Brain Research</source> <volume>34</volume>: <fpage>171</fpage>–<lpage>175</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Ekstrom1"><label>55</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ekstrom</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Kahana</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Caplan</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Fields</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Isham</surname><given-names>E</given-names></name>, <etal>et al</etal>. (<year>2003</year>) <article-title>Cellular networks underlying human spatial navigation</article-title>. <source>Nature</source> <volume>425</volume>: <fpage>184</fpage>–<lpage>188</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Maguire1"><label>56</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Maguire</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Burgess</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Donnett</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Frackowiak</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Frith</surname><given-names>C</given-names></name>, <etal>et al</etal>. (<year>1998</year>) <article-title>Knowing where and getting there: a human navigation network</article-title>. <source>Science</source> <volume>280</volume>: <fpage>921</fpage>–<lpage>924</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Hassabis1"><label>57</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hassabis</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Chu</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Rees</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Weiskopf</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Molyneux</surname><given-names>P</given-names></name>, <etal>et al</etal>. (<year>2009</year>) <article-title>Decoding neuronal ensembles in the human hippocampus</article-title>. <source>Curr Biol</source> <volume>19</volume>: <fpage>546</fpage>–<lpage>554</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Morgan1"><label>58</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Morgan</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Macevoy</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Aguirre</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Epstein</surname><given-names>R</given-names></name> (<year>2011</year>) <article-title>Distances between real-world locations are represented in the human hippocampus</article-title>. <source>J Neurosci</source> <volume>31</volume>: <fpage>1238</fpage>–<lpage>1245</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Taube1"><label>59</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Taube</surname><given-names>J</given-names></name> (<year>2009</year>) <article-title>Head direction cells</article-title>. <source>Scholarpedia</source> <volume>4</volume>: <fpage>1787</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Sargolini1"><label>60</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sargolini</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Fyhn</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Hafting</surname><given-names>T</given-names></name>, <name name-style="western"><surname>McNaughton</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Witter</surname><given-names>M</given-names></name>, <etal>et al</etal>. (<year>2006</year>) <article-title>Conjunctive representation of position, direction, and velocity in entorhinal cortex</article-title>. <source>Science</source> <volume>312</volume>: <fpage>758</fpage>–<lpage>762</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-OKeefe3"><label>61</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>O'Keefe</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Burgess</surname><given-names>N</given-names></name> (<year>2005</year>) <article-title>Dual phase and rate coding in hippocampal place cells: theoretical significance and relationship to entorhinal grid cells</article-title>. <source>Hippocampus</source> <volume>15</volume>: <fpage>853</fpage>–<lpage>866</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Sreenivasan1"><label>62</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sreenivasan</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Fiete</surname><given-names>I</given-names></name> (<year>2011</year>) <article-title>Grid cells generate an analog error-correcting code for singularly precise neural computation</article-title>. <source>Nature Neuroscience</source> <volume>14</volume>: <fpage>1330</fpage>–<lpage>1337</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Arleo2"><label>63</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Arleo</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Gerstner</surname><given-names>W</given-names></name> (<year>2000</year>) <article-title>Spatial cognition and neuro-mimetic navigation: a model of hippocampal place cell activity</article-title>. <source>Biological Cybernetics</source> <volume>83</volume>: <fpage>287</fpage>–<lpage>299</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Hassabis2"><label>64</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hassabis</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Kumaran</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Vann</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Maguire</surname><given-names>E</given-names></name> (<year>2007</year>) <article-title>Patients with hippocampal amnesia cannot imagine new experiences</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>104</volume>: <fpage>1726</fpage>–<lpage>1731</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Hassabis3"><label>65</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hassabis</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Maguire</surname><given-names>E</given-names></name> (<year>2009</year>) <article-title>The construction system of the brain</article-title>. <source>Philosophical Transactions of the Royal Society London B</source> <volume>364</volume>: <fpage>1263</fpage>–<lpage>71</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Fox1"><label>66</label>
<mixed-citation publication-type="other" xlink:type="simple">Fox C, Prescott T (2009) Hippocampus as unitary coherent particle filter. In: International Joint Conference on Neural Networks. Atlanta, GA, USA.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Johnson2"><label>67</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Johnson</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Redish</surname><given-names>AD</given-names></name> (<year>2007</year>) <article-title>Neural ensembles in CA3 transiently encode paths forward of the animal at a decision point</article-title>. <source>J Neurosci</source> <volume>27</volume>: <fpage>12176</fpage>–<lpage>12189</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Bogacz1"><label>68</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bogacz</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Brown</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Moehlis</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Holmes</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Cohen</surname><given-names>J</given-names></name> (<year>2006</year>) <article-title>The physics of optimal decision making: a formal analysis of models and performance in two-alternative forced-choice tasks</article-title>. <source>Psychological Review</source> <volume>113</volume>: <fpage>700</fpage>–<lpage>765</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Machens1"><label>69</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Machens</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Romo</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Brody</surname><given-names>C</given-names></name> (<year>2005</year>) <article-title>Flexible control of mutual inhibition: a neural model of two-interval discrimination</article-title>. <source>Science</source> <volume>307</volume>: <fpage>1121</fpage>–<lpage>1124</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Lisman1"><label>70</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lisman</surname><given-names>J</given-names></name> (<year>2007</year>) <article-title>Role of the dual entorhinal inputs to hippocampus: a hypothesis based on cue/action (non-self/self) couplets</article-title>. <source>Progress in Brain Research</source> <volume>163</volume>: <fpage>615</fpage>–<lpage>625</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Penny1"><label>71</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Penny</surname><given-names>W</given-names></name> (<year>2012</year>) <article-title>Bayesian models of brain and behaviour</article-title>. <source>ISRN Biomathematics</source> <volume>2012</volume>: <fpage>785791</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Ma1"><label>72</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ma</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Beck</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Latham</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Pouget</surname><given-names>A</given-names></name> (<year>2006</year>) <article-title>Bayesian inference with probabilistic population codes</article-title>. <source>Nat Neurosci</source> <volume>9</volume>: <fpage>1432</fpage>–<lpage>1438</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Beck1"><label>73</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Beck</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Latham</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Pouget</surname><given-names>A</given-names></name> (<year>2011</year>) <article-title>Marginalization in neural circuits with divisive normalization</article-title>. <source>J Neurosci</source> <volume>31</volume>: <fpage>15310</fpage>–<lpage>15319</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Fenton1"><label>74</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fenton</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Muller</surname><given-names>R</given-names></name> (<year>1998</year>) <article-title>Place cell discharge is extremely variable during individual passes of the rat through the firing field</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>95</volume>: <fpage>3182</fpage>–<lpage>3187</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Lengyel2"><label>75</label>
<mixed-citation publication-type="book" xlink:type="simple">Lengyel M, Dayan P (2007) Uncertainty, phase and oscillatory hippocampal recall. In: Scholkopf B, Platt J, Hofmann T, editors, Advances in Neural Information Processing Systems 19, Cambridge: MIT Press.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Foster2"><label>76</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Foster</surname><given-names>DJ</given-names></name>, <name name-style="western"><surname>Wilson</surname><given-names>MA</given-names></name> (<year>2006</year>) <article-title>Reverse replay of behavioural sequences in hippocampal place cells during the awake state</article-title>. <source>Nature</source> <volume>440</volume>: <fpage>680</fpage>–<lpage>683</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Attias1"><label>77</label>
<mixed-citation publication-type="other" xlink:type="simple">Attias H (2003) Planning by probabilistic inference. In: Bishop C, Frey B, editors, Proceedings of the 9th International Conference on Artificial Intelligence and Statistics.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Toussaint1"><label>78</label>
<mixed-citation publication-type="other" xlink:type="simple">Toussaint M (2009) Robot trajectory optimisation using approximate inference. In: Danyluk A, Bottou L, Littman M, editors, Proc. of the 26 th International Conference on Machine Learning (ICML 2009).</mixed-citation>
</ref>
<ref id="pcbi.1003383-Botvinick1"><label>79</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Botvinick</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Toussaint</surname><given-names>M</given-names></name> (<year>2012</year>) <article-title>Planning as inference</article-title>. <source>Trends Cogn Sci</source> <volume>16</volume>: <fpage>485</fpage>–<lpage>488</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Solway1"><label>80</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Solway</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Botvinick</surname><given-names>M</given-names></name> (<year>2012</year>) <article-title>Goal-directed decision making as probabilistic inference: a computational framework and potential neural correlates</article-title>. <source>Psychol Rev</source> <volume>119</volume>: <fpage>120</fpage>–<lpage>154</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Bishop2"><label>81</label>
<mixed-citation publication-type="other" xlink:type="simple">Bishop CM (1995) Neural Networks for Pattern Recognition. Oxford University Press, Oxford.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Ghahramani1"><label>82</label>
<mixed-citation publication-type="other" xlink:type="simple">Ghahramani Z, Hinton G (1996) Parameter Estimation for Linear Dynamical Systems. Technical Report CRG-TR-96-2, Department of Computer Science, University of Toronto. Also available from <ext-link ext-link-type="uri" xlink:href="http://www.mlg.eng.cam.ac.uk/zoubin/papers.html" xlink:type="simple">http://www.mlg.eng.cam.ac.uk/zoubin/papers.html</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Beal1"><label>83</label>
<mixed-citation publication-type="other" xlink:type="simple">Beal M (2003) Variational algorithms for approximate Bayesian inference. Ph.D. thesis, University College London.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Daunizeau1"><label>84</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Daunizeau</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Friston</surname><given-names>KJ</given-names></name>, <name name-style="western"><surname>Kiebel</surname><given-names>SJ</given-names></name> (<year>2009</year>) <article-title>Variational Bayesian identification and prediction of stochastic nonlinear dynamic causal models</article-title>. <source>Physica D</source> <volume>238</volume>: <fpage>2089</fpage>–<lpage>2118</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Friston1"><label>85</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Friston</surname><given-names>K</given-names></name> (<year>2010</year>) <article-title>The free-energy principle: a unified brain theory?</article-title> <source>Nat Rev Neurosci</source> <volume>11</volume>: <fpage>127</fpage>–<lpage>138</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Li1"><label>86</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Li</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Todorov</surname><given-names>E</given-names></name> (<year>2007</year>) <article-title>Iterative linearization methods for approximately optimal control and estimation of non-linear stochastic systems</article-title>. <source>International Journal of Control</source> <volume>80</volume>: <fpage>1439</fpage>–<lpage>1453</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Todorov1"><label>87</label>
<mixed-citation publication-type="other" xlink:type="simple">Todorov E (2008) General duality between optimal control and estimation. In: IEEE Conference on Decision and Control. volume 47, pp. 4286–4292.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Muller1"><label>88</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Muller</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Stead</surname><given-names>M</given-names></name> (<year>1997</year>) <article-title>Hippocampal place cells connected by Hebbian synapses can solve spatial problems</article-title>. <source>Hippocampus</source> <volume>6</volume>: <fpage>709</fpage>–<lpage>719</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Johnson3"><label>89</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Johnson</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Redish</surname><given-names>A</given-names></name> (<year>2005</year>) <article-title>Hippocampal replay contributes to within session learning in a temporal difference reinforcement learning model</article-title>. <source>Neural Netw</source> <volume>18</volume>: <fpage>1163</fpage>–<lpage>1171</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Pennartz1"><label>90</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pennartz</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Lee</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Verheul</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Lipa</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Barnes</surname><given-names>C</given-names></name>, <etal>et al</etal>. (<year>2004</year>) <article-title>The ventral striatum in off-line processing: ensemble reactivation during sleep and modulation by hippocampal ripples</article-title>. <source>Journal of Neuroscience</source> <volume>24</volume>: <fpage>6446</fpage>–<lpage>6456</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Foster3"><label>91</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Foster</surname><given-names>DJ</given-names></name>, <name name-style="western"><surname>Wilson</surname><given-names>MA</given-names></name> (<year>2007</year>) <article-title>Hippocampal theta sequences</article-title>. <source>Hippocampus</source> <volume>17</volume>: <fpage>1093</fpage>–<lpage>1099</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-OKeefe4"><label>92</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>O'Keefe</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Recce</surname><given-names>M</given-names></name> (<year>1993</year>) <article-title>Phase relationship between hippocampal place units and the EEG theta rhythm</article-title>. <source>Hippocampus</source> <volume>3</volume>: <fpage>317</fpage>–<lpage>330</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Skaggs1"><label>93</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Skaggs</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Mcnaughton</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Wilson</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Barnes</surname><given-names>C</given-names></name> (<year>1996</year>) <article-title>Theta phase precession in hippocampal neuronal populations and the compression of temporal sequences</article-title>. <source>Hippocampus</source> <volume>6</volume>: <fpage>149</fpage>–<lpage>172</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Dragoi1"><label>94</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dragoi</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Buzsaki</surname><given-names>G</given-names></name> (<year>2006</year>) <article-title>Temporal encoding of place sequences by Hippocampal Cell Assemblies</article-title>. <source>Neuron</source> <volume>50</volume>: <fpage>145</fpage>–<lpage>157</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Marr1"><label>95</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Marr</surname><given-names>D</given-names></name> (<year>1971</year>) <article-title>Simple memory: A theory of archicortex</article-title>. <source>Phil Trans Royal Soc B</source> <volume>262</volume>: <fpage>23</fpage>–<lpage>81</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Alvarez1"><label>96</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Alvarez</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Squire</surname><given-names>L</given-names></name> (<year>1994</year>) <article-title>Memory consolidation and the medial temporal lobe: a simple network model</article-title>. <source>Proceedings National Academy of Sciences</source> <volume>91</volume>: <fpage>7041</fpage>–<lpage>7045</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Mclelland1"><label>97</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mclelland</surname><given-names>J</given-names></name>, <name name-style="western"><surname>McNaughton</surname><given-names>B</given-names></name>, <name name-style="western"><surname>O'Reilly</surname><given-names>R</given-names></name> (<year>1995</year>) <article-title>Why there are complementary learning systems in the hippocampus and neocortex: insights from the successes and failures of connectionist models of learning and memory</article-title>. <source>Psychology Review</source> <volume>102</volume>: <fpage>419</fpage>–<lpage>457</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Wilson1"><label>98</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wilson</surname><given-names>M</given-names></name>, <name name-style="western"><surname>McNaughton</surname><given-names>B</given-names></name> (<year>1994</year>) <article-title>Reactivation of hippocampal ensemble memories during sleep</article-title>. <source>Science</source> <volume>265</volume>: <fpage>676</fpage>–<lpage>679</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Lee1"><label>99</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lee</surname><given-names>AK</given-names></name>, <name name-style="western"><surname>Wilson</surname><given-names>MA</given-names></name> (<year>2002</year>) <article-title>Memory of sequential experience in the hippocampus during slow wave sleep</article-title>. <source>Neuron</source> <volume>36</volume>: <fpage>1183</fpage>–<lpage>1194</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Girardeau1"><label>100</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Girardeau</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Benchenane</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Wiener</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Buzsaki</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Zugaro</surname><given-names>M</given-names></name> (<year>2009</year>) <article-title>Selective suppression of hippocampal ripples impairs spatial memory</article-title>. <source>Nature Neuroscience</source> <volume>12</volume>: <fpage>1222</fpage>–<lpage>1223</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Diba1"><label>101</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Diba</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Buzsaki</surname><given-names>G</given-names></name> (<year>2007</year>) <article-title>Forward and reverse hippocampal place-cell sequences during ripples</article-title>. <source>Nat Neurosci</source> <volume>10</volume>: <fpage>1241</fpage>–<lpage>1242</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Davidson1"><label>102</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Davidson</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Kloosterman</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Wilson</surname><given-names>M</given-names></name> (<year>2009</year>) <article-title>Hippocampal Replay of Extended Experience</article-title>. <source>Neuron</source> <volume>63</volume>: <fpage>497</fpage>–<lpage>507</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Csiscvari1"><label>103</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Csiscvari</surname><given-names>J</given-names></name>, <name name-style="western"><surname>O'Neill</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Allen</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Senior</surname><given-names>T</given-names></name> (<year>2007</year>) <article-title>Place-selective firing contributes to the reverseorder activation of CA1 pyramidal cells during sharp waves in open-field exploration</article-title>. <source>European Journal of Neuroscience</source> <volume>26</volume>: <fpage>704</fpage>–<lpage>716</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Gupta2"><label>104</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gupta</surname><given-names>A</given-names></name>, <name name-style="western"><surname>van der Meer</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Touretzky</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Redish</surname><given-names>A</given-names></name> (<year>2010</year>) <article-title>Hippocampal replay is not a simple function of experience</article-title>. <source>Neuron</source> <volume>65</volume>: <fpage>695</fpage>–<lpage>705</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Karlsson1"><label>105</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Karlsson</surname><given-names>MP</given-names></name>, <name name-style="western"><surname>Frank</surname><given-names>LM</given-names></name> (<year>2009</year>) <article-title>Awake replay of remote experiences in the hippocampus</article-title>. <source>Nat Neurosci</source> <volume>12</volume>: <fpage>913</fpage>–<lpage>918</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Jadhav1"><label>106</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jadhav</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Kemere</surname><given-names>C</given-names></name>, <name name-style="western"><surname>German</surname><given-names>PW</given-names></name>, <name name-style="western"><surname>Frank</surname><given-names>L</given-names></name> (<year>2012</year>) <article-title>Awake Hippocampal Sharp-Wave Ripples Support Spatial Memory</article-title>. <source>Science</source> <volume>336</volume>: <fpage>1454</fpage>–<lpage>1458</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Dragoi2"><label>107</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dragoi</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Tonegawa</surname><given-names>S</given-names></name> (<year>2011</year>) <article-title>Preplay of future place cell sequences by hippocampal cellular assemblies</article-title>. <source>Nature</source> <volume>469</volume>: <fpage>397</fpage>–<lpage>401</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Nardini1"><label>108</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nardini</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Jones</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Bedford</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Braddick</surname><given-names>O</given-names></name> (<year>2008</year>) <article-title>Development of Cue Integration in Human Navigation</article-title>. <source>Current Biology</source> <volume>18</volume>: <fpage>689</fpage>–<lpage>693</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Gray1"><label>109</label>
<mixed-citation publication-type="book" xlink:type="simple">Gray J, McNaughton N (1987) The Neuropsychology of Anxiety: An enquiry into the functions of the septo-hippocampal system. Oxford: Oxford University Press.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Jezek1"><label>110</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jezek</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Henriksen</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Treves</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Moser</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Moser</surname><given-names>M</given-names></name> (<year>2011</year>) <article-title>Theta-paced ickering between placecell maps in the hippocampus</article-title>. <source>Nature</source> <volume>478</volume>: <fpage>246</fpage>–<lpage>251</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Courville1"><label>111</label>
<mixed-citation publication-type="book" xlink:type="simple">Courville AC, Daw ND (2007) The rat as particle filter. In: Platt J, Koller D, Singer Y, Roweis S, editors, Advances in Neural Information Processing Systems 20, Cambridge, MA: MIT Press. pp. 369–376.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Alvernhe1"><label>112</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Alvernhe</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Save</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Poucet</surname><given-names>B</given-names></name> (<year>2011</year>) <article-title>Local remapping of place cell firing in the Tolman detour task</article-title>. <source>European Journal of Neuroscience</source> <volume>33</volume>: <fpage>1696</fpage>–<lpage>1705</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Alvernhe2"><label>113</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Alvernhe</surname><given-names>A</given-names></name>, <name name-style="western"><surname>van Cauter</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Save</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Poucet</surname><given-names>B</given-names></name> (<year>2008</year>) <article-title>Different CA1 and CA3 representations of novel routes in a shortcut situation </article-title>. <source>Journal of Neuroscience</source> <volume>28</volume>: <fpage>7324</fpage>–<lpage>7333</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Pfeiffer1"><label>114</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pfeiffer</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Foster</surname><given-names>D</given-names></name> (<year>2013</year>) <article-title>Hippocampal place-cell sequences depict future paths to remembered goals</article-title>. <source>Nature</source> <volume>497</volume>: <fpage>74</fpage>–<lpage>79</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Friston2"><label>115</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Friston</surname><given-names>KJ</given-names></name>, <name name-style="western"><surname>Harrison</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Penny</surname><given-names>W</given-names></name> (<year>2003</year>) <article-title>Dynamic causal modelling</article-title>. <source>Neuroimage</source> <volume>19</volume>: <fpage>1273</fpage>–<lpage>1302</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Litvak1"><label>116</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Litvak</surname><given-names>V</given-names></name>, <name name-style="western"><surname>Mattout</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Kiebel</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Phillips</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Henson</surname><given-names>R</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <article-title>EEG and MEG data analysis in SPM8</article-title>. <source>Comput Intell Neurosci</source> <volume>2011</volume>: <fpage>852961</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Benchenane1"><label>117</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Benchenane</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Peyrache</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Khamassi</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Tierney</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Gioanni</surname><given-names>Y</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>Coherent theta oscillations and reorganization of spike timing in the hippocampal-prefrontal network upon learning</article-title>. <source>Neuron</source> <volume>66</volume>: <fpage>921</fpage>–<lpage>36</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Beal2"><label>118</label>
<mixed-citation publication-type="other" xlink:type="simple">Beal M (2003) Variational Algorithms for Approximate Bayesian Inference. Ph.D. thesis, Gatsby Computational Neuroscience Unit, University College London.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Todorov2"><label>119</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Todorov</surname><given-names>E</given-names></name> (<year>2009</year>) <article-title>Efficient computation of optimal actions</article-title>. <source>Proceedings National Academy of Sciences</source> <volume>106</volume>: <fpage>11478</fpage>–<lpage>11483</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003383-Abbott1"><label>120</label>
<mixed-citation publication-type="book" xlink:type="simple">Abbott L (2006) Where are the switches on this thing ?, Oxford University Press, chapter 23 Problems in Systems Neuroscience.</mixed-citation>
</ref>
</ref-list></back>
</article>
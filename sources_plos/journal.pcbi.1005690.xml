<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN" "http://jats.nlm.nih.gov/publishing/1.1d3/JATS-journalpublishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-17-00570</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1005690</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Algebra</subject><subj-group><subject>Algebraic topology</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Topology</subject><subj-group><subject>Algebraic topology</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Cell biology</subject><subj-group><subject>Cellular structures and organelles</subject><subj-group><subject>Cell membranes</subject><subj-group><subject>Membrane proteins</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Biochemistry</subject><subj-group><subject>Proteins</subject><subj-group><subject>Globular proteins</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Molecular biology</subject><subj-group><subject>Macromolecular structure analysis</subject><subj-group><subject>Protein structure</subject><subj-group><subject>Protein structure prediction</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Biochemistry</subject><subj-group><subject>Proteins</subject><subj-group><subject>Protein structure</subject><subj-group><subject>Protein structure prediction</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Topology</subject><subj-group><subject>Topological invariants</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Applied mathematics</subject><subj-group><subject>Algorithms</subject><subj-group><subject>Machine learning algorithms</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Simulation and modeling</subject><subj-group><subject>Algorithms</subject><subj-group><subject>Machine learning algorithms</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Artificial intelligence</subject><subj-group><subject>Machine learning</subject><subj-group><subject>Machine learning algorithms</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Physics</subject><subj-group><subject>Thermodynamics</subject><subj-group><subject>Free energy</subject></subj-group></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>TopologyNet: Topology based deep convolutional and multi-task neural networks for biomolecular property predictions</article-title>
<alt-title alt-title-type="running-head">TopologyNet for biomolecular property predictions</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-9951-5586</contrib-id>
<name name-style="western">
<surname>Cang</surname> <given-names>Zixuan</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Resources</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-8132-5998</contrib-id>
<name name-style="western">
<surname>Wei</surname> <given-names>Guo-Wei</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Project administration</role>
<role content-type="http://credit.casrai.org/">Resources</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
</contrib-group>
<aff id="aff001">
<label>1</label>
<addr-line>Department of Mathematics, Michigan State University, East Lansing, MI 48824, USA</addr-line>
</aff>
<aff id="aff002">
<label>2</label>
<addr-line>Department of Biochemistry and Molecular Biology, Michigan State University, East Lansing, MI 48824, USA</addr-line>
</aff>
<aff id="aff003">
<label>3</label>
<addr-line>Department of Electrical and Computer Engineering, Michigan State University, East Lansing, MI 48824, USA</addr-line>
</aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Dunbrack</surname> <given-names>Roland L.</given-names> <suffix>Jr.</suffix></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>Fox Chase Cancer Center, UNITED STATES</addr-line>
</aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">wei@math.msu.edu</email></corresp>
</author-notes>
<pub-date pub-type="collection">
<month>7</month>
<year>2017</year>
</pub-date>
<pub-date pub-type="epub">
<day>27</day>
<month>7</month>
<year>2017</year>
</pub-date>
<volume>13</volume>
<issue>7</issue>
<elocation-id>e1005690</elocation-id>
<history>
<date date-type="received">
<day>6</day>
<month>4</month>
<year>2017</year>
</date>
<date date-type="accepted">
<day>18</day>
<month>7</month>
<year>2017</year>
</date>
</history>
<permissions>
<copyright-year>2017</copyright-year>
<copyright-holder>Cang, Wei</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1005690"/>
<abstract>
<p>Although deep learning approaches have had tremendous success in image, video and audio processing, computer vision, and speech recognition, their applications to three-dimensional (3D) biomolecular structural data sets have been hindered by the geometric and biological complexity. To address this problem we introduce the element-specific persistent homology (ESPH) method. ESPH represents 3D complex geometry by one-dimensional (1D) topological invariants and retains important biological information via a multichannel image-like representation. This representation reveals hidden structure-function relationships in biomolecules. We further integrate ESPH and deep convolutional neural networks to construct a multichannel topological neural network (TopologyNet) for the predictions of protein-ligand binding affinities and protein stability changes upon mutation. To overcome the deep learning limitations from small and noisy training sets, we propose a multi-task multichannel topological convolutional neural network (MM-TCNN). We demonstrate that TopologyNet outperforms the latest methods in the prediction of protein-ligand binding affinities, mutation induced globular protein folding free energy changes, and mutation induced membrane protein folding free energy changes. Availability: weilab.math.msu.edu/TDL/</p>
</abstract>
<abstract abstract-type="summary">
<title>Author summary</title>
<p>The predictions of biomolecular functions and properties from biomolecular structures are of fundamental importance in computational biophysics. The structural and biological complexities of biomolecules and their interactions hinder successful predictions. Machine learning has become an important tool for such predictions. Recent advances in deep learning architectures, particularly convolutional neural network (CNN), have profoundly impacted a number of disciplines, such as image classification and voice recognition. Though CNN can be directly applied to molecular sciences by using a three-dimensional (3D) image-like brute-force representation, it is computationally intractable when applied to large biomolecules and large datasets. We propose a topological strategy to significantly reduce the structural and biological complexity of biomolecules and provide an efficient topology based CNN architecture. Element-specific persistent homology, a new algebraic topology, has been developed to cast biomolecules in a multichannel image-like representation suitable for CNN. The power of the proposed topology based neural network (TopologyNet) is further enhanced by auxiliary descriptors and a multi-task deep learning architecture. It has been demonstrated that TopologyNet framework outperforms other methods in the predictions of protein-ligand binding affinities and mutation induced protein stability changes.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000001</institution-id>
<institution>National Science Foundation</institution>
</institution-wrap>
</funding-source>
<award-id>IIS-1302285</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-8132-5998</contrib-id>
<name name-style="western">
<surname>Wei</surname> <given-names>Guo-Wei</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award002">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000001</institution-id>
<institution>National Science Foundation</institution>
</institution-wrap>
</funding-source>
<award-id>DMS-1721024</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-8132-5998</contrib-id>
<name name-style="western">
<surname>Wei</surname> <given-names>Guo-Wei</given-names></name>
</principal-award-recipient>
</award-group>
<funding-statement>Funds are received from National Science Foundation IIS-1302285 (<ext-link ext-link-type="uri" xlink:href="https://www.nsf.gov/div/index.jsp?div=IIS" xlink:type="simple">https://www.nsf.gov/div/index.jsp?div=IIS</ext-link>) to GW, National Science Foundation DMS-1721024 (<ext-link ext-link-type="uri" xlink:href="https://www.nsf.gov/div/index.jsp?div=DMS" xlink:type="simple">https://www.nsf.gov/div/index.jsp?div=DMS</ext-link>) to GW, and Michigan State University (<ext-link ext-link-type="uri" xlink:href="https://vprgs.msu.edu/" xlink:type="simple">https://vprgs.msu.edu/</ext-link>) to GW. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="8"/>
<table-count count="5"/>
<page-count count="27"/>
</counts>
<custom-meta-group>
<custom-meta>
<meta-name>PLOS Publication Stage</meta-name>
<meta-value>vor-update-to-uncorrected-proof</meta-value>
</custom-meta>
<custom-meta>
<meta-name>Publication Update</meta-name>
<meta-value>2017-08-08</meta-value>
</custom-meta>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>All protein-ligand binding data sets are available at <ext-link ext-link-type="uri" xlink:href="http://www.pdbbind.org.cn/" xlink:type="simple">http://www.pdbbind.org.cn/</ext-link>. One mutation data set (S2648) can be found at <ext-link ext-link-type="uri" xlink:href="http://www.abren.net/protherm/" xlink:type="simple">http://www.abren.net/protherm/</ext-link>, and specific data sets are given by Dehouck Y, Grosfils A, Folch B, Gilis D, Bogaerts P, Rooman M. Fast and accurate predictions of protein stability changes upon mutations using statistical potentials and neural networks: PoPMuSiC-2.0. Structural Bioinformatics. 2009;25:2537-2543. Another mutation data set (M223) is given by Kroncke BM, Duran AM, Mendenhall JL, Meiler J, Blume JD, Sanders CR. Documentation of an Imperative To Improve Methods for Predicting Membrane Protein Stability. Biochemistry. 2016;55:5002-5009.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<disp-quote>
<p>This is a <italic>PLOS Computational Biology</italic> Methods paper.</p>
</disp-quote>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Understanding the structure-function relationships of biomolecules is fundamentally important in computational biophysics and experimental biology. As such, methods that can robustly predict biomolecular properties, such as protein-ligand binding affinity and protein stability change upon mutation from three-dimensional (3D) structures are important tools to help us understand this relationship. Numerous approaches have been developed to unveil the structure-function relationship. Physics based models make use of fundamental laws of physics, i.e., quantum mechanics, molecular mechanics, continuum mechanics, multiscale modeling, statistical mechanics, thermodynamics, etc, to investigate structure-function relationships and predict function from structure. Physical methods provide important insights and are indispensable for understanding the relationships between protein structure and function.</p>
<p>The exponential growth of biological data has set the stage for data-driven discovery of structure-function relationships. Indeed, the Protein Data Bank (PDB) has accumulated near 130,000 tertiary structures. The availability of 3D structural data enables knowledge based approaches to offer complementary and competitive predictions of structure-function relationships. Recent advances in machine learning algorithms have made data driven approaches more competitive and powerful than ever. Arguably, machine learning is one of the most important developments in data analysis. Machine learning has become an indispensable tool in biomolecular data analysis and prediction. Virtually every computational problem in computational biology and biophysics, such as the prediction of solvation free energies, protein-ligand binding affinities, mutation impacts, pKa values, etc, has a class of knowledge based approaches that are either parallel or complementary to physics based approaches. The ability to recognize nonlinear and high-order interactions among features as well as the capability of handling data with underlying spatial dimensions hierarchically has lead to breakthroughs in deep convolutional neural networks in image processing, video, audio and computer vision [<xref ref-type="bibr" rid="pcbi.1005690.ref001">1</xref>, <xref ref-type="bibr" rid="pcbi.1005690.ref002">2</xref>]. Likewise, recurrent nets have shed light on sequential data such as text and speech [<xref ref-type="bibr" rid="pcbi.1005690.ref003">3</xref>, <xref ref-type="bibr" rid="pcbi.1005690.ref004">4</xref>]. Deep learning has fueled the rapid growth in several areas of data science [<xref ref-type="bibr" rid="pcbi.1005690.ref003">3</xref>, <xref ref-type="bibr" rid="pcbi.1005690.ref004">4</xref>]. Machine learning based approaches are advantageous due to their ability to handle large data sets and nonlinear relationships in physically derived descriptors. Notably, deep learning can automatically extract optimal high level features and discover intricate structures in large data sets.</p>
<p>Given multiple learning tasks, multi-task learning (MTL) [<xref ref-type="bibr" rid="pcbi.1005690.ref005">5</xref>] provides a powerful tool to exploit the intrinsic relatedness among learning tasks, transfer predictive information among tasks, and achieve better generalized performance than single task learning. During the learning stage, MTL algorithms seek to learn a shared representation (e.g., shared distribution of a given hyper-parameter [<xref ref-type="bibr" rid="pcbi.1005690.ref006">6</xref>], shared low-rank subspace [<xref ref-type="bibr" rid="pcbi.1005690.ref007">7</xref>], shared feature subset [<xref ref-type="bibr" rid="pcbi.1005690.ref008">8</xref>] and clustered task structure [<xref ref-type="bibr" rid="pcbi.1005690.ref009">9</xref>]), and use the shared representation to bridge between tasks and transfer knowledge. MTL has applications to the bioactivity of small molecular drugs [<xref ref-type="bibr" rid="pcbi.1005690.ref010">10</xref>–<xref ref-type="bibr" rid="pcbi.1005690.ref012">12</xref>] and genomics [<xref ref-type="bibr" rid="pcbi.1005690.ref013">13</xref>]. Linear regression based MTL heavily depends on well crafted features, while neural network based MTL allows more flexible task coupling and is able to deliver satisfactory results with a large number of low level features provided such features have the representative power of the problem.</p>
<p>For complex 3D biomolecular data, the physical features used in machine learning vary greatly in their nature. Typical features are generated from geometric properties, electrostatics, atom types, atomic partial charges, and graph theory based properties [<xref ref-type="bibr" rid="pcbi.1005690.ref014">14</xref>]. Such manually extracted features can be used in a deep neural network, but the performance heavily relies on feature engineering. In contrast, convolutional neural networks learn to extract high level representations hierarchically from low level features while maintaining the underlying spatial relationships. However, the cost is huge for directly applying convolutional neural network to the 3D biomolecules, especially if long-range interactions are included. A major obstacle in the development of deep learning nets for 3D biomolecular data is their entanglement between geometric complexity and biological complexity.</p>
<p>Most theoretical models for the study of structure-function relationships of biomolecules are based on geometric modeling techniques. Mathematically, these approaches exploit local geometric information, i.e., coordinates, distances, angles, areas, and sometimes curvatures [<xref ref-type="bibr" rid="pcbi.1005690.ref015">15</xref>] for the physical modeling of biomolecular systems. Indeed, the importance of geometric modeling for structural biology [<xref ref-type="bibr" rid="pcbi.1005690.ref016">16</xref>], and biophysics cannot be overemphasized. However, geometry based models often contain too much structural detail and are frequently computationally intractable for large structures or datasets. In many biological problems, such as the opening or closing of ion channels, the association or dissociation of binding ligands, the folding or unfolding of proteins, and the symmetry breaking or formation of virus capsids, obvious topological changes exist. In fact, one only needs qualitative topological information to understand many physical and biological functions. In short, <italic>topology-function relationships</italic> exist in many biomolecular systems.</p>
<p>Topology offers entirely different approaches and could provide significant simplification of biomolecular data [<xref ref-type="bibr" rid="pcbi.1005690.ref017">17</xref>–<xref ref-type="bibr" rid="pcbi.1005690.ref024">24</xref>]. The study of topology deals with the connectivity of different components in a space, and characterizes independent entities, rings and higher dimensional faces within the space [<xref ref-type="bibr" rid="pcbi.1005690.ref025">25</xref>]. Topological methods produce a high level of abstraction to many biological processes. For example, the opening and closing of ion channels, the assembly or disassembly of virus capsids, the folding and unfolding of proteins, and the association or dissociation of ligands are reflected by topological changes. The fundamental task of topological data analysis is to extract topological invariants, namely the intrinsic features of the underlying space, of a given data set without additional structure information. Examples include covalent bonds, hydrogen bonds, van der Waals interactions, etc. A fundamental concept in algebraic topology is simplicial homology, which concerns the identification of topological invariants from a set of discrete node coordinates such as atomic coordinates in a protein or a protein-ligand complex. For a given (protein) configuration, number of independent components, rings and cavities are topological invariants and they are refered to as Betti-0, Betti-1 and Betti-2 numbers respectively. Conventional topology or homology is truly free of metrics or coordinates, and thus retains too little geometric information to be practically useful for the predictions of biomolecular properties. To address this issue, spatial scales are embeded in the topology, which equips the topological representations with geometric information.</p>
<p>Persistent homology is a relatively new branch of algebraic topology that embeds multiscale geometric information in topological invariants to achieve an interplay between geometry and topology. It creates a variety of topologies of a given object by varying a filtration parameter, such as the radii of balls centered at the nodes or the level set of a surface function. As a result, persistent homology can capture topological structures continuously over a range of spatial scales. Unlike commonly used computational homology which results in truly metric free representations, persistent homology embeds geometric information in topological invariants, e.g., Betti numbers so that “birth” and “death” of isolated components, circles, rings, voids or cavities can be monitored at any geometric scale by topological measurements. In the past decade, persistent homology has been developed as a new multiscale representation of topological features. The 0-th dimensional version was originally introduced for computer vision applications under the name “size function” [<xref ref-type="bibr" rid="pcbi.1005690.ref026">26</xref>, <xref ref-type="bibr" rid="pcbi.1005690.ref027">27</xref>]. Persistent homology theory and subsequent algorithms were formulated by Edelsbrunner et al. [<xref ref-type="bibr" rid="pcbi.1005690.ref028">28</xref>]. Later, a more general theory was developed by Zomorodian and Carlsson [<xref ref-type="bibr" rid="pcbi.1005690.ref018">18</xref>]. Since that time, there have been significant theoretical development [<xref ref-type="bibr" rid="pcbi.1005690.ref029">29</xref>–<xref ref-type="bibr" rid="pcbi.1005690.ref037">37</xref>] as well as various computational algorithms [<xref ref-type="bibr" rid="pcbi.1005690.ref038">38</xref>–<xref ref-type="bibr" rid="pcbi.1005690.ref043">43</xref>]. Persistent homology is often visualized by the use of barcodes [<xref ref-type="bibr" rid="pcbi.1005690.ref044">44</xref>, <xref ref-type="bibr" rid="pcbi.1005690.ref045">45</xref>], where horizontal line segments or bars represent homology generators that survive over different filtration scales.</p>
<p>Persistent homology has been applied to computational biology [<xref ref-type="bibr" rid="pcbi.1005690.ref046">46</xref>–<xref ref-type="bibr" rid="pcbi.1005690.ref048">48</xref>], in the mathematical modeling and prediction of nano particles, proteins and other biomolecules [<xref ref-type="bibr" rid="pcbi.1005690.ref047">47</xref>, <xref ref-type="bibr" rid="pcbi.1005690.ref049">49</xref>, <xref ref-type="bibr" rid="pcbi.1005690.ref050">50</xref>]. Previously, we have introduced molecular topological fingerprint (TF) to reveal topology-function relationships in protein folding and protein flexibility [<xref ref-type="bibr" rid="pcbi.1005690.ref049">49</xref>]. Contrary to many other fields where short-lived topological events are considered noise, we have shown that such short-lived properties are in fact important components in biomolecular analysis and should be included in molecular topological fingerprints. Quantitative topological analysis has been cultivated to predict the curvature energy of fullerene isomers [<xref ref-type="bibr" rid="pcbi.1005690.ref050">50</xref>, <xref ref-type="bibr" rid="pcbi.1005690.ref051">51</xref>] and protein folding stability [<xref ref-type="bibr" rid="pcbi.1005690.ref049">49</xref>]. Differential geometry based persistent homology [<xref ref-type="bibr" rid="pcbi.1005690.ref051">51</xref>], multidimensional persistence [<xref ref-type="bibr" rid="pcbi.1005690.ref052">52</xref>], and multiresolutional persistent homology [<xref ref-type="bibr" rid="pcbi.1005690.ref053">53</xref>, <xref ref-type="bibr" rid="pcbi.1005690.ref054">54</xref>] have been proposed to better characterize biomolecular data [<xref ref-type="bibr" rid="pcbi.1005690.ref052">52</xref>], detect protein cavities [<xref ref-type="bibr" rid="pcbi.1005690.ref055">55</xref>], and resolve ill-posed inverse problems in cryo-EM structure determination [<xref ref-type="bibr" rid="pcbi.1005690.ref056">56</xref>]. A persistent homology based machine learning algorithm has also been developed for protein structural classification [<xref ref-type="bibr" rid="pcbi.1005690.ref057">57</xref>]. However, ordinary persistent homology oversimplifies biological information. Consequently, persistent homology based machine learning algorithms are not as competitive as other conventional techniques in protein structural classification [<xref ref-type="bibr" rid="pcbi.1005690.ref057">57</xref>, <xref ref-type="bibr" rid="pcbi.1005690.ref058">58</xref>].</p>
<p>The objective of the present work is to introduce a new framework for the structure based biomolecular property predictions using element-specific persistent homology, and convolutional and multi-task neural networks. In this framework, element-specific persistent homology reduces geometric and biological complexities and provides a sufficient and structured low level representation for neural networks. Given this representation, convolutional neural networks can then learn from data to extract high level representations of the biomolecular systems, while retaining the spatial relationships, and construct mappings from these representations to the target properties. For the prediction problems whose available datasets are small, multi-task learning by jointly learning the related prediction problems with larger available datasets helps to extract a proper high level representation for the target applications. The element-specific treatment is inspired by the RF-score method [<xref ref-type="bibr" rid="pcbi.1005690.ref059">59</xref>] for binding affinity prediction. Element-specific persistent homology is originated in our previous work using classic machine learning methods. [<xref ref-type="bibr" rid="pcbi.1005690.ref060">60</xref>, <xref ref-type="bibr" rid="pcbi.1005690.ref061">61</xref>] In this work, we further develop topology based neural network (TopologyNet) models for the predictions of biomolecular structure-function relationships. Specifically, we integrate ESPH and convolutional neural networks (CNNs) to improve modern methods for protein-ligand binding affinity and protein mutation impact predictions from 3D biomolecular data. In this approach, topological invariants are used to reduce the dimensionality of 3D biomolecular data. Additionally, element-specific persistent barcodes offer image-like topological representations to facilitate convolutional deep neural networks. Moreover, biological information is retained by element-specific topological fingerprints and described in multichannels in our image like representation. Furthermore, convolutional neural networks uncover hidden relationships between biomolecular topological invariants and biological functions. Finally, a multi-task multichannel topological convolutional neural network (MM-TCNN) framework is introduced to exploit the relations among various structure-function predictions and enhance the prediction for problems with small and noisy training data. Our hypothesis is that many biomolecular predictions share a common set of topological fingerprints representations and are highly correlated to each other. As a result, multi-task deep learning by simultaneous training for globular proteins and membrane proteins improves upon existing predictions for the mutation induced stability changes of membrane proteins whose training data size is relatively small.</p>
</sec>
<sec id="sec002" sec-type="results">
<title>Results</title>
<sec id="sec003">
<title>Deep learning prediction of protein-ligand binding affinities</title>
<p>Protein-ligand binding is a fundamental biological process in cells and involves detailed molecular recognition, synergistic protein-ligand interaction, and may involve protein conformational changes. Agonist binding is crucial to receptor functions and typically triggers a physiological response, such as transmitter-mediated signal transduction, hormone and growth factor regulated metabolic pathways, stimulus-initiated gene expression, enzyme production, cell secretion, etc. Understanding protein-ligand interactions has been a fundamental issue in molecular biophysics, structural biology and medicine. A specific task in drug and protein design is to predict protein-ligand binding affinity from given structural information [<xref ref-type="bibr" rid="pcbi.1005690.ref062">62</xref>] Protein-ligand binding affinity is a measurement of rate of binding which indicates the degree of occupancy of a ligand at the corresponding protein binding site and is affected by several factors including intermolecular interaction strength and solvation effects. The ability to predict protein-ligand binding affinity to a desired accuracy is a prerequisite for the success of many applications in biochemistry such as protein-ligand docking and drug discovery. In general, there are three types of binding affinity predictors (commonly called scoring functions): physics based [<xref ref-type="bibr" rid="pcbi.1005690.ref063">63</xref>, <xref ref-type="bibr" rid="pcbi.1005690.ref064">64</xref>], empirical [<xref ref-type="bibr" rid="pcbi.1005690.ref065">65</xref>–<xref ref-type="bibr" rid="pcbi.1005690.ref072">72</xref>], and knowledge based [<xref ref-type="bibr" rid="pcbi.1005690.ref073">73</xref>–<xref ref-type="bibr" rid="pcbi.1005690.ref075">75</xref>]. In general, physics based scoring functions invoke QM and QM/MM approaches [<xref ref-type="bibr" rid="pcbi.1005690.ref076">76</xref>, <xref ref-type="bibr" rid="pcbi.1005690.ref077">77</xref>] to provide unique insights into the molecular mechanism of protein-ligand interactions. A prevalent view is that binding involves intermolecular forces, such as steric contacts, ionic bonds, hydrogen bonds, hydrophobic effects and van der Waals interactions. Empirical scoring functions work well but require carefully selected data sets and parametrization [<xref ref-type="bibr" rid="pcbi.1005690.ref065">65</xref>–<xref ref-type="bibr" rid="pcbi.1005690.ref068">68</xref>]. However, both physics based scoring functions and empirical scoring functions employ linear superposition principles that are not explicitly designed to deal with exponentially growing and increasingly diverse experimental data sets. Knowledge based scoring functions use modern machine learning techniques, which utilize nonlinear regression and exploit large data sets to uncover underlying patterns within the data sets. Given the current massive and complex data challenges, knowledge based scoring functions outperform other scoring functions. [<xref ref-type="bibr" rid="pcbi.1005690.ref065">65</xref>].</p>
<p>In this study, the proposed method is tested on the PDBBind 2007 data set [<xref ref-type="bibr" rid="pcbi.1005690.ref078">78</xref>]. The PDBBind 2007 core set of 195 protein-ligand complexes is used as the test set and the PDBBind 2007 refined set, excluding the PDBBind 2007 core set, is used as the training set with 1105 protein-ligand complexes. A comparison between our TNet-binding predictor (TNet-BP) and other binding affinity predictors is summarized in <xref ref-type="table" rid="pcbi.1005690.t001">Table 1</xref>. TNet-BP outperforms all the other scoring functions reported by Li <italic>et al</italic> [<xref ref-type="bibr" rid="pcbi.1005690.ref059">59</xref>] on the task of binding affinity prediction from structures.</p>
<table-wrap id="pcbi.1005690.t001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005690.t001</object-id>
<label>Table 1</label>
<caption>
<title>Performance comparisons of TNet-BP and other methods.</title>
</caption>
<alternatives>
<graphic id="pcbi.1005690.t001g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005690.t001" xlink:type="simple"/>
<table border="0" frame="box" rules="all">
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left" style="background-color:#b1b1b1">Method</th>
<th align="left" style="background-color:#b1b1b1"><italic>R</italic><sub><italic>P</italic></sub></th>
<th align="left" style="background-color:#b1b1b1">RMSE</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">TNet-BP</td>
<td align="char" char=".">0.826<xref ref-type="table-fn" rid="t001fn002"><sup>a</sup></xref></td>
<td align="char" char=".">1.37</td>
</tr>
<tr>
<td align="left" style="background-color:#e6e6e6">RF::VinaElem</td>
<td align="char" char="." style="background-color:#e6e6e6">0.803</td>
<td align="char" char="." style="background-color:#e6e6e6">1.42</td>
</tr>
<tr>
<td align="left">RF:Vina</td>
<td align="char" char=".">0.739</td>
<td align="char" char=".">1.61</td>
</tr>
<tr>
<td align="left" style="background-color:#e6e6e6">Cyscore</td>
<td align="char" char="." style="background-color:#e6e6e6">0.660</td>
<td align="char" char="." style="background-color:#e6e6e6">1.79</td>
</tr>
<tr>
<td align="left">X-Score::HMScore</td>
<td align="char" char=".">0.644</td>
<td align="char" char=".">1.83</td>
</tr>
<tr>
<td align="left" style="background-color:#e6e6e6">MLR::Vina</td>
<td align="char" char="." style="background-color:#e6e6e6">0.622</td>
<td align="char" char="." style="background-color:#e6e6e6">1.87</td>
</tr>
<tr>
<td align="left">HYDE2.0::HbondsHydrophobic</td>
<td align="char" char=".">0.620</td>
<td align="char" char=".">1.89</td>
</tr>
<tr>
<td align="left" style="background-color:#e6e6e6">DrugScore</td>
<td align="char" char="." style="background-color:#e6e6e6">0.569</td>
<td align="char" char="." style="background-color:#e6e6e6">1.96</td>
</tr>
<tr>
<td align="left">SYBYL::ChemScore</td>
<td align="char" char=".">0.555</td>
<td align="char" char=".">1.98</td>
</tr>
<tr>
<td align="left" style="background-color:#e6e6e6">AutoDock Vina</td>
<td align="char" char="." style="background-color:#e6e6e6">0.554</td>
<td align="char" char="." style="background-color:#e6e6e6">1.99</td>
</tr>
<tr>
<td align="left">DS::PLP1</td>
<td align="char" char=".">0.545</td>
<td align="char" char=".">2.00</td>
</tr>
<tr>
<td align="left" style="background-color:#e6e6e6">GOLD::ASP</td>
<td align="char" char="." style="background-color:#e6e6e6">0.534</td>
<td align="char" char="." style="background-color:#e6e6e6">2.02</td>
</tr>
<tr>
<td align="left">SYBYL::G-Score</td>
<td align="char" char=".">0.492</td>
<td align="char" char=".">2.08</td>
</tr>
<tr>
<td align="left" style="background-color:#e6e6e6">DS::LUDI3</td>
<td align="char" char="." style="background-color:#e6e6e6">0.487</td>
<td align="char" char="." style="background-color:#e6e6e6">2.09</td>
</tr>
<tr>
<td align="left">DS:LigScore2</td>
<td align="char" char=".">0.464</td>
<td align="char" char=".">2.12</td>
</tr>
<tr>
<td align="left" style="background-color:#e6e6e6">GlideScore-XP</td>
<td align="char" char="." style="background-color:#e6e6e6">0.457</td>
<td align="char" char="." style="background-color:#e6e6e6">2.14</td>
</tr>
<tr>
<td align="left">DS::PMF</td>
<td align="char" char=".">0.445</td>
<td align="char" char=".">2.14</td>
</tr>
<tr>
<td align="left" style="background-color:#e6e6e6">GOLD::ChemScore</td>
<td align="char" char="." style="background-color:#e6e6e6">0.441</td>
<td align="char" char="." style="background-color:#e6e6e6">2.15</td>
</tr>
<tr>
<td align="left">PHOENIX</td>
<td align="char" char=".">0.616</td>
<td align="char" char=".">2.16</td>
</tr>
<tr>
<td align="left" style="background-color:#e6e6e6">SYBYL::D-Score</td>
<td align="char" char="." style="background-color:#e6e6e6">0.392</td>
<td align="char" char="." style="background-color:#e6e6e6">2.19</td>
</tr>
<tr>
<td align="left">DS::Jain</td>
<td align="char" char=".">0.316</td>
<td align="char" char=".">2.24</td>
</tr>
<tr>
<td align="left" style="background-color:#e6e6e6">IMP::RankScore</td>
<td align="char" char="." style="background-color:#e6e6e6">0.322</td>
<td align="char" char="." style="background-color:#e6e6e6">2.25</td>
</tr>
<tr>
<td align="left">GOLD::GoldScore</td>
<td align="char" char=".">0.295</td>
<td align="char" char=".">2.29</td>
</tr>
<tr>
<td align="left" style="background-color:#e6e6e6">SYBYL::PMF-Score</td>
<td align="char" char="." style="background-color:#e6e6e6">0.268</td>
<td align="char" char="." style="background-color:#e6e6e6">2.29</td>
</tr>
<tr>
<td align="left">SYBYL::F-Score</td>
<td align="char" char=".">0.216</td>
<td align="char" char=".">2.35</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t001fn001">
<p>Comparison of optimal Pearson correlation coefficients <italic>R</italic><sub><italic>P</italic></sub> and RMSEs (<italic>pK</italic><sub><italic>d</italic></sub>/<italic>pK</italic><sub><italic>i</italic></sub>) of various scoring functions for the prediction of protein-ligand binding affinity of the PDBBind 2007 core set. Except for the result of our TNet-BP, all other results are adopted from Li <italic>et al</italic> [<xref ref-type="bibr" rid="pcbi.1005690.ref059">59</xref>].</p></fn>
<fn id="t001fn002">
<p><italic><sup>a</sup></italic> Median results (The best <italic>R</italic><sub><italic>P</italic></sub> = 0.828 and best RMSE = 1.37 for this method).</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>TNet-BP is also validated on a larger dataset, PDBBind v2016 refined set of 4057 complexes, where the training set contains 3767 samples which is the refined set minus the core set, and the testing set is the core set with 290 samples. All the model parameters and training procedures are the same as that used for v2007 dataset except that the epoch number is set to 500 instead of 2000 due to the larger data size. The median <italic>R</italic><sub><italic>P</italic></sub> and RMSE are 0.81 and 1.34 pKd/pKi units, respectively.</p>
</sec>
<sec id="sec004">
<title>Deep learning prediction of protein folding free energy changes upon mutation</title>
<p>Apart from some unusual exceptions, proteins fold into specific three-dimensional structures to provide the structural basis for living organisms. Protein functions, i.e., acting as enzymes, cell signaling mediators, ligand receptors, and structural supports, are typical consequences of a delicate balance between protein structural stability and flexibility. Mutation that changes protein amino acid sequences through non-synonymous single nucleotide substitutions (nsSNPs) plays a fundamental role in selective evolution. Such substitutions may lead to the loss or the modification of certain functions. Mutations are often associated with various human diseases [<xref ref-type="bibr" rid="pcbi.1005690.ref079">79</xref>, <xref ref-type="bibr" rid="pcbi.1005690.ref080">80</xref>]. For example, mutations in proteases and their natural inhibitors result in more than 60 human hereditary diseases [<xref ref-type="bibr" rid="pcbi.1005690.ref081">81</xref>]. Additionally, mutation can also lead to drug resistance [<xref ref-type="bibr" rid="pcbi.1005690.ref082">82</xref>]. Artificially designed mutations are used to understand mutation impacts to protein structural stability, flexibility and function, as well as mutagenic diseases, and evolution pathways of organisms [<xref ref-type="bibr" rid="pcbi.1005690.ref083">83</xref>]. However, mutagenesis experiments are typically costly and time-consuming. Computational prediction of mutation impacts is able to systematically explore protein structural instabilities, functions, disease connections, and organismal evolution pathways [<xref ref-type="bibr" rid="pcbi.1005690.ref084">84</xref>] and provide an economical, fast, and potentially accurate alternative to mutagenesis experiments. Many computational methods have been developed in the past decade, including support vector machine based approach [<xref ref-type="bibr" rid="pcbi.1005690.ref085">85</xref>], statistical potentials based approach [<xref ref-type="bibr" rid="pcbi.1005690.ref086">86</xref>], knowledge-modified MM/PBSA approach [<xref ref-type="bibr" rid="pcbi.1005690.ref087">87</xref>], Rosetta protocols [<xref ref-type="bibr" rid="pcbi.1005690.ref088">88</xref>], FoldX (3.0, beta 6.1) [<xref ref-type="bibr" rid="pcbi.1005690.ref084">84</xref>], SDM [<xref ref-type="bibr" rid="pcbi.1005690.ref089">89</xref>], DUET [<xref ref-type="bibr" rid="pcbi.1005690.ref090">90</xref>], PPSC (Prediction of Protein Stability, version 1.0) with the 8 (M8) and 47 (M47) feature sets [<xref ref-type="bibr" rid="pcbi.1005690.ref091">91</xref>], PROVEAN [<xref ref-type="bibr" rid="pcbi.1005690.ref092">92</xref>], ELASPIC [<xref ref-type="bibr" rid="pcbi.1005690.ref093">93</xref>], STRUM [<xref ref-type="bibr" rid="pcbi.1005690.ref094">94</xref>], and EASE-MM [<xref ref-type="bibr" rid="pcbi.1005690.ref095">95</xref>].</p>
<p>The proposed method is tested on a data set of 2648 mutation instances of 131 proteins named “S2648” data set [<xref ref-type="bibr" rid="pcbi.1005690.ref086">86</xref>] in a 5-fold cross validation task over the “S2648” set and a task of prediction of the “S350” set which is a subset of “S2648” set. The “S2648” set, excluding the “S350” subset, is used as the training set in the prediction of the “S350” set. All thermodynamic data are obtained from the ProTherm database [<xref ref-type="bibr" rid="pcbi.1005690.ref096">96</xref>]. A comparison of the performance of various methods is summarized in <xref ref-type="table" rid="pcbi.1005690.t002">Table 2</xref>. Among them, STRUM [<xref ref-type="bibr" rid="pcbi.1005690.ref094">94</xref>] is based on structural, evolutionary and sequence information and results in excellent performance. We therefore have constructed two topology based neural network mutation predictors (TNet-MPs). TNet-MP-1 is solely based on topological information while TNet-MP-2 is aided by auxiliary features characterizing electrostatics, evolutionary, and sequence information, which is merged into the convolutional neural network at one of the fully connected layers. TNet-MP-2 is able to significantly improve our original topological prediction, indicating the importance of the aforementioned auxiliary information to mutation prediction. The details of handcrafted features can be found in <xref ref-type="supplementary-material" rid="pcbi.1005690.s001">S1 Text</xref>. Handcrafted features.</p>
<table-wrap id="pcbi.1005690.t002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005690.t002</object-id>
<label>Table 2</label>
<caption>
<title>Performance comparisons of TNet-MP and other methods.</title>
</caption>
<alternatives>
<graphic id="pcbi.1005690.t002g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005690.t002" xlink:type="simple"/>
<table border="0" frame="box" rules="all">
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left" rowspan="2" style="background-color:#b1b1b1">Method</th>
<th align="center" colspan="3" style="background-color:#b1b1b1">S350</th>
<th align="center" colspan="3" style="background-color:#b1b1b1">S2648</th>
</tr>
<tr>
<th align="center" style="background-color:#b1b1b1"><italic>n</italic><xref ref-type="table-fn" rid="t002fn005"><sup>d</sup></xref></th>
<th align="center" style="background-color:#b1b1b1"><italic>R</italic><sub><italic>P</italic></sub></th>
<th align="center" style="background-color:#b1b1b1">RMSE</th>
<th align="center" style="background-color:#b1b1b1"><italic>n</italic><xref ref-type="table-fn" rid="t002fn005"><sup>d</sup></xref></th>
<th align="center" style="background-color:#b1b1b1"><italic>R</italic><sub><italic>P</italic></sub></th>
<th align="center" style="background-color:#b1b1b1">RMSE</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" style="background-color:#e6e6e6">TNet-MP-2</td>
<td align="center" style="background-color:#e6e6e6">350</td>
<td align="char" char="." style="background-color:#e6e6e6">0.81</td>
<td align="char" char="." style="background-color:#e6e6e6">0.94</td>
<td align="center" style="background-color:#e6e6e6">2648</td>
<td align="char" char="." style="background-color:#e6e6e6">0.77</td>
<td align="char" char="." style="background-color:#e6e6e6">0.94</td>
</tr>
<tr>
<td align="left">STRUM<xref ref-type="table-fn" rid="t002fn003"><sup>b</sup></xref></td>
<td align="center">350</td>
<td align="char" char=".">0.79</td>
<td align="char" char=".">0.98</td>
<td align="center">2647</td>
<td align="char" char=".">0.77</td>
<td align="char" char=".">0.94</td>
</tr>
<tr>
<td align="left" style="background-color:#e6e6e6">TNet-MP-1</td>
<td align="center" style="background-color:#e6e6e6">350</td>
<td align="char" char="." style="background-color:#e6e6e6">0.74</td>
<td align="char" char="." style="background-color:#e6e6e6">1.07</td>
<td align="center" style="background-color:#e6e6e6">2648</td>
<td align="char" char="." style="background-color:#e6e6e6">0.72</td>
<td align="char" char="." style="background-color:#e6e6e6">1.02</td>
</tr>
<tr>
<td align="left">mCSM<xref ref-type="table-fn" rid="t002fn003"><sup>b</sup></xref><sup>,</sup><xref ref-type="table-fn" rid="t002fn004"><sup>c</sup></xref></td>
<td align="center">350</td>
<td align="char" char=".">0.73</td>
<td align="char" char=".">1.08</td>
<td align="center">2643</td>
<td align="char" char=".">0.69</td>
<td align="char" char=".">1.07</td>
</tr>
<tr>
<td align="left" style="background-color:#e6e6e6">INPS<xref ref-type="table-fn" rid="t002fn003"><sup>b</sup></xref><sup>,</sup><xref ref-type="table-fn" rid="t002fn004"><sup>c</sup></xref></td>
<td align="center" style="background-color:#e6e6e6">350</td>
<td align="char" char="." style="background-color:#e6e6e6">0.68</td>
<td align="char" char="." style="background-color:#e6e6e6">1.25</td>
<td align="center" style="background-color:#e6e6e6">2648</td>
<td align="char" char="." style="background-color:#e6e6e6">0.56</td>
<td align="char" char="." style="background-color:#e6e6e6">1.26</td>
</tr>
<tr>
<td align="left">PoPMuSiC 2.0<xref ref-type="table-fn" rid="t002fn003"><sup>b</sup></xref></td>
<td align="center">350</td>
<td align="char" char=".">0.67</td>
<td align="char" char=".">1.16</td>
<td align="center">2647</td>
<td align="char" char=".">0.61</td>
<td align="char" char=".">1.17</td>
</tr>
<tr>
<td align="left" style="background-color:#e6e6e6">PoPMuSiC 1.0<xref ref-type="table-fn" rid="t002fn002"><sup>a</sup></xref></td>
<td align="center" style="background-color:#e6e6e6">350</td>
<td align="char" char="." style="background-color:#e6e6e6">0.62</td>
<td align="char" char="." style="background-color:#e6e6e6">1.23</td>
<td align="center" style="background-color:#e6e6e6">-</td>
<td align="center" style="background-color:#e6e6e6">-</td>
<td align="center" style="background-color:#e6e6e6">-</td>
</tr>
<tr>
<td align="left">I-Mutant 3.0<xref ref-type="table-fn" rid="t002fn003"><sup>b</sup></xref></td>
<td align="center">338</td>
<td align="char" char=".">0.53</td>
<td align="char" char=".">1.35</td>
<td align="center">2636</td>
<td align="char" char=".">0.60</td>
<td align="char" char=".">1.19</td>
</tr>
<tr>
<td align="left" style="background-color:#e6e6e6">Dmutant<xref ref-type="table-fn" rid="t002fn002"><sup>a</sup></xref></td>
<td align="center" style="background-color:#e6e6e6">350</td>
<td align="char" char="." style="background-color:#e6e6e6">0.48</td>
<td align="char" char="." style="background-color:#e6e6e6">1.38</td>
<td align="center" style="background-color:#e6e6e6">-</td>
<td align="center" style="background-color:#e6e6e6">-</td>
<td align="center" style="background-color:#e6e6e6">-</td>
</tr>
<tr>
<td align="left">Automute<xref ref-type="table-fn" rid="t002fn002"><sup>a</sup></xref></td>
<td align="center">315</td>
<td align="char" char=".">0.46</td>
<td align="char" char=".">1.42</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
</tr>
<tr>
<td align="left" style="background-color:#e6e6e6">CUPSAT<xref ref-type="table-fn" rid="t002fn002"><sup>a</sup></xref></td>
<td align="center" style="background-color:#e6e6e6">346</td>
<td align="char" char="." style="background-color:#e6e6e6">0.37</td>
<td align="char" char="." style="background-color:#e6e6e6">1.46</td>
<td align="center" style="background-color:#e6e6e6">-</td>
<td align="center" style="background-color:#e6e6e6">-</td>
<td align="center" style="background-color:#e6e6e6">-</td>
</tr>
<tr>
<td align="left">Eris<xref ref-type="table-fn" rid="t002fn002"><sup>a</sup></xref></td>
<td align="center">334</td>
<td align="char" char=".">0.35</td>
<td align="char" char=".">1.49</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
</tr>
<tr>
<td align="left" style="background-color:#e6e6e6">I-Mutant 2.0<xref ref-type="table-fn" rid="t002fn002"><sup>a</sup></xref></td>
<td align="center" style="background-color:#e6e6e6">346</td>
<td align="char" char="." style="background-color:#e6e6e6">0.29</td>
<td align="char" char="." style="background-color:#e6e6e6">1.50</td>
<td align="center" style="background-color:#e6e6e6">-</td>
<td align="center" style="background-color:#e6e6e6">-</td>
<td align="center" style="background-color:#e6e6e6">-</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t002fn001">
<p>Comparison of Pearson correlation coefficients (<italic>R</italic><sub><italic>P</italic></sub>) and RMSEs (kcal/mol) of various methods on the prediction task of the “S350” set and 5-fold cross validation of the “S2648”. TNet-MP-1 is our multichannel topological convolutional neural network model that solely utilizes topological information. TNet-MP-2 is our model that complements TNet-MP-1 with auxiliary features.</p>
</fn>
<fn id="t002fn002">
<p><italic><sup>a</sup></italic> Data directly obtained from Worth <italic>et al</italic> [<xref ref-type="bibr" rid="pcbi.1005690.ref089">89</xref>].</p>
</fn>
<fn id="t002fn003">
<p><italic><sup>b</sup></italic> Data obtained from Quan <italic>et al</italic> [<xref ref-type="bibr" rid="pcbi.1005690.ref094">94</xref>].</p>
</fn>
<fn id="t002fn004">
<p><italic><sup>c</sup></italic> The results reported in the publications are listed in the table. According to Ref. [<xref ref-type="bibr" rid="pcbi.1005690.ref094">94</xref>], the data from the online server has <italic>R</italic><sub><italic>p</italic></sub> (RMSE) of 0.59 (1.28) and 0.70 (1.13) for INPS and mCSM respectively in the task of S350 set.</p>
</fn>
<fn id="t002fn005">
<p><italic><sup>d</sup></italic> Number of samples successfully processed.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="sec005">
<title>Multi-task deep learning prediction of membrane protein mutation impacts</title>
<p>Multi-task learning offers an efficient way to improve the predictions associated with small data sets by taking the advantage of other larger data sets [<xref ref-type="bibr" rid="pcbi.1005690.ref097">97</xref>]. Although a large amount of thermodynamic data is available for globular protein mutations, the mutation data set for membrane proteins is relatively small, between 200 and 300 proteins [<xref ref-type="bibr" rid="pcbi.1005690.ref098">98</xref>]. The small size of membrane protein mutation data limits the success of data driven approaches, such as ensemble of trees. While the popular multi-task learning framework built on linear regression with regularization techniques lacks the ability to extract the relationship between very low level descriptors and the target quantity. A neural network with a hierarchical structure provides a promising option for such problems. We add the prediction of globular protein stability changes upon mutation as an auxiliary task for the prediction of membrane protein stability changes upon mutation. In the designed network architecture, two tasks share convolution layers and the network splits into two branches with fully connected layers for the two tasks. Intuitively, the task of globular protein mutation predictions help to extract higher level features from low level topological representations. Thus, the branch for membrane protein mutation predictions learns the feature-target relationship from the learned high level features.</p>
<p>The proposed method is tested on a set of 223 mutation instances of membrane proteins covering 7 protein families named “M223” data set [<xref ref-type="bibr" rid="pcbi.1005690.ref098">98</xref>] with 5-fold cross validation. A comparison with other methods is shown in <xref ref-type="table" rid="pcbi.1005690.t003">Table 3</xref>. TNet-MMP-1 employes multichannel topological convolutional neural networks with topological features from the “M223” data set, while TNet-MMP-2 is a multi-task multichannel topological convolutional neural network (MM-TCNN) architecture. Unlike TNet-MP-2, both TNet-MMP-1 and TNet-MMP-2 do not use auxiliary features. Our goal is to test the performance of the multi-task architecture on the improvement of high level feature extraction from low level features. Pearson correlation coefficient of membrane protein mutation prediction is improved by 9.6%, i.e., from 0.52 to 0.57 by the multi-task algorithm that trains and predicts the present “M223” data set with the “S2648” date set. As noted by Kroncke <italic>et al</italic>, there is no reliable methods for the prediction of membrane protein mutation impacts at the present [<xref ref-type="bibr" rid="pcbi.1005690.ref098">98</xref>]. Our TNet results, though not satisfactory, are the best among the methods tested on this problem.</p>
<table-wrap id="pcbi.1005690.t003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005690.t003</object-id>
<label>Table 3</label>
<caption>
<title>Performance comparisons of TNet-MMP and other methods.</title>
</caption>
<alternatives>
<graphic id="pcbi.1005690.t003g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005690.t003" xlink:type="simple"/>
<table border="0" frame="box" rules="all">
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left" style="background-color:#b1b1b1">Method</th>
<th align="left" style="background-color:#b1b1b1"><italic>R</italic><sub><italic>P</italic></sub></th>
<th align="left" style="background-color:#b1b1b1">RMSE</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">TNet-MMP-2<xref ref-type="table-fn" rid="t003fn005"><sup>d</sup></xref></td>
<td align="char" char=".">0.57</td>
<td align="char" char=".">1.09</td>
</tr>
<tr>
<td align="left" style="background-color:#e6e6e6">TNet-MMP-1<xref ref-type="table-fn" rid="t003fn004"><sup>c</sup></xref></td>
<td align="char" char="." style="background-color:#e6e6e6">0.52</td>
<td align="char" char="." style="background-color:#e6e6e6">1.15</td>
</tr>
<tr>
<td align="left">Rosetta-MP</td>
<td align="char" char=".">0.31</td>
<td align="center">-</td>
</tr>
<tr>
<td align="left" style="background-color:#e6e6e6">Rosetta (High)<xref ref-type="table-fn" rid="t003fn002"><sup>a</sup></xref></td>
<td align="char" char="." style="background-color:#e6e6e6">0.28</td>
<td align="center" style="background-color:#e6e6e6">-</td>
</tr>
<tr>
<td align="left">FoldX</td>
<td align="char" char=".">0.26</td>
<td align="char" char=".">2.56</td>
</tr>
<tr>
<td align="left" style="background-color:#e6e6e6">PROVEAN</td>
<td align="char" char="." style="background-color:#e6e6e6">0.26</td>
<td align="char" char="." style="background-color:#e6e6e6">4.23</td>
</tr>
<tr>
<td align="left">Rosetta-MPddG</td>
<td align="char" char=".">0.19</td>
<td align="center">-</td>
</tr>
<tr>
<td align="left" style="background-color:#e6e6e6">Rosetta (low)<xref ref-type="table-fn" rid="t003fn003"><sup>b</sup></xref></td>
<td align="char" char="." style="background-color:#e6e6e6">0.18</td>
<td align="center" style="background-color:#e6e6e6">-</td>
</tr>
<tr>
<td align="left">SDM</td>
<td align="char" char=".">0.09</td>
<td align="char" char=".">2.40</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t003fn001">
<p>Comparison of Pearson correlation coefficients (<italic>R</italic><sub><italic>P</italic></sub>) and RMSEs (kcal/mol) on 5-fold cross validation for the “M223” data set for various methods. Except for the present results for TNet-MMP-1 and TNet-MMP-2, all other results are adopted from Kroncke <italic>et al</italic> [<xref ref-type="bibr" rid="pcbi.1005690.ref098">98</xref>]. The results of Rosetta methods are obtained from Fig. S1 of Ref. [<xref ref-type="bibr" rid="pcbi.1005690.ref098">98</xref>] where RMSE is not given. The results of other methods are obtained from Table S1 of Ref. [<xref ref-type="bibr" rid="pcbi.1005690.ref098">98</xref>]. Many less competitive results of the machine learning based methods reported in Ref. [<xref ref-type="bibr" rid="pcbi.1005690.ref098">98</xref>] are not listed since these servers were not machine learning based. Among the methods listed, only Rosetta methods have terms describing the membrane protein system and other methods are not specifically tuned for membrane proteins.</p>
</fn>
<fn id="t003fn002">
<p><italic><sup>a</sup></italic> High resolution.</p>
</fn>
<fn id="t003fn003">
<p><italic><sup>b</sup></italic> Low resolution.</p>
</fn>
<fn id="t003fn004">
<p><italic><sup>c</sup></italic> The multichannel topological convolutional neural network architecture with topological features from “S223” data set.</p>
</fn>
<fn id="t003fn005">
<p><italic><sup>d</sup></italic> The multi-task multichannel topological convolutional neural network (MM-TCNN) architecture trained with an auxiliary task of globular protein prediction using the “S2648” data set.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
</sec>
<sec id="sec006" sec-type="conclusions">
<title>Discussion</title>
<p>The adoption of convolutional neural network concepts in this work is motivated by the underlying spatial relationship along the distance scale (filtration) dimension. Properties that reside in different distance scales are heterogeneous so unlike images or videos, there is no obvious transferable property of the convolution filters along the convolution dimension in the proposed method. To take this into consideration, the convolution layers are substituted with “locally connected layers”, where the local connection properties are conserved whilst the filters applied to different distance scales are allowed to be different. The RMSE is in kcal/mol for the mutation problems and pKd/pKi units for the protein-ligand binding problem. The performance in <italic>R</italic><sub><italic>P</italic></sub> (RMSE) significantly decreases from 0.81 (0.94) to 0.77 (1.02) for the task of “S350” set prediction in the mutation impact example. This shows that the construction of lower level features in the lower sparse layers benefits from sharing filters along the distance scale and indicates the existence of some common rules for feature extractions at different distance scales.</p>
<p>Intuitively, the dimension 0 inputs describe pairwise atomic interactions, which clearly contribute to the prediction of the target properties. In contrast, dimension 1 and dimension 2 topological features characterize the hydrophobic network and geometric rings and voids. To understand to what extent the higher topological dimensions help the characterization of biomolecules, we separate the dimension 0 inputs from higher dimensional inputs in the prediction of “S350” set in the mutation impact on protein stability example and in the protein-ligand binding affinity prediction for v2007 set example. To compare the performance of different sets of features, 50 single models are trained for each feature set. Twenty of the 50 trained models are randomly chosen and bagged, and this procedure is repeated 100 times with the median results reported. The individual performances measured by <italic>R</italic><sub><italic>P</italic></sub> (RMSE) for dimension 0 features are 0.73 (1.09) and 0.82 (1.40), respectively for the mutation and binding predictions. For dimensions 1 and 2 features, <italic>R</italic><sub><italic>P</italic></sub> (RMSE) are 0.66 (1.21) and 0.78 (1.54), respectively for the mutation and binding predictions. The combination of all dimension features results in better <italic>R</italic><sub><italic>P</italic></sub> (RMSE) of 0.74 (1.08) and 0.83 (1.37), respectively for the mutation and binding predictions, showing that two sets of features both contribute to predictions. The alpha complex is used for geometric characterization and therefore is in <inline-formula id="pcbi.1005690.e001"><alternatives><graphic id="pcbi.1005690.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005690.e001" xlink:type="simple"/><mml:math display="inline" id="M1"><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi> <mml:mn>3</mml:mn></mml:msup></mml:math></alternatives></inline-formula> with Betti number up to dimension 2. It is possible that the higher dimensional Betti numbers in a more abstract setup such as Vietoris-Rips complex for the characterization of an interaction network will enrich the representation and deliver improved results.</p>
<p>Another popular class of machine learning methods is the ensemble of trees methods. Many modern methods for biomolecular property prediction are based on random forest (RF) and gradient boosting trees (GBTs). The ensemble of decision trees has the capability of learning complicated functions, but GBTs learn to partition the feature space based on the training data which means that they do not have the ability to appropriately extrapolate the learned function to broader situations than the provided training data. Additionally, it is generally the case that data samples are unevenly distributed. It has been observed that in many applications, where among the dataset, there are just a handful of samples with large absolute value for the target property, methods of ensembles of trees tend to overestimate (underestimate) the border cases with very negative (positive) target values. The neural network, due to its different ways of learning the underlying function, seems to be able to deliver better results for the border cases. Therefore, similar to the idea of bagging, methods of ensembles of trees and neural network based methods may result in different error characteristics for different samples and can potentially improve the predictive power by correcting each others’ error when the results from different models are averaged. In the example of prediction of the “S350” set, we obtained performance of 0.82 (0.92) for <italic>R</italic><sub><italic>P</italic></sub> (RMSE) in our other work using handcrafted features with gradient boosting trees [<xref ref-type="bibr" rid="pcbi.1005690.ref060">60</xref>]. When the results are averaged for the two methods, the performance is improved to 0.83 (0.89) which is better than both individual methods. Similar improvement is observed for the protein-ligand binding example with v2007 set. Our method based on handcrafted features and gradient boosting trees with performance 0.82 (1.40) [<xref ref-type="bibr" rid="pcbi.1005690.ref061">61</xref>] and the method presented in this work with performance 0.83 (1.37) can achieve improved performance of 0.84 (1.35) when the two results are combined by averaging. An intuitive illustration is shown in <xref ref-type="fig" rid="pcbi.1005690.g001">Fig 1</xref>. It can be seen from the plot that the neural network based method presented in this work performs better than the GBT based method for samples with high ΔΔ<italic>G</italic> or with low ΔΔ<italic>G</italic>. The slope of linear fitting of the predicted values to the experimental data is 0.66 for the neural network based method and 0.60 for the GBT based method which also illustrates that the neural network based method handles border cases better. The observed improvement is marginal since it is mainly on a small portion of the samples.</p>
<fig id="pcbi.1005690.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005690.g001</object-id>
<label>Fig 1</label>
<caption>
<title>A comparison of behaviors of the GBT based method and the neural network based method.</title>
<p>The plot is for the prediction task of the S350 dataset. The linear fit for GBT prediction [<xref ref-type="bibr" rid="pcbi.1005690.ref060">60</xref>] is <italic>y</italic> = 0.603<italic>x</italic> − 0.435 and for TNet-MP-2, <italic>y</italic> = 0.657<italic>x</italic> − 0.422.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005690.g001" xlink:type="simple"/>
</fig>
<p>In conclusion, the approach introduced in this work utilizes element-specific persistent homology to efficiently characterize 3D biomolecular structures in terms of multichannel topological invariants. Convolutional neural network facilitates the automatic feature extraction from multichannel topological invariant inputs. The flexible and hierarchical structure of neural network allows seamless combination of automatically extracted features and handcrafted features. It also makes it easy to implement multi-task learning by combining related tasks to a desired level of model sharing by tuning the layer of model branching. The proposed topology based neural network (TopologyNet) methods have been shown to outperform other existing methods in protein-ligand binding affinity predictions and mutation induced protein stability change predictions. The proposed methods can be easily extended to other applications in the structural prediction of biomolecular properties. They have the potential to further benefit from the fast accumulating biomolecular data. The combination of the proposed methods and existing RF and GBT based methods is expected to deliver improved results.</p>
</sec>
<sec id="sec007" sec-type="materials|methods">
<title>Methods</title>
<p>In this section, we give a brief explanation of persistent homology before introducing topological representations of protein-ligand binding and protein changes upon mutation. Multichannel topological deep learning and multi-task topological deep learning architectures are constructed for binding affinity and mutation impact predictions. The source codes with examples of feature construction for the binding problem and the mutation problem are in <xref ref-type="supplementary-material" rid="pcbi.1005690.s003">S1 Code</xref>. Binding topological features and <xref ref-type="supplementary-material" rid="pcbi.1005690.s004">S2 Code</xref>. Mutation topological features respectively. The network architectures, parameters, and training procedures are listed in <xref ref-type="supplementary-material" rid="pcbi.1005690.s002">S2 Text</xref>. Network architectures. The description of the auxiliary features together with pseudocode for the mutation application are listed in <xref ref-type="supplementary-material" rid="pcbi.1005690.s001">S1 Text</xref>. Handcrafted features.</p>
<sec id="sec008">
<title>Persistent homology</title>
<p>Simplicial homology gives a computable way to distinguish one space from another in topology and is built on simplicial complexes which can be used to extract topological invariants in a given data set. A simplicial complex <italic>K</italic> is a topological space that is constructed from geometric components of a data set, including discrete vertices (nodes or atoms in a protein), edges (line segments or bonds in a biomolecule), triangles, tetrahedrons and their high dimensional counterparts, under certain rules. Specifically, a 0-simplex is a vertex, a 1-simplex an edge, a 2-simplex a triangle, and a 3-simplex represents a tetrahedron. The identification of connectivity of a given data set can follow different rules which leads to, for example, Vietoris-Rips (VR) complex, Čech complex and alpha complex. The linear combination of <italic>k</italic>-simplexes is called <italic>k</italic>-chain, which is introduced to associate the topological space, i.e., simplicial complex, with algebra groups, which further facilitate the computation of the topological invariants (i.e., Betti numbers) in a given data set. Specifically, the set of all <italic>k</italic>-chains of a simplicial complex <italic>K</italic> are elements of a chain group, which is an abelian group with a modulo-2 addition operation rule. Loosely speaking, a boundary operator systematically eliminates one vertex from the <italic>k</italic>-simplex at a time, which leads to a family of abelian groups, including the <italic>k</italic>th cycle group and the <italic>k</italic>th boundary group. The quotient group of the <italic>k</italic>th cycle group and the <italic>k</italic>th boundary group is called the <italic>k</italic>th homology group. The <italic>k</italic>th Betti number is computed for the rank of the <italic>k</italic>th homology group.</p>
<p>Persistent homology is constructed via a filtration process, in which the connectivity of the given data set is systematically reset according to a scale parameter. More specifically, a nested sequence of subcomplexes is defined via a filtration parameter, such as the growing radius of protein atoms located at their initial coordinates. For each subcomplex, homology groups and the corresponding Betti numbers can be computed. Therefore, the evolution of topological invariants over the filtration process can be recorded as a barcode [<xref ref-type="bibr" rid="pcbi.1005690.ref045">45</xref>] or a persistence diagram. For a given data set, barcodes represent the persistence of its topological features over different spatial scales.</p>
</sec>
<sec id="sec009">
<title>Topological representation of biomolecules</title>
<sec id="sec010">
<title>Topological fingerprints</title>
<p>A basic assumption of persistent homology as applied to biomolecular function prediction is that 1D biomolecular persistent barcodes are able to effectively characterize 3D biomolecular structures. We call such barcodes topological fingerprints (TFs) [<xref ref-type="bibr" rid="pcbi.1005690.ref049">49</xref>, <xref ref-type="bibr" rid="pcbi.1005690.ref050">50</xref>]. <xref ref-type="fig" rid="pcbi.1005690.g002">Fig 2</xref> illustrates the TFs of a wild type protein (PDB:1hmk) and its mutant obtained from persistent homology calculations using the VR complex. The mutation (W60A) occurred at residue 60 from Trp to Ala is shown at <xref ref-type="fig" rid="pcbi.1005690.g002">Fig 2a and 2b</xref>. A large residue (Trp) at the protein surface is replaced by a relatively small one (Ala). The corresponding barcodes are given in <xref ref-type="fig" rid="pcbi.1005690.g002">Fig 2c and 2d</xref>, where three panels from top to bottom are for Betti-0, Betti-1, and Betti-2, respectively. The barcodes for the wild type are generated using heavy atoms within 6Å from the mutation site. The mutant barcodes are obtained with the same set of heavy atoms in the protein except for those in the mutated residue. In two Betti-0 panels, the difference in the number of bars is equal to the difference in the number of heavy atoms between the wild type and mutant. Broadly speaking, the lengths of short bars reflect the bond length of the corresponding heavy atom. Therefore, in both the wild type protein and the mutant, bond lengths for most heavy atoms are smaller than 1.8Å. Additionally, bars that end between 1.8Å and 3.8 Å might correlate with hydrogen bonds. Comparing <bold>c</bold> and <bold>d</bold>, one can easily note the increase in the number of bars that end in the range of 1.8–3.8 Å in the mutant, which indicates a less compact atom arrangement. In Betti-1 and Betti-2 panels, the mutant has fewer bars than the wild type does because a smaller surface residue at 60 creates fewer ring and cavity contacts with the rest of the protein.</p>
<fig id="pcbi.1005690.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005690.g002</object-id>
<label>Fig 2</label>
<caption>
<title>An illustration of barcode changes from wild type to mutant proteins.</title>
<p><bold>a</bold> The wild type protein (PDB:1hmk) with residue 60 as Trp. <bold>b</bold> The mutant with residue 60 as Ala. <bold>c</bold> Wild type protein barcodes for heavy atoms within 6 Å of the mutation site. Three panels from top to bottom are Betti-0, Betti-1, and Betti-2 barcodes, respectively. The horizontal axis is the filtration radius (Å). <bold>d</bold> Mutant protein barcodes obtained similarly to those of the wild type.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005690.g002" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec011">
<title>Element-specific persistent homology</title>
<p>The all heavy atom topological representation of proteins does not provide enough biological information about protein structures, such as bond length distribution of a given type of atoms, hydrogen bonds, hydrophobic and hydrophilic effects, etc. Therefore, we use the element-specific topological fingerprint (ESTF) to offer a more detailed characterization of protein-ligand binding and protein mutation. For example, Betti-1 and Betti-2 ESTFs from carbon atoms are associated with hydrophobic interaction networks in biomolecules. Similarly ESTFs between nitrogen and oxygen atoms correlate to hydrophilic interactions and/or hydrogen bonds in biomolcules. However, hydrogen atoms are typically absent from structures in the PDB and thus are not used in our data driven ESTF description. For proteins, commonly occurring heavy atom types include C, N, O, and S. For ligands, we use 9 commonly occurring atom types, namely C, N, O, S, P, F, Cl, Br, and I. To characterize the interactions between protein and ligand binding, we construct cross protein-ligand ESTFs such that one type of heavy atoms is chosen from the protein and the other from the ligand. Therefore, there are a total of 36 sets of ESTFs in each topological dimension. For mutation characterization, we describe the interactions between mutated residue and the rest of the protein and arrive at 9 sets of ESTFs in each topological dimension considering { C, N, O } for protein atoms. Similarly, we generate 9 sets of cross ESTFs in each topological dimension from the wild type protein to study the interactions between the residue to be mutated and the rest of the protein. However, high dimensional Betti-1 and Betti-2 invariants require the formation of high order complexes. As non-carbon atoms do not occur very often, Betti-1 and Betti-2 ESTFs are generated for all carbon atoms or all heavy atoms, except specified.</p>
<p>The TFs and ESTFs are originally stored as collections of barcodes denoted by <inline-formula id="pcbi.1005690.e002"><alternatives><graphic id="pcbi.1005690.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005690.e002" xlink:type="simple"/><mml:math display="inline" id="M2"><mml:mrow><mml:mi mathvariant="double-struck">B</mml:mi> <mml:mo>(</mml:mo> <mml:mi>α</mml:mi> <mml:mo>,</mml:mo> <mml:mi mathvariant="script">C</mml:mi> <mml:mo>,</mml:mo> <mml:mi mathvariant="script">D</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> with <italic>α</italic> labeling the selection of atoms depending on atom types and affiliations (i.e., protein, ligand or mutated residue). <inline-formula id="pcbi.1005690.e003"><alternatives><graphic id="pcbi.1005690.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005690.e003" xlink:type="simple"/><mml:math display="inline" id="M3"><mml:mi mathvariant="script">C</mml:mi></mml:math></alternatives></inline-formula> denotes the type of simplicial complex (i.e., VR complex or alpha complex) and <inline-formula id="pcbi.1005690.e004"><alternatives><graphic id="pcbi.1005690.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005690.e004" xlink:type="simple"/><mml:math display="inline" id="M4"><mml:mi mathvariant="script">D</mml:mi></mml:math></alternatives></inline-formula> indicates the dimension, such as Betti-0, Betti-1, or Betti-2. A collection of barcodes can have any number of barcodes and thus can not be directly fed to deep learning models. Additionally, as shown in <xref ref-type="fig" rid="pcbi.1005690.g002">Fig 2</xref>, it is important to keep track of the birth, death, and persistence patterns of the barcodes, because this information is associated with the bond length, ring or cavity size, flexibility and steric effect. Moreover, Jeffrey suggested that there are strong, moderate and weak hydrogen bond interactions with donor-acceptor distances of 2.2-2.5Å, 2.5-3.2Å, and 3.2-4.0Å, respectively [<xref ref-type="bibr" rid="pcbi.1005690.ref099">99</xref>]. To this end, we construct structured vectors <bold>V</bold><sup>b</sup>, <bold>V</bold><sup>d</sup>, and <bold>V</bold><sup>p</sup> to respectively describe the birth, death, and persistent patterns of the barcodes in various spatial dimensions. Practically, the filtration interval [0, <italic>L</italic>] is divided into <italic>n</italic> equal length subintervals and the patterns are characterized on each subinterval. The description vectors are defined as
<disp-formula id="pcbi.1005690.e005"><alternatives><graphic id="pcbi.1005690.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005690.e005" xlink:type="simple"/><mml:math display="block" id="M5"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msubsup><mml:mi mathvariant="bold">V</mml:mi> <mml:mi>i</mml:mi> <mml:mi mathvariant="normal">b</mml:mi></mml:msubsup></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:mo>∥</mml:mo> <mml:mo>{</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>b</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>d</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>∈</mml:mo> <mml:mi mathvariant="double-struck">B</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>α</mml:mi> <mml:mo>,</mml:mo> <mml:mi mathvariant="script">C</mml:mi> <mml:mo>,</mml:mo> <mml:mi mathvariant="script">D</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>|</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>i</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>L</mml:mi> <mml:mo>/</mml:mo> <mml:mi>n</mml:mi> <mml:mo>≤</mml:mo> <mml:msub><mml:mi>b</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>≤</mml:mo> <mml:mi>i</mml:mi> <mml:mi>L</mml:mi> <mml:mo>/</mml:mo> <mml:mi>n</mml:mi> <mml:mo>}</mml:mo> <mml:mo>∥</mml:mo> <mml:mo>,</mml:mo> <mml:mspace width="0.166667em"/><mml:mn>1</mml:mn> <mml:mo>≤</mml:mo> <mml:mi>i</mml:mi> <mml:mo>&lt;</mml:mo> <mml:mi>n</mml:mi> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:msubsup><mml:mi mathvariant="bold">V</mml:mi> <mml:mi>i</mml:mi> <mml:mi mathvariant="normal">d</mml:mi></mml:msubsup></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:mo>∥</mml:mo> <mml:mo>{</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>b</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>d</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>∈</mml:mo> <mml:mi mathvariant="double-struck">B</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>α</mml:mi> <mml:mo>,</mml:mo> <mml:mi mathvariant="script">C</mml:mi> <mml:mo>,</mml:mo> <mml:mi mathvariant="script">D</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>|</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>i</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>L</mml:mi> <mml:mo>/</mml:mo> <mml:mi>n</mml:mi> <mml:mo>≤</mml:mo> <mml:msub><mml:mi>d</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>≤</mml:mo> <mml:mi>i</mml:mi> <mml:mi>L</mml:mi> <mml:mo>/</mml:mo> <mml:mi>n</mml:mi> <mml:mo>}</mml:mo> <mml:mo>∥</mml:mo> <mml:mo>,</mml:mo> <mml:mspace width="0.166667em"/><mml:mn>1</mml:mn> <mml:mo>≤</mml:mo> <mml:mi>i</mml:mi> <mml:mo>&lt;</mml:mo> <mml:mi>n</mml:mi> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:msubsup><mml:mi mathvariant="bold">V</mml:mi> <mml:mi>i</mml:mi> <mml:mi mathvariant="normal">p</mml:mi></mml:msubsup></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:mo>∥</mml:mo> <mml:mo>{</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>b</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>d</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>∈</mml:mo> <mml:mi mathvariant="double-struck">B</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>α</mml:mi> <mml:mo>,</mml:mo> <mml:mi mathvariant="script">C</mml:mi> <mml:mo>,</mml:mo> <mml:mi mathvariant="script">D</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>|</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>i</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>L</mml:mi> <mml:mo>/</mml:mo> <mml:mi>n</mml:mi> <mml:mo>≥</mml:mo> <mml:msub><mml:mi>b</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mspace width="0.166667em"/><mml:mi>i</mml:mi> <mml:mi>L</mml:mi> <mml:mo>/</mml:mo> <mml:mi>n</mml:mi> <mml:mo>≤</mml:mo> <mml:msub><mml:mi>d</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>}</mml:mo> <mml:mo>∥</mml:mo> <mml:mo>,</mml:mo> <mml:mspace width="0.166667em"/><mml:mn>1</mml:mn> <mml:mo>≤</mml:mo> <mml:mi>i</mml:mi> <mml:mo>≤</mml:mo> <mml:mi>n</mml:mi> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(1)</label></disp-formula>
where ‖⋅‖ is cardinality of sets. Here <italic>b</italic><sub><italic>j</italic></sub>, <italic>d</italic><sub><italic>j</italic></sub> are birth and death of bar <italic>j</italic>. The three types of representation vectors are computed for sets of Betti-1 and Betti-2 bars. For Betti-0 bars, since their birth positions are uniformly 0, only <bold>V</bold><sup>d</sup> needs to be addressed. To characterize pairwise interactions between atoms, it is convenient to simply use pairwise distance information between atoms. The corresponding image-like representation, denoted by <bold>V</bold><sup>r</sup>, can be constructed similarly to <bold>V</bold><sup>d</sup> by substituting the set of barcodes by a collection of distances between the atom pairs of interest. It should be noted that <bold>V</bold><sup>r</sup> is not equivalent to <bold>V</bold><sup>d</sup> in most simplicial complex setups. Generally speaking, <bold>V</bold><sup>r</sup> also reflects the 0th order topological connectivity information. It is used as the characterization of 0th order connectivity of the biomolecules in the applications shown in this work. Finally, we let <italic>X</italic><sub><italic>s</italic></sub> denote all the feature vectors for the <italic>s</italic>th sample and let <italic>Y</italic><sub><italic>s</italic></sub> denote the corresponding target value.</p>
</sec>
<sec id="sec012">
<title>Image-like multichannel topological representation</title>
<p>To feed the outputs of TFs into the convolutional neural network, the barcodes are transformed to a 1D-image-like representation with multiple channels. Topological feature vectors, <bold>V</bold><sup>b</sup>, <bold>V</bold><sup>d</sup>, and <bold>V</bold><sup>p</sup>, can be viewed as one-dimensional (1D) images. Each subinterval in the filtration axis represents a digit (or pixel) in the 1D-image-like representation. Such a treatment of topological features describes the topological information with appropriately chosen resolution of <italic>L</italic>/<italic>n</italic>. Meanwhile, the chemical information in the ESTFs of <inline-formula id="pcbi.1005690.e006"><alternatives><graphic id="pcbi.1005690.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005690.e006" xlink:type="simple"/><mml:math display="inline" id="M6"><mml:mrow><mml:mi mathvariant="double-struck">B</mml:mi> <mml:mo>(</mml:mo> <mml:mi>α</mml:mi> <mml:mo>,</mml:mo> <mml:mi mathvariant="script">C</mml:mi> <mml:mo>,</mml:mo> <mml:mi mathvariant="script">D</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> are described by multiple channels in the 1D-image-like representation, which is similar to the RGB color image representation. However, in our description, each pixel is associated with <italic>m</italic> channels to describe different element type, protein mutation status (i.e., wild type and mutant), topological dimension (i.e., Betti-0, Betti-1 and Betti-2), and topological event (i.e., birth, death, and persistence). Each element in the 1D-image-like representation is standardized to have zero mean and unit variance among the data sets. This 1D-image-like topological representation can be easily transferred among problems such as protein-ligand binding affinity modeling and prediction of protein stability change upon mutation. Traditional machine learning approaches require manual extraction of features for each domain of application. When the convolutional neural network is applied, the convolution layers identify local patterns of atomic interactions and the fully connected layers then extract higher level descriptions of the system by combining local patterns at various distance scales.</p>
</sec>
<sec id="sec013">
<title>Multichannel topological invariants for protein-ligand binding prediction</title>
<p>In computation, the binding affinity, or alternatively the binding free energy, can be modeled via an energy cycle as shown in <xref ref-type="fig" rid="pcbi.1005690.g003">Fig 3</xref> where the main contributors to the process are intermolecular interactions and solvation effects. In this work, we consider the set of element types <inline-formula id="pcbi.1005690.e007"><alternatives><graphic id="pcbi.1005690.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005690.e007" xlink:type="simple"/><mml:math display="inline" id="M7"><mml:mrow><mml:msup><mml:mi mathvariant="double-struck">L</mml:mi> <mml:mi mathvariant="normal">e</mml:mi></mml:msup> <mml:mo>=</mml:mo> <mml:mrow><mml:mo>{</mml:mo> <mml:mi mathvariant="normal">C</mml:mi> <mml:mo>,</mml:mo> <mml:mi mathvariant="normal">N</mml:mi> <mml:mo>,</mml:mo> <mml:mi mathvariant="normal">O</mml:mi> <mml:mo>,</mml:mo> <mml:mi mathvariant="normal">S</mml:mi> <mml:mo>,</mml:mo> <mml:mi mathvariant="normal">P</mml:mi> <mml:mo>,</mml:mo> <mml:mi mathvariant="normal">F</mml:mi> <mml:mo>,</mml:mo> <mml:mtext>Cl</mml:mtext> <mml:mo>,</mml:mo> <mml:mtext>Br</mml:mtext> <mml:mo>,</mml:mo> <mml:mi mathvariant="normal">I</mml:mi> <mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> contained in ligands and <inline-formula id="pcbi.1005690.e008"><alternatives><graphic id="pcbi.1005690.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005690.e008" xlink:type="simple"/><mml:math display="inline" id="M8"><mml:mrow><mml:msup><mml:mi mathvariant="double-struck">P</mml:mi> <mml:mi mathvariant="normal">e</mml:mi></mml:msup> <mml:mo>=</mml:mo> <mml:mrow><mml:mo>{</mml:mo> <mml:mi mathvariant="normal">C</mml:mi> <mml:mo>,</mml:mo> <mml:mi mathvariant="normal">N</mml:mi> <mml:mo>,</mml:mo> <mml:mi mathvariant="normal">O</mml:mi> <mml:mo>,</mml:mo> <mml:mi mathvariant="normal">S</mml:mi> <mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> contained in proteins. We define an opposition distance between two atoms <italic>a</italic><sub><italic>i</italic></sub> and <italic>a</italic><sub><italic>j</italic></sub> as
<disp-formula id="pcbi.1005690.e009"><alternatives><graphic id="pcbi.1005690.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005690.e009" xlink:type="simple"/><mml:math display="block" id="M9"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi>d</mml:mi> <mml:mrow><mml:mi>o</mml:mi> <mml:mi>p</mml:mi></mml:mrow></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mo>{</mml:mo> <mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mi>d</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>,</mml:mo> <mml:mi>A</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≠</mml:mo> <mml:mi>A</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="left"><mml:mi>∞</mml:mi></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>,</mml:mo> <mml:mi>A</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mi>A</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo>,</mml:mo></mml:math></alternatives> <label>(2)</label></disp-formula>
where <italic>d</italic>(⋅, ⋅) is Euclidean distance between two atoms and <italic>A</italic>(⋅) denotes the affiliation of an atom which is either a protein or a ligand.</p>
<fig id="pcbi.1005690.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005690.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Energy cycle of protein-ligand binding free energy modeling.</title>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005690.g003" xlink:type="simple"/>
</fig>
<p>The ESTFs used in this application are summarized in <xref ref-type="table" rid="pcbi.1005690.t004">Table 4</xref>. The structured description vectors of the ESTFs are generated according to the definition given in <xref ref-type="disp-formula" rid="pcbi.1005690.e005">Eq (1)</xref>. As shown in <xref ref-type="table" rid="pcbi.1005690.t004">Table 4</xref>, five sets of ESTFs are constructed. The differences between the description vectors arising from Set 2 and Set 3, and between those arising from Set 4 and Set 5 are also employed as representation vectors to address the impact of ligand binding resulting in a total of 72 representation vectors (i.e., channels) forming the 1D-image-like representation of the protein-ligand complex. Pairwise interactions are characterized for the 36 element pairs with {C, N, O, S} for the protein and {C, N, O, S, F, P, Cl, Br, I} for the ligand with <bold>V</bold><sup><italic>d</italic></sup> providing 36 channels. The birth (<bold>V</bold><sup><italic>b</italic></sup>), death (<bold>V</bold><sup><italic>d</italic></sup>), and persistence (<bold>V</bold><sup><italic>p</italic></sup>) for Betti-1 and Betti-2 barcodes are computed for carbon atoms and all heavy atoms of the protein and the protein-ligand complex which results in 24 channels. The difference between the characterization of the protein and the protein-ligand complex accounts for another 12 channels. Thus, we have a total of 72 channels. Here, 0-dimensional TFs describe intramolecular interactions between the protein and ligand. All heavy atom TFs delineate the geometric effect of protein-ligand binding. The TFs of carbon atoms account for hydrophobic effects and also implicitly reflect the solvation effects. The distance scale interval, [0, 50] Å is divided into bins of length 0.25 Å.</p>
<table-wrap id="pcbi.1005690.t004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005690.t004</object-id>
<label>Table 4</label>
<caption>
<title>Topological representations of protein-ligand complexes.</title>
</caption>
<alternatives>
<graphic id="pcbi.1005690.t004g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005690.t004" xlink:type="simple"/>
<table border="0" frame="box" rules="all">
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left">Set</th>
<th align="left">Atoms used</th>
<th align="left">Distance</th>
<th align="left">Complex</th>
<th align="left">Dimension</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">1</td>
<td align="left">
<inline-formula id="pcbi.1005690.e010">
<alternatives>
<graphic id="pcbi.1005690.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005690.e010" xlink:type="simple"/>
<mml:math display="inline" id="M10">
<mml:mrow>
<mml:mrow>
<mml:mo>{</mml:mo>
<mml:mi>a</mml:mi>
<mml:mo>∈</mml:mo>
<mml:mi mathvariant="double-struck">P</mml:mi>
<mml:mo>|</mml:mo>
<mml:mi>T</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>a</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi mathvariant="normal">P</mml:mi>
</mml:msub>
<mml:mo>}</mml:mo>
</mml:mrow>
<mml:mo>∪</mml:mo>
<mml:mrow>
<mml:mo>{</mml:mo>
<mml:mi>a</mml:mi>
<mml:mo>∈</mml:mo>
<mml:mi mathvariant="double-struck">L</mml:mi>
<mml:mo>|</mml:mo>
<mml:mi>T</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>a</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi mathvariant="normal">L</mml:mi>
</mml:msub>
<mml:mo>}</mml:mo>
</mml:mrow>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi mathvariant="normal">P</mml:mi>
</mml:msub>
<mml:mo>∈</mml:mo>
<mml:msup>
<mml:mi mathvariant="double-struck">P</mml:mi>
<mml:mi mathvariant="normal">e</mml:mi>
</mml:msup>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi mathvariant="normal">L</mml:mi>
</mml:msub>
<mml:mo>∈</mml:mo>
<mml:msup>
<mml:mi mathvariant="double-struck">L</mml:mi>
<mml:mi mathvariant="normal">e</mml:mi>
</mml:msup>
</mml:mrow>
</mml:math>
</alternatives>
</inline-formula>
</td>
<td align="left"><italic>d</italic><sup><italic>op</italic></sup></td>
<td align="left">-</td>
<td align="left">0</td>
</tr>
<tr>
<td align="left">2</td>
<td align="left">
<inline-formula id="pcbi.1005690.e011">
<alternatives>
<graphic id="pcbi.1005690.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005690.e011" xlink:type="simple"/>
<mml:math display="inline" id="M11">
<mml:mrow>
<mml:mo>{</mml:mo>
<mml:mi>a</mml:mi>
<mml:mo>∈</mml:mo>
<mml:mi mathvariant="double-struck">P</mml:mi>
<mml:mo>|</mml:mo>
<mml:mi>T</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>a</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>∈</mml:mo>
<mml:msup>
<mml:mi mathvariant="double-struck">P</mml:mi>
<mml:mi mathvariant="normal">e</mml:mi>
</mml:msup>
<mml:mo>}</mml:mo>
</mml:mrow>
</mml:math>
</alternatives>
</inline-formula>
</td>
<td align="left">Euclidean</td>
<td align="left">Alpha</td>
<td align="left">1,2</td>
</tr>
<tr>
<td align="left">3</td>
<td align="left">
<inline-formula id="pcbi.1005690.e012">
<alternatives>
<graphic id="pcbi.1005690.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005690.e012" xlink:type="simple"/>
<mml:math display="inline" id="M12">
<mml:mrow>
<mml:mrow>
<mml:mo>{</mml:mo>
<mml:mi>a</mml:mi>
<mml:mo>∈</mml:mo>
<mml:mi mathvariant="double-struck">P</mml:mi>
<mml:mo>|</mml:mo>
<mml:mi>T</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>a</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>∈</mml:mo>
<mml:msup>
<mml:mi mathvariant="double-struck">P</mml:mi>
<mml:mi mathvariant="normal">e</mml:mi>
</mml:msup>
<mml:mo>}</mml:mo>
</mml:mrow>
<mml:mo>∪</mml:mo>
<mml:mrow>
<mml:mo>{</mml:mo>
<mml:mi>a</mml:mi>
<mml:mo>∈</mml:mo>
<mml:mi mathvariant="double-struck">L</mml:mi>
<mml:mo>|</mml:mo>
<mml:mi>T</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>a</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>∈</mml:mo>
<mml:msup>
<mml:mi mathvariant="double-struck">L</mml:mi>
<mml:mi mathvariant="normal">e</mml:mi>
</mml:msup>
<mml:mo>}</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</alternatives>
</inline-formula>
</td>
<td align="left">Euclidean</td>
<td align="left">Alpha</td>
<td align="left">1,2</td>
</tr>
<tr>
<td align="left">4</td>
<td align="left">
<inline-formula id="pcbi.1005690.e013">
<alternatives>
<graphic id="pcbi.1005690.e013g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005690.e013" xlink:type="simple"/>
<mml:math display="inline" id="M13">
<mml:mrow>
<mml:mo>{</mml:mo>
<mml:mi>a</mml:mi>
<mml:mo>∈</mml:mo>
<mml:mi mathvariant="double-struck">P</mml:mi>
<mml:mo>|</mml:mo>
<mml:mi>T</mml:mi>
<mml:mo>(</mml:mo>
<mml:mi>a</mml:mi>
<mml:mo>)</mml:mo>
<mml:mo>=</mml:mo>
<mml:mi mathvariant="normal">C</mml:mi>
<mml:mo>}</mml:mo>
</mml:mrow>
</mml:math>
</alternatives>
</inline-formula>
</td>
<td align="left">Euclidean</td>
<td align="left">Alpha</td>
<td align="left">1,2</td>
</tr>
<tr>
<td align="left">5</td>
<td align="left">
<inline-formula id="pcbi.1005690.e014">
<alternatives>
<graphic id="pcbi.1005690.e014g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005690.e014" xlink:type="simple"/>
<mml:math display="inline" id="M14">
<mml:mrow>
<mml:mo>{</mml:mo>
<mml:mi>a</mml:mi>
<mml:mo>∈</mml:mo>
<mml:mi mathvariant="double-struck">P</mml:mi>
<mml:mo>|</mml:mo>
<mml:mi>T</mml:mi>
<mml:mo>(</mml:mo>
<mml:mi>a</mml:mi>
<mml:mo>)</mml:mo>
<mml:mo>=</mml:mo>
<mml:mi mathvariant="normal">C</mml:mi>
<mml:mo>}</mml:mo>
<mml:mo>∪</mml:mo>
<mml:mo>{</mml:mo>
<mml:mi mathvariant="normal">a</mml:mi>
<mml:mo>∈</mml:mo>
<mml:mi mathvariant="double-struck">L</mml:mi>
<mml:mo>|</mml:mo>
<mml:mi mathvariant="normal">T</mml:mi>
<mml:mo>(</mml:mo>
<mml:mi mathvariant="normal">a</mml:mi>
<mml:mo>)</mml:mo>
<mml:mo>=</mml:mo>
<mml:mi mathvariant="normal">C</mml:mi>
<mml:mo>}</mml:mo>
</mml:mrow>
</mml:math>
</alternatives>
</inline-formula>
</td>
<td align="left">Euclidean</td>
<td align="left">Alpha</td>
<td align="left">1,2</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t004fn001">
<p>
<inline-formula id="pcbi.1005690.e015">
<alternatives>
<graphic id="pcbi.1005690.e015g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005690.e015" xlink:type="simple"/>
<mml:math display="inline" id="M15">
<mml:mi mathvariant="double-struck">P</mml:mi>
</mml:math>
</alternatives>
</inline-formula> and <inline-formula id="pcbi.1005690.e016"><alternatives><graphic id="pcbi.1005690.e016g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005690.e016" xlink:type="simple"/><mml:math display="inline" id="M16"><mml:mi mathvariant="double-struck">L</mml:mi></mml:math></alternatives></inline-formula> are sets of atoms in protein and in ligand. <italic>T</italic>(⋅) denotes element type of an atom. <italic>e</italic><sub>P</sub> is an element type in protein and <italic>e</italic><sub>L</sub> is an element type in ligand. “Complex” refers to the type of simplicial complex used and “Dimension” refers to the dimensionality of a topological invariant.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="sec014">
<title>Multichannel topological invariants for the prediction of protein folding free energy change upon mutation</title>
<p>Modeling protein folding free energy change upon mutation basically involves the unfolded states and folded structures of the mutant and the wild type as shown in <xref ref-type="fig" rid="pcbi.1005690.g004">Fig 4</xref>. Since unfolded states of proteins are highly dynamic which significantly increases the modeling cost due to the need of sampling over large conformation space, we only analyze the folded states of the mutants and the wild type proteins in this application. Similar to the protein-ligand binding affinity prediction, atomic interactions between specific element types, geometric effects, and hydrophobic effects are characterized. The persistent homology analysis performed in this application is summarized in <xref ref-type="table" rid="pcbi.1005690.t005">Table 5</xref>. The differences between the description vectors arising from Sets 1 and 2, and between those arising from Sets 3 and 4 are also included to account for changes caused by mutation. The 1D-image-like representation in this application thus has a channel size of 45. The pairwise interaction pattern is characterized for 9 element pairs from the element set {C, N, O }. For example, the interactions between the carbon atoms of the mutation site and the nitrogen atoms from the rest of the protein. Such characterization for mutant protein, wild protein, and the difference between these characterizations account for 27 channels. The birth, death, and bar persistence are characterized for Betti-1 and Betti-2 barcodes for all heavy atoms of both the wild type protein and the mutant protein resulting in 12 channels. The difference between the mutant and the wild type, which accounts for 6 channels, is also included. Thus, we have a total of 45 channels. The distance scale interval, [0, 12] Å is divided into bins of length 0.25 Å. An example of the persistent homology barcodes of a mutant and its wild type is given in <xref ref-type="fig" rid="pcbi.1005690.g002">Fig 2</xref>.</p>
<fig id="pcbi.1005690.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005690.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Mutation induced protein folding free energy changes.</title>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005690.g004" xlink:type="simple"/>
</fig>
<table-wrap id="pcbi.1005690.t005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005690.t005</object-id>
<label>Table 5</label>
<caption>
<title>Topological representations for protein mutation problem.</title>
</caption>
<alternatives>
<graphic id="pcbi.1005690.t005g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005690.t005" xlink:type="simple"/>
<table border="0" frame="box" rules="all">
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left">Set</th>
<th align="left">Atoms selected</th>
<th align="left">Distance</th>
<th align="left">Complex</th>
<th align="left">Dimension</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">1</td>
<td align="left">
<inline-formula id="pcbi.1005690.e017">
<alternatives>
<graphic id="pcbi.1005690.e017g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005690.e017" xlink:type="simple"/>
<mml:math display="inline" id="M17">
<mml:mrow>
<mml:mrow>
<mml:mo>{</mml:mo>
<mml:mi>a</mml:mi>
<mml:mo>∈</mml:mo>
</mml:mrow>
<mml:msup>
<mml:mi mathvariant="double-struck">P</mml:mi>
<mml:mi mathvariant="normal">W</mml:mi>
</mml:msup>
<mml:mrow>
<mml:mo>\</mml:mo>
</mml:mrow>
<mml:msup>
<mml:mi mathvariant="double-struck">M</mml:mi>
<mml:mi mathvariant="normal">W</mml:mi>
</mml:msup>
<mml:mrow>
<mml:mo>|</mml:mo>
<mml:mi>T</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>a</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi mathvariant="normal">P</mml:mi>
</mml:msub>
<mml:mo>}</mml:mo>
</mml:mrow>
<mml:mo>∪</mml:mo>
<mml:mrow>
<mml:mo>{</mml:mo>
<mml:mi>a</mml:mi>
<mml:mo>∈</mml:mo>
<mml:msup>
<mml:mi mathvariant="double-struck">M</mml:mi>
<mml:mi mathvariant="normal">W</mml:mi>
</mml:msup>
<mml:mo>|</mml:mo>
<mml:mi>T</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>a</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi mathvariant="normal">M</mml:mi>
</mml:msub>
<mml:mo>}</mml:mo>
</mml:mrow>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi mathvariant="normal">P</mml:mi>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi mathvariant="normal">M</mml:mi>
</mml:msub>
<mml:mo>∈</mml:mo>
<mml:msup>
<mml:mi mathvariant="double-struck">P</mml:mi>
<mml:mi mathvariant="normal">e</mml:mi>
</mml:msup>
</mml:mrow>
</mml:math>
</alternatives>
</inline-formula>
</td>
<td align="left"><italic>d</italic><sup><italic>op</italic></sup></td>
<td align="left">-</td>
<td align="left">0</td>
</tr>
<tr>
<td align="left">2</td>
<td align="left">
<inline-formula id="pcbi.1005690.e018">
<alternatives>
<graphic id="pcbi.1005690.e018g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005690.e018" xlink:type="simple"/>
<mml:math display="inline" id="M18">
<mml:mrow>
<mml:mrow>
<mml:mo>{</mml:mo>
<mml:mi>a</mml:mi>
<mml:mo>∈</mml:mo>
</mml:mrow>
<mml:msup>
<mml:mi mathvariant="double-struck">P</mml:mi>
<mml:mi mathvariant="normal">M</mml:mi>
</mml:msup>
<mml:mrow>
<mml:mo>\</mml:mo>
</mml:mrow>
<mml:msup>
<mml:mi mathvariant="double-struck">M</mml:mi>
<mml:mi mathvariant="normal">M</mml:mi>
</mml:msup>
<mml:mrow>
<mml:mo>|</mml:mo>
<mml:mi>T</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>a</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi mathvariant="normal">P</mml:mi>
</mml:msub>
<mml:mo>}</mml:mo>
</mml:mrow>
<mml:mo>∪</mml:mo>
<mml:mrow>
<mml:mo>{</mml:mo>
<mml:mi>a</mml:mi>
<mml:mo>∈</mml:mo>
<mml:msup>
<mml:mi mathvariant="double-struck">M</mml:mi>
<mml:mi mathvariant="normal">M</mml:mi>
</mml:msup>
<mml:mo>|</mml:mo>
<mml:mi>T</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>a</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi mathvariant="normal">M</mml:mi>
</mml:msub>
<mml:mo>}</mml:mo>
</mml:mrow>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi mathvariant="normal">P</mml:mi>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi mathvariant="normal">M</mml:mi>
</mml:msub>
<mml:mo>∈</mml:mo>
<mml:msup>
<mml:mi mathvariant="double-struck">P</mml:mi>
<mml:mi mathvariant="normal">e</mml:mi>
</mml:msup>
</mml:mrow>
</mml:math>
</alternatives>
</inline-formula>
</td>
<td align="left"><italic>d</italic><sup><italic>op</italic></sup></td>
<td align="left">-</td>
<td align="left">0</td>
</tr>
<tr>
<td align="left">3</td>
<td align="left">
<inline-formula id="pcbi.1005690.e019">
<alternatives>
<graphic id="pcbi.1005690.e019g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005690.e019" xlink:type="simple"/>
<mml:math display="inline" id="M19">
<mml:mrow>
<mml:mo>{</mml:mo>
<mml:mi>a</mml:mi>
<mml:mo>∈</mml:mo>
<mml:msup>
<mml:mi mathvariant="double-struck">P</mml:mi>
<mml:mi mathvariant="normal">W</mml:mi>
</mml:msup>
<mml:mo>|</mml:mo>
<mml:mi>T</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>a</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>∈</mml:mo>
<mml:msup>
<mml:mi mathvariant="double-struck">P</mml:mi>
<mml:mi mathvariant="normal">e</mml:mi>
</mml:msup>
<mml:mo>}</mml:mo>
</mml:mrow>
</mml:math>
</alternatives>
</inline-formula>
</td>
<td align="left">Euclidean</td>
<td align="left">Alpha</td>
<td align="left">1,2</td>
</tr>
<tr>
<td align="left">4</td>
<td align="left">
<inline-formula id="pcbi.1005690.e020">
<alternatives>
<graphic id="pcbi.1005690.e020g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005690.e020" xlink:type="simple"/>
<mml:math display="inline" id="M20">
<mml:mrow>
<mml:mo>{</mml:mo>
<mml:mi>a</mml:mi>
<mml:mo>∈</mml:mo>
<mml:msup>
<mml:mi mathvariant="double-struck">P</mml:mi>
<mml:mi mathvariant="normal">M</mml:mi>
</mml:msup>
<mml:mo>|</mml:mo>
<mml:mi>T</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>a</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>∈</mml:mo>
<mml:msup>
<mml:mi mathvariant="double-struck">P</mml:mi>
<mml:mi mathvariant="normal">e</mml:mi>
</mml:msup>
<mml:mo>}</mml:mo>
</mml:mrow>
</mml:math>
</alternatives>
</inline-formula>
</td>
<td align="left">Euclidean</td>
<td align="left">Alpha</td>
<td align="left">1,2</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t005fn001">
<p>Here <inline-formula id="pcbi.1005690.e021"><alternatives><graphic id="pcbi.1005690.e021g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005690.e021" xlink:type="simple"/><mml:math display="inline" id="M21"><mml:msup><mml:mi mathvariant="double-struck">P</mml:mi> <mml:mi mathvariant="normal">W</mml:mi></mml:msup></mml:math></alternatives></inline-formula>, <inline-formula id="pcbi.1005690.e022"><alternatives><graphic id="pcbi.1005690.e022g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005690.e022" xlink:type="simple"/><mml:math display="inline" id="M22"><mml:msup><mml:mi mathvariant="double-struck">P</mml:mi> <mml:mi mathvariant="normal">M</mml:mi></mml:msup></mml:math></alternatives></inline-formula>, <inline-formula id="pcbi.1005690.e023"><alternatives><graphic id="pcbi.1005690.e023g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005690.e023" xlink:type="simple"/><mml:math display="inline" id="M23"><mml:msup><mml:mi mathvariant="double-struck">M</mml:mi> <mml:mi mathvariant="normal">W</mml:mi></mml:msup></mml:math></alternatives></inline-formula>, and <inline-formula id="pcbi.1005690.e024"><alternatives><graphic id="pcbi.1005690.e024g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005690.e024" xlink:type="simple"/><mml:math display="inline" id="M24"><mml:msup><mml:mi mathvariant="double-struck">M</mml:mi> <mml:mi mathvariant="normal">M</mml:mi></mml:msup></mml:math></alternatives></inline-formula> are sets of atoms of wild type protein, mutant protein, mutation site in the wild type protein, and mutated site in the mutant protein. Here <inline-formula id="pcbi.1005690.e025"><alternatives><graphic id="pcbi.1005690.e025g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005690.e025" xlink:type="simple"/><mml:math display="inline" id="M25"><mml:mrow><mml:msup><mml:mi mathvariant="double-struck">P</mml:mi> <mml:mi mathvariant="normal">e</mml:mi></mml:msup> <mml:mo>=</mml:mo> <mml:mrow><mml:mo>{</mml:mo> <mml:mi mathvariant="normal">C</mml:mi> <mml:mo>,</mml:mo> <mml:mi mathvariant="normal">N</mml:mi> <mml:mo>,</mml:mo> <mml:mi mathvariant="normal">O</mml:mi> <mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> and <italic>T</italic>(⋅) is the same as defined in <xref ref-type="table" rid="pcbi.1005690.t004">Table 4</xref>. The distance function <italic>d</italic><sup><italic>op</italic></sup> is similar to the one defined in <xref ref-type="disp-formula" rid="pcbi.1005690.e009">Eq (2)</xref>, while the affiliation function <italic>A</italic>(⋅) returns either <inline-formula id="pcbi.1005690.e026"><alternatives><graphic id="pcbi.1005690.e026g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005690.e026" xlink:type="simple"/><mml:math display="inline" id="M26"><mml:mi mathvariant="double-struck">M</mml:mi></mml:math></alternatives></inline-formula> or <inline-formula id="pcbi.1005690.e027"><alternatives><graphic id="pcbi.1005690.e027g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005690.e027" xlink:type="simple"/><mml:math display="inline" id="M27"><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi> <mml:mo>\</mml:mo> <mml:mi mathvariant="double-struck">M</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
</sec>
<sec id="sec015">
<title>Multichannel topological convolutional neural network</title>
<p>The preprocessed multichannel topological image is standardized with mean 0 and standard deviation 1 for use in the convolutional neural network. A convolutional neural network with a few 1D convolution layers, followed by several fully connected layers, is used to extract higher level features from multichannel topological images and to perform regression with the learned features. An illustration of the convolutional neural network structure is shown in <xref ref-type="fig" rid="pcbi.1005690.g005">Fig 5</xref>. A brief review of multichannel topological convolutional neural network concepts is given in the case of 1D-image-like inputs. Convolution operation, optimization method for feedforward neural networks, and dropout out technique which prevents overfitting are discussed. One of the advantages of multichannel topological convolutional deep neural networks is their ability to extract features hierarchically from low level topological representations.</p>
<fig id="pcbi.1005690.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005690.g005</object-id>
<label>Fig 5</label>
<caption>
<title>An illustration of the 1D convolutional neural network.</title>
<p>The network consists of repeated convolution layers and pooling layers followed by several fully connected layers.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005690.g005" xlink:type="simple"/>
</fig>
<sec id="sec016">
<title>Convolution operation</title>
<p>Consider an <italic>n</italic> × <italic>m</italic> second order tensor <bold>V</bold>, where <italic>n</italic> is the number of topological feature pixels and <italic>m</italic> is number of channels for each pixel. In this approach, <italic>n</italic> corresponds to the radius filtration dimension of the biomolecular topological analysis and <italic>m</italic> corresponds the number of representation vectors used which are defined in <xref ref-type="disp-formula" rid="pcbi.1005690.e005">Eq (1)</xref>. With a predefined window size <italic>w</italic>, a convolutional filter <bold>F</bold> can be represented by a <italic>w</italic> × <italic>m</italic> second order tensor. By moving the window of size <italic>w</italic> along the radius filtration direction of <bold>V</bold>, a sequence of <italic>N</italic><sub><italic>f</italic></sub> second order tensors, which are subtensors of <italic>V</italic>, are obtained and can be concatenated to form an <italic>N</italic><sub><italic>f</italic></sub> × <italic>w</italic> × <italic>m</italic> third order tensor <bold>T</bold>. The filter <bold>F</bold> operated on <bold>T</bold> results in a first order tensor <bold>T</bold><sub><italic>ijk</italic></sub><bold>F</bold><sub><italic>jk</italic></sub> by tensor contraction. Concatenating the outputs of <italic>n</italic><sub><italic>f</italic></sub> filters gives an <italic>N</italic><sub><italic>f</italic></sub> × <italic>n</italic><sub><italic>f</italic></sub> second order tensor. Generally speaking, a 1D convolution layer takes an <italic>n</italic> × <italic>m</italic> tensor and outputs an <italic>N</italic><sub><italic>f</italic></sub> × <italic>n</italic><sub><italic>f</italic></sub> tensor.</p>
</sec>
<sec id="sec017">
<title>Optimization</title>
<p>Feedforward neural networks are usually trained by backpropagation where the error of the output layer is calculated and is propagated backward through the network to update its weights. For structured neural networks, conventional <italic>L</italic><sub>2</sub> minimization does not work. One popular approach of training a neural network is the stochastic gradient decent (SGD) method. Let Θ be the parameters in the network and <inline-formula id="pcbi.1005690.e028"><alternatives><graphic id="pcbi.1005690.e028g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005690.e028" xlink:type="simple"/><mml:math display="inline" id="M28"><mml:mrow><mml:mi mathvariant="script">L</mml:mi> <mml:mo>(</mml:mo> <mml:mo>Θ</mml:mo> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> be the objective function or learning kernel that is to be minimized. SGD method updates Θ<sub><italic>i</italic></sub> to Θ<sub><italic>i</italic>+1</sub> from step <italic>i</italic> to step <italic>i</italic> + 1 as
<disp-formula id="pcbi.1005690.e029"><alternatives><graphic id="pcbi.1005690.e029g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005690.e029" xlink:type="simple"/><mml:math display="block" id="M29"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mo>Θ</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mo>Θ</mml:mo> <mml:mi>i</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi> <mml:msub><mml:mo>∇</mml:mo> <mml:mo>Θ</mml:mo></mml:msub> <mml:mi mathvariant="script">L</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mo>Θ</mml:mo> <mml:mi>i</mml:mi></mml:msub> <mml:mo>;</mml:mo> <mml:msub><mml:mi>X</mml:mi> <mml:mi>s</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>Y</mml:mi> <mml:mi>s</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(3)</label></disp-formula>
where <italic>τ</italic> is the learning rate, <italic>X</italic><sub><italic>s</italic></sub> and <italic>Y</italic><sub><italic>s</italic></sub> are the input and target of the <italic>s</italic>th sample of the training set. In practice, the training set (<italic>X</italic>, <italic>Y</italic>) is often split into mini-batches {(<italic>X</italic><sub><italic>s</italic></sub>, <italic>Y</italic><sub><italic>s</italic></sub>)}<sub><italic>s</italic>∈<italic>S</italic></sub>. SGD method then goes through each mini-batch instead of going through only one example at a time. When the landscape of the objective function is like a long steep valley, momentum is added to accelerate convergence of the algorithm. The updating scheme can therefore be changed to
<disp-formula id="pcbi.1005690.e030"><alternatives><graphic id="pcbi.1005690.e030g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005690.e030" xlink:type="simple"/><mml:math display="block" id="M30"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mo>Δ</mml:mo> <mml:msub><mml:mo>Θ</mml:mo> <mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:msub><mml:mo>Θ</mml:mo> <mml:mi>i</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mo>Θ</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mo>Θ</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:msub><mml:mo>Θ</mml:mo> <mml:mi>i</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>η</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>τ</mml:mi> <mml:msub><mml:mo>∇</mml:mo> <mml:mo>Θ</mml:mo></mml:msub> <mml:mi mathvariant="script">L</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mo>Θ</mml:mo> <mml:mi>i</mml:mi></mml:msub> <mml:mo>;</mml:mo> <mml:msubsup><mml:mi>X</mml:mi> <mml:mi>s</mml:mi> <mml:mi>i</mml:mi></mml:msubsup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>Y</mml:mi> <mml:mi>s</mml:mi> <mml:mi>i</mml:mi></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mi>η</mml:mi> <mml:mo>Δ</mml:mo> <mml:msub><mml:mo>Θ</mml:mo> <mml:mi>i</mml:mi></mml:msub> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(4)</label></disp-formula>
where 0 ≤ <italic>η</italic> ≤ 1 is a scalar coefficient for the momentum term.</p>
</sec>
<sec id="sec018">
<title>Dropout</title>
<p>Neural networks with several convolution layers and fully connected layers possess a large number of degrees of freedom which can easily lead to overfitting. The dropout technique is an easy way of preventing network overfitting [<xref ref-type="bibr" rid="pcbi.1005690.ref100">100</xref>]. During the training process, hidden units are randomly chosen to feed zero values to their connected neighbors in the next layer. Suppose that a percentage of neurons at a certain layer are chosen to be dropped during training. Then, in the testing process, the output of this layer is computed by multiplying a coefficient such as 1 − λ, where λ is the dropout rate, to approximate the average of the network after dropout in each training step.</p>
</sec>
<sec id="sec019">
<title>Bagging (bootstrap aggregating)</title>
<p>In addition to dropout technique which regularizes each individual model, bagging is a technique to combine the output of several models trained separately by averaging to reduce generalization error. This is based on the assumption that models with randomness in the training process likely make different errors on testing data. Generally, bagging trains different models on different subsets of the training set. Specifically, as neural networks have relatively high underlying randomness caused by factors including the random weights initialization and the random mini-batch partition, it can benefit from bagging even if the individual models are trained on the same dataset. In this work, bagging of neural network models trained individually with the same architecture and training dataset is used.</p>
</sec>
<sec id="sec020">
<title>Incorporating non-image-like features</title>
<p>Deep learning architecture also allows the use of non-image-like features together with image or image-like features. In this work, additional auxiliary features, which are important to mutation analysis, are incorporated after the convolution layers as shown in <xref ref-type="fig" rid="pcbi.1005690.g006">Fig 6</xref>. This approach leads to a 9% improvement to mutation prediction of the “S2648” data set.</p>
<fig id="pcbi.1005690.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005690.g006</object-id>
<label>Fig 6</label>
<caption>
<title>The deep learning architecture for the application to globular proteins.</title>
<p>The non-image-like features are incorporated in the multichannel topological convolutional deep neural network by merging the features into the network at one of the fully connected layers.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005690.g006" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec021">
<title>Multi-task deep learning</title>
<p>We construct a multi-task multichannel topological convolutional neural network (MM-TCNN) architecture to carry out simultaneous training and prediction. The common topological attributes and underlying physical interactions in features provide a basis for multi-task predictions. Because the deep neural networks are jointly trained from multiple prediction tasks, we expect the networks to generate robust high-level representations from low level TFs for prediction problems. We also expect that the refined representation would lead to prediction models with improved generalized performance. From the proposed deep learning models, we hope to gain insights into how the nonlinear and nonlocal interactions among topological features impact various prediction tasks, which could further lead to better understanding towards the interactions among biomolecular prediction tasks. Finally, tasks with insufficient training data sets will be more likely to benefit from the information collected from tasks with large training sets in a multi-task learning framework. <xref ref-type="fig" rid="pcbi.1005690.g007">Fig 7</xref> illustrates our multi-task multichannel topological deep learning architecture for simultaneous training and prediction of globular protein and membrane protein mutation impacts.</p>
<fig id="pcbi.1005690.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005690.g007</object-id>
<label>Fig 7</label>
<caption>
<title>Workflow of the multi-task topological deep learning model.</title>
<p>The multi-task multichannel topological convolutional neural network model shares and transforms topological information for the simultaneous training and prediction of globular protein and membrane protein mutation impacts on protein stability.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005690.g007" xlink:type="simple"/>
</fig>
<p>In the present mutation analysis, there are two data sets. The mutation data of the large data set for globular proteins are more reliable, while those of the small data set for membrane proteins are noisy and less reliable due to the fact that the current technologies for membrane protein mutagenesis experiments are immature. The prediction for membrane proteins benefits from joint learning with the prediction for globular proteins. The coupling of the two predictions through a neural network is shown in <xref ref-type="fig" rid="pcbi.1005690.g008">Fig 8</xref>.</p>
<fig id="pcbi.1005690.g008" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005690.g008</object-id>
<label>Fig 8</label>
<caption>
<title>The multi-task deep learning architecture for membrane proteins.</title>
<p>Using globular protein stability change upon mutation as an auxiliary task to improve the task of membrane protein mutation prediction. The globular protein stability change upon mutation prediction is used as an auxiliary task to improve the task of predicting membrane protein stability changes upon mutation. The solid arrows show the path of information passing when the model is applied for predictions. The dotted and dashed arrows mark the paths of backpropagation when the network is trained with globular protein data set and membrane protein data set respectively.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005690.g008" xlink:type="simple"/>
</fig>
<p>The general objective function to minimize for multi-task learning through neural networks can be decomposed into training loss, similarity penalty for shared layers, and regularization term as
<disp-formula id="pcbi.1005690.e031"><alternatives><graphic id="pcbi.1005690.e031g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005690.e031" xlink:type="simple"/><mml:math display="block" id="M31"><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mi mathvariant="script">L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>Θ</mml:mo><mml:mo>;</mml:mo><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>Y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mo>=</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover></mml:mstyle><mml:msub><mml:mi mathvariant="script">J</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mo>Θ</mml:mo><mml:mrow><mml:mi>S</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mo>Θ</mml:mo><mml:mrow><mml:mi>B</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow/></mml:mtd><mml:mtd columnalign="left"><mml:mo>+</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi mathvariant="script">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mo>Θ</mml:mo><mml:mrow><mml:mi>S</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mo>Θ</mml:mo><mml:mrow><mml:mi>S</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow/></mml:mtd><mml:mtd columnalign="left"><mml:mo>+</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi mathvariant="script">R</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mo>Θ</mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(5)</label></disp-formula>
where Θ is the collection of all parameters to be updated, Θ<sub><italic>Sj</italic></sub> is the set of parameters for the <italic>j</italic>th task of the shared layers, Θ<sub><italic>Bj</italic></sub> is the set of parameters for the <italic>j</italic>th branch of neurons dedicated for the <italic>j</italic>th task, and (<italic>X</italic><sub><italic>j</italic></sub>, <italic>Y</italic><sub><italic>j</italic></sub>) are training data for the <italic>j</italic>th task. Here <inline-formula id="pcbi.1005690.e032"><alternatives><graphic id="pcbi.1005690.e032g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005690.e032" xlink:type="simple"/><mml:math display="inline" id="M32"><mml:mi mathvariant="script">P</mml:mi></mml:math></alternatives></inline-formula> is the penalty function which penalizes the difference among <italic>N</italic> sets of parameters. Finally <inline-formula id="pcbi.1005690.e033"><alternatives><graphic id="pcbi.1005690.e033g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005690.e033" xlink:type="simple"/><mml:math display="inline" id="M33"><mml:mrow><mml:mi mathvariant="script">R</mml:mi> <mml:mo>(</mml:mo> <mml:mo>·</mml:mo> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> is the regularization term which prevents overfitting and <inline-formula id="pcbi.1005690.e034"><alternatives><graphic id="pcbi.1005690.e034g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005690.e034" xlink:type="simple"/><mml:math display="inline" id="M34"><mml:mi mathvariant="script">J</mml:mi></mml:math></alternatives></inline-formula> is the <italic>j</italic>th loss function. In this work, we force the shared layers of the two problems to be the same and the regularization of the network is realized using dropout.</p>
</sec>
<sec id="sec022">
<title>Model training and prediction</title>
<p>Due to the complexity of the network for the mutation example with auxiliary features, a brief parameter search is performed using Hyperopt [<xref ref-type="bibr" rid="pcbi.1005690.ref101">101</xref>] with only 50 trials allowing flexibility in number of neurons, activation function, and weight initialization. In the protein-ligand binding example, only around 10 sets of parameters are selected manually and tested because of the large input size for the problem.</p>
<p>In the protein-ligand binding affinity predictions, we repeatedly train 100 single neural networks individually. To test the performance of bagging of the models, we randomly select 50 trained models from the 100 individually trained networks and output the average value of the outputs from the 50 selected models as the prediction. The performance is then computed for the bagging. This process is repeated 100 times and both median and best results are reported.</p>
<p>In the mutation induced protein stability predictions, we use the same procedure used in the protein-ligand binding prediction, for the “S350” task, where the training and testing split is predefined. In the case of cross validation, 10 sets of 5-fold splits are generated randomly and 20 single models are generated for each split. The average prediction is taken over the 20 models within each split and the median result of the 10 splits is reported. Bagging of only 20 models is performed here because it is not valid to do bagging of predictors on different cross validation splits. The bagging of 50 models will result in 50(individual models)x10(cross validation splits)x5(five folds) = 2500 training processes which is too computationally expensive. Details of the network architectures of the three examples can be found in Multichannel topological convolutional neural network.</p>
</sec>
<sec id="sec023">
<title>Software</title>
<p>Dionysus software [<xref ref-type="bibr" rid="pcbi.1005690.ref102">102</xref>] with CGAL library [<xref ref-type="bibr" rid="pcbi.1005690.ref103">103</xref>] is used for persistent homology computation on alpha complex. Javaplex [<xref ref-type="bibr" rid="pcbi.1005690.ref104">104</xref>] and Dipha [<xref ref-type="bibr" rid="pcbi.1005690.ref043">43</xref>] software packages are used for persistent homology computation on Vietoris-Rips complex. The neural networks are realized using Keras [<xref ref-type="bibr" rid="pcbi.1005690.ref105">105</xref>] wrapper of Theano [<xref ref-type="bibr" rid="pcbi.1005690.ref106">106</xref>] backend. Various functions from Numpy and Scipy [<xref ref-type="bibr" rid="pcbi.1005690.ref107">107</xref>] packages are used to process data and evaluate the performance.</p>
</sec>
</sec>
</sec>
<sec id="sec024">
<title>Supporting information</title>
<supplementary-material id="pcbi.1005690.s001" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005690.s001" xlink:type="simple">
<label>S1 Text</label>
<caption>
<title>Handcrafted features.</title>
<p>Handcrafted auxiliary features for prediction of protein folding free energy change upon mutation.</p>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1005690.s002" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005690.s002" xlink:type="simple">
<label>S2 Text</label>
<caption>
<title>Network architectures.</title>
<p>Detailed architectures and parameters of the neural networks introduced in this work.</p>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1005690.s003" mimetype="application/zip" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005690.s003" xlink:type="simple">
<label>S1 Code</label>
<caption>
<title>Binding topological features.</title>
<p>Source code for the generation of 1D image-like topological features for the binding problem.</p>
<p>(ZIP)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1005690.s004" mimetype="application/zip" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005690.s004" xlink:type="simple">
<label>S2 Code</label>
<caption>
<title>Mutation topological features.</title>
<p>Source code for the generation of 1D image-like topological features for the mutation problem.</p>
<p>(ZIP)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>We thank David Bramer for proofreading this manuscript.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1005690.ref001">
<label>1</label>
<mixed-citation publication-type="other" xlink:type="simple">Krizhevsky A, Sutskever I, Hinton GE. Imagenet classification with deep convolutional neural networks. In: Advances in neural information processing systems; 2012. p. 1097–1105.</mixed-citation>
</ref>
<ref id="pcbi.1005690.ref002">
<label>2</label>
<mixed-citation publication-type="other" xlink:type="simple">Simonyan K, Zisserman A. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:14091556. 2014;.</mixed-citation>
</ref>
<ref id="pcbi.1005690.ref003">
<label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>LeCun</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Bengio</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Hinton</surname> <given-names>G</given-names></name>. <article-title>Deep learning</article-title>. <source>Nature</source>. <year>2015</year>;<volume>521</volume>(<issue>7553</issue>):<fpage>436</fpage>–<lpage>444</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature14539" xlink:type="simple">10.1038/nature14539</ext-link></comment> <object-id pub-id-type="pmid">26017442</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref004">
<label>4</label>
<mixed-citation publication-type="other" xlink:type="simple">Ngiam J, Khosla A, Kim M, Nam J, Lee H, Ng AY. Multimodal deep learning. In: Proceedings of the 28th international conference on machine learning (ICML-11); 2011. p. 689–696.</mixed-citation>
</ref>
<ref id="pcbi.1005690.ref005">
<label>5</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Caruana</surname> <given-names>R</given-names></name>. <chapter-title>Multitask learning</chapter-title>. In: <source>Learning to learn</source>. <publisher-name>Springer</publisher-name>; <year>1998</year>. p. <fpage>95</fpage>–<lpage>133</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005690.ref006">
<label>6</label>
<mixed-citation publication-type="other" xlink:type="simple">Evgeniou T, Pontil M. Regularized multi–task learning. In: Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining. ACM; 2004. p. 109–117.</mixed-citation>
</ref>
<ref id="pcbi.1005690.ref007">
<label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Evgeniou</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Pontil</surname> <given-names>M</given-names></name>. <article-title>Multi-task feature learning</article-title>. <source>Advances in neural information processing systems</source>. <year>2007</year>;<volume>19</volume>:<fpage>41</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005690.ref008">
<label>8</label>
<mixed-citation publication-type="other" xlink:type="simple">Liu J, Ji S, Ye J. Multi-task feature learning via efficient l 2, 1-norm minimization. In: Proceedings of the twenty-fifth conference on uncertainty in artificial intelligence. AUAI Press; 2009. p. 339–348.</mixed-citation>
</ref>
<ref id="pcbi.1005690.ref009">
<label>9</label>
<mixed-citation publication-type="other" xlink:type="simple">Zhou J, Chen J, Ye J. Clustered multi-task learning via alternating structure optimization. In: Advances in neural information processing systems; 2011. p. 702–710.</mixed-citation>
</ref>
<ref id="pcbi.1005690.ref010">
<label>10</label>
<mixed-citation publication-type="other" xlink:type="simple">Unterthiner T, Mayr A, Klambauer G, Hochreiter S. Toxicity prediction using deep learning. arXiv preprint arXiv:150301445. 2015;.</mixed-citation>
</ref>
<ref id="pcbi.1005690.ref011">
<label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Lusci</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Pollastri</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Baldi</surname> <given-names>P</given-names></name>. <article-title>Deep architectures and deep learning in chemoinformatics: the prediction of aqueous solubility for drug-like molecules</article-title>. <source>Journal of chemical information and modeling</source>. <year>2013</year>;<volume>53</volume>(<issue>7</issue>):<fpage>1563</fpage>–<lpage>1575</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1021/ci400187y" xlink:type="simple">10.1021/ci400187y</ext-link></comment> <object-id pub-id-type="pmid">23795551</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref012">
<label>12</label>
<mixed-citation publication-type="other" xlink:type="simple">Wallach I, Dzamba M, Heifets A. AtomNet: A Deep Convolutional Neural Network for Bioactivity Prediction in Structure-based Drug Discovery. arXiv preprint arXiv:151002855. 2015;.</mixed-citation>
</ref>
<ref id="pcbi.1005690.ref013">
<label>13</label>
<mixed-citation publication-type="other" xlink:type="simple">Dahl GE, Jaitly N, Salakhutdinov R. Multi-task neural networks for QSAR predictions. arXiv preprint arXiv:14061231. 2014;.</mixed-citation>
</ref>
<ref id="pcbi.1005690.ref014">
<label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Wang</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Zhao</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Wei</surname> <given-names>GW</given-names></name>. <article-title>Automatic parametrization of non-polar implicit solvent models for the blind prediction of solvation free energies</article-title>. <source>Journal of Chemical Physics</source>. <year>2016</year>;<volume>145</volume>:<fpage>124110</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1063/1.4963193" xlink:type="simple">10.1063/1.4963193</ext-link></comment> <object-id pub-id-type="pmid">27782659</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref015">
<label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Nguyen</surname> <given-names>DD</given-names></name>, <name name-style="western"><surname>Wei</surname> <given-names>GW</given-names></name>. <article-title>The impact of surface area, volume, curvature and Lennard-Jones potential to solvation modeling</article-title>. <source>Journal of Computational Chemistry</source>. <year>2017</year>; <volume>38</volume>:<fpage>24</fpage>–<lpage>36</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005690.ref016">
<label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Feng</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Xia</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Tong</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Wei</surname> <given-names>GW</given-names></name>. <article-title>Geometric modeling of subcellular structures, organelles and large multiprotein complexes</article-title>. <source>International Journal for Numerical Methods in Biomedical Engineering</source>. <year>2012</year>;<volume>28</volume>:<fpage>1198</fpage>–<lpage>1223</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/cnm.2532" xlink:type="simple">10.1002/cnm.2532</ext-link></comment> <object-id pub-id-type="pmid">23212797</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref017">
<label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schlick</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Olson</surname> <given-names>WK</given-names></name>. <article-title>Trefoil knotting revealed by molecular dynamics simulations of supercoiled DNA</article-title>. <source>Science</source>. <year>1992</year>;<volume>257</volume>(<issue>5073</issue>):<fpage>1110</fpage>–<lpage>1115</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.257.5073.1110" xlink:type="simple">10.1126/science.257.5073.1110</ext-link></comment> <object-id pub-id-type="pmid">1509261</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref018">
<label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Zomorodian</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Carlsson</surname> <given-names>G</given-names></name>. <article-title>Computing persistent homology</article-title>. <source>Discrete Comput Geom</source>. <year>2005</year>;<volume>33</volume>:<fpage>249</fpage>–<lpage>274</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s00454-004-1146-y" xlink:type="simple">10.1007/s00454-004-1146-y</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref019">
<label>19</label>
<mixed-citation publication-type="other" xlink:type="simple">Sumners DW. Knot theory and DNA. In: Proceedings of Symposia in Applied Mathematics. vol. 45; 1992. p. 39–72.</mixed-citation>
</ref>
<ref id="pcbi.1005690.ref020">
<label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Darcy</surname> <given-names>IK</given-names></name>, <name name-style="western"><surname>Vazquez</surname> <given-names>M</given-names></name>. <article-title>Determining the topology of stable protein-DNA complexes</article-title>. <source>Biochemical Society Transactions</source>. <year>2013</year>;<volume>41</volume>:<fpage>601</fpage>–<lpage>605</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1042/BST20130004" xlink:type="simple">10.1042/BST20130004</ext-link></comment> <object-id pub-id-type="pmid">23514161</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref021">
<label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Heitsch</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Poznanovic</surname> <given-names>S</given-names></name>. <article-title>Combinatorial insights into RNA secondary structure</article-title>, in <name name-style="western"><surname>Jonoska</surname> <given-names>N.</given-names></name> and <name name-style="western"><surname>Saito</surname> <given-names>M.</given-names></name>, editors. <source>Discrete and Topological Models in Molecular Biology</source>. <year>2014</year>;<volume>Chapter 7</volume>:<fpage>145</fpage>–<lpage>166</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/978-3-642-40193-0_7" xlink:type="simple">10.1007/978-3-642-40193-0_7</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref022">
<label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Demerdash</surname> <given-names>ONA</given-names></name>, <name name-style="western"><surname>Daily</surname> <given-names>MD</given-names></name>, <name name-style="western"><surname>Mitchell</surname> <given-names>JC</given-names></name>. <article-title>Structure-Based Predictive Models for Allosteric Hot Spots</article-title>. <source>PLOS Computational Biology</source>. <year>2009</year>;<volume>5</volume>:<fpage>e1000531</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1000531" xlink:type="simple">10.1371/journal.pcbi.1000531</ext-link></comment> <object-id pub-id-type="pmid">19816556</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref023">
<label>23</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>DasGupta</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Liang</surname> <given-names>J</given-names></name>. <source>Models and Algorithms for Biomolecules and Molecular Networks</source>. <publisher-name>John Wiley &amp; Sons</publisher-name>; <year>2016</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005690.ref024">
<label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Shi</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Koehl</surname> <given-names>P</given-names></name>. <article-title>Geometry and topology for modeling biomolecular surfaces</article-title>. <source>Far East J Applied Math</source>. <year>2011</year>;<volume>50</volume>:<fpage>1</fpage>–<lpage>34</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005690.ref025">
<label>25</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Kaczynski</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Mischaikow</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Mrozek</surname> <given-names>M</given-names></name>. <chapter-title>Computational Homology</chapter-title>. <source>vol. 157 of Applied Mathematical Sciences</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Springer-Verlag</publisher-name>; <year>2004</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005690.ref026">
<label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Frosini</surname> <given-names>P</given-names></name>. <article-title>A distance for similarity classes of submanifolds of a Euclidean space</article-title>. <source>BUllentin of Australian Mathematical Society</source>. <year>1990</year>;<volume>42</volume>(<issue>3</issue>):<fpage>407</fpage>–<lpage>416</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1017/S0004972700028574" xlink:type="simple">10.1017/S0004972700028574</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref027">
<label>27</label>
<mixed-citation publication-type="other" xlink:type="simple">Robins V. Towards computing homology from finite approximations. In: Topology Proceedings. vol. 24; 1999. p. 503–532.</mixed-citation>
</ref>
<ref id="pcbi.1005690.ref028">
<label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Edelsbrunner</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Letscher</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Zomorodian</surname> <given-names>A</given-names></name>. <article-title>Topological persistence and simplification</article-title>. <source>Discrete Comput Geom</source>. <year>2002</year>;<volume>28</volume>:<fpage>511</fpage>–<lpage>533</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s00454-002-2885-2" xlink:type="simple">10.1007/s00454-002-2885-2</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref029">
<label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bendich</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Harer</surname> <given-names>J</given-names></name>. <article-title>Persistent Intersection Homology</article-title>. <source>Foundations of Computational Mathematics (FOCM)</source>. <year>2011</year>;<volume>11</volume>(<issue>3</issue>):<fpage>305</fpage>–<lpage>336</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s10208-010-9081-1" xlink:type="simple">10.1007/s10208-010-9081-1</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref030">
<label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Cohen-Steiner</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Edelsbrunner</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Harer</surname> <given-names>J</given-names></name>. <article-title>Stability of Persistence Diagrams</article-title>. <source>Discrete &amp; Computational Geometry</source>. <year>2007</year>;<volume>37</volume>(<issue>1</issue>):<fpage>103</fpage>–<lpage>120</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s00454-006-1276-5" xlink:type="simple">10.1007/s00454-006-1276-5</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref031">
<label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Cohen-Steiner</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Edelsbrunner</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Harer</surname> <given-names>J</given-names></name>. <article-title>Extending Persistence Using Poincaré and Lefschetz Duality</article-title>. <source>Foundations of Computational Mathematics</source>. <year>2009</year>;<volume>9</volume>(<issue>1</issue>):<fpage>79</fpage>–<lpage>103</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s10208-008-9038-9" xlink:type="simple">10.1007/s10208-008-9038-9</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref032">
<label>32</label>
<mixed-citation publication-type="other" xlink:type="simple">Cohen-Steiner D, Edelsbrunner H, Harer J, Morozov D. Persistent Homology for Kernels, Images, and Cokernels. In: Proceedings of the Twentieth Annual ACM-SIAM Symposium on Discrete Algorithms. SODA 09; 2009. p. 1011–1020.</mixed-citation>
</ref>
<ref id="pcbi.1005690.ref033">
<label>33</label>
<mixed-citation publication-type="other" xlink:type="simple">Chazal F, Cohen-Steiner D, Glisse M, Guibas LJ, Oudot S. Proximity of persistence modules and their diagrams. In: Proc. 25th ACM Sympos. on Comput. Geom.; 2009. p. 237–246.</mixed-citation>
</ref>
<ref id="pcbi.1005690.ref034">
<label>34</label>
<mixed-citation publication-type="other" xlink:type="simple">Chazal F, Guibas LJ, Oudot SY, Skraba P. Persistence-based clustering in riemannian manifolds. In: Proceedings of the 27th annual ACM symposium on Computational geometry. SoCG’11; 2011. p. 97–106.</mixed-citation>
</ref>
<ref id="pcbi.1005690.ref035">
<label>35</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Carlsson</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Zomorodian</surname> <given-names>A</given-names></name>. <article-title>The theory of multidimensional persistence</article-title>. <source>Discrete Computational Geometry</source>. <year>2009</year>;<volume>42</volume>(<issue>1</issue>):<fpage>71</fpage>–<lpage>93</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s00454-009-9176-0" xlink:type="simple">10.1007/s00454-009-9176-0</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref036">
<label>36</label>
<mixed-citation publication-type="other" xlink:type="simple">Carlsson G, de Silva V, Morozov D. Zigzag persistent homology and real-valued functions. In: Proc. 25th Annu. ACM Sympos. Comput. Geom.; 2009. p. 247–256.</mixed-citation>
</ref>
<ref id="pcbi.1005690.ref037">
<label>37</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>de Silva</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Morozov</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Vejdemo-Johansson</surname> <given-names>M</given-names></name>. <article-title>Persistent cohomology and circular coordinates</article-title>. <source>Discrete and Comput Geom</source>. <year>2011</year>;<volume>45</volume>:<fpage>737</fpage>–<lpage>759</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s00454-011-9344-x" xlink:type="simple">10.1007/s00454-011-9344-x</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref038">
<label>38</label>
<mixed-citation publication-type="other" xlink:type="simple">Oudot SY, Sheehy DR. Zigzag Zoology: Rips Zigzags for Homology Inference. In: Proc. 29th Annual Symposium on Computational Geometry; 2013. p. 387–396.</mixed-citation>
</ref>
<ref id="pcbi.1005690.ref039">
<label>39</label>
<mixed-citation publication-type="other" xlink:type="simple">Dey TK, Fan F, Wang Y. Computing topological persistence for simplicial maps. In: Proc. 30th Annu. Sympos. Comput. Geom. (SoCG); 2014. p. 345–354.</mixed-citation>
</ref>
<ref id="pcbi.1005690.ref040">
<label>40</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Mischaikow</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Nanda</surname> <given-names>V</given-names></name>. <article-title>Morse Theory for Filtrations and Efficient Computation of Persistent Homology</article-title>. <source>Discrete and Computational Geometry</source>. <year>2013</year>;<volume>50</volume>(<issue>2</issue>):<fpage>330</fpage>–<lpage>353</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s00454-013-9529-6" xlink:type="simple">10.1007/s00454-013-9529-6</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref041">
<label>41</label>
<mixed-citation publication-type="other" xlink:type="simple">Tausz A, Vejdemo-Johansson M, Adams H. JavaPlex: A research software package for persistent (co)homology; 2011. Software available at <ext-link ext-link-type="uri" xlink:href="http://code.google.com/p/javaplex" xlink:type="simple">http://code.google.com/p/javaplex</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1005690.ref042">
<label>42</label>
<mixed-citation publication-type="other" xlink:type="simple">Nanda V. Perseus: the persistent homology software;. Software available at <ext-link ext-link-type="uri" xlink:href="http://www.sas.upenn.edu/~vnanda/perseus" xlink:type="simple">http://www.sas.upenn.edu/~vnanda/perseus</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1005690.ref043">
<label>43</label>
<mixed-citation publication-type="other" xlink:type="simple">Bauer U, Kerber M, Reininghaus J. Distributed computation of persistent homology. Proceedings of the Sixteenth Workshop on Algorithm Engineering and Experiments (ALENEX). 2014;.</mixed-citation>
</ref>
<ref id="pcbi.1005690.ref044">
<label>44</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Carlsson</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Zomorodian</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Collins</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Guibas</surname> <given-names>LJ</given-names></name>. <article-title>Persistence Barcodes for Shapes</article-title>. <source>International Journal of Shape Modeling</source>. <year>2005</year>;<volume>11</volume>(<issue>2</issue>):<fpage>149</fpage>–<lpage>187</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1142/S0218654305000761" xlink:type="simple">10.1142/S0218654305000761</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref045">
<label>45</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ghrist</surname> <given-names>R</given-names></name>. <article-title>Barcodes: The persistent topology of data</article-title>. <source>Bull Amer Math Soc</source>. <year>2008</year>;<volume>45</volume>:<fpage>61</fpage>–<lpage>75</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1090/S0273-0979-07-01191-3" xlink:type="simple">10.1090/S0273-0979-07-01191-3</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref046">
<label>46</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kasson</surname> <given-names>PM</given-names></name>, <name name-style="western"><surname>Zomorodian</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Park</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Singhal</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Guibas</surname> <given-names>LJ</given-names></name>, <name name-style="western"><surname>Pande</surname> <given-names>VS</given-names></name>. <article-title>Persistent voids a new structural metric for membrane fusion</article-title>. <source>Bioinformatics</source>. <year>2007</year>;<volume>23</volume>:<fpage>1753</fpage>–<lpage>1759</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/bioinformatics/btm250" xlink:type="simple">10.1093/bioinformatics/btm250</ext-link></comment> <object-id pub-id-type="pmid">17488753</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref047">
<label>47</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gameiro</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Hiraoka</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Izumi</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Kramar</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Mischaikow</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Nanda</surname> <given-names>V</given-names></name>. <article-title>Topological measurement of protein compressibility via persistence diagrams</article-title>. <source>Japan Journal of Industrial and Applied Mathematics</source>. <year>2014</year>;<volume>32</volume>:<fpage>1</fpage>–<lpage>17</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s13160-014-0153-5" xlink:type="simple">10.1007/s13160-014-0153-5</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref048">
<label>48</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Dabaghian</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Memoli</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Frank</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Carlsson</surname> <given-names>G</given-names></name>. <article-title>A Topological Paradigm for Hippocampal Spatial Map Formation Using Persistent Homology</article-title>. <source>PLoS Comput Biol</source>. <year>2012</year>;<volume>8</volume>(<issue>8</issue>):<fpage>e1002581</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1002581" xlink:type="simple">10.1371/journal.pcbi.1002581</ext-link></comment> <object-id pub-id-type="pmid">22912564</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref049">
<label>49</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Xia</surname> <given-names>KL</given-names></name>, <name name-style="western"><surname>Wei</surname> <given-names>GW</given-names></name>. <article-title>Persistent homology analysis of protein structure, flexibility and folding</article-title>. <source>International Journal for Numerical Methods in Biomedical Engineerings</source>. <year>2014</year>;<volume>30</volume>:<fpage>814</fpage>–<lpage>844</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/cnm.2655" xlink:type="simple">10.1002/cnm.2655</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref050">
<label>50</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Xia</surname> <given-names>KL</given-names></name>, <name name-style="western"><surname>Feng</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Tong</surname> <given-names>YY</given-names></name>, <name name-style="western"><surname>Wei</surname> <given-names>GW</given-names></name>. <article-title>Persistent Homology for the quantitative prediction of fullerene stability</article-title>. <source>Journal of Computational Chemsitry</source>. <year>2015</year>;<volume>36</volume>:<fpage>408</fpage>–<lpage>422</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/jcc.23816" xlink:type="simple">10.1002/jcc.23816</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref051">
<label>51</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Wang</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Wei</surname> <given-names>GW</given-names></name>. <article-title>Object-oriented Persistent Homology</article-title>. <source>Journal of Computational Physics</source>. <year>2016</year>;<volume>305</volume>:<fpage>276</fpage>–<lpage>299</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.jcp.2015.10.036" xlink:type="simple">10.1016/j.jcp.2015.10.036</ext-link></comment> <object-id pub-id-type="pmid">26705370</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref052">
<label>52</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Xia</surname> <given-names>KL</given-names></name>, <name name-style="western"><surname>Wei</surname> <given-names>GW</given-names></name>. <article-title>Multidimensional persistence in biomolecular data</article-title>. <source>Journal Computational Chemistry</source>. <year>2015</year>;<volume>36</volume>:<fpage>1502</fpage>–<lpage>1520</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/jcc.23953" xlink:type="simple">10.1002/jcc.23953</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref053">
<label>53</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Xia</surname> <given-names>KL</given-names></name>, <name name-style="western"><surname>Zhao</surname> <given-names>ZX</given-names></name>, <name name-style="western"><surname>Wei</surname> <given-names>GW</given-names></name>. <article-title>Multiresolution persistent homology for excessively large biomolecular datasets</article-title>. <source>Journal of Chemical Physics</source>. <year>2015</year>;<volume>143</volume>:<fpage>134103</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1063/1.4931733" xlink:type="simple">10.1063/1.4931733</ext-link></comment> <object-id pub-id-type="pmid">26450288</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref054">
<label>54</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Xia</surname> <given-names>KL</given-names></name>, <name name-style="western"><surname>Zhao</surname> <given-names>ZX</given-names></name>, <name name-style="western"><surname>Wei</surname> <given-names>GW</given-names></name>. <article-title>Multiresolution topological simplification</article-title>. <source>Journal Computational Biology</source>. <year>2015</year>;<volume>22</volume>:<fpage>1</fpage>–<lpage>5</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1089/cmb.2015.0104" xlink:type="simple">10.1089/cmb.2015.0104</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref055">
<label>55</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Liu</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Zhao</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Tong</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Wei</surname> <given-names>GW</given-names></name>. <article-title>ESES: software for Eulerian solvent excluded surface</article-title>. <source>Journal of Computational Chemistry</source>. <year>2017</year>;<volume>38</volume>:<fpage>446</fpage>–<lpage>466</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/jcc.24682" xlink:type="simple">10.1002/jcc.24682</ext-link></comment> <object-id pub-id-type="pmid">28052350</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref056">
<label>56</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Xia</surname> <given-names>KL</given-names></name>, <name name-style="western"><surname>Wei</surname> <given-names>GW</given-names></name>. <article-title>Persistent topology for cryo-EM data analysis</article-title>. <source>International Journal for Numerical Methods in Biomedical Engineering</source>. <year>2015</year>;<volume>31</volume>:<fpage>e02719</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/cnm.2719" xlink:type="simple">10.1002/cnm.2719</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref057">
<label>57</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Cang</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Mu</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Wu</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Opron</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Xia</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Wei</surname> <given-names>GW</given-names></name>. <article-title>A topological approach to protein classification</article-title>. <source>Molecular based Mathematical Biologys</source>. <year>2015</year>;<volume>3</volume>:<fpage>140</fpage>–<lpage>162</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005690.ref058">
<label>58</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kusano</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Fukumizu</surname> <given-names>CK</given-names></name>, <name name-style="western"><surname>Hiraoka</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>TOHOKU</surname> <given-names>A</given-names></name>. <article-title>Persistence weighted Gaussian kernel for topological data analysis</article-title>. <source>Statistics</source>. <year>2016</year>;<volume>1</volume>:<fpage>1</fpage>–<lpage>2</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005690.ref059">
<label>59</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Li</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Leung</surname> <given-names>KS</given-names></name>, <name name-style="western"><surname>Wong</surname> <given-names>MH</given-names></name>, <name name-style="western"><surname>Ballester</surname> <given-names>PJ</given-names></name>. <article-title>Improving AutoDock Vina using random forest: the growing accuracy of binding affinity prediction by the effective exploitation of larger data sets</article-title>. <source>Molecular Informatics</source>. <year>2015</year>;<volume>34</volume>(<issue>2–3</issue>):<fpage>115</fpage>–<lpage>126</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/minf.201400132" xlink:type="simple">10.1002/minf.201400132</ext-link></comment> <object-id pub-id-type="pmid">27490034</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref060">
<label>60</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Cang</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Wei</surname> <given-names>GW</given-names></name>. <article-title>Analysis and prediction of protein folding energy changes upon mutation by element specific persistent homology</article-title>. <source>Bioinformatics</source>. <year>2017</year>; Accepted. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/bioinformatics/btx460" xlink:type="simple">10.1093/bioinformatics/btx460</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref061">
<label>61</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Cang</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Wei</surname> <given-names>GW</given-names></name>. <article-title>Integration of element specific persistent homology and machine learning for protein-ligand binding affinity prediction</article-title>. <source>International Journal for Numerical Methods in Biomedical Engineering</source>. <year>2017</year>; Accepted. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/cnm.2914" xlink:type="simple">10.1002/cnm.2914</ext-link></comment> <object-id pub-id-type="pmid">28677268</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref062">
<label>62</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gilson</surname> <given-names>MK</given-names></name>, <name name-style="western"><surname>Zhou</surname> <given-names>HX</given-names></name>. <article-title>Calculation of protein-ligand binding affinities</article-title>. <source>Annual Review of Biophysics and Biomolecular Structur</source>. <year>2007</year>;<volume>36</volume>:<fpage>21</fpage>–<lpage>42</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1146/annurev.biophys.36.040306.132550" xlink:type="simple">10.1146/annurev.biophys.36.040306.132550</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref063">
<label>63</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ortiz</surname> <given-names>AR</given-names></name>, <name name-style="western"><surname>Pisabarro</surname> <given-names>MT</given-names></name>, <name name-style="western"><surname>Gago</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Wade</surname> <given-names>RC</given-names></name>. <article-title>Prediction of Drug Binding Affinities by Comparative Binding Energy Analysis</article-title>. <source>J Med Chem</source>. <year>1995</year>;<volume>38</volume>:<fpage>2681</fpage>–<lpage>2691</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1021/jm00014a020" xlink:type="simple">10.1021/jm00014a020</ext-link></comment> <object-id pub-id-type="pmid">7629807</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref064">
<label>64</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Yin</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Biedermannova</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Vondrasek</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Dokholyan</surname> <given-names>NV</given-names></name>. <article-title>MedusaScore: An Acurate Force Field-Based Scoring Function for Virtual Drug Screening</article-title>. <source>Journal of Chemical Information and Model</source>. <year>2008</year>;<volume>48</volume>:<fpage>1656</fpage>–<lpage>1662</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1021/ci8001167" xlink:type="simple">10.1021/ci8001167</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref065">
<label>65</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Zheng</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Merz</surname> <given-names>KM</given-names> <suffix>Jr</suffix></name>. <article-title>Ligand Identification Scoring Algorithm (LISA)</article-title>. <source>Journal of Chemical Information and Model</source>. <year>2011</year>;<volume>51</volume>:<fpage>1296</fpage>–<lpage>1306</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1021/ci2000665" xlink:type="simple">10.1021/ci2000665</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref066">
<label>66</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Verkhivker</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Appelt</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Freer</surname> <given-names>ST</given-names></name>, <name name-style="western"><surname>Villafranca</surname> <given-names>JE</given-names></name>. <article-title>Empirical free energy calculations of ligand-protein crystallographic complexes. I. Knowledge based ligand-protein interaction potentials applied to the prediction of human immunodeficiency virus protease binding affinity</article-title>. <source>Protein Eng</source>. <year>1995</year>;<volume>8</volume>:<fpage>677</fpage>–<lpage>691</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/protein/8.7.677" xlink:type="simple">10.1093/protein/8.7.677</ext-link></comment> <object-id pub-id-type="pmid">8577696</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref067">
<label>67</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Eldridge</surname> <given-names>MD</given-names></name>, <name name-style="western"><surname>Murray</surname> <given-names>CW</given-names></name>, <name name-style="western"><surname>Auton</surname> <given-names>TR</given-names></name>, <name name-style="western"><surname>Paolini</surname> <given-names>GV</given-names></name>, <name name-style="western"><surname>Mee</surname> <given-names>RP</given-names></name>. <article-title>Empirical scoring functions: I. The development of a fast empirical scoring function to estimate the binding affinity of ligands in receptor complexes</article-title>. <source>J Comput Aided Mol Des</source>. <year>1997</year>;<volume>11</volume>:<fpage>425</fpage>–<lpage>445</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1023/A:1007996124545" xlink:type="simple">10.1023/A:1007996124545</ext-link></comment> <object-id pub-id-type="pmid">9385547</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref068">
<label>68</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Wang</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Lai</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>S</given-names></name>. <article-title>Further development and validation of empirical scoring functions for structure based binding affinity prediction</article-title>. <source>J Comput Aided Mol Des</source>. <year>2002</year>;<volume>16</volume>:<fpage>11</fpage>–<lpage>26</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1023/A:1016357811882" xlink:type="simple">10.1023/A:1016357811882</ext-link></comment> <object-id pub-id-type="pmid">12197663</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref069">
<label>69</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Zheng</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Ucisik</surname> <given-names>MN</given-names></name>, <name name-style="western"><surname>Merz</surname> <given-names>KM</given-names> <suffix>Jr</suffix></name>. <article-title>The Movable Type Method Applied to Protein–Ligand Binding</article-title>. <source>Journal of Chemical Theory and Computation</source>. <year>2013</year>;<volume>9</volume>:<fpage>5526</fpage>–<lpage>5538</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1021/ct4005992" xlink:type="simple">10.1021/ct4005992</ext-link></comment> <object-id pub-id-type="pmid">24535920</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref070">
<label>70</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Muegge</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Martin</surname> <given-names>Y</given-names></name>. <article-title>A general and fast scoring function for protein-ligand interactions: a simplified potential approach</article-title>. <source>J Med Chem</source>. <year>1999</year>;<volume>42</volume>(<issue>5</issue>):<fpage>791</fpage>–<lpage>804</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1021/jm980536j" xlink:type="simple">10.1021/jm980536j</ext-link></comment> <object-id pub-id-type="pmid">10072678</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref071">
<label>71</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Velec</surname> <given-names>HFG</given-names></name>, <name name-style="western"><surname>Gohlke</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Klebe</surname> <given-names>G</given-names></name>. <article-title>Knowledge-Based Scoring Function Derived from Small Molecule Crystal Data with Superior Recognition Rate of Near-Native Ligand Poses and Better Affinity Prediction</article-title>. <source>J Med Chem</source>. <year>2005</year>;<volume>48</volume>:<fpage>6296</fpage>–<lpage>6303</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1021/jm050436v" xlink:type="simple">10.1021/jm050436v</ext-link></comment> <object-id pub-id-type="pmid">16190756</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref072">
<label>72</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Huang</surname> <given-names>SY</given-names></name>, <name name-style="western"><surname>Zou</surname> <given-names>X</given-names></name>. <article-title>An iterative knowledge-based scoring function to predict protein-ligand interactions: I. Derivation of interaction potentials</article-title>. <source>J Comput Chem</source>. <year>2006</year>;<volume>27</volume>:<fpage>1865</fpage>–<lpage>1875</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/jcc.20504" xlink:type="simple">10.1002/jcc.20504</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref073">
<label>73</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Li</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Leung</surname> <given-names>KS</given-names></name>, <name name-style="western"><surname>Wong</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Ballester</surname> <given-names>PJ</given-names></name>. <article-title>Substituting random forest for multiple linear regression improves binding affinity prediction of scoring functions: Cyscore as a case study</article-title>. <source>BMC Bioinformatics</source>. <year>2014</year>;<volume>15</volume>(<issue>291</issue>).</mixed-citation>
</ref>
<ref id="pcbi.1005690.ref074">
<label>74</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kinnings</surname> <given-names>SL</given-names></name>, <name name-style="western"><surname>Liu</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Tonge</surname> <given-names>PJ</given-names></name>, <name name-style="western"><surname>Jackson</surname> <given-names>RM</given-names></name>, <name name-style="western"><surname>Xie</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Bourne</surname> <given-names>PE</given-names></name>. <article-title>A machine learning based method to improve docking scoring functions and its application to drug repurposing</article-title>. <source>Journal of Chemical Information and Model</source>. <year>2011</year>;<volume>51</volume>(<issue>2</issue>):<fpage>408</fpage>–<lpage>419</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1021/ci100369f" xlink:type="simple">10.1021/ci100369f</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref075">
<label>75</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ashtawy</surname> <given-names>HM</given-names></name>, <name name-style="western"><surname>Mahapatra</surname> <given-names>NR</given-names></name>. <article-title>A Comparative Assessment of Ranking Accuracies of Conventional and Machine-Learning-Based Scoring Functions for Protein-Ligand Binding Affinity Prediction</article-title>. <source>IEEE/ACM Transactions on computational biology and bioinformatics</source>. <year>2012</year>;<volume>9</volume>(<issue>5</issue>):<fpage>1301</fpage>–<lpage>1313</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1109/TCBB.2012.36" xlink:type="simple">10.1109/TCBB.2012.36</ext-link></comment> <object-id pub-id-type="pmid">22411892</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref076">
<label>76</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>MacKerell J A</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Bashford</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Bellot</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Dunbrack J R</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Evanseck</surname> <given-names>JD</given-names></name>, <name name-style="western"><surname>Field</surname> <given-names>MJ</given-names></name>, <etal>et al</etal>. <article-title>All-Atom Empirical Potential for Molecular Modeling and Dynamics Studies of Proteins</article-title>. <source>Journal of Physical Chemistry B</source>. <year>1998</year>;<volume>102</volume>(<issue>18</issue>):<fpage>3586</fpage>–<lpage>3616</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1021/jp973084f" xlink:type="simple">10.1021/jp973084f</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref077">
<label>77</label>
<mixed-citation publication-type="other" xlink:type="simple">Case DA, Berryman JT, Betz RM, Cerutti DS, III TEC, Darden TA, et al. AMBER 2015. University of California, San Francisco. 2015;.</mixed-citation>
</ref>
<ref id="pcbi.1005690.ref078">
<label>78</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Liu</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Li</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Han</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Liu</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Zhao</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Nie</surname> <given-names>W</given-names></name>, <etal>et al</etal>. <article-title>PDB-wide collection of binding data: current status of the PDBbind database</article-title>. <source>Bioinformatics</source>. <year>2015</year>;<volume>31</volume>(<issue>3</issue>):<fpage>405</fpage>–<lpage>412</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/bioinformatics/btu626" xlink:type="simple">10.1093/bioinformatics/btu626</ext-link></comment> <object-id pub-id-type="pmid">25301850</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref079">
<label>79</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Zhang</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Miteva</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Alexov</surname> <given-names>E</given-names></name>. <article-title>Analyzing effects of naturally occurring missense mutations</article-title>. <source>Comput Math Methods Med</source>. <year>2012</year>;<volume>2012</volume>:<fpage>805827</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1155/2012/805827" xlink:type="simple">10.1155/2012/805827</ext-link></comment> <object-id pub-id-type="pmid">22577471</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref080">
<label>80</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kucukkal</surname> <given-names>TG</given-names></name>, <name name-style="western"><surname>Petukh</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Li</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Alexov</surname> <given-names>E</given-names></name>. <article-title>Structural and physico-chemical effects of disease and non-disease nsSNPs on proteins</article-title>. <source>Curr Opin Struct Biol</source>. <year>2015</year>;<volume>32</volume>:<fpage>18</fpage>–<lpage>24</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.sbi.2015.01.003" xlink:type="simple">10.1016/j.sbi.2015.01.003</ext-link></comment> <object-id pub-id-type="pmid">25658850</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref081">
<label>81</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Puente</surname> <given-names>XS</given-names></name>, <name name-style="western"><surname>Sanchez</surname> <given-names>LM</given-names></name>, <name name-style="western"><surname>Overall</surname> <given-names>CM</given-names></name>, <name name-style="western"><surname>Lopez-Otin</surname> <given-names>C</given-names></name>. <article-title>Human and mouse proteases: a comparative genomic approach</article-title>. <source>Nat Rev Genet</source>. <year>2003</year>;<volume>4</volume>:<fpage>544</fpage>–<lpage>558</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nrg1111" xlink:type="simple">10.1038/nrg1111</ext-link></comment> <object-id pub-id-type="pmid">12838346</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref082">
<label>82</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Martinez</surname> <given-names>JL</given-names></name>, <name name-style="western"><surname>Baquero</surname> <given-names>F</given-names></name>. <article-title>Mutation Frequencies and Antibiotic Resistance</article-title>. <source>Antimicrobial Agents and Chemotherapy</source>. <year>2000</year>;<volume>44</volume>:<fpage>1771</fpage>–<lpage>1777</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1128/AAC.44.7.1771-1777.2000" xlink:type="simple">10.1128/AAC.44.7.1771-1777.2000</ext-link></comment> <object-id pub-id-type="pmid">10858329</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref083">
<label>83</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Fersht</surname> <given-names>AR</given-names></name>. <article-title>Dissection of the structure and activity of the tyrosyl-tRNA synthetase by site-directed mutagenesis</article-title>. <source>Biochemistry</source>. <year>1978</year>;<volume>26</volume>:<fpage>8031</fpage>–<lpage>8037</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1021/bi00399a001" xlink:type="simple">10.1021/bi00399a001</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref084">
<label>84</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Guerois</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Nielsen</surname> <given-names>JE</given-names></name>, <name name-style="western"><surname>Serrano</surname> <given-names>L</given-names></name>. <article-title>Predicting Changes in the Stability of Proteins and Protein Complexes: A Study of More Than 1000 Mutations</article-title>. <source>J Mol Biol</source>. <year>2002</year>;<volume>320</volume>:<fpage>369</fpage>–<lpage>387</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0022-2836(02)00442-4" xlink:type="simple">10.1016/S0022-2836(02)00442-4</ext-link></comment> <object-id pub-id-type="pmid">12079393</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref085">
<label>85</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Capriotti</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Fariselli</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Casadio</surname> <given-names>R</given-names></name>. <article-title>I-Mutant2.0: predicting stability changes upon mutation from the protein sequence or structure</article-title>. <source>Nucleic Acids Research</source>. <year>2005</year>;<volume>33</volume>:<fpage>W306</fpage>–<lpage>W310</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/nar/gki375" xlink:type="simple">10.1093/nar/gki375</ext-link></comment> <object-id pub-id-type="pmid">15980478</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref086">
<label>86</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Dehouck</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Grosfils</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Folch</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Gilis</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Bogaerts</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Rooman</surname> <given-names>M</given-names></name>. <article-title>Fast and accurate predictions of protein stability changes upon mutations using statistical potentials and neural networks: PoPMuSiC-2.0</article-title>. <source>Bioinformatics</source>. <year>2009</year>;<volume>25</volume>:<fpage>2537</fpage>–<lpage>2543</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/bioinformatics/btp445" xlink:type="simple">10.1093/bioinformatics/btp445</ext-link></comment> <object-id pub-id-type="pmid">19654118</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref087">
<label>87</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Getov</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Petukh</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Alexov</surname> <given-names>E</given-names></name>. <article-title>SAAFEC: Predicting the Effect of Single Point Mutations on Protein Folding Free Energy Using a Knowledge-Modified MM/PBSA Approach</article-title>. <source>International Journal of Molecular Sciences</source>. <year>2016</year>;<volume>17</volume>:<fpage>512</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3390/ijms17040512" xlink:type="simple">10.3390/ijms17040512</ext-link></comment> <object-id pub-id-type="pmid">27070572</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref088">
<label>88</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kellogg</surname> <given-names>EH</given-names></name>, <name name-style="western"><surname>Leaver-Fay</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Baker</surname> <given-names>D</given-names></name>. <article-title>Role of conformational sampling in computing mutation-induced changes in protein structure and stability</article-title>. <source>Proteins: Struct, Funct, Genet</source>. <year>2011</year>;<volume>79</volume>:<fpage>830</fpage>–<lpage>838</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/prot.22921" xlink:type="simple">10.1002/prot.22921</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref089">
<label>89</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Worth</surname> <given-names>CL</given-names></name>, <name name-style="western"><surname>Preissner</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Blundell</surname> <given-names>TL</given-names></name>. <article-title>SDM-a server for predicting effects of mutations on protein stability and malfunction</article-title>. <source>Nucleic Acids Res</source>. <year>2011</year>;<volume>39</volume>:<fpage>W215</fpage>–<lpage>W222</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/nar/gkr363" xlink:type="simple">10.1093/nar/gkr363</ext-link></comment> <object-id pub-id-type="pmid">21593128</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref090">
<label>90</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Pires</surname> <given-names>DEV</given-names></name>, <name name-style="western"><surname>Ascher</surname> <given-names>DB</given-names></name>, <name name-style="western"><surname>Blundell</surname> <given-names>TL</given-names></name>. <article-title>DUET: a server for predicting effects of mutations on protein stability using an integrated computational approach</article-title>. <source>Nucleic Acids Res</source>. <year>2014</year>;<volume>42</volume>:<fpage>W314</fpage>–<lpage>W319</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/nar/gku411" xlink:type="simple">10.1093/nar/gku411</ext-link></comment> <object-id pub-id-type="pmid">24829462</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref091">
<label>91</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Yang</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Chen</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Tan</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Vihinen</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Shen</surname> <given-names>B</given-names></name>. <article-title>Structure-based prediction of the effects of a missense variant on protein stability</article-title>. <source>Amino Acids</source>. <year>2013</year>;<volume>44</volume>:<fpage>847</fpage>–<lpage>855</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s00726-012-1407-7" xlink:type="simple">10.1007/s00726-012-1407-7</ext-link></comment> <object-id pub-id-type="pmid">23064876</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref092">
<label>92</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Choi</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Sims</surname> <given-names>GE</given-names></name>, <name name-style="western"><surname>Murphy</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Miller</surname> <given-names>JR</given-names></name>, <name name-style="western"><surname>Chan</surname> <given-names>AP</given-names></name>. <article-title>Predicting the functional effect of amino acid substitutions and indels</article-title>. <source>PLoS One</source>. <year>2014</year>;<volume>7</volume>:<fpage>e46688</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0046688" xlink:type="simple">10.1371/journal.pone.0046688</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref093">
<label>93</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Berliner</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Teyra</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Colak</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Garcia Lopez</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Kim</surname> <given-names>PM</given-names></name>. <article-title>Combining structural modeling with ensemble machine learning to accurately predict protein fold stability and binding affinity effects upon mutation</article-title>. <source>PLoS One</source>. <year>2014</year>;<volume>9</volume>:<fpage>e107353</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0107353" xlink:type="simple">10.1371/journal.pone.0107353</ext-link></comment> <object-id pub-id-type="pmid">25243403</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref094">
<label>94</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Quan</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Lv</surname> <given-names>Q</given-names></name>, <name name-style="western"><surname>Zhang</surname> <given-names>Y</given-names></name>. <article-title>STRUM: structure-based prediction of protein stability changes upon single-point mutation</article-title>. <source>Bioinformatics</source>. <year>2016</year>;<volume>32</volume>(<issue>19</issue>):<fpage>2936</fpage>–<lpage>2946</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/bioinformatics/btw361" xlink:type="simple">10.1093/bioinformatics/btw361</ext-link></comment> <object-id pub-id-type="pmid">27318206</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref095">
<label>95</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Folkman</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Stantic</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Sattar</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Zhou</surname> <given-names>Y</given-names></name>. <article-title>EASEMM: Sequence-Based Prediction of Mutation-Induced Stability Changes with Feature-Based Multiple Models</article-title>. <source>J Mol Biol</source>. <year>2016</year>;<volume>428</volume>:<fpage>1394</fpage>–<lpage>1405</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.jmb.2016.01.012" xlink:type="simple">10.1016/j.jmb.2016.01.012</ext-link></comment> <object-id pub-id-type="pmid">26804571</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref096">
<label>96</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bava</surname> <given-names>KA</given-names></name>, <name name-style="western"><surname>Gromiha</surname> <given-names>MM</given-names></name>, <name name-style="western"><surname>Uedaira</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Kitajima</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Sarai</surname> <given-names>A</given-names></name>. <article-title>ProTherm, version 4.0: thermodynamic database for proteins and mutants</article-title>. <source>Nucleic acids research</source>. <year>2004</year>;<volume>32</volume>(<issue>suppl 1</issue>):<fpage>D120</fpage>–<lpage>D121</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/nar/gkh082" xlink:type="simple">10.1093/nar/gkh082</ext-link></comment> <object-id pub-id-type="pmid">14681373</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref097">
<label>97</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Zhou</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Chen</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Ye</surname> <given-names>J</given-names></name>. <source>Malsar: Multi-task learning via structural regularization</source>. <publisher-name>Arizona State University</publisher-name>. <year>2011</year>;.</mixed-citation>
</ref>
<ref id="pcbi.1005690.ref098">
<label>98</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kroncke</surname> <given-names>BM</given-names></name>, <name name-style="western"><surname>Duran</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Mendenhall</surname> <given-names>JL</given-names></name>, <name name-style="western"><surname>Meiler</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Blume</surname> <given-names>JD</given-names></name>, <name name-style="western"><surname>Sanders</surname> <given-names>CR</given-names></name>. <article-title>Documentation of an Imperative To Improve Methods for Predicting Membrane Protein Stability</article-title>. <source>Biochemistry</source>. <year>2016</year>;<volume>55</volume>:<fpage>5002</fpage>–<lpage>5009</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1021/acs.biochem.6b00537" xlink:type="simple">10.1021/acs.biochem.6b00537</ext-link></comment> <object-id pub-id-type="pmid">27564391</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005690.ref099">
<label>99</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Jeffrey</surname> <given-names>GA</given-names></name>, <name name-style="western"><surname>Jeffrey</surname> <given-names>GA</given-names></name>. <source>An introduction to hydrogen bonding</source>. <volume>vol. 12</volume>. <publisher-name>Oxford university press</publisher-name> <publisher-loc>New York</publisher-loc>; <year>1997</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005690.ref100">
<label>100</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Srivastava</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Hinton</surname> <given-names>GE</given-names></name>, <name name-style="western"><surname>Krizhevsky</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Sutskever</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Salakhutdinov</surname> <given-names>R</given-names></name>. <article-title>Dropout: a simple way to prevent neural networks from overfitting</article-title>. <source>Journal of Machine Learning Research</source>. <year>2014</year>;<volume>15</volume>(<issue>1</issue>):<fpage>1929</fpage>–<lpage>1958</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005690.ref101">
<label>101</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bergstra</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Yamins</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Cox</surname> <given-names>DD</given-names></name>. <article-title>Making a Science of Model Search: Hyperparameter Optimization in Hundreds of Dimensions for Vision Architectures</article-title>. <source>ICML (1)</source>. <year>2013</year>;<volume>28</volume>:<fpage>115</fpage>–<lpage>123</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005690.ref102">
<label>102</label>
<mixed-citation publication-type="other" xlink:type="simple">Morozov D. Dionysus library for computing persistent homology; 2012.</mixed-citation>
</ref>
<ref id="pcbi.1005690.ref103">
<label>103</label>
<mixed-citation publication-type="other" xlink:type="simple">Damiand G. Combinatorial Maps. In: CGAL User and Reference Manual. 4.0 ed. CGAL Editorial Board; 2012.</mixed-citation>
</ref>
<ref id="pcbi.1005690.ref104">
<label>104</label>
<mixed-citation publication-type="other" xlink:type="simple">Tausz A, Vejdemo-Johansson M, Adams H. JavaPlex: A research software package for persistent (co)homology. In: Hong H, Yap C, editors. Proceedings of ICMS 2014. Lecture Notes in Computer Science 8592; 2014. p. 129–136.</mixed-citation>
</ref>
<ref id="pcbi.1005690.ref105">
<label>105</label>
<mixed-citation publication-type="other" xlink:type="simple">Chollet F. Keras; 2015. <ext-link ext-link-type="uri" xlink:href="https://github.com/fchollet/keras" xlink:type="simple">https://github.com/fchollet/keras</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1005690.ref106">
<label>106</label>
<mixed-citation publication-type="other" xlink:type="simple">Theano Development Team. Theano: A Python framework for fast computation of mathematical expressions. arXiv e-prints. 2016;abs/1605.02688.</mixed-citation>
</ref>
<ref id="pcbi.1005690.ref107">
<label>107</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Walt</surname> <given-names>Svd</given-names></name>, <name name-style="western"><surname>Colbert</surname> <given-names>SC</given-names></name>, <name name-style="western"><surname>Varoquaux</surname> <given-names>G</given-names></name>. <article-title>The NumPy array: a structure for efficient numerical computation</article-title>. <source>Computing in Science &amp; Engineering</source>. <year>2011</year>;<volume>13</volume>(<issue>2</issue>):<fpage>22</fpage>–<lpage>30</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1109/MCSE.2011.37" xlink:type="simple">10.1109/MCSE.2011.37</ext-link></comment></mixed-citation>
</ref>
</ref-list>
</back>
</article>
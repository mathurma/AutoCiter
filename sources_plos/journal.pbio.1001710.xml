<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="nlm-ta">PLoS Biol</journal-id>
<journal-id journal-id-type="pmc">plosbiol</journal-id><journal-title-group>
<journal-title>PLoS Biology</journal-title></journal-title-group>
<issn pub-type="ppub">1544-9173</issn>
<issn pub-type="epub">1545-7885</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PBIOLOGY-D-13-00972</article-id>
<article-id pub-id-type="doi">10.1371/journal.pbio.1001710</article-id>
<article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group></article-categories>
<title-group>
<article-title>Constructing Noise-Invariant Representations of Sound in the Auditory Pathway</article-title>
<alt-title alt-title-type="running-head">Noise-Invariant Sound Representations</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Rabinowitz</surname><given-names>Neil C.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Willmore</surname><given-names>Ben D. B.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>King</surname><given-names>Andrew J.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Schnupp</surname><given-names>Jan W. H.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
</contrib-group>
<aff id="aff1"><label>1</label><addr-line>Department of Physiology, Anatomy and Genetics, University of Oxford, Oxford, United Kingdom</addr-line></aff>
<aff id="aff2"><label>2</label><addr-line>Center for Neural Science, New York University, New York, New York, United States of America</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Zador</surname><given-names>Anthony M.</given-names></name>
<role>Academic Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group>
<aff id="edit1"><addr-line>Cold Spring Harbor Laboratory, United States of America</addr-line></aff>
<author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">neil@cns.nyu.edu</email> (N.C.R.); <email xlink:type="simple">jan.schnupp@dpag.ox.ac.uk</email> (J.W.H.S.)</corresp>
<fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn>
<fn fn-type="con"><p>The author(s) have made the following declarations about their contributions: Conceived and designed the experiments: NCR BDBW AJK JWHS. Performed the experiments: NCR BDBW. Analyzed the data: NCR BDBW. Wrote the paper: NCR BDBW AJK JWHS.</p></fn>
</author-notes>
<pub-date pub-type="collection"><month>11</month><year>2013</year></pub-date>
<pub-date pub-type="epub"><day>12</day><month>11</month><year>2013</year></pub-date>
<volume>11</volume>
<issue>11</issue>
<elocation-id>e1001710</elocation-id>
<history>
<date date-type="received"><day>12</day><month>3</month><year>2013</year></date>
<date date-type="accepted"><day>4</day><month>10</month><year>2013</year></date>
</history>
<permissions>
<copyright-year>2013</copyright-year>
<copyright-holder>Rabinowitz et al</copyright-holder><license xlink:type="simple"><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions>
<abstract abstract-type="toc"><sec>
<title/>
<p>Along the auditory pathway from auditory nerve to midbrain to cortex, individual neurons adapt progressively to sound statistics, enabling the discernment of foreground sounds, such as speech, over background noise.</p>
</sec></abstract>
<abstract>
<p>Identifying behaviorally relevant sounds in the presence of background noise is one of the most important and poorly understood challenges faced by the auditory system. An elegant solution to this problem would be for the auditory system to represent sounds in a noise-invariant fashion. Since a major effect of background noise is to alter the statistics of the sounds reaching the ear, noise-invariant representations could be promoted by neurons adapting to stimulus statistics. Here we investigated the extent of neuronal adaptation to the mean and contrast of auditory stimulation as one ascends the auditory pathway. We measured these forms of adaptation by presenting complex synthetic and natural sounds, recording neuronal responses in the inferior colliculus and primary fields of the auditory cortex of anaesthetized ferrets, and comparing these responses with a sophisticated model of the auditory nerve. We find that the strength of both forms of adaptation increases as one ascends the auditory pathway. To investigate whether this adaptation to stimulus statistics contributes to the construction of noise-invariant sound representations, we also presented complex, natural sounds embedded in stationary noise, and used a decoding approach to assess the noise tolerance of the neuronal population code. We find that the code for complex sounds in the periphery is affected more by the addition of noise than the cortical code. We also find that noise tolerance is correlated with adaptation to stimulus statistics, so that populations that show the strongest adaptation to stimulus statistics are also the most noise-tolerant. This suggests that the increase in adaptation to sound statistics from auditory nerve to midbrain to cortex is an important stage in the construction of noise-invariant sound representations in the higher auditory brain.</p>
</abstract>
<abstract abstract-type="summary"><title>Author Summary</title>
<p>We rarely hear sounds (such as someone talking) in isolation, but rather against a background of noise. When mixtures of sounds and background noise reach the ears, peripheral auditory neurons represent the whole sound mixture. Previous evidence suggests, however, that the higher auditory brain represents just the sounds of interest, and is less affected by the presence of background noise. The neural mechanisms underlying this transformation are poorly understood. Here, we investigate these mechanisms by studying the representation of sound by populations of neurons at three stages along the auditory pathway; we simulate the auditory nerve and record from neurons in the midbrain and primary auditory cortex of anesthetized ferrets. We find that the transformation from noise-sensitive representations of sound to noise-tolerant processing takes place gradually along the pathway from auditory nerve to midbrain to cortex. Our results suggest that this results from neurons adapting to the statistics of heard sounds.</p>
</abstract>
<funding-group><funding-statement>The Wellcome Trust (Wellcome Principal Research Fellowship to AJK; WT076508AIA) <ext-link ext-link-type="uri" xlink:href="http://www.wellcome.ac.uk/" xlink:type="simple">http://www.wellcome.ac.uk/</ext-link>. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="18"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>Because our auditory world usually contains many competing sources, behaviorally important sounds are often obscured by background noise. To accurately recognize these sounds, the auditory brain must therefore represent them in a way that is robust to noise. Previous work has suggested that the auditory system does build such sound representations. In the auditory periphery, sounds are represented in terms of their physical structure, including any noise <xref ref-type="bibr" rid="pbio.1001710-Joris1">[1]</xref>–<xref ref-type="bibr" rid="pbio.1001710-Schreiner1">[3]</xref>, while data from human imaging studies suggest that, in higher areas of auditory cortex (AC), relevant sounds are represented in a more context-independent, categorical manner <xref ref-type="bibr" rid="pbio.1001710-Formisano1">[4]</xref>–<xref ref-type="bibr" rid="pbio.1001710-Ding2">[8]</xref>. However, we know very little about the neural computations that might generate noise invariance or where exactly along the auditory pathway this is achieved.</p>
<p>We do, on the other hand, know that the firing patterns of individual auditory neurons change with acoustic context. Numerous experiments have varied the statistics of sound stimulation, such as sounds' overall intensity, modulation depth, or contrast, or the presence of background noise. In response to these manipulations, auditory neurons from the periphery to primary cortex have been observed to change their gain <xref ref-type="bibr" rid="pbio.1001710-Nagel1">[9]</xref>–<xref ref-type="bibr" rid="pbio.1001710-Rabinowitz2">[12]</xref>, temporal receptive field shape (i.e., modulation transfer function, MTF) <xref ref-type="bibr" rid="pbio.1001710-Nagel1">[9]</xref>,<xref ref-type="bibr" rid="pbio.1001710-Sharpee1">[11]</xref>,<xref ref-type="bibr" rid="pbio.1001710-Rees1">[13]</xref>–<xref ref-type="bibr" rid="pbio.1001710-Lesica1">[17]</xref>, spectral receptive field shape <xref ref-type="bibr" rid="pbio.1001710-Blake1">[18]</xref>,<xref ref-type="bibr" rid="pbio.1001710-Valentine1">[19]</xref>, and output nonlinearities <xref ref-type="bibr" rid="pbio.1001710-Dean1">[20]</xref>,<xref ref-type="bibr" rid="pbio.1001710-Watkins1">[21]</xref>, or they undergo more complex changes in response patterns <xref ref-type="bibr" rid="pbio.1001710-BarYosef1">[22]</xref>,<xref ref-type="bibr" rid="pbio.1001710-BarYosef2">[23]</xref>. These changes have been explored or explained in terms of signal detection theory <xref ref-type="bibr" rid="pbio.1001710-Sharpee1">[11]</xref>, efficient coding <xref ref-type="bibr" rid="pbio.1001710-Lesica1">[17]</xref>,<xref ref-type="bibr" rid="pbio.1001710-Dean1">[20]</xref>,<xref ref-type="bibr" rid="pbio.1001710-Escab1">[24]</xref>, or maintaining sensitivity to ecologically relevant stimuli <xref ref-type="bibr" rid="pbio.1001710-Watkins1">[21]</xref>,<xref ref-type="bibr" rid="pbio.1001710-BarYosef2">[23]</xref>. Such forms of adaptation—not to the repetition of a fixed stimulus, but to the statistics of ongoing stimulation—offer a plausible neural mechanism for the construction of noise-invariant representations. A population of neurons that adapts to the constant statistics of a background noise could become desensitized to that noise, while still accurately representing simultaneously presented, modulated foreground sounds.</p>
<p>Here, we investigated whether adaptation to stimulus statistics in the auditory system enables the brain to build noise-invariant representations of sounds. To do this, we carried out three experiments. First, we measured neural responses to complex sounds embedded in stationary noise, by recording from single units and small multi-unit clusters in the auditory midbrain and cortex and by simulating responses in the auditory periphery. We find that as one progresses through the auditory pathway, neural responses become progressively more independent of the level of background noise. Second, we measured how the coding of individual neurons in these auditory centers is affected by the changes in stimulus statistics induced by adding background noise. We find that there is a progressive increase through the auditory pathway in the strength of adaptation to the altered stimulus statistics. Third, we considered how the noise-dependent responses of individual units combine to produce population codes. Population representations are usually addressed only indirectly, for example, by summing up results from individual units (though see <xref ref-type="bibr" rid="pbio.1001710-Shetake1">[25]</xref>,<xref ref-type="bibr" rid="pbio.1001710-Mesgarani1">[26]</xref>), but here we investigated these directly, by asking how well the original, “clean” sounds could be decoded from the population responses to noise-tainted stimuli. We find a progressive increase in the noise tolerance of population representations of sound. Moreover, neuron-level changes in the strength of adaptation and population-level changes in the noise tolerance of decoding are well correlated both within and across auditory centers. This suggests that adaptation to stimulus statistics may indeed be a neural mechanism that drives the construction of noise-tolerant representations of sound.</p>
</sec><sec id="s2">
<title>Results</title>
<p>We recorded neural responses in the central nucleus of the inferior colliculus (IC) and the primary fields of the AC in ferrets, while presenting a set of natural sounds in high and low signal-to-noise ratio (SNR) conditions (referred to as “clean” and “noisy” below). We compared these recorded neural responses against a sophisticated model of sound representation in the auditory nerve (AN) <xref ref-type="bibr" rid="pbio.1001710-Zilany1">[27]</xref>. The simulated auditory nerve (sAN) model captures the functional components of the auditory periphery from the middle ear to the AN, including the adaptation that occurs at synapses between inner hair cells and AN fibers.</p>
<p>We presented four audio segments (two speech, two environmental), to which spectrally matched noise had been added. In the “clean” condition, the SNR was 20 dB; in the “noisy” conditions, SNRs were 10 dB, 0 dB, or −10 dB (<xref ref-type="fig" rid="pbio-1001710-g001">Figure 1</xref>). Fifty different noise tokens were used, so that responses reflected the average properties of the noise. We refer to the sounds in the clean condition as being the signal, and the sounds in the noisy conditions as being the signal plus noise. The noise we used was stationary—that is, its statistics did not change over time; it also had a flat modulation spectrum and no cross-band correlation. Such noises are exemplified by the sounds of rain, vacuum cleaners, jet engines, and radio static <xref ref-type="bibr" rid="pbio.1001710-Lesica1">[17]</xref>,<xref ref-type="bibr" rid="pbio.1001710-McDermott1">[28]</xref>. We used this subclass of noise as such sounds are almost always ecologically irrelevant, and their statistics differ from those of relevant signals; the signal/noise distinction was therefore as unambiguous as possible. Very little sound signal was detectable to our ears in the noisiest condition, which lies close to the threshold of human and animal speech recognition abilities during active listening <xref ref-type="bibr" rid="pbio.1001710-Shetake1">[25]</xref>,<xref ref-type="bibr" rid="pbio.1001710-Miller1">[29]</xref>–<xref ref-type="bibr" rid="pbio.1001710-Phatak1">[31]</xref>.</p>
<fig id="pbio-1001710-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pbio.1001710.g001</object-id><label>Figure 1</label><caption>
<title>Single unit responses to clean and noisy sounds.</title>
<p>Left column, the spectrogram of a segment of speech under four noise conditions, with the noise level increasing (i.e., the SNR decreasing) from top to bottom. Second to fourth columns, example rasters showing the responses of sAN responses and of responses recorded in the IC and AC, over 50 stimulus presentations. Gray lines, average PSTH.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1001710.g001" position="float" xlink:type="simple"/></fig>
<p>For each auditory center (sAN, IC, AC), we measured how the neural coding of sounds changed as background noise was introduced. We found that, as we progressed from sAN to IC to AC, the distribution of neural responses became progressively more tolerant (i.e., less sensitive) to the level of background noise. This was evident at the gross level, as the distribution of sAN firing rates for each unit, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e001" xlink:type="simple"/></inline-formula>, changed considerably as a function of the background noise level, while IC firing rates changed less, and AC even less so (<xref ref-type="fig" rid="pbio-1001710-g002">Figure 2A–B</xref>). More notably, when we conditioned these response distributions on each 5 ms stimulus time bin, the response distributions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e002" xlink:type="simple"/></inline-formula> became more statistically independent of the background noise level from sAN to IC to AC (<xref ref-type="fig" rid="pbio-1001710-g002">Figure 2C</xref>). This demonstrates that neural responses to complex sounds become less sensitive to background noise level as one ascends the auditory pathway.</p>
<fig id="pbio-1001710-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pbio.1001710.g002</object-id><label>Figure 2</label><caption>
<title>Along the auditory pathway, neurons' response distributions become increasingly independent of the level of background noise.</title>
<p>(A) Average distribution of normalized firing rates by location/SNR. For each unit, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e003" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e004" xlink:type="simple"/></inline-formula> is the firing rate. This shows that the average response distribution within the population changes less with noise in higher auditory centers. (B) Kullback–Leibler divergence between individual units' normalized firing-rate distributions evoked from clean sounds and evoked from noisy sounds. Smaller values indicate that firing rate distributions were similar. This shows that individual neurons' response distributions change less with noise in higher auditory centers. (C) Statistical independence of stimulus-conditioned response distributions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e005" xlink:type="simple"/></inline-formula> to the background noise level (see <xref ref-type="sec" rid="s4">Materials and Methods</xref> for details of metric). Lower values indicate that response distributions were highly dependent on the stimulus SNR; a value of 1 indicates that response distributions were completely independent of the stimulus SNR. Median values of 0.80/0.84/0.88 for sAN/IC/AC (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e006" xlink:type="simple"/></inline-formula>, pairwise rank-sums tests).</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1001710.g002" position="float" xlink:type="simple"/></fig><sec id="s2a">
<title>Adaptive Coding</title>
<p>What underlies this shift in coding, such that the responses of neurons in higher auditory centers are overall more tolerant to noise? To understand this, we considered three ways in which noise affects signals within auditory neurons' receptive fields (<xref ref-type="fig" rid="pbio-1001710-g003">Figure 3A</xref>).</p>
<fig id="pbio-1001710-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pbio.1001710.g003</object-id><label>Figure 3</label><caption>
<title>Effect of background noise on incoming signals within neurons' receptive fields.</title>
<p>(A) Left, sound intensity within a cortical neuron's receptive field for clean (20 dB) and noisy (0 dB) stimulation (see <xref ref-type="supplementary-material" rid="pbio.1001710.s001">Figure S1B</xref>). Right, distribution of the sounds' within-channel intensities. (B) Signals in (A) after adaptation to signal statistics.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1001710.g003" position="float" xlink:type="simple"/></fig>
<p>First, noise is an energy mask: when components of the original signal have intensities (within the receptive field) lower than that of the noise, they are obscured. Second, although the statistics of noise might not change over time, the noise itself is a time-varying stimulus, and auditory neurons may respond to noise transients <xref ref-type="bibr" rid="pbio.1001710-Woolley1">[32]</xref>,<xref ref-type="bibr" rid="pbio.1001710-Louage1">[33]</xref>. Because neurons in higher auditory centers progressively filter out faster temporal modulations <xref ref-type="bibr" rid="pbio.1001710-Joris1">[1]</xref>, the energy of noise transients within neurons' linear receptive fields decreases from AN to IC to AC. However, simulations demonstrate that this alone cannot account for the observed differences in noise independence (<xref ref-type="supplementary-material" rid="pbio.1001710.s001">Figure S1</xref>).</p>
<p>Finally, adding noise affects the statistics of the stimulus within the receptive field in two ways: it increases the baseline intensity, and it reduces the effective size of the peaks in intensity above the baseline—that is, it lowers the contrast. These effects can be roughly summarized as changing the mean (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e007" xlink:type="simple"/></inline-formula>) and standard deviation (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e008" xlink:type="simple"/></inline-formula>) of the stimulus intensity distribution (which is, incidentally, non-Gaussian <xref ref-type="bibr" rid="pbio.1001710-Escab1">[24]</xref>,<xref ref-type="bibr" rid="pbio.1001710-Attias1">[34]</xref>,<xref ref-type="bibr" rid="pbio.1001710-Singh1">[35]</xref>).</p>
<p>If auditory neurons faithfully encoded stimuli within their receptive fields—irrespective of the stimulus statistics—then the response distributions would change their <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e009" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e010" xlink:type="simple"/></inline-formula> along with the stimulus distribution. However, if neurons adapted to the statistics—for example, by normalizing their responses relative to the local <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e011" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e012" xlink:type="simple"/></inline-formula>—then the response distributions would change less with the addition of noise (<xref ref-type="fig" rid="pbio-1001710-g003">Figure 3B</xref>). Indeed, as shown above, the response distributions of sAN units changed considerably when noise was introduced, while those of IC units changed less, and cortex even less so. The increased noise tolerance in higher auditory centers may therefore result from a progressive increase in the strength of adaptation to stimulus statistics along the auditory pathway.</p>
</sec><sec id="s2b">
<title><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e013" xlink:type="simple"/></inline-formula>- and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e014" xlink:type="simple"/></inline-formula>-Adaptation Grow Stronger Along the Auditory Pathway</title>
<p>Given our reasoning above, we predicted that neuronal adaptation to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e015" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e016" xlink:type="simple"/></inline-formula> would increase along the auditory pathway. Previous experiments have shown that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e017" xlink:type="simple"/></inline-formula>-adaptation increases from AN to IC <xref ref-type="bibr" rid="pbio.1001710-Dean1">[20]</xref>,<xref ref-type="bibr" rid="pbio.1001710-Wen1">[36]</xref> and that there is strong <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e018" xlink:type="simple"/></inline-formula>-adaptation in AC <xref ref-type="bibr" rid="pbio.1001710-Rabinowitz1">[10]</xref>,<xref ref-type="bibr" rid="pbio.1001710-Rabinowitz2">[12]</xref>; however, the overall changes in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e019" xlink:type="simple"/></inline-formula>- and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e020" xlink:type="simple"/></inline-formula>-adaptation across the auditory pathway are unknown.</p>
<p>We first tested the hypothesis that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e021" xlink:type="simple"/></inline-formula>-adaptation increases along the auditory pathway. Taking the neural responses to natural sounds, we quantified the degree to which introducing background noise changed the neural responses during the “baseline” periods of sound stimulation, such as when there was little stimulus energy within neurons' receptive fields to drive spiking. Rather than attempt to estimate neurons' receptive fields, we instead measured the relevant responses operationally. We defined a reference firing rate for each unit, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e022" xlink:type="simple"/></inline-formula>, at the 33rd percentile of that unit's firing rate distribution during clean sound stimulation. We then calculated how often the firing rate exceeded <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e023" xlink:type="simple"/></inline-formula> under different noise conditions (<xref ref-type="fig" rid="pbio-1001710-g004">Figure 4A</xref>). The motivation for this measure is that, when <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e024" xlink:type="simple"/></inline-formula>-adaptation is weak, responses are sensitive to the baseline intensity of the stimulus, so adding noise should drive this value up. If <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e025" xlink:type="simple"/></inline-formula>-adaptation is strong, such that the neuron adapts out the increased baseline intensity of the stimulus, then the firing rate should exceed <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e026" xlink:type="simple"/></inline-formula> about as often in the noisy conditions as in the clean condition. We refer to these two possibilities as being of low, or high, baseline invariance (BI), respectively.</p>
<fig id="pbio-1001710-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pbio.1001710.g004</object-id><label>Figure 4</label><caption>
<title>Increasing adaptation to stimulus baseline along the auditory pathway.</title>
<p>(A) Calculation of BI, a measure of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e027" xlink:type="simple"/></inline-formula>-adaptation, for an example sAN fiber. CDF, cumulative distribution of firing rates. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e028" xlink:type="simple"/></inline-formula>, the 33rd percentile of the CDF under clean sound stimulation —that is, the firing rate with the cumulative probability <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e029" xlink:type="simple"/></inline-formula>. BI indicates how little <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e030" xlink:type="simple"/></inline-formula> changes with SNR, as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e031" xlink:type="simple"/></inline-formula>. (B) Units' BI in each location.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1001710.g004" position="float" xlink:type="simple"/></fig>
<p>Introducing noise caused sAN fibers to change their firing relative to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e032" xlink:type="simple"/></inline-formula> the most, and AC units the least (<xref ref-type="fig" rid="pbio-1001710-g004">Figure 4B</xref>; median BI of 87/96/98% for sAN/IC/AC; <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e033" xlink:type="simple"/></inline-formula>). Similar results were obtained with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e034" xlink:type="simple"/></inline-formula> placed at other percentiles between 10% and 50%. This confirms that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e035" xlink:type="simple"/></inline-formula>-adaptation increases along the auditory pathway.</p>
<p>We next tested the hypothesis that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e036" xlink:type="simple"/></inline-formula>-adaptation increases along the auditory pathway, by comparing how changes in contrast affect the gain of neurons at each location <xref ref-type="bibr" rid="pbio.1001710-Rabinowitz1">[10]</xref>,<xref ref-type="bibr" rid="pbio.1001710-Rabinowitz2">[12]</xref>. We analyzed units' responses to dynamic random chord (DRC) sequences of differing contrasts (<xref ref-type="fig" rid="pbio-1001710-g005">Figure 5A</xref>). DRCs comprise a sequence of chords, composed of tones whose levels are drawn from particular distributions. This allows efficient estimation of the spectrotemporal receptive fields (STRFs) of auditory neurons <xref ref-type="bibr" rid="pbio.1001710-deCharms1">[37]</xref>–<xref ref-type="bibr" rid="pbio.1001710-Ahrens1">[39]</xref>. Varying the width of the level distributions allows parametric control over stimulus contrast. As in previous studies <xref ref-type="bibr" rid="pbio.1001710-Rabinowitz1">[10]</xref>,<xref ref-type="bibr" rid="pbio.1001710-Rabinowitz2">[12]</xref>, we modeled neuronal responses using the linear–nonlinear (LN) framework <xref ref-type="bibr" rid="pbio.1001710-Chichilnisky1">[40]</xref>,<xref ref-type="bibr" rid="pbio.1001710-Simoncelli1">[41]</xref>, assuming that each neuron had a fixed (i.e., contrast-independent) STRF and a variable (contrast-sensitive) output nonlinearity. Contrast-dependent changes in coding are thus revealed through changes to output nonlinearities <xref ref-type="bibr" rid="pbio.1001710-Rabinowitz1">[10]</xref>,<xref ref-type="bibr" rid="pbio.1001710-Rabinowitz2">[12]</xref>.</p>
<fig id="pbio-1001710-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pbio.1001710.g005</object-id><label>Figure 5</label><caption>
<title>Increasing adaptation to stimulus contrast along the auditory pathway.</title>
<p>(A) Schematic of adaptive-LN model. Top/bottom, DRC stimuli. DRCs are filtered through a STRF, then passed through an output nonlinearity, yielding the firing rate (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e037" xlink:type="simple"/></inline-formula>). Output nonlinearities change with stimulus contrast. Insets, example time series. (B) Example units, nonlinearities during low (blue) and high (red) contrast DRCs. Insets, STRFs. Bottom, distributions of STRF-filtered DRCs under low/high contrast. (C) Nonlinearities in (B), replotted in normalized coordinates. (D) Contrast-dependent changes to the slope of units' nonlinearities. (E) Percentage of residual signal power explained by gain kernel model above an LN model <xref ref-type="bibr" rid="pbio.1001710-Rabinowitz2">[12]</xref>. (F) Log increase in Fisher information in units' encoding of low contrast stimuli, resulting from adaptation to this distribution. Zero, no adaptation. Larger positive values, greater adaptation.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1001710.g005" position="float" xlink:type="simple"/></fig>
<p>Changing contrast had little effect on sAN coding, but caused small gain changes for IC units, and large gain changes for cortical units (<xref ref-type="fig" rid="pbio-1001710-g005">Figure 5B</xref>; further examples in <xref ref-type="supplementary-material" rid="pbio.1001710.s002">Figure S2</xref>). Higher in the auditory pathway, contrast-dependent gain changes were stronger (sAN/IC/AC medians: 11/27/44%; <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e038" xlink:type="simple"/></inline-formula>; <xref ref-type="fig" rid="pbio-1001710-g005">Figure 5D</xref>), occurred on slower timescales (time constants <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e039" xlink:type="simple"/></inline-formula> negligible/35/117 ms for sAN/IC/AC; <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e040" xlink:type="simple"/></inline-formula>; <xref ref-type="supplementary-material" rid="pbio.1001710.s003">Figure S3</xref>), and were more important to adaptive-LN model predictive power (median improvement over LN model for sAN/IC/AC: 8/10/20%; not significant for sAN vs. IC, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e041" xlink:type="simple"/></inline-formula> otherwise; <xref ref-type="fig" rid="pbio-1001710-g005">Figure 5E</xref>) <xref ref-type="bibr" rid="pbio.1001710-Rabinowitz2">[12]</xref>. We confirmed this with a Fisher information analysis: by comparing how much Fisher information a unit typically carried in its firing rate about a low contrast stimulus when it was adapted to low contrast with the amount it typically carried about the same stimulus when it was adapted to high contrast, we found that contrast-adaptive changes in coding were more profound higher up in the auditory pathway (<xref ref-type="fig" rid="pbio-1001710-g005">Figure 5F</xref>; median <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e042" xlink:type="simple"/></inline-formula> of 0.6/1.0/2.0 for sAN/IC/AC; <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e043" xlink:type="simple"/></inline-formula>). Thus there is an increase in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e044" xlink:type="simple"/></inline-formula>-adaptation along the auditory pathway.</p>
</sec><sec id="s2c">
<title>Population Representations of Sound</title>
<p>Given that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e045" xlink:type="simple"/></inline-formula>- and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e046" xlink:type="simple"/></inline-formula>-adaptation increase along the auditory pathway, how does this affect the representation of complex sounds by populations of auditory neurons? To answer this, we used a stimulus reconstruction method <xref ref-type="bibr" rid="pbio.1001710-Bialek1">[42]</xref>–<xref ref-type="bibr" rid="pbio.1001710-Pasley1">[45]</xref> that quantified how accurately the spectrogram of a presented sound could be reconstructed from the neuronal responses of each population.</p>
<p>The reconstruction was done as follows. We first trained a spectrogram decoder on the population's responses to clean sounds (<xref ref-type="fig" rid="pbio-1001710-g006">Figure 6</xref>). This decoder was based on a dictionary approach (see <xref ref-type="sec" rid="s4">Materials and Methods</xref> section “Population Decoding”). We then tested the decoder on a novel set of responses to clean sounds and measured how close the reconstructed spectrograms, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e047" xlink:type="simple"/></inline-formula>, were to the original sound spectrograms, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e048" xlink:type="simple"/></inline-formula>, using a similarity metric, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e049" xlink:type="simple"/></inline-formula>. These measurements quantify the degree to which the spectrogram of the clean sounds was encoded in the population responses.</p>
<fig id="pbio-1001710-g006" position="float"><object-id pub-id-type="doi">10.1371/journal.pbio.1001710.g006</object-id><label>Figure 6</label><caption>
<title>Decoding the population representations of clean and noisy sounds.</title>
<p>Schematic of the decoding of neural responses. For each auditory center, a decoder was trained to reconstruct the clean sound spectrogram from the population responses to the clean sounds. We then measured the performance of these decoders when reconstructing spectrograms from the responses to both clean and noisy sounds. Top row, spectrogram of a 2(20 dB SNR) and noisy (10/0/−10 dB SNR) conditions. Left column, decoder training from responses to clean sounds. Population responses are shown as neurograms: each row depicts the time-varying firing rate of a single unit in the population; rows are organized by CF. Right, reconstructed spectrograms (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e050" xlink:type="simple"/></inline-formula>) from population responses to noisy sounds, using the same decoders as trained on the left. The similarity between the reconstructed spectrogram <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e051" xlink:type="simple"/></inline-formula> and the presented spectrogram <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e052" xlink:type="simple"/></inline-formula> is measured by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e053" xlink:type="simple"/></inline-formula>; likewise, the similarity between <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e054" xlink:type="simple"/></inline-formula> and the original, clean spectrogram <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e055" xlink:type="simple"/></inline-formula> is measured by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e056" xlink:type="simple"/></inline-formula>. The tendencies for the sAN decoder to produce <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e057" xlink:type="simple"/></inline-formula>-like spectrograms, and the IC and AC decoders to produce <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e058" xlink:type="simple"/></inline-formula>-like spectrograms, are most visible for the 0 dB and −10 dB conditions.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1001710.g006" position="float" xlink:type="simple"/></fig>
<p>For all three auditory centers, reconstruction accuracy increased with population size (<xref ref-type="fig" rid="pbio-1001710-g007">Figure 7A</xref>). The best reconstructions were available from sAN responses; reconstructions from IC and AC were less accurate. This is likely to be due to several factors. In particular, the synthetic sAN population provided more uniform coverage of the frequency spectrum (<xref ref-type="supplementary-material" rid="pbio.1001710.s004">Figure S4</xref>), and contained less trial-to-trial variability than the recorded data. Also, both IC and AC are well known to have greater low-pass modulation filtering <xref ref-type="bibr" rid="pbio.1001710-Joris1">[1]</xref>, which should reduce the overall fidelity of the spectrogram encoding at these higher auditory centers.</p>
<fig id="pbio-1001710-g007" position="float"><object-id pub-id-type="doi">10.1371/journal.pbio.1001710.g007</object-id><label>Figure 7</label><caption>
<title>Population representations of natural sounds become more noise-tolerant along the auditory pathway.</title>
<p>(A) Similarity between decoded responses to the clean sounds (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e059" xlink:type="simple"/></inline-formula>), and the clean sounds' spectrograms (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e060" xlink:type="simple"/></inline-formula>). Abscissa, sampled population size. Colored areas, bootstrapped 95% confidence intervals. (B–C) Similarity between decoded responses to the noisy sounds (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e061" xlink:type="simple"/></inline-formula>), and the spectrograms of the presented, noisy sounds (B), or the spectrograms of the original, clean sounds (C). Reconstructions are from the full populations in each location. Red bars are the same in (B) and (C), denoting <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e062" xlink:type="simple"/></inline-formula> (i.e., the rightmost points for each curve in A). Error bars, bootstrapped 95% confidence intervals. (D) Index of whether decoded responses were more similar to the presented, noisy sound (negative values), or the original, clean sound (positive values). Similarities denoted by asterisks (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e063" xlink:type="simple"/></inline-formula>) are normalized to the maximum score for each location, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e064" xlink:type="simple"/></inline-formula>. Error bars, 95% confidence intervals. Pairwise comparison statistics (bootstrapped): <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e065" xlink:type="simple"/></inline-formula> (***), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e066" xlink:type="simple"/></inline-formula> (**), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e067" xlink:type="simple"/></inline-formula> (*). (E) Decoder accuracy in recovering the clean sound's identity from noisy responses, relative to accuracy in doing so from clean responses.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1001710.g007" position="float" xlink:type="simple"/></fig></sec><sec id="s2d">
<title>What Is Being Encoded by Neural Populations?</title>
<p>Our interest was not in the absolute performance of these decoders, but rather in how the stimulus representations changed with the addition of background noise. We began by asking, what are sAN, IC, and AC encoding in their population responses? This is a difficult question to address since the dimensionality of a population response is very high. We therefore recast this problem as follows. We considered a scenario where the higher brain has learned to recognize sounds in the absence of noise, based on the respective encodings in sAN, IC, and AC. We then asked what would happen if the brain then tries to extract sound features from responses to the noisy sounds, if it is assumed that neural populations encode sound features in exactly the same way as when noise was absent.</p>
<p>We considered two hypotheses for what might happen. First, when the brain attempts to reconstruct stimulus features from the noisy sounds, it might accurately recover the whole sound mixture, containing the superimposed signal and noise. Alternatively, the reconstructed stimulus might include the signal alone, and not the noise. We denote these two possibilities as “mixture”-like and “signal only”–like representations. These are two ends of a spectrum: the sAN, IC, and AC populations may show different degrees of “mixture”-like and “signal only”–like coding.</p>
<p>To test these hypotheses, we used the same decoders (which had already been trained on the clean stimuli) to reconstruct the stimulus spectrograms from the responses of the three populations to the noisy sounds. We quantified how the accuracy of the reconstructed spectrograms (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e068" xlink:type="simple"/></inline-formula>) changed across noise levels, by measuring the similarity of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e069" xlink:type="simple"/></inline-formula> both to the presented, noisy spectrograms (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e070" xlink:type="simple"/></inline-formula>; <xref ref-type="fig" rid="pbio-1001710-g007">Figure 7B</xref>) and to the spectrogram of the original, clean sound (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e071" xlink:type="simple"/></inline-formula>; <xref ref-type="fig" rid="pbio-1001710-g007">Figure 7C</xref>). To be able to compare these values across different populations, we normalized these measurements, by dividing them by that population's value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e072" xlink:type="simple"/></inline-formula> (the absolute performance of the decoder on the clean sound responses). We denote the normalized values as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e073" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e074" xlink:type="simple"/></inline-formula>, respectively.</p>
<p>The rationale for these measurements was as follows. If the reconstructed spectrogram contains both the signal and the noise, then <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e075" xlink:type="simple"/></inline-formula> should be more similar to the spectrogram of the noisy, presented sound, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e076" xlink:type="simple"/></inline-formula>, than it is to the spectrogram of the original, clean sound, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e077" xlink:type="simple"/></inline-formula>, which contains the signal alone. Thus, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e078" xlink:type="simple"/></inline-formula> would be less than 0. On the other hand, if the reconstructed spectrogram contains the signal, but not the noise, then <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e079" xlink:type="simple"/></inline-formula> should be more similar to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e080" xlink:type="simple"/></inline-formula> than to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e081" xlink:type="simple"/></inline-formula>, and so <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e082" xlink:type="simple"/></inline-formula> would be greater than 0.</p>
<p>For the sAN responses, we found that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e083" xlink:type="simple"/></inline-formula>. This indicates that, using a fixed decoder, both the signal and the noise are extracted from the sAN responses. In other words, the noise directly impinges on the encoding of the signal in the sAN responses. The reverse was true for AC, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e084" xlink:type="simple"/></inline-formula>. This indicates that, using a fixed decoder, the signal can be extracted from the AC responses, without recovering much of the noise. The IC responses lay between these two extrema (<xref ref-type="fig" rid="pbio-1001710-g007">Figure 7D</xref>).</p>
<p>It is important to emphasize here that this does not imply that noise features are altogether discarded by the level of the cortex, and not represented at all. The decoders here were specifically trained to extract the clean signal; these results therefore highlight how much or how little the encoding of the original signal is affected by the addition of background noise. As we used new noise tokens on each presentation, it was not possible to train decoders to extract the noise in the mixture from the response (rather than the clean sound), nor to accurately determine the extent to which transient noise features can be recovered from population responses. We therefore treat the noise here as a nuisance variable—that is, as a distractor from the encoding of the ecologically more relevant components of the sound signal.</p>
<p>In sum, while population representations in the periphery are more “mixture”-like, insofar as stationary noises are encoded in a similar way as complex sounds, there is a shift towards more “signal only”–like population representations in midbrain and then cortex, wherein stationary noise is not encoded together with the foreground sound.</p>
</sec><sec id="s2e">
<title>Noise-Tolerant Population Representations of Sound</title>
<p>We next asked a related but different question: If we start with a population representation of the clean sound, how tolerant is this representation to the addition of background noise? Unlike the question above, this requires us to take into account that the addition of noise degrades any reconstruction (<xref ref-type="fig" rid="pbio-1001710-g007">Figure 7B–C</xref>).</p>
<p>To measure noise tolerance, we reasoned as follows. The decoder estimates a relationship between the population response and the clean sound spectrogram (i.e., the signal). If a population representation is noise-tolerant, such that the response does not change considerably when background noise is added, then <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e085" xlink:type="simple"/></inline-formula> should be as accurately recovered from responses to the noisy sounds as it is from the clean sounds (i.e., <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e086" xlink:type="simple"/></inline-formula> should be high). Conversely, if the population representation is noise-intolerant, such that the response changes considerably when background noise is added, then <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e087" xlink:type="simple"/></inline-formula> should be more poorly recovered from responses to the noisy sounds than from responses to the clean sounds (i.e., <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e088" xlink:type="simple"/></inline-formula> should be low). We found that for moderate noise levels, the value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e089" xlink:type="simple"/></inline-formula> was highest for the AC, and lowest for the sAN (<xref ref-type="fig" rid="pbio-1001710-g007">Figure 7E</xref>). This suggests that cortex maintains a more consistent representation of the signal as noise is added.</p>
<p>Thus, the population representations of sound change through the auditory pathway. In the periphery, neural populations that encode the signal also encode the noise in a similar way, responding to features of the mixed input. By the level of the cortex, however, neural populations represent the signal in a more noise-tolerant fashion, by responding to the sound features that are common between clean and noisy conditions.</p>
</sec><sec id="s2f">
<title>Adaptive Coding Partially Accounts for Noise-Tolerant Populations</title>
<p>Earlier, we demonstrated that adaptation to stimulus statistics increases along the auditory pathway. We therefore asked whether this could account for how background noise affects population representations of complex sounds along the auditory pathway.</p>
<p>To develop this hypothesis, we simulated populations of model auditory neurons with variable degrees of adaptation to sound statistics (<xref ref-type="supplementary-material" rid="pbio.1001710.s005">Figure S5</xref>). These simulations confirmed that increasing <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e090" xlink:type="simple"/></inline-formula>-adaptation and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e091" xlink:type="simple"/></inline-formula>-adaptation could account for the decoder results shown in <xref ref-type="fig" rid="pbio-1001710-g007">Figure 7D–E</xref>. In particular, the simulations made two specific predictions. The first is that the increase in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e092" xlink:type="simple"/></inline-formula>-adaptation along the auditory pathway may be responsible for the shift from encoding <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e093" xlink:type="simple"/></inline-formula> (in sAN) to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e094" xlink:type="simple"/></inline-formula> (in AC), as observed in <xref ref-type="fig" rid="pbio-1001710-g007">Figure 7D</xref>. This is because <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e095" xlink:type="simple"/></inline-formula>-adaptation would remove the strong differences in response baselines between the representations of clean and noisy sounds (<xref ref-type="fig" rid="pbio-1001710-g003">Figure 3B</xref>, top). The second prediction is that the increase in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e096" xlink:type="simple"/></inline-formula>-adaptation along the auditory pathway could be responsible for the increased tolerance of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e097" xlink:type="simple"/></inline-formula> decoding to the addition of noise, as observed in <xref ref-type="fig" rid="pbio-1001710-g007">Figure 7E</xref>. This is because <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e098" xlink:type="simple"/></inline-formula>-adaptation rescales the representation of the stimulus, such that the peaks in intensity are relatively independent of the noise level (<xref ref-type="fig" rid="pbio-1001710-g003">Figure 3B</xref>, bottom).</p>
<p>To test the first prediction—that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e099" xlink:type="simple"/></inline-formula>-adaptation drives populations to represent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e100" xlink:type="simple"/></inline-formula> rather than <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e101" xlink:type="simple"/></inline-formula>—we subdivided each neuronal population into four groups according to the neurons' baseline invariance (BI; our measure of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e102" xlink:type="simple"/></inline-formula>-adaptation). For example, in IC, the 20 neurons with lowest BI formed a subpopulation with mean BI of 83%, and the 20 neurons with highest BI formed a subpopulation with mean BI of 99%. We then decoded responses from each of the 12 subpopulations. We found that the subpopulations with larger BI yielded more <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e103" xlink:type="simple"/></inline-formula>-like spectrograms upon decoding (<xref ref-type="fig" rid="pbio-1001710-g008">Figure 8A</xref>). That is, neurons with stronger adaptation to baseline sound intensity showed more “signal only”–like coding than “mixture”-like coding. This factor largely explained the differences in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e104" xlink:type="simple"/></inline-formula> between each level of the pathway (<xref ref-type="supplementary-material" rid="pbio.1001710.s011">Table S1A</xref>).</p>
<fig id="pbio-1001710-g008" position="float"><object-id pub-id-type="doi">10.1371/journal.pbio.1001710.g008</object-id><label>Figure 8</label><caption>
<title>Higher <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e105" xlink:type="simple"/></inline-formula>- and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e106" xlink:type="simple"/></inline-formula>-adaptation explain the increased noise-tolerance of population representations.</title>
<p>(A) Relationship between decoder performance and BI (measure of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e107" xlink:type="simple"/></inline-formula>-adaptation). Each point represents a subpopulation (one quarter) of the units from each of the sAN/IC/AC populations, subdivided according to units' BI (values in <xref ref-type="fig" rid="pbio-1001710-g004">Figure 4B</xref>). Abscissa, mean BI in the subpopulation. Ordinate, performance of the subpopulation decoder. Lines, linear fit per SNR. (B) Relationship between decoder performance and CI (measure of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e108" xlink:type="simple"/></inline-formula>-adaptation), similar to (A). Here, each point represents a subpopulation (one quarter) of the units from each of the sAN/IC/AC populations, subdivided according to the amount of units' contrast adaptation (values in <xref ref-type="fig" rid="pbio-1001710-g005">Figure 5D</xref>). sAN values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e109" xlink:type="simple"/></inline-formula> were adjusted for low BI (see <xref ref-type="supplementary-material" rid="pbio.1001710.s006">Figure S6</xref>).</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1001710.g008" position="float" xlink:type="simple"/></fig>
<p>To test the second prediction—that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e110" xlink:type="simple"/></inline-formula>-adaptation drives populations to encode <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e111" xlink:type="simple"/></inline-formula> in a more noise-tolerant fashion—we again subdivided each population into four groups, by sorting units by their contrast-dependent gain changes—that is, the extent of their contrast invariance (our measure of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e112" xlink:type="simple"/></inline-formula>-adaptation). Those subpopulations with stronger contrast-dependent gain control yielded <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e113" xlink:type="simple"/></inline-formula>-representations that degraded less with the addition of noise. This factor largely explained the differences in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e114" xlink:type="simple"/></inline-formula> across auditory centers (<xref ref-type="fig" rid="pbio-1001710-g008">Figure 8B</xref>, <xref ref-type="supplementary-material" rid="pbio.1001710.s011">Table S1B</xref>). Together, these results support the notion that adaptation to stimulus statistics is an important mechanism that drives populations of auditory neurons to represent sounds a noise-tolerant way.</p>
</sec></sec><sec id="s3">
<title>Discussion</title>
<p>Our data show that, as one progresses along the auditory pathway from the AN to IC to AC, neurons show increasing adaptation to the mean (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e115" xlink:type="simple"/></inline-formula>, <xref ref-type="fig" rid="pbio-1001710-g004">Figure 4</xref>) and contrast (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e116" xlink:type="simple"/></inline-formula>, <xref ref-type="fig" rid="pbio-1001710-g005">Figure 5</xref>) of sounds. This adaptation to stimulus statistics is relevant to hearing in noisy environments, because an important effect of background noise is to change these sound statistics. By adapting to such changes, populations of neurons could, in principle, produce a relatively noise-invariant code for nonstationary sounds (<xref ref-type="fig" rid="pbio-1001710-g003">Figure 3</xref>). Consistent with this hypothesis, we found that population representations of natural sounds in higher auditory centers show stronger tolerance to the addition of stationary background noise (<xref ref-type="fig" rid="pbio-1001710-g007">Figure 7</xref>), and that this noise tolerance could largely be explained by increases in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e117" xlink:type="simple"/></inline-formula>- and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e118" xlink:type="simple"/></inline-formula>-adaptation (<xref ref-type="fig" rid="pbio-1001710-g008">Figure 8</xref>). This suggests that the increase in adaptation to stimulus statistics along the auditory pathway makes an important contribution to the construction of noise-invariant representations of sound.</p>
<sec id="s3a">
<title>Towards Normalized Representations</title>
<p>The effect of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e119" xlink:type="simple"/></inline-formula>- and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e120" xlink:type="simple"/></inline-formula>-adaptation can be understood by representing the structure of a sound as a time-varying function, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e121" xlink:type="simple"/></inline-formula>. The brain does not have direct access to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e122" xlink:type="simple"/></inline-formula>; instead, when the sound is produced at a particular amplitude (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e123" xlink:type="simple"/></inline-formula>) and is heard against a background of other sounds (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e124" xlink:type="simple"/></inline-formula>), the signal that the ear actually receives is the sound mixture <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e125" xlink:type="simple"/></inline-formula>. To identify a sound, the brain must recover the sound structure, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e126" xlink:type="simple"/></inline-formula>, without being confused by the often irrelevant variables <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e127" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e128" xlink:type="simple"/></inline-formula>.</p>
<p>Experiments with synthetic DRC stimuli show a shift in coding away from a raw signal (resembling <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e129" xlink:type="simple"/></inline-formula>) in the periphery toward a more normalized signal (resembling <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e130" xlink:type="simple"/></inline-formula>) in the cortex. When the contrast of DRCs is manipulated, we find that sAN responses to DRCs are reasonably well described by an LN model without gain changes. Their firing rate is a function of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e131" xlink:type="simple"/></inline-formula>—that is, the DRC filtered through that neuron's STRF (<xref ref-type="fig" rid="pbio-1001710-g005">Figure 5B</xref>). This suggests that the AN, as a whole, provides a relatively veridical representation of sound mixtures reaching the ear. In comparison, many cortical units, and some IC units, adapt to changes in DRC contrast by changing their gain. These units' firing rates are not a function of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e132" xlink:type="simple"/></inline-formula> (as in the sAN); they are often better described as a function of a normalized variable, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e133" xlink:type="simple"/></inline-formula>, in which the stimulus contrast (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e134" xlink:type="simple"/></inline-formula>) has been divided out (<xref ref-type="fig" rid="pbio-1001710-g005">Figure 5C</xref>). Even though AC neurons do not show complete contrast-invariance for these stimuli (the median AC gain change was 44%; perfect <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e135" xlink:type="simple"/></inline-formula>-encoding would be 100% gain change; <xref ref-type="fig" rid="pbio-1001710-g005">Figure 5D</xref>), AC neurons' responses depend less on stimulus contrast than those in IC or sAN. A similar shift in coding is evident when considering small changes in the mean level of a DRC. Whereas each sAN fiber provides a relatively fixed representation of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e136" xlink:type="simple"/></inline-formula>, IC and AC units adjust their baseline firing rates so that they effectively subtract out the stimulus mean (<xref ref-type="supplementary-material" rid="pbio.1001710.s007">Figures S7</xref> and <xref ref-type="supplementary-material" rid="pbio.1001710.s008">S8</xref>). The effect of adaptation to stimulus statistics is thus that cortex (and, to a lesser degree, IC) provides a sound representation that is closer to the underlying sound, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e137" xlink:type="simple"/></inline-formula>, than to the sound mixture reaching the ear, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e138" xlink:type="simple"/></inline-formula>.</p>
</sec><sec id="s3b">
<title>Functional Mechanisms for Building Noise-Invariant Representations</title>
<p>It is likely that adaptation to stimulus statistics is one of several changes in neural coding that contributes towards the construction of noise-invariant representations of sounds. Related findings were obtained by Lesica and Grothe <xref ref-type="bibr" rid="pbio.1001710-Lesica1">[17]</xref>, who studied changes in MTFs of IC neurons under noisy stimulation. Just as our investigation of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e139" xlink:type="simple"/></inline-formula>- and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e140" xlink:type="simple"/></inline-formula>-adaptations was initially motivated by considering how the statistics of within-receptive field signals would change under clean and noisy sound stimulation (<xref ref-type="fig" rid="pbio-1001710-g003">Figure 3</xref>), so Lesica and Grothe began by investigating the difference in the amplitude modulation spectra between foreground vocalizations and background noises. They observed that vocalizations contain more power in slow (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e141" xlink:type="simple"/></inline-formula>Hz) amplitude modulations than background noises. When the authors presented vocalizations to gerbils and recorded from neurons in the IC, they found that single units' MTFs shifted from being bandpass to more lowpass, suggesting that IC neurons redirect their coding capacity to modulation bands of higher SNR under noisy conditions.</p>
<p>Similar results were recently obtained by Ding and Simon <xref ref-type="bibr" rid="pbio.1001710-Ding2">[8]</xref>, who measured the aggregate activity in human AC via magnetoencephalography, as subjects listened to speech in spectrally matched noise. They found that as background noise is added to speech, the entrainment of aggregate cortical activity to slow temporal modulations (&lt;4 Hz) in the speech signal remains high, while entrainment to faster (4–8 Hz) modulations degrades with noise. Since the gross envelope of the original speech can be decoded from aggregate responses to the clean and noisy stimuli, noise induces a change in response gain as well as changes to MTFs.</p>
<p>The relationship between our observations of increasing <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e142" xlink:type="simple"/></inline-formula>-adaptation from periphery to cortex, and these previous findings of changing MTFs in IC neurons and aggregate cortical activity, may depend on the modulation specificity of the gain changes. For instance, a nonspecific increase in neural response gain would manifest as an overall upwards shift in the MTF. Conversely, an upwards shift within a small region of the MTF corresponds to a modulation-band–specific increase in gain. One possibility is that during complex sound stimulation, auditory neurons determine their gain independently for different modulation “channels” (such as described in modulation filterbank models <xref ref-type="bibr" rid="pbio.1001710-McDermott1">[28]</xref>,<xref ref-type="bibr" rid="pbio.1001710-Dau1">[46]</xref>), as a function of the signal statistics within each channel. This might have different effects on MTFs depending on the modulation spectrum of the background noise. In indirect support of this possibility, the extent to which the coding of different cells is affected by a given background noise appears to depend on each cell's modulation tuning <xref ref-type="bibr" rid="pbio.1001710-Moore1">[47]</xref>. An alternative possibility is that auditory neurons might always become more modulation lowpass in the presence of background noise, regardless of the noise's actual modulation statistics. This might reflect a set of priors about what is signal and what is noise in an incoming sound mixture. Our set of unique sounds and background noises was too small to test these two hypotheses (or even to measure MTFs). Nevertheless, if auditory neurons additionally demonstrate modulation-specific gain in response to noise, it is likely that this effect grows stronger from periphery to cortex.</p>
<p>These data also provide some insight as to how our results might extend to more complex classes of background noise. Here, we have characterized coding changes induced by adding stationary noise with flat modulation spectra and no cross-band correlations. Many background sounds have more complex (often 1/<italic>f</italic>-like) modulation spectra <xref ref-type="bibr" rid="pbio.1001710-McDermott1">[28]</xref>,<xref ref-type="bibr" rid="pbio.1001710-Singh1">[35]</xref>; a greater proportion of their modulation energy lies within the common passband of midbrain and cortical auditory neurons. Since our simulations suggest that greater modulation tuning plays only a small part in enabling tolerance to noise with flat modulation spectra, it should be less important still for enabling tolerance to noise with 1/<italic>f</italic>-like modulation spectra. We therefore expect that the adaptive coding we and others describe is crucial for more general classes of background noise. Beyond this, some background sound textures also contain correlations across carrier or modulation channels <xref ref-type="bibr" rid="pbio.1001710-McDermott1">[28]</xref>, while others are nonstationary, changing their statistics over time. An understanding of how these noise features differentially affect signal encodings along the auditory pathway would require further experiments utilizing a broader set of background noises.</p>
<p>An alternative hypothesis for how the brain builds noise-invariant representations of sound is that the very nature of these representations may be changing along the auditory pathway, from an emphasis on encoding predominantly spectrotemporal information in the periphery to encoding information about the presence of higher level auditory features in cortex. This, for instance, is a position recently argued for by Chechik and Nelken <xref ref-type="bibr" rid="pbio.1001710-Chechik1">[48]</xref>, based on their investigation of the responses of cat cortical neurons to the components of natural birdsong. Emerging data from the avian brain support this idea: the avian analogue of AC appears to shift its encoding toward sparse representations of song elements, which can be encoded in a noise-robust manner <xref ref-type="bibr" rid="pbio.1001710-Schneider1">[49]</xref>. Our results relate to this hypothesis by emphasizing that, to the extent that the mammalian midbrain and cortex do encode spectrotemporal information about ongoing sounds, they do so in progressively more normalized coordinates. This captures at least some (but likely not all) of the proposed representational shifts from periphery to cortex.</p>
<p>Finally, bottom-up mechanisms are undoubtedly just a part of a broader infrastructure for selecting and enhancing representations of particular sounds heard within complex acoustic scenes. In our experiments, we chose stimuli for which the assignment of the tags “signal” and “noise” (or “foreground”/“background,” or “relevant”/“irrelevant”) to components of the mixture is reasonably justified by the different statistical structures of natural and background sounds <xref ref-type="bibr" rid="pbio.1001710-Lesica1">[17]</xref>,<xref ref-type="bibr" rid="pbio.1001710-McDermott1">[28]</xref>,<xref ref-type="bibr" rid="pbio.1001710-Singh1">[35]</xref>,<xref ref-type="bibr" rid="pbio.1001710-Woolley2">[50]</xref>. On the other hand, there are also many real-world situations for which such assignment is ambiguous, and depends on task-specific demands. Listening to a single talker against a background of many is one notable instance. Yet human imaging studies reveal that in such circumstances, the neural representation of attended talkers is selectively enhanced relative to that of unattended talkers, even at low SNRs <xref ref-type="bibr" rid="pbio.1001710-Ding1">[7]</xref>,<xref ref-type="bibr" rid="pbio.1001710-Mesgarani1">[26]</xref>,<xref ref-type="bibr" rid="pbio.1001710-ZionGolumbic1">[51]</xref>. While noise tolerance appears to grow even stronger between core and belt AC <xref ref-type="bibr" rid="pbio.1001710-Ding1">[7]</xref>,<xref ref-type="bibr" rid="pbio.1001710-Ding2">[8]</xref>, this is likely to be attention-dependent <xref ref-type="bibr" rid="pbio.1001710-Ding1">[7]</xref>,<xref ref-type="bibr" rid="pbio.1001710-Ding2">[8]</xref>,<xref ref-type="bibr" rid="pbio.1001710-Rees3">[52]</xref>–<xref ref-type="bibr" rid="pbio.1001710-Billings1">[54]</xref>. Understanding how we create noise-tolerant representations of sound within more complex mixtures is thus interwoven with questions of how we segment these scenes, how we tag the components as “signal” and “noise,” and how we direct our attention accordingly.</p>
<p>In sum, our results provide a clear picture of a bottom-up process that contributes to the emergence of noise-invariant representations of natural sounds in the auditory brain. As neurons' adaptation to stimulus statistics gradually grows stronger along the auditory pathway, populations of these neurons progressively shift from encoding low-level physical attributes of incoming sounds towards more mean-, contrast-, and noise-independent information about stimulus identity. The result is a major computational step towards the context-invariant, categorical sound representations that are seen in higher areas of AC.</p>
</sec></sec><sec id="s4" sec-type="materials|methods">
<title>Materials and Methods</title>
<sec id="s4a">
<title>Animals and Physiology</title>
<p>All animal procedures were approved by the local ethical review committee and performed under license from the UK Home Office.</p>
<p>Extra-cellular recordings were performed in medetomidine/ketamine-anesthetized ferrets. Previous work has shown that this does not affect the contrast adaptation properties of cortical neurons <xref ref-type="bibr" rid="pbio.1001710-Rabinowitz1">[10]</xref>. Full surgical procedures for cortical recordings (primary auditory cortex and anterior auditory field), spike-sorting routines, unit selection criteria, and sound presentation methods (diotic, earphones, 48828 kHz sample rate) are provided in ref. <xref ref-type="bibr" rid="pbio.1001710-Rabinowitz2">[12]</xref>. Surgery for IC recordings were performed as in ref. <xref ref-type="bibr" rid="pbio.1001710-Dahmen1">[55]</xref>. Recordings were made bilaterally in both locations.</p>
<p>The AN was simulated using the complete model of Zilany et al. <xref ref-type="bibr" rid="pbio.1001710-Zilany1">[27]</xref>. We generated spiking responses from 100 fibers at a 100 kHz sample rate, with the same distribution of center frequencies (CFs) and spontaneous rates (SRs) as in that paper (see section “AN Model” below); <italic>n</italic> = 85 fibers were used based on reliably evoked responses to the natural stimuli <xref ref-type="bibr" rid="pbio.1001710-Rabinowitz1">[10]</xref>,<xref ref-type="bibr" rid="pbio.1001710-Rabinowitz2">[12]</xref>.</p>
</sec><sec id="s4b">
<title>Stimuli</title>
<p>Four natural sound segments were presented (forest sounds, rain, female speech, male speech sped up by 50%), with a combined duration of 16 s, to 5 animals (IC, 2 animals, <italic>n</italic> = 80 units; AC, 3 animals, <italic>n</italic> = 124 units). For each sound, noise tokens were synthesized with the same power spectrum and duration, and mixed with the original source. The amplitudes of the source and noise were scaled so that the SNR was 20 dB for the clean condition, and 10/0/−10 dB for the noisy conditions, with a fixed root-mean-square (RMS) level of 80 dB SPL. The “clean” condition was therefore high-SNR, but not entirely noise-free; this was necessary to keep its (log)-spectrogram bounded from below at reasonable values. Fifty unique noise tokens were generated for each sound and each SNR. All sounds included 5 ms cosine ramps at onset and offset. The set of stimuli were presented in random order, interleaved with ∼7 min of DRC stimulation. DRCs were constructed from tones spaced at 1/6-octave intervals from 500 Hz to 22.6 kHz; these changed in level synchronously every 25 ms. Tone levels were drawn from uniform distributions with a mean <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e143" xlink:type="simple"/></inline-formula> dB SPL, and halfwidths of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e144" xlink:type="simple"/></inline-formula> dB. Responses to these DRCs informed the analysis in <xref ref-type="fig" rid="pbio-1001710-g008">Figure 8B</xref>.</p>
<p>The analysis in <xref ref-type="fig" rid="pbio-1001710-g005">Figure 5A–F</xref> was from DRCs presented to a further 6 animals (IC, 3 animals, <italic>n</italic> = 136 units; AC, 3 animals, <italic>n</italic> = 76 units); these procedures were as described in ref. <xref ref-type="bibr" rid="pbio.1001710-Rabinowitz2">[12]</xref>. Here, tones were 1/4-octave spaced, and tone-level distributions had <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e145" xlink:type="simple"/></inline-formula> dB SPL and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e146" xlink:type="simple"/></inline-formula> dB. Approximately 30–60 min of DRCs were presented during each penetration. Stimuli in <xref ref-type="supplementary-material" rid="pbio.1001710.s007">Figures S7</xref> and <xref ref-type="supplementary-material" rid="pbio.1001710.s008">S8</xref> were presented to 2 animals (IC) and 4 animals (AC).</p>
</sec><sec id="s4c">
<title>AN Model</title>
<p>We simulated the AN using the phenomenological model of Zilany et al. <xref ref-type="bibr" rid="pbio.1001710-Zilany1">[27]</xref>. We chose the Zilany model because it captures many physiological features of the AN responses to simple and complex sounds, including middle-ear filtering, cochlear compression, and two-tone suppression. It does not explicitly model the action of the olivocochlear bundle, such as the medial olivocochlear reflex, which modulates cochlear gain during periods of high-amplitude stimulation <xref ref-type="bibr" rid="pbio.1001710-Cooper1">[56]</xref> and may therefore improve the audibility of transient sounds, such as tones or vowels, in noise <xref ref-type="bibr" rid="pbio.1001710-Hienz1">[57]</xref>,<xref ref-type="bibr" rid="pbio.1001710-Guinan1">[58]</xref>. However, it does capture the adaptation of AN responses to the mean level of a sound as experimentally measured in the cat AN <xref ref-type="bibr" rid="pbio.1001710-Wen1">[36]</xref>,<xref ref-type="bibr" rid="pbio.1001710-Zilany2">[59]</xref>.</p>
<p>We used the full AN model as provided in the authors' code, including the exact (rather than approximate) implementation of power law adaptation. We simulated 100 AN fibers, using the same distribution of CFs and SRs that the authors used in that paper, based on previous physiological data <xref ref-type="bibr" rid="pbio.1001710-Joris2">[60]</xref>. Of the 100 fibers, 16 were low SR, 23 were medium SR, and 61 were high SR. For each SR, fibers had log-spaced CFs between 250 Hz and 20 kHz.</p>
<p>We ran three controls on this model. First, we tested whether there was a difference in the results from low, medium, or high SR fibers, and found little to no difference between the metrics presented in the main text. Second, Zilany et al. present both an exact and an approximate implementation of power law adaptation; we therefore simulated both and found that the two implementations produced very similar results.</p>
<p>Finally, the adaptation built into the model allows past stimulation history to affect current responses. We therefore tested whether the decoder results changed as we increased the length of preceding stimulation. To do this, we simulated the stimulus presentation sequences used during physiological recordings, where natural sounds were played back-to-back (with a 100 ms silence between sounds). The stimuli were presented in pseudorandom order, as in physiology experiments. As the time and memory complexity of the sAN simulation algorithm grows exponentially with stimulus length, the longest sequences we were able to present in reasonable time were four sounds (i.e., 16 s) in duration. Next, we selected the responses to either the first, the second, the third, or the fourth sound in each sequence. The first set of responses were generated with 0 s of preceding stimulation; these were discarded to avoid unstable initial behavior. We considered each of the remaining sets of responses: the second set, with an average of 4 s of preceding stimulation; the third, with an average of 8 s; and the fourth, with an average of 12 s. Using this schema, we simulated three entire sAN populations and calculated the relevant decoder metrics for each. There was very little difference between the values of the metrics in <xref ref-type="fig" rid="pbio-1001710-g007">Figure 7D–E</xref> when the amount of preceding stimulation was varied between 4 and 12 s. We were therefore confident that the simulated adaptation had reached a steady state. Data in the main text are from the fourth set of responses; these are simulated with an adaptation “memory” of 12 s of natural stimulation.</p>
</sec><sec id="s4d">
<title>KL Divergence Calculation</title>
<p>To measure how the distributions of units' responses changed with the addition of noise (<xref ref-type="fig" rid="pbio-1001710-g002">Figure 2B</xref>), we performed the following analysis for each unit. We began with the trial-averaged, time-varying firing rates evoked over the stimulus ensemble for each SNR (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e147" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e148" xlink:type="simple"/></inline-formula> is SNR and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e149" xlink:type="simple"/></inline-formula> is time), at a 5 ms resolution. We scaled these firing rates relative to the maximum firing rate produced by that unit in the 20 dB SNR condition: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e150" xlink:type="simple"/></inline-formula>. We then approximated the distributions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e151" xlink:type="simple"/></inline-formula> for each SNR <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e152" xlink:type="simple"/></inline-formula>, by binning <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e153" xlink:type="simple"/></inline-formula> at a resolution (bin size) of 0.01, and using a maximum <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e154" xlink:type="simple"/></inline-formula> of 2 (enforced for consistency; no <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e155" xlink:type="simple"/></inline-formula> ever exceeded this value). The counts in each bin were augmented by a value of 0.5 (generally about 2%–10% of the observed count; equivalent to using a weak Dirichlet prior with a uniform base measure <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e156" xlink:type="simple"/></inline-formula>); this ensured that the results remained finite. We then normalized the counts to have unitary sum. Finally, we computed the Kullback–Leibler divergence between <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e157" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e158" xlink:type="simple"/></inline-formula>, with values shown in <xref ref-type="fig" rid="pbio-1001710-g002">Figure 2B</xref>.</p>
</sec><sec id="s4e">
<title>Noise Independence Calculation</title>
<p>To assess how the stimulus-conditioned responses depended on the level of background noise, we calculated a mutual information (MI)-based measure for each unit (<xref ref-type="fig" rid="pbio-1001710-g002">Figure 2C</xref>). For each background-noise condition (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e159" xlink:type="simple"/></inline-formula>), we labeled the stimulus in each time bin with an index, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e160" xlink:type="simple"/></inline-formula>, using the same <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e161" xlink:type="simple"/></inline-formula> indices across SNRs. We then calculated the (bias-corrected) MI between the unit's evoked response distributions, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e162" xlink:type="simple"/></inline-formula>, and the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e163" xlink:type="simple"/></inline-formula> index, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e164" xlink:type="simple"/></inline-formula>, and the MI between <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e165" xlink:type="simple"/></inline-formula> and both the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e166" xlink:type="simple"/></inline-formula> index and the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e167" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e168" xlink:type="simple"/></inline-formula>. Bias-corrections were performed by shuffling labels <xref ref-type="bibr" rid="pbio.1001710-Panzeri1">[61]</xref>. The ratio between these respective quantities measures the proportion of the response entropy that can be reduced by knowing the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e169" xlink:type="simple"/></inline-formula> index, as compared with knowing both the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e170" xlink:type="simple"/></inline-formula> index and the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e171" xlink:type="simple"/></inline-formula>. If the responses are statistically independent of the noise, then <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e172" xlink:type="simple"/></inline-formula> should equal <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e173" xlink:type="simple"/></inline-formula>, as knowing the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e174" xlink:type="simple"/></inline-formula> adds no further information. Consequently, a value of 1 means that the response distribution contains information about the underlying sound stimulus but not the level of background noise; lower values mean that the information about the underlying sound stimulus is more SNR-dependent.</p>
</sec><sec id="s4f">
<title>Estimating Contrast-Dependent Gain Changes</title>
<p>To measure how the slope of units' nonlinearities changed as the contrast of the DRC stimuli changed (<xref ref-type="fig" rid="pbio-1001710-g005">Figures 5D</xref> and <xref ref-type="fig" rid="pbio-1001710-g008">8B</xref>), we used the following process. As described in the section “Stimuli” above, units in <xref ref-type="fig" rid="pbio-1001710-g005">Figure 5D</xref> were stimulated with DRCs used in a previous study <xref ref-type="bibr" rid="pbio.1001710-Rabinowitz2">[12]</xref>. We considered only data from the two uniform contrast conditions in that study—that is, DRC segments where all tone levels were drawn from a distribution with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e175" xlink:type="simple"/></inline-formula> dB (i.e., <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e176" xlink:type="simple"/></inline-formula> dB), or where all tone levels were drawn from a distribution with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e177" xlink:type="simple"/></inline-formula> dB (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e178" xlink:type="simple"/></inline-formula> dB). We fitted the following nonlinearity to this dataset:<disp-formula id="pbio.1001710.e179"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pbio.1001710.e179" xlink:type="simple"/><label>(1)</label></disp-formula><disp-formula id="pbio.1001710.e180"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pbio.1001710.e180" xlink:type="simple"/><label>(2)</label></disp-formula><disp-formula id="pbio.1001710.e181"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pbio.1001710.e181" xlink:type="simple"/><label>(3)</label></disp-formula>The reported values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e182" xlink:type="simple"/></inline-formula> are given as percentages; this is the ratio:<disp-formula id="pbio.1001710.e183"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pbio.1001710.e183" xlink:type="simple"/><label>(4)</label></disp-formula></p>
<p>Thus 0% indicates no slope changes, and 100% indicates perfect compensation for stimulus contrast. It is also possible under this metric that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e184" xlink:type="simple"/></inline-formula> can exceed 100%: this indicates that the unit's gain change was even stronger than was necessary to compensate for the changes in contrast.</p>
<p>The units in <xref ref-type="fig" rid="pbio-1001710-g008">Figure 8B</xref> were stimulated with a different set of DRCs. These had tone-level distributions with half-widths drawn from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e185" xlink:type="simple"/></inline-formula> dB (and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e186" xlink:type="simple"/></inline-formula> as above). We fitted the same contrast-dependent nonlinearity as above (<xref ref-type="disp-formula" rid="pbio.1001710.e179">Equations 1</xref>–<xref ref-type="disp-formula" rid="pbio.1001710.e181">3</xref>). Here, since a broader range of contrasts was used, the reported values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e187" xlink:type="simple"/></inline-formula> are given as:<disp-formula id="pbio.1001710.e188"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pbio.1001710.e188" xlink:type="simple"/><label>(5)</label></disp-formula></p>
<p>There were no significant differences between the measures in <xref ref-type="disp-formula" rid="pbio.1001710.e183">Equations 4</xref> and <xref ref-type="disp-formula" rid="pbio.1001710.e188">5</xref>.</p>
</sec><sec id="s4g">
<title>Estimating Contrast-Dependent Changes in Coding (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e189" xlink:type="simple"/></inline-formula>)</title>
<p>As the contrast of DRC stimuli changed, units' output nonlinearities predominantly changed their gain (as in <xref ref-type="fig" rid="pbio-1001710-g005">Figure 5B</xref>). Some units' output nonlinearities also showed other adaptive shifts (examples in <xref ref-type="supplementary-material" rid="pbio.1001710.s002">Figure S2</xref>). To quantify the overall effect of contrast-dependent changes to output nonlinearities, we constructed a measure of how these adaptive shifts change the amount of information a unit's firing rate carries about the ongoing stimulus (<xref ref-type="fig" rid="pbio-1001710-g005">Figure 5F</xref>).</p>
<p>As above (see “Estimating Contrast-Dependent Gain Changes”; <xref ref-type="fig" rid="pbio-1001710-g005">Figures 5D</xref> and <xref ref-type="fig" rid="pbio-1001710-g008">8B</xref>), we limited our analysis for each unit to data from the two uniform contrast conditions. For each unit, we fitted individual output nonlinearities for the two conditions (these are the blue and red curves shown in <xref ref-type="fig" rid="pbio-1001710-g005">Figure 5B</xref> and <xref ref-type="supplementary-material" rid="pbio.1001710.s002">Figure S2A</xref>); we denote these two curves as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e190" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e191" xlink:type="simple"/></inline-formula>, respectively:<disp-formula id="pbio.1001710.e192"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pbio.1001710.e192" xlink:type="simple"/><label>(6)</label></disp-formula><disp-formula id="pbio.1001710.e193"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pbio.1001710.e193" xlink:type="simple"/><label>(7)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e194" xlink:type="simple"/></inline-formula> is the STRF-filtered DRC for that unit. Unlike in the previous section, these two nonlinearities were not constrained to have the same values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e195" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e196" xlink:type="simple"/></inline-formula>.</p>
<p>For sigmoidal <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e197" xlink:type="simple"/></inline-formula>, and Poisson spiking, the Fisher information conveyed by the unit about <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e198" xlink:type="simple"/></inline-formula> is:<disp-formula id="pbio.1001710.e199"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pbio.1001710.e199" xlink:type="simple"/><label>(8)</label></disp-formula></p>
<p>Where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e200" xlink:type="simple"/></inline-formula>.</p>
<p>Using these equations, we estimated the expected <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e201" xlink:type="simple"/></inline-formula> over the low contrast distribution of stimuli for both <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e202" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e203" xlink:type="simple"/></inline-formula>. We generated <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e204" xlink:type="simple"/></inline-formula> samples of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e205" xlink:type="simple"/></inline-formula> values from the low contrast distribution (by filtering a long, low contrast DRC through the STRF) and calculated the expectations <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e206" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e207" xlink:type="simple"/></inline-formula> over these samples. Finally, we defined:<disp-formula id="pbio.1001710.e208"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pbio.1001710.e208" xlink:type="simple"/><label>(9)</label></disp-formula>where the logarithm removes the dependency on the maximum firing rate. Thus, this measure estimates how much more Fisher information a unit carries about low contrast stimuli when it is adapted to low contrast stimulation, compared with when it is adapted to high contrast stimulation.</p>
</sec><sec id="s4h">
<title>Population Decoding</title>
<p>Log-amplitude spectrograms of natural sounds were computed with 256 frequency bins (0.1–24 kHz) and downsampled to 5 ms time resolution. Neuronal responses were binned at 5 ms resolution to match the resolution of the spectrograms. Responses to 40 randomly selected repeats of the clean sound were set aside as a training set for the decoder.</p>
<p>We decoded the stimulus spectrogram from population responses using a dictionary approach. We made the following assumptions: (1) the responses of pairs of units, or of a given unit at two different times, were conditionally independent given the stimulus; (2) the expected firing rate of unit <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e209" xlink:type="simple"/></inline-formula> in time bin <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e210" xlink:type="simple"/></inline-formula> was a function of the recent history of stimulation—that is, of the spectrogram segment <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e211" xlink:type="simple"/></inline-formula> (where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e212" xlink:type="simple"/></inline-formula> is the full sound spectrogram, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e213" xlink:type="simple"/></inline-formula> is frequency, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e214" xlink:type="simple"/></inline-formula> is a history index, covering 20 bins—i.e., 100 ms); and (3) the observed firing rate of unit <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e215" xlink:type="simple"/></inline-formula> at time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e216" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e217" xlink:type="simple"/></inline-formula>, was the result of an inhomogeneous Poisson process, with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e218" xlink:type="simple"/></inline-formula> for some function <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e219" xlink:type="simple"/></inline-formula>. Rather than attempting to parameterize <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e220" xlink:type="simple"/></inline-formula>, we obtained maximum a posteriori estimates of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e221" xlink:type="simple"/></inline-formula> from the 40 repeats of the training data, using a conjugate prior <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e222" xlink:type="simple"/></inline-formula>. This prior ensured that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e223" xlink:type="simple"/></inline-formula> was always greater than 0.024; if <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e224" xlink:type="simple"/></inline-formula> were allowed to drop to 0, the decoder results would be skewed by units with very low average firing rates.</p>
<p>Inference consisted of calculating, for each time bin <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e225" xlink:type="simple"/></inline-formula>, the posterior distribution over spectrogram segments <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e226" xlink:type="simple"/></inline-formula>, which could have produced the responses in that bin. Because only 16 s of unique training stimuli were presented (i.e., only approximately 3,200 spectrogram segments), the log posterior over this reduced set of elements, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e227" xlink:type="simple"/></inline-formula>, could be fully computed from the responses of each unit <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e228" xlink:type="simple"/></inline-formula>, time bin <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e229" xlink:type="simple"/></inline-formula>, and repeat <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e230" xlink:type="simple"/></inline-formula> (via a uniform prior over the presented <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e231" xlink:type="simple"/></inline-formula>, assumption (3), and Bayes' rule), and then summed across units and repeats by assumption (1). A single estimate of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e232" xlink:type="simple"/></inline-formula> was then produced from the posterior mean, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e233" xlink:type="simple"/></inline-formula>.</p>
<p>Finally, it was necessary to integrate the successive binwise estimates of recent spectrogram history, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e234" xlink:type="simple"/></inline-formula>, into a single decoded spectrogram, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e235" xlink:type="simple"/></inline-formula>. This we achieved by convolution with a kernel: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e236" xlink:type="simple"/></inline-formula>. Given typical neural integration dynamics, we used exponential kernels, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e237" xlink:type="simple"/></inline-formula>. Optimal <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e238" xlink:type="simple"/></inline-formula> values were found at 25/35/100 ms for sAN/IC/AC, by maximizing <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e239" xlink:type="simple"/></inline-formula> as a function of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e240" xlink:type="simple"/></inline-formula> over a validation data set. The choice of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e241" xlink:type="simple"/></inline-formula> nevertheless had very little impact on decoder metrics (<xref ref-type="supplementary-material" rid="pbio.1001710.s009">Figure S9</xref>).</p>
<p>Spectrograms were decoded from responses to the remaining 10 repeats of the clean sounds, as well as from responses to 10 repeats from each of the noisy sound presentations.</p>
<p>To compare spectrograms <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e242" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e243" xlink:type="simple"/></inline-formula>, we calculated the mean square error (MSE) between the two, as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e244" xlink:type="simple"/></inline-formula>. We scaled these values relative to a “prior MSE,” <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e245" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e246" xlink:type="simple"/></inline-formula> is the spectrogram decoded from the prior distribution over <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e247" xlink:type="simple"/></inline-formula>, such that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e248" xlink:type="simple"/></inline-formula>. The prior MSE gives the error when a decoder has no neural responses to decode, so all stimuli in the dictionary are equally likely. We defined the decoded spectrogram similarity metric as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e249" xlink:type="simple"/></inline-formula>.</p>
<p>As described in the main text, and in <xref ref-type="fig" rid="pbio-1001710-g007">Figure 7A</xref>, the absolute fidelity of these reconstructions, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e250" xlink:type="simple"/></inline-formula>, differed between sAN, IC, and AC. Our interest was not, however, in these absolute quantities, but rather in how the reconstruction fidelity changed within a location when noise was added. We therefore calculated, for each location, the degradation of reconstruction fidelity relative to the low noise condition, via the normalized metrics, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e251" xlink:type="simple"/></inline-formula>. This uses each low noise condition as an internal control for each location. These metrics were stable with population size (<xref ref-type="supplementary-material" rid="pbio.1001710.s010">Figure S10</xref>).</p>
<p>Metrics could take negative values when reconstructions were very poor; this occurred when MSEs were worse than the prior MSE. For <xref ref-type="fig" rid="pbio-1001710-g008">Figure 8B</xref>, sAN values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e252" xlink:type="simple"/></inline-formula> were adjusted for low BI: we removed the discrepancy between inferred and actual spectrogram means via an adjusted MSE, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e253" xlink:type="simple"/></inline-formula>. Unadjusted data are shown in <xref ref-type="supplementary-material" rid="pbio.1001710.s006">Figure S6</xref>.</p>
<p>Error bounds on similarity metrics were obtained by bootstrapping. We subsampled units from the respective populations 50 times over and parameterized the bootstrapped statistics with Gaussians.</p>
<p>Several features of this decoder are worth particular mention.</p>
<p>We assumed that neural responses were conditionally independent given the stimulus. Note that this is not an assumption that neurons are wholly independent of one another (e.g., that STRFs did not overlap, or that signal correlations were 0), but rather that trial-to-trial correlations were not relevant to stimulus coding (i.e., that noise correlations were 0). Thus, though we simultaneously recorded an average of four neurons at a time per electrode penetration, we grouped all nonsimultaneously recorded data together, and discarded the trial labels. Although noise correlations do exist among auditory neurons <xref ref-type="bibr" rid="pbio.1001710-Rothschild1">[62]</xref>,<xref ref-type="bibr" rid="pbio.1001710-Sakata1">[63]</xref>, to our knowledge, there are few existing studies that successfully take this coordinated variability into account to improve high-dimensional stimulus reconstruction <xref ref-type="bibr" rid="pbio.1001710-Mesgarani2">[43]</xref>–<xref ref-type="bibr" rid="pbio.1001710-Pasley1">[45]</xref>. Here, we made the assumption of conditional independence for two reasons: (1) since our AN model had no correlated noise source, we wished to put the decoders from the three locations on an equal footing; (2) more importantly, ignoring noise correlations rendered inference far more tractable. It is nevertheless likely that, using more sophisticated decoders, absolute reconstruction fidelity would improve with noise correlations taken into account <xref ref-type="bibr" rid="pbio.1001710-Averbeck1">[64]</xref>; this has been found to be the case in recent decoding studies attempting stimulus categorization <xref ref-type="bibr" rid="pbio.1001710-Graf1">[65]</xref>,<xref ref-type="bibr" rid="pbio.1001710-Jeanne1">[66]</xref>. In building such models for reconstruction, it would also be important to address the empirical question as to how correlations between auditory neurons change as background noise is introduced into a sound <xref ref-type="bibr" rid="pbio.1001710-Graf1">[65]</xref>,<xref ref-type="bibr" rid="pbio.1001710-Adibi1">[67]</xref>.</p>
<p>Our decoder was trained on a limited set of signals, namely 40 repeats of 16 s of “clean” (20 dB SNR) sound stimulation. As a result, the output of the decoder was restricted to convex combinations of spectrogram segments from the training signals (i.e., a dictionary). The decoder was therefore not a general-purpose algorithm. Nevertheless, by design, the noisy spectrograms lay within the reconstruction space. In particular, decoding with no information (or when the decoder rates each stimulus segment as equally likely) produces the spectrogram of the added noise.</p>
<p>It is worth emphasizing that the decoder therefore had implicit knowledge of the clean signals' inherent structure, via the dictionary of spectrogram segments. In particular, this amounts to a prior on the spectrogram correlations over a 100 ms history. In general, incorporating such prior knowledge has been demonstrated to improve the performance of spectrogram reconstruction algorithms <xref ref-type="bibr" rid="pbio.1001710-Mesgarani2">[43]</xref>,<xref ref-type="bibr" rid="pbio.1001710-Ramirez1">[44]</xref>; conversely, such a strong prior as a dictionary reduces the ability to extrapolate to signals that lack this structure. Our emphasis in this work, therefore, is not on the gross performance of the decoder, but on how well its assumptions about the respective populations' encoding schemes remain robust across noise conditions. In this respect, a high similarity between <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e254" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e255" xlink:type="simple"/></inline-formula> indicates that a population encodes the noise in a noisy stimulus much like the signal in the clean stimulus (which the decoder is trained to decode). On the other hand, a high similarity between <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e256" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e257" xlink:type="simple"/></inline-formula> indicates that a population tends to encode the sound features that are common between the clean and noisy sounds.</p>
<p>Finally, it is an empirical question beyond the scope of this article as to whether the decoded responses would maintain these properties with more structured sources of background noise, or those that lay outside the training set of the decoder.</p>
</sec></sec><sec id="s5">
<title>Supporting Information</title>
<supplementary-material id="pbio.1001710.s001" mimetype="image/tiff" xlink:href="info:doi/10.1371/journal.pbio.1001710.s001" position="float" xlink:type="simple"><label>Figure S1</label><caption>
<p><bold>Increasing independence of response distributions to background noise level cannot be explained by increased modulation filtering.</bold> This figure shows a simulated experiment designed to test whether the results in <xref ref-type="fig" rid="pbio-1001710-g002">Figure 2</xref> could be explained by changes in the temporal integration properties of neurons in the auditory pathway. We constructed populations of model auditory neurons, simulated their responses to the natural sounds presented in the main text, and performed the same analysis as in <xref ref-type="fig" rid="pbio-1001710-g002">Figure 2</xref>. The populations were identical except for the parameter <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e258" xlink:type="simple"/></inline-formula>, defining the temporal integration properties of the model neurons. Further details follow, but in brief, (A) shows a general schematic for how the model neurons process sound stimuli, (B) illustrates how <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e259" xlink:type="simple"/></inline-formula> affects input signals in the model, and (C) is a direct analogue of <xref ref-type="fig" rid="pbio-1001710-g002">Figure 2C</xref>, using the model neurons. (A) Model of auditory neurons used in the simulation. This comprises two stages. The first stage is a simple model of cochlear filtering. We began with the pressure waveforms of the natural sounds used in the main text. We simulated frequency-selective cochlear channels by filtering the sound waveforms through a gammatone filterbank. This was implemented as a set of 50 IIR gammatone filters <xref ref-type="bibr" rid="pbio.1001710-Slaney1">[68]</xref>, using the Brian simulator <xref ref-type="bibr" rid="pbio.1001710-Goodman1">[69]</xref> in Python. Filter CFs were ERB-spaced between 250 Hz and 20 kHz, as in ref. <xref ref-type="bibr" rid="pbio.1001710-Glasberg1">[70]</xref>. We next extracted the amplitude envelope of each filter output, via the magnitude of the Hilbert transform. We then applied a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e260" xlink:type="simple"/></inline-formula> compressive nonlinearity to envelopes to approximate the amplitude compression that occurs at the cochlea <xref ref-type="bibr" rid="pbio.1001710-Ruggero1">[71]</xref>. In the second stage, we constructed populations of model auditory neurons, based on the output of the 50 cochlear channels. Populations were defined by the choice of a single parameter, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e261" xlink:type="simple"/></inline-formula>, which characterizes the temporal integration properties of the model neurons in each population. We assumed that each auditory neuron within a model population received input from only one peripheral channel. As a simple approximation of how the modulation-following characteristics of neurons change as one ascends the auditory pathway <xref ref-type="bibr" rid="pbio.1001710-Joris1">[1]</xref>, we low-pass filtered the inputs to these model neurons, using an 8th-order Chebyshev Type I low-pass filter, with a cutoff frequency chosen from either <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e262" xlink:type="simple"/></inline-formula> (to model AN neurons, denoted here as mAN), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e263" xlink:type="simple"/></inline-formula> (to model IC neurons, denoted here as mIC), or <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e264" xlink:type="simple"/></inline-formula> (to model cortical neurons, denoted here as mAC). Next, we passed the modulation-filtered input signal for each neuron, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e265" xlink:type="simple"/></inline-formula>, through a sigmoidal output nonlinearity. The output of this stage was a time-varying firing rate, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e266" xlink:type="simple"/></inline-formula>, from which we generated spike trains via an inhomogeneous Poisson process. Thus, for each model location (defined by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e267" xlink:type="simple"/></inline-formula>), we generated a set of spike data of the same form as that used in the main text. The model used here is equivalent to a linear-nonlinear-linear-nonlinear-Poisson (LNLNP) forward model. The gammatone filters, Hilbert envelope, and compressive nonlinearity cast the time-varying pressure signal into a 50-dimensional time series via a LN process (the first LN of the LNLN model). The second linear (L) stage was similar to that used in a STRF model: each model neuron collapsed this high-dimensional signal down to a one-dimensional time-series via a convolution with a spectro-temporal kernel. We used simple kernels: these were separable in frequency and time, sparse in the frequency domain (the weight was nonzero for only one frequency channel), and modulation low-pass in the time domain. The final nonlinear (N) stage was provided by a point nonlinearity. (B) A 1.5 s segment of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e268" xlink:type="simple"/></inline-formula>, the “within-channel intensity” (i.e., STRF-filtered input signal) of a model auditory neuron as described in (A). These were produced from a cochlear filter with a CF of 1.3 kHz, together with AN-, IC-, and AC-like modulation filtering as simulated from the model in (A). These panels parallel <xref ref-type="fig" rid="pbio-1001710-g003">Figure 3A</xref>, showing the within-channel intensity from a clean (20 dB SNR) sound (lower lines in the left panels), and that from a noisy (0 dB SNR) version of the same sound (upper lines). The mAC neuron is more modulation low-pass; fluctuations in sound intensity introduced by the noise have less energy for the mAC neuron than for the mAN fiber. (C) Statistical independence of stimulus-conditioned response distributions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e269" xlink:type="simple"/></inline-formula> to the background noise level, measured from the populations of model neurons. This panel is a direct analogue of <xref ref-type="fig" rid="pbio-1001710-g002">Figure 2C</xref>. Median values of noise independence for mAN/mIC/mAN were 0.80/0.80/0.83. Since the only factor that differentiates the mAN, mIC, and mAC populations from each other is the modulation cutoff frequency, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e270" xlink:type="simple"/></inline-formula>, this estimates that increased modulation filtering along the auditory pathway is responsible for about a third of the effect observed in the measured data in <xref ref-type="fig" rid="pbio-1001710-g002">Figure 2C</xref>. The larger differences between auditory centers observed in the main text could be obtained by simulating increased <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e271" xlink:type="simple"/></inline-formula>- and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e272" xlink:type="simple"/></inline-formula>-adaptation along the auditory pathway, as in <xref ref-type="supplementary-material" rid="pbio.1001710.s005">Figure S5</xref> (unpublished data).</p>
<p>(TIFF)</p>
</caption></supplementary-material><supplementary-material id="pbio.1001710.s002" mimetype="image/tiff" xlink:href="info:doi/10.1371/journal.pbio.1001710.s002" position="float" xlink:type="simple"><label>Figure S2</label><caption>
<p><bold>Further examples of adaptation to contrast, as shown in </bold><xref ref-type="fig" rid="pbio-1001710-g005"><bold>Figure 5B–C</bold></xref><bold>.</bold> In addition to the general trend of an increasing slope of the nonlinearity with contrast, some sAN fibers (Examples 1 and 2) underwent small shifts in mean level at lower contrast; greater effects were seen in some IC units (Examples 4 and 5). Some IC units showed other contrast-dependent changes to nonlinearities, including horizontal shifts (Example 1) and changes in saturation points (Example 3). While more complex models of contrast-dependent changes to nonlinearities were sometimes needed to characterize the behavior of IC neurons (such as the more general classes of contrast kernel models described in ref. <xref ref-type="bibr" rid="pbio.1001710-Rabinowitz2">[12]</xref>),changes in slope for IC units were, overall, smaller than in cortex, but larger than in the sAN.</p>
<p>(TIFF)</p>
</caption></supplementary-material><supplementary-material id="pbio.1001710.s003" mimetype="image/tiff" xlink:href="info:doi/10.1371/journal.pbio.1001710.s003" position="float" xlink:type="simple"><label>Figure S3</label><caption>
<p><bold>Fitted time constants for gain control at different levels of the auditory pathway.</bold> These time constants were obtained using the same stimuli and procedure as previously documented <xref ref-type="bibr" rid="pbio.1001710-Rabinowitz2">[12]</xref>. After a change in the spectral pattern of contrast of a DRC, the gain of IC and cortical units' nonlinearities changed with an approximately exponential time course, with median time constants of 35 ms in IC and 117 ms in AC. Contrast-dependent gain changes were generally weak or nonexistent in the sAN, with estimated time constants being below 25 ms (and hence not detectable with this method). Pairwise differences significant at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e273" xlink:type="simple"/></inline-formula> (rank-sum tests).</p>
<p>(TIFF)</p>
</caption></supplementary-material><supplementary-material id="pbio.1001710.s004" mimetype="image/tiff" xlink:href="info:doi/10.1371/journal.pbio.1001710.s004" position="float" xlink:type="simple"><label>Figure S4</label><caption>
<p><bold>The more uniform coverage of frequency space by the simulated AN population does not explain the decoding results in the main text.</bold> (A) Histogram of best frequencies of units in each location. (B, C) The more uniform frequency coverage by the population of sAN fibers, compared with that of the measured IC and cortical populations, could not explain the differences in normalized decoder performance shown in <xref ref-type="fig" rid="pbio-1001710-g007">Figure 7D–E</xref>. Here, we halved the sAN population in size, keeping only the simulated fibers with higher CFs (&gt;2 kHz). This produced near identical values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e274" xlink:type="simple"/></inline-formula> (B) and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e275" xlink:type="simple"/></inline-formula> (C) to the full sAN population. While these relative metrics remained unaffected, the absolute performance of the decoder for the clean sound (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e276" xlink:type="simple"/></inline-formula>) was lower for the high-CF subpopulation than the full sAN population (not shown). This is consistent with the trends shown in <xref ref-type="fig" rid="pbio-1001710-g007">Figure 7A</xref>: since the high-CF subpopulation contained only 42 simulated fibers (rather than the full 85), there was less information available for inference. However, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e277" xlink:type="simple"/></inline-formula> for the high-CF subpopulation was lower than that predicted by <xref ref-type="fig" rid="pbio-1001710-g007">Figure 7A</xref>: subpopulations of 42 randomly selected fibers (i.e., with more uniform coverage of the spectrum) yielded values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e278" xlink:type="simple"/></inline-formula> that were on average 10 percentage points higher than the high-CF subpopulation. Thus we can conclude that the greater coverage of the frequency spectrogram by the population of simulated AN fibers, compared with that of the measured IC and cortical populations, contributes to the better absolute decoder performance for the clean sound (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e279" xlink:type="simple"/></inline-formula>) in the sAN.</p>
<p>(TIFF)</p>
</caption></supplementary-material><supplementary-material id="pbio.1001710.s005" mimetype="image/tiff" xlink:href="info:doi/10.1371/journal.pbio.1001710.s005" position="float" xlink:type="simple"><label>Figure S5</label><caption>
<p><bold>Simulation of how both temporal integration and adaptation affect the population encoding of complex sounds, with and without background noise.</bold> This figure shows simulated experiments designed to test whether the results in <xref ref-type="fig" rid="pbio-1001710-g007">Figure 7D and 7E</xref> could be explained by changes in the temporal integration and/or adaptation properties of neurons in the auditory pathway. As in <xref ref-type="supplementary-material" rid="pbio.1001710.s001">Figure S1</xref>, we constructed populations of model auditory neurons, simulated their responses to the natural sounds presented in the main text, and performed the same decoding analyses as in the main text. The simulation was similar to that performed in <xref ref-type="supplementary-material" rid="pbio.1001710.s001">Figure S1</xref>, and thus followed the same schema as in <xref ref-type="supplementary-material" rid="pbio.1001710.s001">Figure S1A</xref>. However, <xref ref-type="supplementary-material" rid="pbio.1001710.s001">Figure S1</xref> only considered populations of neurons that differed in their temporal integration properties. Here, we simulated populations that also differed in the strength of their adaptation to stimulus statistics. We constructed populations of model neurons that were identical to each other, except for the value of three parameters: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e280" xlink:type="simple"/></inline-formula>, defining the temporal integration properties of the model neurons (as in the simulations in <xref ref-type="supplementary-material" rid="pbio.1001710.s001">Figure S1</xref>); <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e281" xlink:type="simple"/></inline-formula>, defining the strength of the model neurons' adaptation to the mean intensity; and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e282" xlink:type="simple"/></inline-formula>, defining the strength of the model neurons' adaptation to the stimulus contrast. Varying these parameters allowed us to test hypotheses about the factors underlying the results in <xref ref-type="fig" rid="pbio-1001710-g007">Figure 7D–E</xref>. For each population, the values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e283" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e284" xlink:type="simple"/></inline-formula> affected the operation of each neuron's sigmoidal output nonlinearity. The shapes of these output nonlinearities were allowed to vary as a function of stimulus statistics, in order to impart adaptation to the neuron. Thus, for each model location (defined by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e285" xlink:type="simple"/></inline-formula>), and each set of adaptation parameters (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e286" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e287" xlink:type="simple"/></inline-formula>), we generated a set of spike data of the same form as that used in the main text. Further details follow, but in brief: (A) illustrates how <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e288" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e289" xlink:type="simple"/></inline-formula> affect the output nonlinearities of neurons in the model; (B) shows the results of fitting these parameters to model populations under different constraints, and compares the performance of the models (symbols) directly with the observed data described in the main text (histogram bars; cf., <xref ref-type="fig" rid="pbio-1001710-g007">Figure 7D–E</xref>). (A) Adaptive output nonlinearities used in the model. Neural responses were simulated as in <xref ref-type="supplementary-material" rid="pbio.1001710.s001">Figure S1A</xref>, except that each neuron's output nonlinearities was changed for each of the 16 presented stimuli (4 unique sounds ×4 SNRs). The 3×3 grid of panels shows how different values of the parameters <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e290" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e291" xlink:type="simple"/></inline-formula> change the way a model neuron's output nonlinearities depend on stimulus statistics. The two lower panels show stimulus statistics (as in <xref ref-type="supplementary-material" rid="pbio.1001710.s001">Figure S1B</xref>) for two example sounds (red and blue), and for the ensemble of all sounds presented. The parameters <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e292" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e293" xlink:type="simple"/></inline-formula> quantify the degree to which output nonlinearities changed as a function of sound statistics (respectively, as a function of the mean of the distribution of within-channel intensities and of the standard deviation). We modeled changes in the neurons' stimulus–response relationships based on observations from experiments using synthetic stimuli (<xref ref-type="fig" rid="pbio-1001710-g005">Figures 5</xref>, <xref ref-type="supplementary-material" rid="pbio.1001710.s005">S5</xref>, <xref ref-type="supplementary-material" rid="pbio.1001710.s006">S6</xref>, and <xref ref-type="supplementary-material" rid="pbio.1001710.s010">S10</xref>; see also previous work in refs. <xref ref-type="bibr" rid="pbio.1001710-Nagel1">[9]</xref>,<xref ref-type="bibr" rid="pbio.1001710-Rabinowitz1">[10]</xref>,<xref ref-type="bibr" rid="pbio.1001710-Rabinowitz2">[12]</xref>,<xref ref-type="bibr" rid="pbio.1001710-Dean1">[20]</xref>,<xref ref-type="bibr" rid="pbio.1001710-Wen1">[36]</xref>,<xref ref-type="bibr" rid="pbio.1001710-Dean2">[72]</xref>). These data suggest that when the stimulus <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e294" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e295" xlink:type="simple"/></inline-formula> change, auditory neurons' output nonlinearities undergo compensatory shifts. This includes horizontal shifts due to changes in mean level (<xref ref-type="supplementary-material" rid="pbio.1001710.s007">Figures S7</xref> and <xref ref-type="supplementary-material" rid="pbio.1001710.s008">S8</xref>) and slope changes due to changes in stimulus variance or contrast (<xref ref-type="fig" rid="pbio-1001710-g005">Figures 5</xref> and <xref ref-type="supplementary-material" rid="pbio.1001710.s002">S2</xref>). While other changes to neurons' nonlinearities and/or spectral and temporal integration properties may also change with stimulus statistics (e.g., refs. <xref ref-type="bibr" rid="pbio.1001710-Nagel1">[9]</xref>,<xref ref-type="bibr" rid="pbio.1001710-Kvale1">[16]</xref>,<xref ref-type="bibr" rid="pbio.1001710-Dean1">[20]</xref>,<xref ref-type="bibr" rid="pbio.1001710-Wen1">[36]</xref>), we focused here on these two major effects. We used sigmoidal output nonlinearities for all model neurons, of the form <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e296" xlink:type="simple"/></inline-formula>, with a maximum firing rate of 100 spikes/s, a minimum of 0, an inflection point at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e297" xlink:type="simple"/></inline-formula>, and a natural scale (i.e., inverse gain) of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e298" xlink:type="simple"/></inline-formula>. The values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e299" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e300" xlink:type="simple"/></inline-formula> depended on <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e301" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e302" xlink:type="simple"/></inline-formula>, respectively. The extent of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e303" xlink:type="simple"/></inline-formula>-adaptation (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e304" xlink:type="simple"/></inline-formula>) was used to determine whether the parameter c was the same for all 16 sounds (4 sound identities × 4 SNRs; <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e305" xlink:type="simple"/></inline-formula>), or whether it differed across sounds (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e306" xlink:type="simple"/></inline-formula>). Likewise, the extent of <italic>σ</italic>-adaptation (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e307" xlink:type="simple"/></inline-formula>) was used to determine the extent to which <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e308" xlink:type="simple"/></inline-formula> differed across sounds. Thus <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e309" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e310" xlink:type="simple"/></inline-formula> determined how the output nonlinearity changed from sound to sound. Adaptive output nonlinearities for a given model neuron were calculated as follows. We began by calculating the within-channel intensities, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e311" xlink:type="simple"/></inline-formula> (as illustrated in <xref ref-type="supplementary-material" rid="pbio.1001710.s001">Figure S1B</xref>), for each of the 16 sounds. We denote the distributions of within-channel intensities for these 16 sounds as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e312" xlink:type="simple"/></inline-formula>; …; <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e313" xlink:type="simple"/></inline-formula>, and the distribution of within-channel intensities over the ensemble of all the sounds as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e314" xlink:type="simple"/></inline-formula>. We denote the mean and standard deviation of these distributions as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e315" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e316" xlink:type="simple"/></inline-formula>, respectively (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e317" xlink:type="simple"/></inline-formula>). Three of these distributions for the mAC neuron in (B) are illustrated in the bottom two panels of (C). In the bottom-most panel, the gray area shows <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e318" xlink:type="simple"/></inline-formula>, the black dashed vertical line shows <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e319" xlink:type="simple"/></inline-formula>, and the thick black horizontal line shows <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e320" xlink:type="simple"/></inline-formula>. In the second bottom panel, red and blue areas (and lines) show the respective distributions from two individual sounds within the ensemble. For brevity, we refer to these two examples here as the red and the blue sound. Next, the nonlinearity parameters <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e321" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e322" xlink:type="simple"/></inline-formula> were calculated for sound <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e323" xlink:type="simple"/></inline-formula> as:<disp-formula id="pbio.1001710.e324"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pbio.1001710.e324" xlink:type="simple"/><label>(10)</label></disp-formula><disp-formula id="pbio.1001710.e325"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pbio.1001710.e325" xlink:type="simple"/><label>(11)</label></disp-formula>The top left grid panel in (A) shows the output nonlinearity for a model neuron with no <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e326" xlink:type="simple"/></inline-formula>- or <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e327" xlink:type="simple"/></inline-formula>- adaptation—that is, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e328" xlink:type="simple"/></inline-formula>. Here, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e329" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e330" xlink:type="simple"/></inline-formula>, which are both independent of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e331" xlink:type="simple"/></inline-formula>. This model neuron thus has a fixed output nonlinearity (black line) that is independent of stimulus statistics. Vertical dashed lines show the means of the distributions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e332" xlink:type="simple"/></inline-formula> for the ensemble, red, and blue sounds. This fixed output nonlinearity is shadowed in gray for reference in the remaining eight panels in the grid. The bottom left grid panel shows the output nonlinearities for the red and blue sounds for a model neuron with 100% <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e333" xlink:type="simple"/></inline-formula>-adaptation and 0% <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e334" xlink:type="simple"/></inline-formula>-adaptation (i.e., <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e335" xlink:type="simple"/></inline-formula> = 1, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e336" xlink:type="simple"/></inline-formula> = 0). This neuron has <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e337" xlink:type="simple"/></inline-formula>, so it adapts its coding for sound <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e338" xlink:type="simple"/></inline-formula> so that the inflection point of its nonlinearity is centered around <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e339" xlink:type="simple"/></inline-formula>. The top right grid panel shows the output nonlinearities for the red and blue sounds for a model neuron with 0% <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e340" xlink:type="simple"/></inline-formula>-adaptation and 100% <italic>σ</italic>-adaptation (i.e., <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e341" xlink:type="simple"/></inline-formula> = 0, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e342" xlink:type="simple"/></inline-formula> = 1). This model neuron has <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e343" xlink:type="simple"/></inline-formula>, so it adapts its coding for sound <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e344" xlink:type="simple"/></inline-formula> by changing its slope to match the width of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e345" xlink:type="simple"/></inline-formula>. The remaining grid panels show how other example values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e346" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e347" xlink:type="simple"/></inline-formula> affect output nonlinearities when coding the red and blue sounds. Intermediate values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e348" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e349" xlink:type="simple"/></inline-formula> yield only partial adaptations of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e350" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e351" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e352" xlink:type="simple"/></inline-formula>. In total, we simulated model neurons with values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e353" xlink:type="simple"/></inline-formula> ranging from 0% to 100% in 5% increments, and the same for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e354" xlink:type="simple"/></inline-formula>; thus, this grid exemplifies only 9 of the 441 pairs of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e355" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e356" xlink:type="simple"/></inline-formula> values. (B) Our goal was to determine the extent to which the three factors—differences in modulation filtering (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e357" xlink:type="simple"/></inline-formula>), adaptation to the stimulus mean level (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e358" xlink:type="simple"/></inline-formula>), and adaptation to the stimulus contrast (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e359" xlink:type="simple"/></inline-formula>)—could account for the observations presented in <xref ref-type="fig" rid="pbio-1001710-g007">Figure 7D</xref> (the apparent shift from representing <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e360" xlink:type="simple"/></inline-formula> towards representing <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e361" xlink:type="simple"/></inline-formula>) and <xref ref-type="fig" rid="pbio-1001710-g007">Figure 7E</xref> (the increased noise-tolerance in decoding <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e362" xlink:type="simple"/></inline-formula>). To do so, we determined the values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e363" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e364" xlink:type="simple"/></inline-formula> for a model AN population (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e365" xlink:type="simple"/></inline-formula> = 750 Hz), a model IC population (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e366" xlink:type="simple"/></inline-formula> = 95 Hz), and a model AC population (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e367" xlink:type="simple"/></inline-formula> = 24 Hz), which produced representations of natural sounds best matched to the observations in <xref ref-type="fig" rid="pbio-1001710-g007">Figure 7D–E</xref>. We fitted <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e368" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e369" xlink:type="simple"/></inline-formula> under five different sets of constraints (shown here as separate rows), to test whether and how each of the three parameters (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e370" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e371" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e372" xlink:type="simple"/></inline-formula>) contributed to these results. For each experiment, the observed data from <xref ref-type="fig" rid="pbio-1001710-g007">Figure 7D</xref> are shown as the histogram bars in the middle column, and the observed data from <xref ref-type="fig" rid="pbio-1001710-g007">Figure 7E</xref> are shown as the histogram bars in the right column. The symbols in these two columns show the values of these metrics obtained from modeling. The left columns show fitted values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e373" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e374" xlink:type="simple"/></inline-formula>, as explained below. As these experiments required extensive simulation, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e375" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e376" xlink:type="simple"/></inline-formula> were calculated to 5% precision. We present five experiments here as separate rows. In the first experiment, nonlinearities were fixed (i.e., there was no adaptation; <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e377" xlink:type="simple"/></inline-formula>). Here, mAN/mIC/mAC populations differed only by their values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e378" xlink:type="simple"/></inline-formula>. In the second experiment, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e379" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e380" xlink:type="simple"/></inline-formula> were free to vary, but were each constrained to be identical across the mAN, mIC, and mAC populations (giving a model with two free parameters). As in the first experiment, the three populations differed only in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e381" xlink:type="simple"/></inline-formula>. We allowed <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e382" xlink:type="simple"/></inline-formula> to vary between the three populations in the third experiment (4 free parameters), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e383" xlink:type="simple"/></inline-formula> to vary between the three populations in the fourth experiment (4 free parameters), and both to vary across location in the fifth experiment (6 free parameters). In each case, we fitted the free parameters to minimize the total squared error between the 18 data points in <xref ref-type="fig" rid="pbio-1001710-g007">Figure 7D and 7E</xref> (as obtained from IC and cortical recordings, and from the full AN simulation), and the model populations' values of these metrics. These are shown in middle and right columns of each row (histogram bars show observed values; symbols show model values). The best fit values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e384" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e385" xlink:type="simple"/></inline-formula> are shown in the left column. First row, in the absence of adaptive coding, differences in modulation tuning could not account for the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e386" xlink:type="simple"/></inline-formula> shift, nor the increased noise-tolerance of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e387" xlink:type="simple"/></inline-formula> coding. These data do show an important reference: in the absence of adaptation, populations of auditory neurons would encode <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e388" xlink:type="simple"/></inline-formula> rather than <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e389" xlink:type="simple"/></inline-formula> (middle panel). Second row, in the presence of adaptive coding, differences in modulation tuning partially contribute towards increased noise-tolerance of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e390" xlink:type="simple"/></inline-formula> encoding from periphery to cortex, but are not sufficient to explain the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e391" xlink:type="simple"/></inline-formula> shift. Third row, allowing the strength of adaptation to stimulus mean (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e392" xlink:type="simple"/></inline-formula>) to take different values for the model AN, IC, and AC populations was sufficient to explain the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e393" xlink:type="simple"/></inline-formula> shift, but not the increased noise-tolerance of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e394" xlink:type="simple"/></inline-formula> encoding. Fourth row, allowing the strength of adaptation to stimulus contrast (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e395" xlink:type="simple"/></inline-formula>) to take different values for the mAN, mIC, and mAC populations was sufficient to explain the increased noise-tolerance of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e396" xlink:type="simple"/></inline-formula> encoding, but not the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e397" xlink:type="simple"/></inline-formula> shift. Bottom row, allowing both the strength of adaptation to stimulus mean and stimulus contrast to change for each model population can explain the results observed in <xref ref-type="fig" rid="pbio-1001710-g007">Figure 7D and 7E</xref>. This analysis predicts that both the strength of adaptation to the stimulus mean (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e398" xlink:type="simple"/></inline-formula>) and the strength of adaptation to its contrast (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e399" xlink:type="simple"/></inline-formula>) should increase from the AN to the IC to the cortex.</p>
<p>(TIFF)</p>
</caption></supplementary-material><supplementary-material id="pbio.1001710.s006" mimetype="image/tiff" xlink:href="info:doi/10.1371/journal.pbio.1001710.s006" position="float" xlink:type="simple"><label>Figure S6</label><caption>
<p><bold>Adjusted </bold><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e400" xlink:type="simple"/></inline-formula><bold> for sAN units in </bold><xref ref-type="fig" rid="pbio-1001710-g008"><bold>Figure 8B</bold></xref><bold>.</bold> The results of <xref ref-type="fig" rid="pbio-1001710-g008">Figure 8B</xref> show the relationship between the strength of <italic>σ</italic>-adaptation and the noise-tolerance of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e401" xlink:type="simple"/></inline-formula> encoding. However, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e402" xlink:type="simple"/></inline-formula> is also affected by BI (<xref ref-type="fig" rid="pbio-1001710-g008">Figure 8A</xref>). Because the sAN units had low BI (<xref ref-type="fig" rid="pbio-1001710-g004">Figure 4B</xref>), decoding the responses of the sAN population to noisy sounds produced spectrograms that included the noise present in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e403" xlink:type="simple"/></inline-formula> but not <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e404" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pbio-1001710-g006">Figure 6</xref>); as a result, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e405" xlink:type="simple"/></inline-formula> was even lower for the sAN. Therefore, to elucidate the relationship between <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e406" xlink:type="simple"/></inline-formula>-adaptation and the noise-tolerance of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e407" xlink:type="simple"/></inline-formula> encoding, we compensated for the low BI of sAN units in that figure. As described in <xref ref-type="sec" rid="s4">Materials and Methods</xref>, this involved using a baseline-corrected similarity metric, which ignored the difference in mean between the decoded and clean spectrograms. Here, we show the effect of that compensation on <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e408" xlink:type="simple"/></inline-formula>. Pluses show the uncorrected metric for the sAN; stars show the corrected metrics as in <xref ref-type="fig" rid="pbio-1001710-g008">Figure 8B</xref>. The correction had little to no impact on <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e409" xlink:type="simple"/></inline-formula> for IC and cortical subpopulations; for the IC and AC data points on this plot, the difference between corrected and uncorrected metrics differed by an average of 0.5% (and hence are not depicted).</p>
<p>(TIFF)</p>
</caption></supplementary-material><supplementary-material id="pbio.1001710.s007" mimetype="image/tiff" xlink:href="info:doi/10.1371/journal.pbio.1001710.s007" position="float" xlink:type="simple"><label>Figure S7</label><caption>
<p><bold>A separate set of experiments characterizing adaptation to the mean stimulus intensity in sAN, IC, and AC neurons.</bold> (A) Schematic of a LN model. In this experiment, we probed auditory neurons using DRC stimuli. As in the experiment presented in <xref ref-type="fig" rid="pbio-1001710-g005">Figure 5</xref>, these were constructed as superpositions of tones, whose time-varying levels, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e410" xlink:type="simple"/></inline-formula>, were drawn from particular distributions (shown in B). The transformation of the sound into a time-varying spike rate (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e411" xlink:type="simple"/></inline-formula>) is modeled as a two-stage procedure: first, the sound spectrogram (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e412" xlink:type="simple"/></inline-formula>; top and bottom; colors denote tone level) is filtered through a linear STRF. This reduces the large dimensionality of the input space to a 1D time-varying signal, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e413" xlink:type="simple"/></inline-formula>. Second, this signal is passed through a sigmoidal output nonlinearity, yielding the firing rate (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e414" xlink:type="simple"/></inline-formula>). (B) Statistics of the DRCs were controlled by varying the distribution of tone levels, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e415" xlink:type="simple"/></inline-formula>. In this set of experiments, the mean (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e416" xlink:type="simple"/></inline-formula>) of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e417" xlink:type="simple"/></inline-formula> was varied (cf., the experiment shown in <xref ref-type="fig" rid="pbio-1001710-g005">Figure 5</xref>, where the width of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e418" xlink:type="simple"/></inline-formula> was varied). (C) For each unit, the distribution of STRF-filtered DRCs, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e419" xlink:type="simple"/></inline-formula>, depends on the distributions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e420" xlink:type="simple"/></inline-formula> shown in (B). (D) Illustration of a fixed output nonlinearity for an idealized neuron with no adaptation to the mean. The two colors show the portion of the nonlinearity that would be explored by the stimulus distributions shown in (B) and (C). (E) Illustration of two output nonlinearities for an idealized neuron with complete (dynamic-range) adaptation to the mean. This neuron no longer has a single fixed output nonlinearity; rather, the nonlinearity is horizontally shifted to cover the presented range of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e421" xlink:type="simple"/></inline-formula> values. (F) Data from example units in each location. These show how output nonlinearities change as the mean tone level (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e422" xlink:type="simple"/></inline-formula>) changed. STRFs (insets) range from 0.5 kHz to 22.6 kHz on the frequency (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e423" xlink:type="simple"/></inline-formula>) axis, and are shown over only 100 ms of the 200 ms history (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e424" xlink:type="simple"/></inline-formula>) at 25 ms resolution. Colors denote nonlinearities in different mean-level conditions; corresponding distributions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e425" xlink:type="simple"/></inline-formula> shown below. For the example AN fiber, there is (approximately) a single output nonlinearity that remains relatively unchanged as a function of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e426" xlink:type="simple"/></inline-formula>; in the example IC and cortical units, output nonlinearities undergo considerable horizontal shifts as a function of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e427" xlink:type="simple"/></inline-formula>. Further examples shown in <xref ref-type="supplementary-material" rid="pbio.1001710.s008">Figure S8</xref>. (G) Nonlinearities in (F), replotted as a function of normalized <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e428" xlink:type="simple"/></inline-formula> coordinates. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e429" xlink:type="simple"/></inline-formula>-adaptation induces a shift away from the encoding of the unnormalized signal, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e430" xlink:type="simple"/></inline-formula>, in the periphery, towards the encoding of the normalized signal, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e431" xlink:type="simple"/></inline-formula>, in IC and cortex. (H) Histogram of the degree of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e432" xlink:type="simple"/></inline-formula>-adaptation in each location. This was measured by fitting a single sigmoid for all the output nonlinearities, with a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e433" xlink:type="simple"/></inline-formula>-dependent inflection point:<disp-formula id="pbio.1001710.e434"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pbio.1001710.e434" xlink:type="simple"/><label>(12)</label></disp-formula><disp-formula id="pbio.1001710.e435"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pbio.1001710.e435" xlink:type="simple"/><label>(13)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e999" xlink:type="simple"/></inline-formula> is expectation over the distribution of STRF-filtered signals. Here, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e436" xlink:type="simple"/></inline-formula> measures the horizontal displacement of the curve. A value of 0% (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e437" xlink:type="simple"/></inline-formula>) indicates an independent encoding of the unnormalized variable, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e438" xlink:type="simple"/></inline-formula>. A value of 100% (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e439" xlink:type="simple"/></inline-formula>) indicates complete compensation for mean level. The median shift was 7% for the simulated AN units (<italic>n</italic> = 85), 101% for the recorded IC units (<italic>n</italic> = 32), and 100% for the cortical data (<italic>n</italic> = 287). The difference between IC and AC was not significant (rank-sum test; <italic>p</italic>&gt;0.5), but the differences between AN and IC/AC were (<italic>p</italic>&lt;10<sup>−6</sup>). As these data were collected from different units from the natural sound study described in the main text, we could not compare the magnitude of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e440" xlink:type="simple"/></inline-formula>-dependent shift in output nonlinearities with the decoder metrics.</p>
<p>(TIFF)</p>
</caption></supplementary-material><supplementary-material id="pbio.1001710.s008" mimetype="image/tiff" xlink:href="info:doi/10.1371/journal.pbio.1001710.s008" position="float" xlink:type="simple"><label>Figure S8</label><caption>
<p><bold>Further examples of adaptation to mean tone level, as shown in <xref ref-type="supplementary-material" rid="pbio.1001710.s007">Figure S7F</xref>–G.</bold> (A) Output nonlinearities for five example sAN fibers (left), five IC units (middle), and five cortical units (right). Insets show units' STRFs, as in <xref ref-type="fig" rid="pbio-1001710-g005">Figure 5B</xref>. For each example, top panel shows the fitted output nonlinearities for DRCs presented at different mean levels. All DRCs were constructed of pure tones; tones had levels drawn from a uniform distribution with halfwidth <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e441" xlink:type="simple"/></inline-formula> dB, and means of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e442" xlink:type="simple"/></inline-formula> dB SPL (orange), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e443" xlink:type="simple"/></inline-formula> dB SPL (green), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e444" xlink:type="simple"/></inline-formula> dB SPL (blue), or <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e445" xlink:type="simple"/></inline-formula> dB SPL (purple). Three to four of these conditions were usually presented for each unit; some IC units were only tested with two <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e446" xlink:type="simple"/></inline-formula> conditions. Using the LN model shown in <xref ref-type="supplementary-material" rid="pbio.1001710.s007">Figure S7A</xref>, the DRC stimuli produced from each of these tone-level distributions are filtered through units' STRFs to produce time-varying signals, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e447" xlink:type="simple"/></inline-formula>. The statistics of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e448" xlink:type="simple"/></inline-formula> for each condition are a function of the coefficients in the STRF. Thus, the distributions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e449" xlink:type="simple"/></inline-formula> vary from unit to unit in a number of ways. For example, STRFs dominated by a single coefficient (e.g., sAN Example 4, IC Example 1) have more uniform-like <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e450" xlink:type="simple"/></inline-formula>, while STRFs with a large number of nonzero coefficients are more Gaussian-like (e.g., most cortical units). Also, the net balance between excitatory (red) and inhibitory (blue) coefficients of the STRF determine how increasing <italic>μ</italic> changes the mean of the distribution <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e451" xlink:type="simple"/></inline-formula>. With more excitation in the STRF (most examples), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e452" xlink:type="simple"/></inline-formula> increased for larger<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e453" xlink:type="simple"/></inline-formula>; with more inhibition, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e454" xlink:type="simple"/></inline-formula> decreased for larger <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e455" xlink:type="simple"/></inline-formula> (AC Examples 1, 4, and 5). In a small number of cases, excitation and inhibition were approximately equal (AC Example 2), such that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e456" xlink:type="simple"/></inline-formula> did not change considerably with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e457" xlink:type="simple"/></inline-formula>. (B) Output nonlinearities for the units in (A), replotted as a function of normalized coefficients, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e458" xlink:type="simple"/></inline-formula>, as in <xref ref-type="supplementary-material" rid="pbio.1001710.s007">Figure S7G</xref>. As in <xref ref-type="fig" rid="pbio-1001710-g005">Figure 5B–C</xref>, output nonlinearities were generally independent of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e459" xlink:type="simple"/></inline-formula> in the sAN, but changed considerably with mean level in the IC and cortex. The trend was such that in these higher stages of the pathway, responses were better described as a function of normalized coefficients. While differences in the shape of nonlinearities often arose in IC and cortex from changing <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e460" xlink:type="simple"/></inline-formula> (e.g., IC Example 5, AC Example 3), a simple horizontal shift in nonlinearities usually described a major component of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e461" xlink:type="simple"/></inline-formula>-dependent changes.</p>
<p>(TIFF)</p>
</caption></supplementary-material><supplementary-material id="pbio.1001710.s009" mimetype="image/tiff" xlink:href="info:doi/10.1371/journal.pbio.1001710.s009" position="float" xlink:type="simple"><label>Figure S9</label><caption>
<p><bold>Differences in decoder performance were not the result of the time constants used to reconstruct spectrograms.</bold> As described in <xref ref-type="sec" rid="s4">Materials and Methods</xref>, the decoder constructs an estimate of the recent spectrogram history for each 5 ms bin. In order to integrate these successive estimates into a single decoded spectrogram, we convolved the set of estimates with exponential kernels, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e462" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e463" xlink:type="simple"/></inline-formula> ms for sAN, 35 ms for IC, and 100 ms for AC. Here, similarity metrics as used in the main text are shown for values of <italic>τ</italic> ranging from 5 ms to 100 ms. As in <xref ref-type="fig" rid="pbio-1001710-g007">Figure 7</xref>, shaded regions show 95% confidence intervals. Filled circles show the <italic>τ</italic> values used in the main text; these were chosen to maximize <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e464" xlink:type="simple"/></inline-formula> for each location. However, values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e465" xlink:type="simple"/></inline-formula> between 25 ms and 100 ms produced very similar results for all locations.</p>
<p>(TIFF)</p>
</caption></supplementary-material><supplementary-material id="pbio.1001710.s010" mimetype="image/tiff" xlink:href="info:doi/10.1371/journal.pbio.1001710.s010" position="float" xlink:type="simple"><label>Figure S10</label><caption>
<p><bold>Stability of metrics with increasing population size.</bold> In <xref ref-type="fig" rid="pbio-1001710-g007">Figure 7A</xref>, we show that the values of the decoder metric <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e466" xlink:type="simple"/></inline-formula> generally increased as more units were included in the analysis. Here, we show how the normalized metrics (A) <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e467" xlink:type="simple"/></inline-formula>, (B) <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e468" xlink:type="simple"/></inline-formula>, and (C) <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e469" xlink:type="simple"/></inline-formula> converged to stable values as the number of units included in the analysis was increased. Thus, the differences across location in the normalized decoder metrics shown in <xref ref-type="fig" rid="pbio-1001710-g007">Figure 7D–E</xref> are not the result of differences in the absolute fidelity of the decoding.</p>
<p>(TIFF)</p>
</caption></supplementary-material><supplementary-material id="pbio.1001710.s011" mimetype="application/pdf" xlink:href="info:doi/10.1371/journal.pbio.1001710.s011" position="float" xlink:type="simple"><label>Table S1</label><caption>
<p><bold>Contributions of increasing BI and CI along the auditory pathway to the results in </bold><xref ref-type="fig" rid="pbio-1001710-g008"><bold>Figure 8</bold></xref><bold>.</bold> In <xref ref-type="fig" rid="pbio-1001710-g008">Figure 8A</xref>, we demonstrate that the shift from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e470" xlink:type="simple"/></inline-formula>-representations in the sAN population to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e471" xlink:type="simple"/></inline-formula>-representations in the AC population can largely be explained by an increase in neurons' BI along the auditory pathway. In <xref ref-type="fig" rid="pbio-1001710-g008">Figure 8B</xref>, we demonstrate that the increasing robustness of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e472" xlink:type="simple"/></inline-formula> encoding can largely be explained by an increase in neurons' contrast invariance along the auditory pathway. This table documents the statistics for these two figures (A for <xref ref-type="fig" rid="pbio-1001710-g008">Figure 8A</xref>; B for <xref ref-type="fig" rid="pbio-1001710-g008">Figure 8B</xref>). The percentages shown quantify the contributions of BI and CI toward explaining the differences between the decoder metrics across locations. The values are relative effect sizes within a general linear model. They were calculated by fitting a set of multiple linear regression models (ANCOVA) to (A) the data points in <xref ref-type="fig" rid="pbio-1001710-g008">Figure 8A</xref> (where the decoder metric is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e473" xlink:type="simple"/></inline-formula>) and (B) <xref ref-type="fig" rid="pbio-1001710-g008">Figure 8B</xref> (where the decoder metric is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e474" xlink:type="simple"/></inline-formula>). The first row of the table considers only the differences between sAN and IC data (for each of A and B, <italic>n</italic>  =  24 data points  =  3 SNRs × 4 subpopulations × 2 locations); the second row considers only the differences between IC and AC data (24 data points); while the third row considers the differences across all three locations (36 data points). To calculate relative effect sizes for (A), we fitted the following four linear models:<disp-formula id="pbio.1001710.e475"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pbio.1001710.e475" xlink:type="simple"/><label>(14)</label></disp-formula><disp-formula id="pbio.1001710.e476"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pbio.1001710.e476" xlink:type="simple"/><label>(15)</label></disp-formula><disp-formula id="pbio.1001710.e477"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pbio.1001710.e477" xlink:type="simple"/><label>(16)</label></disp-formula><disp-formula id="pbio.1001710.e478"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pbio.1001710.e478" xlink:type="simple"/><label>(17)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e479" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e480" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e481" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e482" xlink:type="simple"/></inline-formula> are categorical variables. Model <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e483" xlink:type="simple"/></inline-formula> is the reference model; model <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e484" xlink:type="simple"/></inline-formula> adds BI as an explanatory variable, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e485" xlink:type="simple"/></inline-formula> adds CI, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e486" xlink:type="simple"/></inline-formula> captures across-location differences that remain unexplained by BI and CI. Denoting the residual variance for model <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e487" xlink:type="simple"/></inline-formula> as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e488" xlink:type="simple"/></inline-formula>, the relative effect size of BI was calculated as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e489" xlink:type="simple"/></inline-formula>. The relative effect size of CI was calculated as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e490" xlink:type="simple"/></inline-formula>. The unexplained portion was calculated as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pbio.1001710.e491" xlink:type="simple"/></inline-formula>. The procedure for calculating relative effect sizes for (B) was identical, except the order of adding BI and CI to the multiple linear regression model was reversed.</p>
<p>(PDF)</p>
</caption></supplementary-material></sec></body>
<back>
<ack>
<p>We are grateful to Sandra Tolnai for assistance with data collection. We also would like to thank Fernando Nodal for his helpful contributions to the surgical preparations.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pbio.1001710-Joris1"><label>1</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Joris</surname><given-names>PX</given-names></name>, <name name-style="western"><surname>Schreiner</surname><given-names>CE</given-names></name>, <name name-style="western"><surname>Rees</surname><given-names>A</given-names></name> (<year>2004</year>) <article-title>Neural processing of amplitude-modulated sounds</article-title>. <source>Physiol Rev</source> <volume>84</volume>: <fpage>541</fpage>–<lpage>577</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Young1"><label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Young</surname><given-names>ED</given-names></name> (<year>2008</year>) <article-title>Neural representation of spectral and temporal information in speech</article-title>. <source>Philos Trans R Soc Lond B Biol Sci</source> <volume>363</volume>: <fpage>923</fpage>–<lpage>945</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Schreiner1"><label>3</label>
<mixed-citation publication-type="book" xlink:type="simple">Schreiner CE, Froemke RC, Atencio CA (2011) Spectral processing in auditory cortex. In: Winer JA, Schreiner CE, editors, The auditory cortex, Springer. pp. 275–308.</mixed-citation>
</ref>
<ref id="pbio.1001710-Formisano1"><label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Formisano</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Martino</surname><given-names>FD</given-names></name>, <name name-style="western"><surname>Bonte</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Goebel</surname><given-names>R</given-names></name> (<year>2008</year>) <article-title>“Who” is saying “what”? brain-based decoding of human voice and speech</article-title>. <source>Science</source> <volume>322</volume>: <fpage>970</fpage>–<lpage>973</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Okada1"><label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Okada</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Rong</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Venezia</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Matchin</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Hsieh</surname><given-names>IH</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>Hierarchical organization of human auditory cortex: evidence from acoustic invariance in the response to intelligible speech</article-title>. <source>Cereb Cortex</source> <volume>20</volume>: <fpage>2486</fpage>–<lpage>2495</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Chang1"><label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chang</surname><given-names>EF</given-names></name>, <name name-style="western"><surname>Rieger</surname><given-names>JW</given-names></name>, <name name-style="western"><surname>Johnson</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Berger</surname><given-names>MS</given-names></name>, <name name-style="western"><surname>Barbaro</surname><given-names>NM</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>Categorical speech representation in human superior temporal gyrus</article-title>. <source>Nat Neurosci</source> <volume>13</volume>: <fpage>1428</fpage>–<lpage>1432</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Ding1"><label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ding</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Simon</surname><given-names>JZ</given-names></name> (<year>2012</year>) <article-title>Emergence of neural encoding of auditory objects while listening to competing speakers</article-title>. <source>Proc Natl Acad Sci</source> <volume>109</volume>: <fpage>11854</fpage>–<lpage>11859</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Ding2"><label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ding</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Simon</surname><given-names>JZ</given-names></name> (<year>2013</year>) <article-title>Adaptive temporal encoding leads to a background-insensitive cortical representation of speech</article-title>. <source>J Neurosci</source> <volume>33</volume>: <fpage>5728</fpage>–<lpage>5735</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Nagel1"><label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nagel</surname><given-names>KI</given-names></name>, <name name-style="western"><surname>Doupe</surname><given-names>AJ</given-names></name> (<year>2006</year>) <article-title>Temporal processing and adaptation in the songbird auditory forebrain</article-title>. <source>Neuron</source> <volume>51</volume>: <fpage>845</fpage>–<lpage>859</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Rabinowitz1"><label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rabinowitz</surname><given-names>NC</given-names></name>, <name name-style="western"><surname>Willmore</surname><given-names>BD</given-names></name>, <name name-style="western"><surname>Schnupp</surname><given-names>JW</given-names></name>, <name name-style="western"><surname>King</surname><given-names>AJ</given-names></name> (<year>2011</year>) <article-title>Contrast gain control in auditory cortex</article-title>. <source>Neuron</source> <volume>70</volume>: <fpage>1178</fpage>–<lpage>1191</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Sharpee1"><label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sharpee</surname><given-names>TO</given-names></name>, <name name-style="western"><surname>Nagel</surname><given-names>KI</given-names></name>, <name name-style="western"><surname>Doupe</surname><given-names>AJ</given-names></name> (<year>2011</year>) <article-title>Two-dimensional adaptation in the auditory forebrain</article-title>. <source>J Neurophysiol</source> <volume>106</volume>: <fpage>1841</fpage>–<lpage>1861</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Rabinowitz2"><label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rabinowitz</surname><given-names>NC</given-names></name>, <name name-style="western"><surname>Willmore</surname><given-names>BDB</given-names></name>, <name name-style="western"><surname>Schnupp</surname><given-names>JWH</given-names></name>, <name name-style="western"><surname>King</surname><given-names>AJ</given-names></name> (<year>2012</year>) <article-title>Spectrotemporal contrast kernels for neurons in primary auditory cortex</article-title>. <source>J Neurosci</source> <volume>32</volume>: <fpage>11271</fpage>–<lpage>11284</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Rees1"><label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rees</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Møller</surname><given-names>AR</given-names></name> (<year>1987</year>) <article-title>Stimulus properties influencing the responses of inferior colliculus neurons to amplitude-modulated sounds</article-title>. <source>Hear Res</source> <volume>27</volume>: <fpage>129</fpage>–<lpage>143</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Rees2"><label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rees</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Palmer</surname><given-names>AR</given-names></name> (<year>1989</year>) <article-title>Neuronal responses to amplitude-modulated and pure-tone stimuli in the guinea pig inferior colliculus, and their modification by broadband noise</article-title>. <source>J Acoust Soc Am</source> <volume>85</volume>: <fpage>1978</fpage>–<lpage>1994</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Krishna1"><label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Krishna</surname><given-names>BS</given-names></name>, <name name-style="western"><surname>Semple</surname><given-names>MN</given-names></name> (<year>2000</year>) <article-title>Auditory temporal processing: responses to sinusoidally amplitude modulated tones in the inferior colliculus</article-title>. <source>J Neurophysiol</source> <volume>84</volume>: <fpage>255</fpage>–<lpage>273</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Kvale1"><label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kvale</surname><given-names>MN</given-names></name>, <name name-style="western"><surname>Schreiner</surname><given-names>CE</given-names></name> (<year>2004</year>) <article-title>Short-term adaptation of auditory receptive fields to dynamic stimuli</article-title>. <source>J Neurophysiol</source> <volume>91</volume>: <fpage>604</fpage>–<lpage>612</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Lesica1"><label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lesica</surname><given-names>NA</given-names></name>, <name name-style="western"><surname>Grothe</surname><given-names>B</given-names></name> (<year>2008</year>) <article-title>Efficient temporal processing of naturalistic sounds</article-title>. <source>PLoS ONE</source> <volume>3</volume>: <fpage>e1655</fpage> <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0001655" xlink:type="simple">10.1371/journal.pone.0001655</ext-link></comment></mixed-citation>
</ref>
<ref id="pbio.1001710-Blake1"><label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Blake</surname><given-names>DT</given-names></name>, <name name-style="western"><surname>Merzenich</surname><given-names>MM</given-names></name> (<year>2002</year>) <article-title>Changes of AI receptive fields with sound density</article-title>. <source>J Neurophysiol</source> <volume>88</volume>: <fpage>3409</fpage>–<lpage>3420</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Valentine1"><label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Valentine</surname><given-names>PA</given-names></name>, <name name-style="western"><surname>Eggermont</surname><given-names>JJ</given-names></name> (<year>2004</year>) <article-title>Stimulus dependence of spectro-temporal receptive fields in cat primary auditory cortex</article-title>. <source>Hear Res</source> <volume>196</volume>: <fpage>119</fpage>–<lpage>133</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Dean1"><label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dean</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Harper</surname><given-names>NS</given-names></name>, <name name-style="western"><surname>McAlpine</surname><given-names>D</given-names></name> (<year>2005</year>) <article-title>Neural population coding of sound level adapts to stimulus statistics</article-title>. <source>Nat Neurosci</source> <volume>8</volume>: <fpage>1684</fpage>–<lpage>1689</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Watkins1"><label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Watkins</surname><given-names>PV</given-names></name>, <name name-style="western"><surname>Barbour</surname><given-names>DL</given-names></name> (<year>2008</year>) <article-title>Specialized neuronal adaptation for preserving input sensitivity</article-title>. <source>Nat Neurosci</source> <volume>11</volume>: <fpage>1259</fpage>–<lpage>1261</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-BarYosef1"><label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bar-Yosef</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Rotman</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Nelken</surname><given-names>I</given-names></name> (<year>2002</year>) <article-title>Responses of neurons in cat primary auditory cortex to bird chirps: effects of temporal and spectral context</article-title>. <source>J Neurosci</source> <volume>22</volume>: <fpage>8619</fpage>–<lpage>8632</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-BarYosef2"><label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bar-Yosef</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Nelken</surname><given-names>I</given-names></name> (<year>2007</year>) <article-title>The effects of background noise on the neural responses to natural sounds in cat primary auditory cortex</article-title>. <source>Front Comp Neurosci</source> <volume>1</volume>: <fpage>3</fpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Escab1"><label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Escabí</surname><given-names>MA</given-names></name>, <name name-style="western"><surname>Miller</surname><given-names>LM</given-names></name>, <name name-style="western"><surname>Read</surname><given-names>HL</given-names></name>, <name name-style="western"><surname>Schreiner</surname><given-names>CE</given-names></name> (<year>2003</year>) <article-title>Naturalistic auditory contrast improves spectrotemporal coding in the cat inferior colliculus</article-title>. <source>J Neurosci</source> <volume>23</volume>: <fpage>11489</fpage>–<lpage>11504</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Shetake1"><label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shetake</surname><given-names>JA</given-names></name>, <name name-style="western"><surname>Wolf</surname><given-names>JT</given-names></name>, <name name-style="western"><surname>Cheung</surname><given-names>RJ</given-names></name>, <name name-style="western"><surname>Engineer</surname><given-names>CT</given-names></name>, <name name-style="western"><surname>Ram</surname><given-names>SK</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <article-title>Cortical activity patterns predict robust speech discrimination ability in noise</article-title>. <source>Eur J Neurosci</source> <volume>34</volume>: <fpage>1823</fpage>–<lpage>1838</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Mesgarani1"><label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mesgarani</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Chang</surname><given-names>EF</given-names></name> (<year>2012</year>) <article-title>Selective cortical representation of attended speaker in multi-talker speech perception</article-title>. <source>Nature</source> <volume>485</volume>: <fpage>233</fpage>–<lpage>236</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Zilany1"><label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zilany</surname><given-names>MSA</given-names></name>, <name name-style="western"><surname>Bruce</surname><given-names>IC</given-names></name>, <name name-style="western"><surname>Nelson</surname><given-names>PC</given-names></name>, <name name-style="western"><surname>Carney</surname><given-names>LH</given-names></name> (<year>2009</year>) <article-title>A phenomenological model of the synapse between the inner hair cell and auditory nerve: long-term adaptation with power-law dynamics</article-title>. <source>J Acoust Soc Am</source> <volume>126</volume>: <fpage>2390</fpage>–<lpage>2412</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-McDermott1"><label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>McDermott</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Simoncelli</surname><given-names>E</given-names></name> (<year>2011</year>) <article-title>Sound texture perception via statistics of the auditory periphery: evidence from sound synthesis</article-title>. <source>Neuron</source> <volume>71</volume>: <fpage>926</fpage>–<lpage>940</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Miller1"><label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Miller</surname><given-names>GA</given-names></name>, <name name-style="western"><surname>Nicely</surname><given-names>PE</given-names></name> (<year>1955</year>) <article-title>An analysis of perceptual confusions among some English consonants</article-title>. <source>J Acoust Soc Am</source> <volume>27</volume>: <fpage>338</fpage>–<lpage>352</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Wang1"><label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wang</surname><given-names>MD</given-names></name>, <name name-style="western"><surname>Bilger</surname><given-names>RC</given-names></name> (<year>1973</year>) <article-title>Consonant confusions in noise: a study of perceptual features</article-title>. <source>J Acoust Soc Am</source> <volume>54</volume>: <fpage>1248</fpage>–<lpage>1266</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Phatak1"><label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Phatak</surname><given-names>SA</given-names></name>, <name name-style="western"><surname>Lovitt</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Allen</surname><given-names>JB</given-names></name> (<year>2008</year>) <article-title>Consonant confusions in white noise</article-title>. <source>J Acoust Soc Am</source> <volume>124</volume>: <fpage>1220</fpage>–<lpage>1233</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Woolley1"><label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Woolley</surname><given-names>SMN</given-names></name>, <name name-style="western"><surname>Casseday</surname><given-names>JH</given-names></name> (<year>2005</year>) <article-title>Processing of modulated sounds in the zebra finch auditory midbrain: responses to noise, frequency sweeps, and sinusoidal amplitude modulations</article-title>. <source>J Neurophysiol</source> <volume>94</volume>: <fpage>1143</fpage>–<lpage>1157</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Louage1"><label>33</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Louage</surname><given-names>DHG</given-names></name>, <name name-style="western"><surname>van der Heijden</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Joris</surname><given-names>PX</given-names></name> (<year>2005</year>) <article-title>Enhanced temporal response properties of anteroventral cochlear nucleus neurons to broadband noise</article-title>. <source>J Neurosci</source> <volume>25</volume>: <fpage>1560</fpage>–<lpage>1570</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Attias1"><label>34</label>
<mixed-citation publication-type="book" xlink:type="simple">Attias H, Schreiner C (1997) Temporal low-order statistics of natural sounds. In: Advances in neural information processing systems, Cambridge, MA: MIT Press, volume 9. pp. 27–33.</mixed-citation>
</ref>
<ref id="pbio.1001710-Singh1"><label>35</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Singh</surname><given-names>NC</given-names></name>, <name name-style="western"><surname>Theunissen</surname><given-names>FE</given-names></name> (<year>2003</year>) <article-title>Modulation spectra of natural sounds and ethological theories of auditory processing</article-title>. <source>J Acoust Soc Am</source> <volume>114</volume>: <fpage>3394</fpage>–<lpage>3411</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Wen1"><label>36</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wen</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>GI</given-names></name>, <name name-style="western"><surname>Dean</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Delgutte</surname><given-names>B</given-names></name> (<year>2009</year>) <article-title>Dynamic range adaptation to sound level statistics in the auditory nerve</article-title>. <source>J Neurosci</source> <volume>29</volume>: <fpage>13797</fpage>–<lpage>13808</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-deCharms1"><label>37</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>deCharms</surname><given-names>RC</given-names></name>, <name name-style="western"><surname>Blake</surname><given-names>DT</given-names></name>, <name name-style="western"><surname>Merzenich</surname><given-names>MM</given-names></name> (<year>1998</year>) <article-title>Optimizing sound features for cortical neurons</article-title>. <source>Science</source> <volume>280</volume>: <fpage>1439</fpage>–<lpage>1444</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Linden1"><label>38</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Linden</surname><given-names>JF</given-names></name>, <name name-style="western"><surname>Liu</surname><given-names>RC</given-names></name>, <name name-style="western"><surname>Sahani</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Schreiner</surname><given-names>CE</given-names></name>, <name name-style="western"><surname>Merzenich</surname><given-names>MM</given-names></name> (<year>2003</year>) <article-title>Spectrotemporal structure of receptive fields in areas AI and AAF of mouse auditory cortex</article-title>. <source>J Neurophysiol</source> <volume>90</volume>: <fpage>2660</fpage>–<lpage>2675</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Ahrens1"><label>39</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ahrens</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Linden</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Sahani</surname><given-names>M</given-names></name> (<year>2008</year>) <article-title>Nonlinearities and contextual inuences in auditory cortical responses modeled with multilinear spectrotemporal methods</article-title>. <source>J Neurosci</source> <volume>28</volume>: <fpage>1929</fpage>–<lpage>1942</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Chichilnisky1"><label>40</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chichilnisky</surname><given-names>EJ</given-names></name> (<year>2001</year>) <article-title>A simple white noise analysis of neuronal light responses</article-title>. <source>Network</source> <volume>12</volume>: <fpage>199</fpage>–<lpage>213</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Simoncelli1"><label>41</label>
<mixed-citation publication-type="book" xlink:type="simple">Simoncelli EP, Paninski L, Pillow J, Schwartz O (2004) Characterization of neural responses with stochastic stimuli. In: Gazzaniga M, editor, The cognitive neurosciences III, Cambridge, MA: MIT Press. pp. 327–338.</mixed-citation>
</ref>
<ref id="pbio.1001710-Bialek1"><label>42</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bialek</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Rieke</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Steveninck</surname><given-names>RdRv</given-names></name>, <name name-style="western"><surname>Warland</surname><given-names>D</given-names></name> (<year>1991</year>) <article-title>Reading a neural code</article-title>. <source>Science</source> <volume>252</volume>: <fpage>1854</fpage>–<lpage>1857</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Mesgarani2"><label>43</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mesgarani</surname><given-names>N</given-names></name>, <name name-style="western"><surname>David</surname><given-names>SV</given-names></name>, <name name-style="western"><surname>Fritz</surname><given-names>JB</given-names></name>, <name name-style="western"><surname>Shamma</surname><given-names>SA</given-names></name> (<year>2009</year>) <article-title>Inuence of context and behavior on stimulus reconstruction from neural activity in primary auditory cortex</article-title>. <source>J Neurophysiol</source> <volume>102</volume>: <fpage>3329</fpage>–<lpage>3339</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Ramirez1"><label>44</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ramirez</surname><given-names>AD</given-names></name>, <name name-style="western"><surname>Ahmadian</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Schumacher</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Schneider</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Woolley</surname><given-names>SMN</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <article-title>Incorporating naturalistic correlation structure improves spectrogram reconstruction from neuronal activity in the songbird auditory midbrain</article-title>. <source>J Neurosci</source> <volume>31</volume>: <fpage>3828</fpage>–<lpage>3842</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Pasley1"><label>45</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pasley</surname><given-names>BN</given-names></name>, <name name-style="western"><surname>David</surname><given-names>SV</given-names></name>, <name name-style="western"><surname>Mesgarani</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Flinker</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Shamma</surname><given-names>SA</given-names></name>, <etal>et al</etal>. (<year>2012</year>) <article-title>Reconstructing speech from human auditory cortex</article-title>. <source>PLoS Biol</source> <volume>10</volume>: <fpage>e1001251</fpage> <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pbio.1001251" xlink:type="simple">10.1371/journal.pbio.1001251</ext-link></comment></mixed-citation>
</ref>
<ref id="pbio.1001710-Dau1"><label>46</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dau</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Kollmeier</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Kohlrausch</surname><given-names>A</given-names></name> (<year>1997</year>) <article-title>Modeling auditory processing of amplitude modulation. i. detection and masking with narrow-band carriers</article-title>. <source>J Acoust Soc Am</source> <volume>102</volume>: <fpage>2892</fpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Moore1"><label>47</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Moore</surname><given-names>RC</given-names></name>, <name name-style="western"><surname>Lee</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Theunissen</surname><given-names>FE</given-names></name> (<year>2013</year>) <article-title>noise-invariant neurons in the avian auditory cortex: hearing the song in noise</article-title>. <source>PLoS Comput Biol</source> <volume>9</volume>: <fpage>e1002942</fpage> <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1002942" xlink:type="simple">10.1371/journal.pcbi.1002942</ext-link></comment></mixed-citation>
</ref>
<ref id="pbio.1001710-Chechik1"><label>48</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chechik</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Nelken</surname><given-names>I</given-names></name> (<year>2012</year>) <article-title>Auditory abstraction from spectro-temporal features to coding auditory entities</article-title>. <source>Proc Natl Acad Sci</source> <volume>109</volume> (<issue>46</issue>) <fpage>18968</fpage>–<lpage>18973</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Schneider1"><label>49</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schneider</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Woolley</surname><given-names>S</given-names></name> (<year>2013</year>) <article-title>Sparse and background-invariant coding of vocalizations in auditory scenes</article-title>. <source>Neuron</source> <volume>79</volume>: <fpage>141</fpage>–<lpage>152</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Woolley2"><label>50</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Woolley</surname><given-names>SMN</given-names></name>, <name name-style="western"><surname>Fremouw</surname><given-names>TE</given-names></name>, <name name-style="western"><surname>Hsu</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Theunissen</surname><given-names>FE</given-names></name> (<year>2005</year>) <article-title>Tuning for spectro-temporal modulations as a mechanism for auditory discrimination of natural sounds</article-title>. <source>Nat Neurosci</source> <volume>8</volume>: <fpage>1371</fpage>–<lpage>1379</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-ZionGolumbic1"><label>51</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zion Golumbic</surname><given-names>EM</given-names></name>, <name name-style="western"><surname>Ding</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Bickel</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Lakatos</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Schevon</surname><given-names>CA</given-names></name>, <etal>et al</etal>. (<year>2013</year>) <article-title>Mechanisms underlying selective neuronal tracking of attended speech at a cocktail party</article-title>. <source>Neuron</source> <volume>77</volume>: <fpage>980</fpage>–<lpage>991</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Rees3"><label>52</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rees</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Green</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Kay</surname><given-names>R</given-names></name> (<year>1986</year>) <article-title>Steady-state evoked responses to sinusoidally amplitude-modulated sounds recorded in man</article-title>. <source>Hear Res</source> <volume>23</volume>: <fpage>123</fpage>–<lpage>133</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Cunningham1"><label>53</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cunningham</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Nicol</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Zecker</surname><given-names>SG</given-names></name>, <name name-style="western"><surname>Bradlow</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Kraus</surname><given-names>N</given-names></name> (<year>2001</year>) <article-title>Neurobiologic responses to speech in noise in children with learning problems: deficits and strategies for improvement</article-title>. <source>Clin Neurophysiol</source> <volume>112</volume>: <fpage>758</fpage>–<lpage>767</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Billings1"><label>54</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Billings</surname><given-names>CJ</given-names></name>, <name name-style="western"><surname>Tremblay</surname><given-names>KL</given-names></name>, <name name-style="western"><surname>Stecker</surname><given-names>GC</given-names></name>, <name name-style="western"><surname>Tolin</surname><given-names>WM</given-names></name> (<year>2009</year>) <article-title>Human evoked cortical activity to signal-to-noise ratio and absolute signal level</article-title>. <source>Hear Res</source> <volume>254</volume>: <fpage>15</fpage>–<lpage>24</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Dahmen1"><label>55</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dahmen</surname><given-names>JC</given-names></name>, <name name-style="western"><surname>Keating</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Nodal</surname><given-names>FR</given-names></name>, <name name-style="western"><surname>Schulz</surname><given-names>A</given-names></name>, <name name-style="western"><surname>King</surname><given-names>AJ</given-names></name> (<year>2010</year>) <article-title>Adaptation to stimulus statistics in the perception and neural representation of auditory space</article-title>. <source>Neuron</source> <volume>66</volume>: <fpage>937</fpage>–<lpage>948</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Cooper1"><label>56</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cooper</surname><given-names>NP</given-names></name>, <name name-style="western"><surname>Guinan</surname><given-names>JJ</given-names></name> (<year>2006</year>) <article-title>Efferent-mediated control of basilar membrane motion</article-title>. <source>J of Physiol</source> <volume>576</volume>: <fpage>4954</fpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Hienz1"><label>57</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hienz</surname><given-names>RD</given-names></name>, <name name-style="western"><surname>Stiles</surname><given-names>P</given-names></name>, <name name-style="western"><surname>May</surname><given-names>BJ</given-names></name> (<year>1998</year>) <article-title>Effects of bilateral olivocochlear lesions on vowel formant discrimination in cats</article-title>. <source>Hear Res</source> <volume>116</volume>: <fpage>10</fpage>–<lpage>20</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Guinan1"><label>58</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Guinan</surname><given-names>JJ</given-names></name> (<year>2006</year>) <article-title>Olivocochlear efferents: anatomy, physiology, function, and the measurement of efferent effects in humans</article-title>. <source>Ear Hear</source> <volume>27</volume>: <fpage>589</fpage>–<lpage>607</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Zilany2"><label>59</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zilany</surname><given-names>MSA</given-names></name>, <name name-style="western"><surname>Carney</surname><given-names>LH</given-names></name> (<year>2010</year>) <article-title>Power-law dynamics in an auditory-nerve model can account for neural adaptation to sound-level statistics</article-title>. <source>J Neurosci</source> <volume>30</volume>: <fpage>10380</fpage>–<lpage>10390</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Joris2"><label>60</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Joris</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Yin</surname><given-names>T</given-names></name> (<year>1992</year>) <article-title>Responses to amplitude-modulated tones in the auditory nerve of the cat</article-title>. <source>J Acoust Soc Am</source> <volume>91</volume>: <fpage>215</fpage>–<lpage>232</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Panzeri1"><label>61</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Panzeri</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Senatore</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Montemurro</surname><given-names>MA</given-names></name>, <name name-style="western"><surname>Petersen</surname><given-names>RS</given-names></name> (<year>2007</year>) <article-title>Correcting for the sampling bias problem in spike train information measures</article-title>. <source>J Neurophysiol</source> <volume>98</volume>: <fpage>1064</fpage>–<lpage>1072</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Rothschild1"><label>62</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rothschild</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Nelken</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Mizrahi</surname><given-names>A</given-names></name> (<year>2010</year>) <article-title>Functional organization and population dynamics in the mouse primary auditory cortex</article-title>. <source>Nat Neurosci</source> <volume>13</volume>: <fpage>353</fpage>–<lpage>360</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Sakata1"><label>63</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sakata</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Harris</surname><given-names>KD</given-names></name> (<year>2009</year>) <article-title>Laminar structure of spontaneous and sensory-evoked population activity in auditory cortex</article-title>. <source>Neuron</source> <volume>64</volume>: <fpage>404</fpage>–<lpage>418</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Averbeck1"><label>64</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Averbeck</surname><given-names>BB</given-names></name>, <name name-style="western"><surname>Latham</surname><given-names>PE</given-names></name>, <name name-style="western"><surname>Pouget</surname><given-names>A</given-names></name> (<year>2006</year>) <article-title>Neural correlations, population coding and computation</article-title>. <source>Nat Rev Neurosci</source> <volume>7</volume>: <fpage>358</fpage>–<lpage>366</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Graf1"><label>65</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Graf</surname><given-names>ABA</given-names></name>, <name name-style="western"><surname>Kohn</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Jazayeri</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Movshon</surname><given-names>JA</given-names></name> (<year>2011</year>) <article-title>Decoding the activity of neuronal populations in macaque primary visual cortex</article-title>. <source>Nat Neurosci</source> <volume>14</volume>: <fpage>239</fpage>–<lpage>245</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Jeanne1"><label>66</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jeanne</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Sharpee</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Gentner</surname><given-names>T</given-names></name> (<year>2013</year>) <article-title>Associative learning enhances population coding by inverting interneuronal correlation patterns</article-title>. <source>Neuron</source> <volume>78</volume>: <fpage>352</fpage>–<lpage>363</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Adibi1"><label>67</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Adibi</surname><given-names>M</given-names></name>, <name name-style="western"><surname>McDonald</surname><given-names>JS</given-names></name>, <name name-style="western"><surname>Clifford</surname><given-names>CWG</given-names></name>, <name name-style="western"><surname>Arabzadeh</surname><given-names>E</given-names></name> (<year>2013</year>) <article-title>Adaptation improves neural coding efficiency despite increasing correlations in variability</article-title>. <source>J Neurosci</source> <volume>33</volume>: <fpage>2108</fpage>–<lpage>2120</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Slaney1"><label>68</label>
<mixed-citation publication-type="other" xlink:type="simple">Slaney M (1993) An efficient implementation of the Patterson-Holdsworth auditory filter bank. Apple Computer, Perception Group, Tech Rep.</mixed-citation>
</ref>
<ref id="pbio.1001710-Goodman1"><label>69</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Goodman</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Brette</surname><given-names>R</given-names></name> (<year>2008</year>) <article-title>Brian: a simulator for spiking neural networks in Python</article-title>. <source>Front Neuroinform</source> <volume>2</volume>: <fpage>5</fpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Glasberg1"><label>70</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Glasberg</surname><given-names>BR</given-names></name>, <name name-style="western"><surname>Moore</surname><given-names>BCJ</given-names></name> (<year>1990</year>) <article-title>Derivation of auditory filter shapes from notched-noise data</article-title>. <source>Hear Res</source> <volume>47</volume>: <fpage>103138</fpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Ruggero1"><label>71</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ruggero</surname><given-names>MA</given-names></name> (<year>1992</year>) <article-title>Responses to sound of the basilar membrane of the mammalian cochlea</article-title>. <source>Curr Opin Neurobiol</source> <volume>2</volume>: <fpage>449</fpage>–<lpage>456</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001710-Dean2"><label>72</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dean</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Robinson</surname><given-names>BL</given-names></name>, <name name-style="western"><surname>Harper</surname><given-names>NS</given-names></name>, <name name-style="western"><surname>McAlpine</surname><given-names>D</given-names></name> (<year>2008</year>) <article-title>Rapid neural adaptation to sound level statistics</article-title>. <source>J Neurosci</source> <volume>28</volume>: <fpage>6430</fpage>–<lpage>6438</lpage>.</mixed-citation>
</ref>
</ref-list><glossary><title>Abbreviations</title><def-list><def-item>
<term>AC</term>
<def>
<p>auditory cortex</p>
</def>
</def-item><def-item>
<term>AN</term>
<def>
<p>auditory nerve</p>
</def>
</def-item><def-item>
<term>BI</term>
<def>
<p>baseline invariance</p>
</def>
</def-item><def-item>
<term>CDF</term>
<def>
<p>cumulative distribution function</p>
</def>
</def-item><def-item>
<term>CF</term>
<def>
<p>center frequency</p>
</def>
</def-item><def-item>
<term>dB</term>
<def>
<p>decibels</p>
</def>
</def-item><def-item>
<term>DRC</term>
<def>
<p>dynamic random chord</p>
</def>
</def-item><def-item>
<term>IC</term>
<def>
<p>inferior colliculus</p>
</def>
</def-item><def-item>
<term>KL</term>
<def>
<p>Kullback–Leibler</p>
</def>
</def-item><def-item>
<term>LN</term>
<def>
<p>linear–nonlinear</p>
</def>
</def-item><def-item>
<term>mAC</term>
<def>
<p>model auditory cortex</p>
</def>
</def-item><def-item>
<term>mAN</term>
<def>
<p>model auditory nerve</p>
</def>
</def-item><def-item>
<term>mIC</term>
<def>
<p>model inferior colliculus</p>
</def>
</def-item><def-item>
<term>MSE</term>
<def>
<p>mean square error</p>
</def>
</def-item><def-item>
<term>MTF</term>
<def>
<p>modulation transfer function</p>
</def>
</def-item><def-item>
<term>PSTH</term>
<def>
<p>peri-stimulus time histogram</p>
</def>
</def-item><def-item>
<term>RMS</term>
<def>
<p>root mean square</p>
</def>
</def-item><def-item>
<term>sAN</term>
<def>
<p>simulated auditory nerve</p>
</def>
</def-item><def-item>
<term>SNR</term>
<def>
<p>signal to noise ratio</p>
</def>
</def-item><def-item>
<term>SPL</term>
<def>
<p>sound pressure level</p>
</def>
</def-item><def-item>
<term>SR</term>
<def>
<p>spontaneous rate</p>
</def>
</def-item><def-item>
<term>STRF</term>
<def>
<p>spectro-temporal receptive field</p>
</def>
</def-item></def-list></glossary></back>
</article>
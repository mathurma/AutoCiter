<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
  <front>
    <journal-meta><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id><journal-id journal-id-type="pmc">ploscomp</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS Computational Biology</journal-title></journal-title-group><issn pub-type="ppub">1553-734X</issn><issn pub-type="epub">1553-7358</issn><publisher>
        <publisher-name>Public Library of Science</publisher-name>
        <publisher-loc>San Francisco, USA</publisher-loc>
      </publisher></journal-meta>
    <article-meta><article-id pub-id-type="publisher-id">PCOMPBIOL-D-11-01322</article-id><article-id pub-id-type="doi">10.1371/journal.pcbi.1002336</article-id><article-categories>
        <subj-group subj-group-type="heading">
          <subject>Research Article</subject>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Biology</subject>
          <subj-group>
            <subject>Computational biology</subject>
          </subj-group>
          <subj-group>
            <subject>Model organisms</subject>
            <subj-group>
              <subject>Animal models</subject>
            </subj-group>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Computer science</subject>
          <subj-group>
            <subject>Computer modeling</subject>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline">
          <subject>Computational Biology</subject>
          <subject>Computer Science</subject>
        </subj-group>
      </article-categories><title-group><article-title>A Model of Ant Route Navigation Driven by Scene Familiarity</article-title><alt-title alt-title-type="running-head">Ant Route Navigation Driven by Scene Familiarity</alt-title></title-group><contrib-group>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Baddeley</surname>
            <given-names>Bart</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="corresp" rid="cor1">
            <sup>*</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Graham</surname>
            <given-names>Paul</given-names>
          </name>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Husbands</surname>
            <given-names>Philip</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Philippides</surname>
            <given-names>Andrew</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
        </contrib>
      </contrib-group><aff id="aff1"><label>1</label><addr-line>Centre for Computational Neuroscience and Robotics, Department of Informatics, University of Sussex, Brighton, United Kingdom</addr-line>       </aff><aff id="aff2"><label>2</label><addr-line>Centre for Computational Neuroscience and Robotics, School of Life Sciences, University of Sussex, Brighton, United Kingdom</addr-line>       </aff><contrib-group>
        <contrib contrib-type="editor" xlink:type="simple">
          <name name-style="western">
            <surname>Cruse</surname>
            <given-names>Holk</given-names>
          </name>
          <role>Editor</role>
          <xref ref-type="aff" rid="edit1"/>
        </contrib>
      </contrib-group><aff id="edit1">University of Bielefeld, Germany</aff><author-notes>
        <corresp id="cor1">* E-mail: <email xlink:type="simple">b.t.baddeley@sussex.ac.uk</email></corresp>
        <fn fn-type="con">
          <p>Conceived and designed the experiments: BB PG AP. Performed the experiments: BB. Analyzed the data: BB PG AP. Contributed reagents/materials/analysis tools: BB. Wrote the paper: BB PG PH AP.</p>
        </fn>
      <fn fn-type="conflict">
        <p>The authors have declared that no competing interests exist.</p>
      </fn></author-notes><pub-date pub-type="collection">
        <month>1</month>
        <year>2012</year>
      </pub-date><pub-date pub-type="epub">
        <day>5</day>
        <month>1</month>
        <year>2012</year>
      </pub-date><volume>8</volume><issue>1</issue><elocation-id>e1002336</elocation-id><history>
        <date date-type="received">
          <day>6</day>
          <month>9</month>
          <year>2011</year>
        </date>
        <date date-type="accepted">
          <day>16</day>
          <month>11</month>
          <year>2011</year>
        </date>
      </history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2012</copyright-year><copyright-holder>Baddeley et al</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract>
        <p>In this paper we propose a model of visually guided route navigation in ants that captures the known properties of real behaviour whilst retaining mechanistic simplicity and thus biological plausibility. For an ant, the coupling of movement and viewing direction means that a familiar view specifies a familiar direction of movement. Since the views experienced along a habitual route will be more familiar, route navigation can be re-cast as a search for familiar views. This search can be performed with a simple scanning routine, a behaviour that ants have been observed to perform. We test this proposed route navigation strategy in simulation, by learning a series of routes through visually cluttered environments consisting of objects that are only distinguishable as silhouettes against the sky. In the first instance we determine view familiarity by exhaustive comparison with the set of views experienced during training. In further experiments we train an artificial neural network to perform familiarity discrimination using the training views. Our results indicate that, not only is the approach successful, but also that the routes that are learnt show many of the characteristics of the routes of desert ants. As such, we believe the model represents the only detailed and complete model of insect route guidance to date. What is more, the model provides a general demonstration that visually guided routes can be produced with parsimonious mechanisms that do not specify when or what to learn, nor separate routes into sequences of waypoints.</p>
      </abstract><abstract abstract-type="summary">
        <title>Author Summary</title>
        <p>The interest in insect navigation from diverse disciplines such as psychology and engineering is to a large extent because performance is achieved with such limited brain power. Desert ants are particularly impressive navigators, able to rapidly learn long, visually guided foraging routes. Their elegant behaviours provide inspiration to biomimetic engineers and for psychologists demonstrate the minimal mechanistic requirements for complex spatial behaviours. In this spirit, we have developed a parsimonious model of route navigation that captures many of the known properties of ants routes. Our model uses a neural network trained with the visual scenes experienced along a route to assess the familiarity of any view. Subsequent route navigation involves a simple behavioural routine, in which the simulated ant scans the world and moves in the most familiar direction, as determined by the network. The algorithm exhibits both place-search and route navigation using the same mechanism. Crucially, in our model it is not necessary to specify when or what to learn, nor separate routes into sequences of waypoints; thereby providing proof of concept that route navigation can be achieved without these elements. As such, we believe it represents the only detailed and complete model of insect route guidance to date.</p>
      </abstract><funding-group><funding-statement>BB and AP are supported by EPSRC grant EP/I031758/1. PG is supported by BBSRC grant BB/H013644/1. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts>
        <page-count count="16"/>
      </counts></article-meta>
  </front>
  <body>
    <sec id="s1">
      <title>Introduction</title>
      <p>The impressive ability of social insects to learn long foraging routes guided by visual information <xref ref-type="bibr" rid="pcbi.1002336-Collett1">[1]</xref>–<xref ref-type="bibr" rid="pcbi.1002336-Wystrach1">[8]</xref> provides proof that robust spatial behaviour can be produced with limited neural resources <xref ref-type="bibr" rid="pcbi.1002336-Wehner3">[9]</xref>–<xref ref-type="bibr" rid="pcbi.1002336-Menzel1">[11]</xref>. As such, social insects have become an important model system for understanding the minimal cognitive requirements for navigation <xref ref-type="bibr" rid="pcbi.1002336-Wehner4">[12]</xref>. This is a goal shared by biomimetic engineers and those studying animal cognition using a bottom-up approach to the understanding of natural intelligence <xref ref-type="bibr" rid="pcbi.1002336-Shettleworth1">[13]</xref>.</p>
      <p>In this field, computational models have proved useful as proof of concept <xref ref-type="bibr" rid="pcbi.1002336-Webb1">[14]</xref>, <xref ref-type="bibr" rid="pcbi.1002336-Webb2">[15]</xref> that a particular sensori-motor strategy <xref ref-type="bibr" rid="pcbi.1002336-Cartwright1">[16]</xref> or memory organisation <xref ref-type="bibr" rid="pcbi.1002336-Cruse1">[17]</xref> can account for observed behaviour. Such models of visual navigation that have been successful in replicating place homing are dominated by snapshot-type models; where a single view of the world as memorized from the goal location is compared to the current view in order to drive a search for the goal <xref ref-type="bibr" rid="pcbi.1002336-Cartwright1">[16]</xref>, <xref ref-type="bibr" rid="pcbi.1002336-Lambrinos1">[18]</xref>–<xref ref-type="bibr" rid="pcbi.1002336-Mller2">[26]</xref>. Snapshot approaches only allow for navigation in the immediate vicinity of the goal however, and do not achieve robust route navigation over longer distances <xref ref-type="bibr" rid="pcbi.1002336-Vardy2">[27]</xref>, <xref ref-type="bibr" rid="pcbi.1002336-Smith1">[28]</xref>. Here we present a parsimonious model of visually guided route learning that addresses this issue. By utilising the interaction of sensori-motor constraints and observed innate behaviours we show that it is possible to produce robust behaviour using a learnt holistic representation of a route. Furthermore, we show that the model captures the known properties of route navigation in desert ants. These include the ability to learn a route after a single training run and the ability to learn multiple idiosyncratic routes to a single goal. Importantly, navigation is independent of odometric or compass information, does not specify when or what to learn, nor separate the routes into sequences of waypoints, so providing proof of concept that route navigation can be achieved without these elements. The algorithm also exhibits both place-search and route navigation with the same mechanism.</p>
      <sec id="s1a">
        <title>Navigation in ants</title>
        <p>Individual ant foragers show remarkable navigational ability, shuttling long distances between profitable foraging areas and their nest. Despite low resolution vision and the availability of odometric information, many ant species preferentially guide their foraging routes using learnt visual information <xref ref-type="bibr" rid="pcbi.1002336-Wehner1">[2]</xref>, <xref ref-type="bibr" rid="pcbi.1002336-Harrison1">[29]</xref>–<xref ref-type="bibr" rid="pcbi.1002336-Andel1">[31]</xref>. The robust extraction and learning of the visual information required for route guidance is a product of the interactions between innate behaviours and learning <xref ref-type="bibr" rid="pcbi.1002336-Wehner4">[12]</xref>, <xref ref-type="bibr" rid="pcbi.1002336-Collett2">[32]</xref>. We highlight these interplays by sketching out the career of an individual forager.</p>
        <p>Upon first leaving the nest, a new forager performs a series of short <italic>learning walks</italic> where a carefully orchestrated series of loops and turns allow her to inspect the visual surroundings from close to the nest entrance <xref ref-type="bibr" rid="pcbi.1002336-Muser1">[33]</xref>–<xref ref-type="bibr" rid="pcbi.1002336-Wehner5">[35]</xref>. The knowledge gained during these special manoeuvres means she will be able to use visual information to pin-point the nest entrance after future foraging trips. When she finally leaves the vicinity of the nest she is safely connected to it because of her path integration (PI) system <xref ref-type="bibr" rid="pcbi.1002336-Wehner4">[12]</xref>, <xref ref-type="bibr" rid="pcbi.1002336-Mller4">[36]</xref>. In order to perform path integration, odometry and compass information are continuously combined such that at all times during a foraging journey the ant has the direction and distance information required to take an approximately direct path home. However, PI is subject to cumulative error and cannot take account of passive displacements, such as by a gust of wind. To mitigate these risks and ensure robust navigation, ants therefore learn the visual information required to guide routes between the nest and their foraging grounds [Reviews: <xref ref-type="bibr" rid="pcbi.1002336-Wehner4">[12]</xref>, <xref ref-type="bibr" rid="pcbi.1002336-Cheng1">[37]</xref>]. During the early stages of learning the ants are reliant on their PI system for homing. However, as they become more experienced they come to rely more and more on visual information for route guidance <xref ref-type="bibr" rid="pcbi.1002336-Andel1">[31]</xref>. The use of PI also provides consistent route shapes thereby facilitating and simplifying the learning of appropriate visual information <xref ref-type="bibr" rid="pcbi.1002336-Collett2">[32]</xref>, <xref ref-type="bibr" rid="pcbi.1002336-Collett3">[38]</xref>.</p>
        <p>Extensive behavioural experiments over many years have led to a knowledge base of properties and behavioural signatures of visually guided navigation in ants that can be summarised as follows:</p>
        <list list-type="order">
          <list-item>
            <p>Ants can use visual information to guide routes between their nest and a stable food site <xref ref-type="bibr" rid="pcbi.1002336-Collett1">[1]</xref>, <xref ref-type="bibr" rid="pcbi.1002336-Kohler1">[3]</xref>, <xref ref-type="bibr" rid="pcbi.1002336-Wystrach1">[8]</xref>, <xref ref-type="bibr" rid="pcbi.1002336-Collett4">[39]</xref>.</p>
          </list-item>
          <list-item>
            <p>Routes are idiosyncratic, so individual ants will adopt and remain faithful to unique routes <xref ref-type="bibr" rid="pcbi.1002336-Collett1">[1]</xref>–<xref ref-type="bibr" rid="pcbi.1002336-Kohler1">[3]</xref>, <xref ref-type="bibr" rid="pcbi.1002336-Wystrach1">[8]</xref>.</p>
          </list-item>
          <list-item>
            <p>Routes have a distinct polarity; knowledge of a nest-food route does not imply knowledge of a food-nest route <xref ref-type="bibr" rid="pcbi.1002336-Wehner2">[4]</xref>, <xref ref-type="bibr" rid="pcbi.1002336-Wehner3">[9]</xref>.</p>
          </list-item>
          <list-item>
            <p>Route knowledge defines a <italic>visual corridor</italic> as opposed to a narrow ridge, so the overall shapes of routes are stable but ants do not have to recapitulate them with high precision <xref ref-type="bibr" rid="pcbi.1002336-Collett1">[1]</xref>, <xref ref-type="bibr" rid="pcbi.1002336-Kohler1">[3]</xref>, <xref ref-type="bibr" rid="pcbi.1002336-Wehner3">[9]</xref>, <xref ref-type="bibr" rid="pcbi.1002336-Collett4">[39]</xref>.</p>
          </list-item>
          <list-item>
            <p>The visual knowledge used to define routes can be used independently of any odometric information that the ant may possess <xref ref-type="bibr" rid="pcbi.1002336-Collett1">[1]</xref>–<xref ref-type="bibr" rid="pcbi.1002336-Kohler1">[3]</xref>, <xref ref-type="bibr" rid="pcbi.1002336-Andel1">[31]</xref>, <xref ref-type="bibr" rid="pcbi.1002336-Collett5">[40]</xref>, <xref ref-type="bibr" rid="pcbi.1002336-Collett6">[41]</xref>.</p>
          </list-item>
          <list-item>
            <p>Route following is not dependent on learning a strict sequence of actions. The knowledge needed to guide a route can be accessed out of the usual sequence <xref ref-type="bibr" rid="pcbi.1002336-Collett1">[1]</xref>, <xref ref-type="bibr" rid="pcbi.1002336-Kohler1">[3]</xref>.</p>
          </list-item>
          <list-item>
            <p>Ants can use learnt visual information to drive a search for their nest entrance <xref ref-type="bibr" rid="pcbi.1002336-Wehner1">[2]</xref>, <xref ref-type="bibr" rid="pcbi.1002336-Wehner6">[42]</xref>–<xref ref-type="bibr" rid="pcbi.1002336-Wehner7">[44]</xref>.</p>
          </list-item>
          <list-item>
            <p>The visual information required to follow a route can be learnt very rapidly; however performance becomes more stable with experience <xref ref-type="bibr" rid="pcbi.1002336-Mller3">[34]</xref>, <xref ref-type="bibr" rid="pcbi.1002336-Narendra2">[43]</xref>, <xref ref-type="bibr" rid="pcbi.1002336-Mangan1">[45]</xref>.</p>
          </list-item>
          <list-item>
            <p>Individual ants can learn multiple routes to the same destination <xref ref-type="bibr" rid="pcbi.1002336-Sommer1">[6]</xref>.</p>
          </list-item>
        </list>
      </sec>
      <sec id="s1b">
        <title>Models of visually-guided navigation in insects</title>
        <p>Computational models of visual navigation in insects followed experimental findings where ants <xref ref-type="bibr" rid="pcbi.1002336-Wehner6">[42]</xref> and bees <xref ref-type="bibr" rid="pcbi.1002336-Cartwright1">[16]</xref> had been shown to guide their return to a goal-location by matching retinotopic information as remembered from the goal. With their seminal snapshot model, Cartwright and Collett <xref ref-type="bibr" rid="pcbi.1002336-Cartwright1">[16]</xref> showed that within a certain catchment area <xref ref-type="bibr" rid="pcbi.1002336-Cartwright2">[46]</xref> subsequent search for a goal location can be driven by a comparison of the current view of the world and a view stored at that goal. This has inspired roboticists and biologists to develop homing models <xref ref-type="bibr" rid="pcbi.1002336-Franz1">[19]</xref>–<xref ref-type="bibr" rid="pcbi.1002336-Mller2">[26]</xref> where a single retinotopic view is used to get back to a location.</p>
        <p>Snapshot style models represent elegant, but abstract, sensori-motor strategies for navigation yet there are two major directions where such models need developing. Firstly, although snapshot models are very useful for understanding the information that is available in a visual scene <xref ref-type="bibr" rid="pcbi.1002336-Zeil1">[21]</xref>, <xref ref-type="bibr" rid="pcbi.1002336-Philippides1">[47]</xref>, to fully understand visual navigation we must consider the constraints imposed by a particular motor system and means of locomotion. Secondly, we need to understand how visual knowledge can be applied to the guidance of longer distance journeys and not just to the pin-pointing of a single goal location.</p>
      </sec>
      <sec id="s1c">
        <title>Understanding sensori-motor interactions</title>
        <p>A significant component to any view-based homing algorithm is the sensori-motor interaction. The original snapshot model was developed following extensive experiments with bees. In the final stages of locating an inconspicuous goal, bees and wasps are able to fix the orientation of their body axis, perhaps using compass information, and then translate in any direction <xref ref-type="bibr" rid="pcbi.1002336-Collett7">[48]</xref>–<xref ref-type="bibr" rid="pcbi.1002336-HempeldeIbarra1">[50]</xref>. Inspired by this, the original snapshot model relies on stored views and current views being aligned to an external frame of reference before a matching procedure is used to determine a homing direction <xref ref-type="bibr" rid="pcbi.1002336-Cartwright1">[16]</xref>. This represents a significant challenge for ants, and also for bees and wasps when flying rapidly over longer distances, where translation is predominantly in the direction of the body axis. In the context of our proposed model, however, the tight coupling of sensation and action is used to simplify the problem of learning a route. For an ant with fixed eyes and a relatively immobile head a given view implicitly defines a direction of movement and therefore an action to take. This suggests the following approach:</p>
        <sec id="s1c1">
          <title>Our approach</title>
          <p>A panoramic image can be used as a <italic>Visual Compass</italic>; the difference between a goal image and rotated images from nearby locations is minimised when the rotated images are at the orientation of the original <xref ref-type="bibr" rid="pcbi.1002336-Zeil1">[21]</xref>, <xref ref-type="bibr" rid="pcbi.1002336-Philippides1">[47]</xref>, <xref ref-type="bibr" rid="pcbi.1002336-Labrosse1">[51]</xref>. Therefore, rather than tagging remembered images with an orientation, or rotating into a particular orientation during learning and recall, we use a similar mechanism to a visual compass to search for familiar viewing directions. The fact that ants are moving, and therefore facing, in the overall route direction most of the time during learning means that these familiar viewing directions implicitly define the movement directions required to stay on the route. It is therefore sufficient to learn all of the views exactly as they are experienced. The problem of navigation is then re-framed in terms of a rotational search for the views associated with a route. By visually scanning the environment and moving in the direction that is most similar to the views encountered during learning an ant should be able to reliably retrace her route.</p>
          <p>Note that this process associates the current view not with a particular place but instead with a particular action, that is, “what should I do?” not “where am I?”. In addition, it means that compass information is not necessary during either learning or recall <xref ref-type="bibr" rid="pcbi.1002336-Graham2">[52]</xref>.</p>
        </sec>
      </sec>
      <sec id="s1d">
        <title>Using views for route guidance</title>
        <p>Given the success of snapshot-type models in place-homing, it is natural to assume that navigation over larger scales, that is, along routes, could be achieved by internalizing a series of stored views linked together as a sequence. Route behaviour in this framework would entail homing from one stored view to the next in a fixed sequence. While it has been shown that the catchment areas of individual snapshots can be quite large <xref ref-type="bibr" rid="pcbi.1002336-Zeil1">[21]</xref>–<xref ref-type="bibr" rid="pcbi.1002336-Philippides1">[47]</xref>, <xref ref-type="bibr" rid="pcbi.1002336-Basten1">[53]</xref>, attempts to model route navigation using linked view-based homing have shown it to be a nontrivial problem which requires the agent to both robustly determine at which point a waypoint should be set during route construction and when a waypoint has been reached during navigation <xref ref-type="bibr" rid="pcbi.1002336-Franz1">[19]</xref>, <xref ref-type="bibr" rid="pcbi.1002336-Vardy2">[27]</xref>, <xref ref-type="bibr" rid="pcbi.1002336-Smith1">[28]</xref>. Essentially, for robust route navigation using a sequence of snapshots, an agent needs place recognition to determine where along the route it is <xref ref-type="bibr" rid="pcbi.1002336-Smith2">[54]</xref>. Here we propose a different model that develops and refines ideas that have been recently put forward as an alternative to such a scheme <xref ref-type="bibr" rid="pcbi.1002336-Baddeley1">[55]</xref>. Instead of defining routes in terms of discrete waypoints all views experienced during training are used to learn a holistic route representation.</p>
        <sec id="s1d1">
          <title>Our approach</title>
          <p>An artificial neural network is first trained using the views experienced during a return to the nest. During subsequent navigation the network is used to estimate whether a given view has been experienced before. A behavioural routine facilitates route following by scanning the world and moving in the direction that is most familiar and therefore deemed most likely to be part of the route.</p>
          <p>We feel that this approach has two major benefits. Firstly, we do not attempt to learn in detail specific views along the route, but instead use all of the views to determine a measure of familiarity. In this way our approach provides a compact way of storing the visual information required to follow routes that is also open-ended in that new information can be incorporated at any time in the future. As a corollary, the agent does not need to decide when or which views to learn. Secondly, the agent does not need to determine where along the route it is. By performing visual scans of the world from the current location and moving in the direction that appears most familiar we obviate the need to determine a sequence of views that must be experienced in the correct order.</p>
          <p>Both desert ants and wood ants perform scanning behaviours that support this approach. When released in an unexpected but familiar place the desert ant <italic>Melophorus bagoti</italic> scans the environment by turning rapidly on the spot [A. Wystrach and P. Graham, personal observation]. More than one scan may be performed with short straight runs of a few centimetres separating them before the ant finally sets off in a seemingly purposeful manner. The desert ant <italic>Cataglyphis bombycina</italic> has also been reported to perform a similar scanning behaviour during foraging runs <xref ref-type="bibr" rid="pcbi.1002336-Wehner8">[56]</xref>, <xref ref-type="bibr" rid="pcbi.1002336-Wehner9">[57]</xref>. Wood ants exhibit a second form of scanning behaviour; instead of walking in a straight line, they tend to take a sinuous path <xref ref-type="bibr" rid="pcbi.1002336-Graham3">[58]</xref> which has the effect of producing scans of the world centred on the overall direction of movement.</p>
        </sec>
      </sec>
      <sec id="s1e">
        <title>Preview</title>
        <p>We test our proposed route navigation strategy in simulation, by learning a series of routes through visually cluttered environments consisting of objects that are only distinguishable as silhouettes against the sky. This represents a challenging task due to the paucity of information and the potential for visual aliasing, whereby two locations appear similar enough so as to be indistinguishable. Our results indicate that, not only is the approach successful, but also that the routes that are learnt show many of the features that characterise the routes of desert ants.</p>
      </sec>
    </sec>
    <sec id="s2">
      <title>Results</title>
      <sec id="s2a">
        <title>Navigating with a perfect memory</title>
        <p>Our navigation algorithm consists of two phases. The ant first traverses the route using a combination of PI and obstacle avoidance (as specified in the <xref ref-type="sec" rid="s4">Materials and Methods</xref>) during which the views used to learn the route are experienced. Subsequently, the ant navigates by visually scanning the world and moving in the direction which is deemed most familiar. In the later experiments, the route is learnt by a neural network and the familiarity of each view is the output of the trained network. However, to show the utility of the proposed scanning routine, without the added complication of learning a familiarity metric, we first explored the performance of a system with perfect memory. This was implemented by storing views experienced every 4 cm along a training route and using these to determine view familiarity directly. Following Zeil et al. <xref ref-type="bibr" rid="pcbi.1002336-Zeil1">[21]</xref> we calculate the sum squared difference in pixel intensities between rotated versions of the current view and each stored view. The minimum across all stored images and all viewing directions experienced during a <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e001" xlink:type="simple"/></inline-formula> scan of the world from the current location is deemed the most familiar view for that location and a 10 cm step is taken in the viewing direction associated with this minimum.</p>
        <p><xref ref-type="fig" rid="pcbi-1002336-g001">Figure 1</xref> shows that by storing the views along a training path and using these to drive a subsequent recapitulation of the route, robust behaviour is achievable. We used our algorithm to learn three routes through an environment containing both small and large objects randomly distributed across the environment. Three subsequent navigation paths were attempted for each route. Of the nine paths, all but one successfully return to the nest location, with the one failure caused by the simulated ant being drawn out of the stable <italic>route corridor</italic> by the presence of a tussock that dominates the visual field and causes visual aliasing. Despite the noise added to the movements during the recapitulation, paths are idiosyncratic though inexact. Within a corridor centred on the original route both a good match and a sensible heading are recovered that will, in general, drive the simulated ant towards the goal (<xref ref-type="fig" rid="pcbi-1002336-g001">Figures 1B–D</xref>). Outside of this route corridor the best match becomes poorer and, particularly within areas containing a high degree of visual clutter (i.e. within a group of tussocks) the proposed direction of movement less reliably points towards the goal. This is seen most clearly in panel C where, very close to tussocks, a significant proportion of the homeward directions determined by the algorithm (white arrows in <xref ref-type="fig" rid="pcbi-1002336-g001">Figure 1B–D</xref>) point away from the goal location. Often these erroneous signals direct movements back into the route corridor, although this is clearly a matter of chance.</p>
        <fig id="pcbi-1002336-g001" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002336.g001</object-id>
          <label>Figure 1</label>
          <caption>
            <title>Navigating with a perfect memory.</title>
            <p>A) Three separate routes (red lines) learned in an environment containing both small and large objects. For each of the three routes, that consisted of between 700 and 980 views taken every 1 cm, we show three recapitulations (black lines). During route recapitulations the headings at each step were subject to normally distributed noise with a standard deviation of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e002" xlink:type="simple"/></inline-formula>. The panels to the right of the main figure show example views from points (indicated by squares) along the training route. B,C,D) Various sections of the middle route at a variety of different scales. The figures show the result of running the navigation algorithm at each point within a grid and indicate what action would be taken by an agent placed at that location. The white line indicates the training path and the white arrows indicate the directions that would be chosen from those locations. The underlying pseudocolour plot indicates the quality of the best match to the stored views for each position, with darker hues indicating a better match.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002336.g001" xlink:type="simple"/>
        </fig>
        <p>The routes that are generated show a distinct polarity meaning that they can only be traversed in a single direction as is evidenced by the coherence of the homeward directions (arrows in <xref ref-type="fig" rid="pcbi-1002336-g001">Figure 1B–D</xref>). Importantly, the actions that result from following this strategy are not tied to a coordinate system and are therefore completely independent from the PI system that provided the initial scaffold for learning. In addition, the resulting routes are not dependent on a chained sequence of actions; appropriate actions are taken at any location along the route corridor independent of how that location was reached.</p>
      </sec>
      <sec id="s2b">
        <title>Adding learning walks</title>
        <p>One potential problem with this navigational strategy is that if the simulated ant overshoots the goal it will, in general, carry on heading in the same direction and move further and further away from the goal location (<xref ref-type="fig" rid="pcbi-1002336-g002">Figure 2A</xref>). This is because there are no training views that point back towards the nest once it has been passed. This problem can be mitigated by including an exploratory learning walk during the training phase, a behaviour seen in many species of ants <xref ref-type="bibr" rid="pcbi.1002336-Muser1">[33]</xref>–<xref ref-type="bibr" rid="pcbi.1002336-Wehner5">[35]</xref>. These initial paths take the form of a series of loops centred on the nest as can be seen in <xref ref-type="fig" rid="pcbi-1002336-g002">Figure 2B</xref> which shows the learning walk of a <italic>Melophorus bagoti</italic> worker taken from a paper by Muser et al. <xref ref-type="bibr" rid="pcbi.1002336-Muser1">[33]</xref>. Essentially, this process means that in the region around the nest there will always be some views stored which are oriented back towards the nest.</p>
        <fig id="pcbi-1002336-g002" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002336.g002</object-id>
          <label>Figure 2</label>
          <caption>
            <title>Including learning walks prevents return paths from overshooting the goal.</title>
            <p>A) Without a learning walk the simulated ant overshoots and carries on in the direction it was heading as it approached the nest location. B) By including the views experienced during a learning walk the simulated ant, instead of overshooting, gets repeatedly drawn back to the location of the nest. Red lines training paths, black lines recapitulations.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002336.g002" xlink:type="simple"/>
        </fig>
        <p>To explore the possible effects of these initial short learning walks, the views experienced along them were added to the set of inbound views used for route learning. <xref ref-type="fig" rid="pcbi-1002336-g002">Figure 2</xref> shows the end section of a route navigated after training with and without a learning walk. In these tests the simulation was not stopped when the simulated ant reached the nest location, analogous to blocking the nest entrance in a behavioural experiment. With the addition of a learning walk (<xref ref-type="fig" rid="pcbi-1002336-g002">Figure 2B</xref>), as the simulated ant passes the nest, rather than the best match being from the training route and oriented upwards (as in <xref ref-type="fig" rid="pcbi-1002336-g002">Figure 2A</xref>), the best match comes from the learning walk. The simulated ant is drawn into the loop of the learning walk it first encounters, leading to the looped paths seen in <xref ref-type="fig" rid="pcbi-1002336-g002">Figure 2B</xref>. Close to the nest, the density of points from the learning walk increases and there are multiple views from nearby locations oriented in a variety of directions. The best match at subsequent points will then likely be from different learning walk loops and so the ant stops following a single loop and enters more of a search-type path around the nest. Thus, our algorithm demonstrates both route following and nest search with the same mechanism.</p>
      </sec>
      <sec id="s2c">
        <title>Summary</title>
        <p>Here we have shown that by storing and using panoramic views as they were experienced and aligned during training, we can achieve visually guided route navigation through a scanning routine and without recourse to a compass. The model is of particular interest since the resulting paths show remarkable similarities to many of the features that we observe in the routes of ants. Specifically, independence from the PI system that is assumed to scaffold the original learning; distinct polarity of routes; formation of a route corridor; and procedural rules that can be accessed out of sequence. By including a learning walk we can also get visually driven search for the nest location from the same mechanism. This algorithm demonstrates the efficacy of using a simple scanning behaviour as a strategy for seeking familiar views. However, the algorithm relies on the unrealistic assumption of a perfect memory of views experienced along the training route. We next investigate a more realistic encoding of the visual information required for navigation by training an artificial neural network using the views experienced along a return journey and a learning walk.</p>
      </sec>
      <sec id="s2d">
        <title>Familiarity and Infomax</title>
        <p>Having shown that the proposed scanning routine can produce <italic>ant-like</italic> paths, we next addressed the problem of learning a familiarity metric to use in place of a perfect memory system. Instead of storing all of the views experienced on a training route, the views were used to train a two-layered artificial neural network to perform familiarity discrimination using an Infomax learning rule <xref ref-type="bibr" rid="pcbi.1002336-Lulham1">[59]</xref>. Each view was presented to the network in the order in which it was collected and then discarded. This means that the memory load does not scale with the length of route but remains constant. Once trained, the network takes a panoramic image as input and outputs a familiarity measure indicating the likelihood of the view from that location and orientation being part of the learnt route. The trained network was then used in conjunction with the scanning routine to drive route navigation by presenting the rotated views to the network, and choosing the most familiar direction as the direction in which to navigate. The only difference in the behavioural routine was that the scanning range was reduced from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e003" xlink:type="simple"/></inline-formula> to a slightly more realistic <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e004" xlink:type="simple"/></inline-formula> scan centred on the direction of travel from the previous timestep.</p>
        <p>In a first experiment using this approach we employed the Infomax system to learn the same three training paths as in the previous experiment using a perfect memory. As <xref ref-type="fig" rid="pcbi-1002336-g003">Figure 3</xref> shows, in this instance all returns were completed successfully. We do not believe this indicates that the approach is more robust than the perfect memory system but simply that the noise added to the system did not happen to nudge the agent into an area of the environment where visual aliasing would occur. In other ways the results of this experiment are very similar to the results obtained using a perfect memory. As these routes were learned using a single exposure to each of the training views, we are thus able to fulfil another of the desiderata for ant-like visual mediated route navigation: that routes can be learnt rapidly, in this case following a single trial.</p>
        <fig id="pcbi-1002336-g003" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002336.g003</object-id>
          <label>Figure 3</label>
          <caption>
            <title>Navigating using a trained artificial neural network to assess scene familiarity.</title>
            <p>A) Successful return paths for three different routes. The panels to the right of the main figure show example views from points (indicated by squares) along the training route. B,C,D) Various sections of the middle route at a variety of different scales. The pseudocolour plots indicate the familiarity of the best view as was output from the trained network, with darker hues indicating increased familiarity. Conventions as in <xref ref-type="fig" rid="pcbi-1002336-g001">Figure 1</xref>.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002336.g003" xlink:type="simple"/>
        </fig>
        <p>To show that learning was not environment specific we conducted further simulations. Environments with varying densities of tussocks were randomly generated and a simple algorithm that performed path integration with obstacle avoidance was used to generate paths through them. In all of the environments we provided a distant horizon consisting of bush-like and tree-like objects as would be present in the natural environment of <italic>Melophorus bagoti</italic> <xref ref-type="bibr" rid="pcbi.1002336-Muser1">[33]</xref>. In these experiments we also included a simplified learning walk at the start of training to prevent the simulated ant overshooting the goal.</p>
        <p>We first examined a low tussock density environment compared to the environment used previously. Performance was good, although the lack of nearby objects resulted in less consistent paths (<xref ref-type="fig" rid="pcbi-1002336-g004">Figure 4</xref>). Example views taken from the training route (<xref ref-type="fig" rid="pcbi-1002336-g004">Figure 4</xref>, right) show how the panorama of distant objects provide a stable frame of reference throughout the route. Despite the sparse visual information in this environment, the distant objects help to keep the return paths heading in the right direction. The effect that the structure of the learning walk has on the return paths can be clearly seen near the goal location. As the simulated ant nears the goal it gets drawn into a series of left and right sweeps that reflect the left and right inbound loops of the learning walk and are analogous to an ant's search for its often inconspicuous nest entrance.</p>
        <fig id="pcbi-1002336-g004" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002336.g004</object-id>
          <label>Figure 4</label>
          <caption>
            <title>Navigational performance in a sparse environment with a tussock density of 0.05 <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e005" xlink:type="simple"/></inline-formula>.</title>
            <p>The left panel shows the training (red) and test (black) paths for a 12 m route. The right panel shows example views from points (indicated by squares) from the training route. The combined learning walk and training route consisted of 520 views that were used to train the network.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002336.g004" xlink:type="simple"/>
        </fig>
        <p>We next used an environment with a more dense set of tussocks (<xref ref-type="fig" rid="pcbi-1002336-g005">Figure 5</xref>). In this more densely tussocked world the distant panorama is no longer visible at all points along the route. This clearly makes route learning more difficult as is evidenced by the failures in three of the four runs. Because noise is added to the simulated ant's heading during route recapitulation the simulated ant may stray into previously unexperienced parts of the environment which, even a short distance away from the learnt route, can look very different in this cluttered world. Two attempts fail early when noise added to the heading leads the simulated ant to go to the left of a small tussock taking it into a part of the world with which it is not familiar. The other two returns do reasonably well. They do show some circling of tussocks, driven by training views where the path goes very close to a tussock and dominates the visual field, however both paths make it very close to the nest. This is a challenging environment in which to navigate and was picked to be at the limit of the algorithm's learning power following just one training run; other runs using a similar density of tussocks were more successful. Performance also improved if we removed or reduced the noise that was added to the direction of movement at each timestep. Of course, ordinarily ants would incorporate knowledge from several foraging trips during which time their performance becomes more stable and robust. We investigate this in the next section.</p>
        <fig id="pcbi-1002336-g005" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002336.g005</object-id>
          <label>Figure 5</label>
          <caption>
            <title>Navigational performance in a cluttered environment with a tussock density of 0.75 <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e006" xlink:type="simple"/></inline-formula>.</title>
            <p>The left panel shows the training (red) and test (black) paths for a 12 m route, squares indicate points where example views from the training run (right panel) are taken from. The combined learning walk and training route consisted of 520 views that were used to train the network.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002336.g005" xlink:type="simple"/>
        </fig>
      </sec>
      <sec id="s2e">
        <title>Route performance improves with experience</title>
        <p>Performance of our algorithm was often quite reliable following a single training run but there were still failures (<xref ref-type="fig" rid="pcbi-1002336-g005">Figure 5</xref>). Ants, however, do not just use a single training run but will continue to develop their knowledge of the surroundings during multiple runs. We therefore investigated the effect on performance if multiple subtly different training routes were combined. The path integration algorithm that we used allowed the generation of multiple paths that were similar but not identical. The views collected along a number of paths were used to train the network. The learning scheme did not need to be altered as each view collected was simply presented to the network in the order that it was experienced.</p>
        <p>Performance is shown for a twelve metre route in one of the more challenging environments (tussock density 0.75 <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e007" xlink:type="simple"/></inline-formula>) following 1, 2, 4 and 8 training runs (<xref ref-type="fig" rid="pcbi-1002336-g006">Figure 6</xref>). Using multiple training runs can be seen to aid robustness, and after 8 training runs (<xref ref-type="fig" rid="pcbi-1002336-g006">Figure 6</xref>, far right) the recapitulated routes are efficient and consistent, even in this high tussock density environment. With repeated training runs the network will be exposed to a more comprehensive set of views from the route than with a single training run. It should be noted that using, say, four training runs is not the same as sampling the views four times as often during a single training run. In the latter case, sets of four consecutive points are not independent of each other. Using multiple runs however, views from similar locations are coupled only through the environment and thus variation in the views reflects the variation that will be experienced during navigation. For instance, if the distribution of objects in the world means that the training routes are canalised down a narrow corridor, it is likely that the navigated route will also go down a narrow path and so it does not matter that the training views from each run are similar. However, if the route corridor is broader, or even allows multiple paths, then multiple training routes allow a wider set of views that might be experienced when navigating, to be captured. Multiple runs therefore allow a broader, more robust, route corridor to be learnt.</p>
        <fig id="pcbi-1002336-g006" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002336.g006</object-id>
          <label>Figure 6</label>
          <caption>
            <title>Route following improves with experience.</title>
            <p>Performance improves as more training runs are performed. Performance is shown following one, two, four and eight training runs. In each figure the training runs used for learning are shown in red while the attempts to recapitulate the route are shown in black. As previously, noise is added to paths during route recapitulation. Of the 4 attempts (black lines) shown in each panel 2, 4, 3 and 4 were successful after one, two, four and eight runs respectively.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002336.g006" xlink:type="simple"/>
        </fig>
      </sec>
      <sec id="s2f">
        <title>Learning multiple routes</title>
        <p>It has been shown that <italic>Melophorus bagoti</italic> are able to learn and maintain more than one route memory when forced to learn distinct return paths to their nest from a series of different feeders <xref ref-type="bibr" rid="pcbi.1002336-Sommer1">[6]</xref>. In the experiments performed by Sommer et al. <xref ref-type="bibr" rid="pcbi.1002336-Sommer1">[6]</xref>, seven training runs along a first route were followed by a control run to test whether the ant had learnt the route. This training schedule was repeated for a further two routes that each led back to the same location - the nest. Finally, the ants were tested on the first two routes to see if they had retained the original route memories. Here we attempt to replicate this experiment using our route learning algorithm to learn three 10 m routes performed in an environment with a tussock density of 0.75 <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e008" xlink:type="simple"/></inline-formula>.</p>
        <p>To do this we train a network using the first route. The network is then tested before we continue to train the network using views from the second learning route. The network is then again tested before the final training session using views from the third route, before finally being tested on all three routes. The performance can be seen in <xref ref-type="fig" rid="pcbi-1002336-g007">Figure 7</xref>. The network is able to learn and navigate multiple routes without <italic>forgetting</italic> the earlier ones. It is interesting to note that when the third route is recapitulated following learning, the paths tend to get drawn back onto the previously learnt route 2, representing a possible confabulation of these two memories within the network. The individual route memories are not held separately and the return paths for route 3 are drawn back to route 2 as, at that point in the world, views from routes 2 and 3 are similar. This is not wrong <italic>per se</italic>, as the important thing is that the routes lead safely back to the nest. Also this property of routes can be seen in the original paper <xref ref-type="bibr" rid="pcbi.1002336-Sommer1">[6]</xref>.</p>
        <fig id="pcbi-1002336-g007" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002336.g007</object-id>
          <label>Figure 7</label>
          <caption>
            <title>Learning multiple routes.</title>
            <p>A) Route recapitulation performance (black lines) for each of three routes (red lines) that are learned with the same network. Testing of each of the routes is performed immediately following training on that route and prior to any subsequent learning. The order in which the routes were learnt is indicated by the numbers next to the training routes. B) Performance on the first two routes following learning of all routes, indicating that the route knowledge gained during the first two phases of learning is retained. Having learnt all 3 routes the network must encode 30 m of route information. This increases the likelihood of visual aliasing as is evidenced by the failed recapitulations following learning of all three routes.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002336.g007" xlink:type="simple"/>
        </fig>
      </sec>
    </sec>
    <sec id="s3">
      <title>Discussion</title>
      <p>We have presented a parsimonious model of visual route guidance which replicates the properties and characteristics of ant navigation. We believe this model represents the only detailed and complete model of insect route guidance to date. However, for us, the major value of the model lies in it being a proof of concept that simple architectures and mechanisms can underpin complex cognitive behaviours such as visually guided routes. Visual navigation requires a cognitive toolkit capable of learning appropriate information, organising memories robustly and also a way of converting those memories into spatial decisions. By considering the way that sensory and motor systems are tightly coupled through behaviour, and utilising familiarity measures to drive route recapitulation, we have produced a minimal cognitive architecture that demonstrates visual route guidance and visually guided search for a goal.</p>
      <p>There are three key aspects of this work that we would like to discuss further: (i) Using a familiarity measure to guide routes; (ii) the holistic nature of the route representation; (iii) how learning walks allow route following and nest search with the same mechanism.</p>
      <sec id="s3a">
        <title>View familiarity and recognition vs. recall</title>
        <p>Our own experience tells us that the human capacity for visual recognition is remarkable and clearly outstrips our capacity for recall. For instance, our ability to decide whether we have met somebody before, runs to many more people than those we can explicitly recall specific facts about. Theoretical investigations of abstract neural network models back up this intuition, with familiarity discrimination or recognition models having far greater capacity than associative models with the same number of processing units and weights <xref ref-type="bibr" rid="pcbi.1002336-Amit1">[60]</xref>. Given the limited neural resources available to an ant and the need for rapid learning it makes sense to develop a navigational strategy that relies on recognition, as building either a cognitive map or employing some other form of associative learning are both harder tasks.</p>
        <p>The fact that, in our experiments, sensible behaviour can be generated following a single traversal of a route indicates that a form of recognition memory may be sufficient for route navigation in the real world. In fact we would expect that in many ways the problem would be easier for an ant operating in the real world where there would be more information available to disambiguate different views and thereby reduce visual aliasing. The current model presupposes that the only information available to guide behaviour is provided by the high contrast silhouettes of objects against the sky. While we know that ants are able to use skylines to orient themselves <xref ref-type="bibr" rid="pcbi.1002336-Graham1">[7]</xref>, any additional visual information, for example colour, texture or celestial cues, information from other modalities <xref ref-type="bibr" rid="pcbi.1002336-Wehner9">[57]</xref>, <xref ref-type="bibr" rid="pcbi.1002336-Steck1">[61]</xref>, <xref ref-type="bibr" rid="pcbi.1002336-Seidl1">[62]</xref>, or internal motivational cues, would only help to reduce aliasing and improve reliability.</p>
        <p>Whether insects have the appropriate brain architecture for storing visual information in this way is not known, though the mushroom bodies would be the obvious candidate neural structure. These higher brain centres, that are enlarged and elaborated in central place foraging insects, have been implicated in a number of cognitive functions including olfactory processing and associative learning <xref ref-type="bibr" rid="pcbi.1002336-McGuire1">[63]</xref>–<xref ref-type="bibr" rid="pcbi.1002336-Blum1">[65]</xref>, attention <xref ref-type="bibr" rid="pcbi.1002336-vanSwinderen1">[66]</xref>, sensory integration , sensory filtering <xref ref-type="bibr" rid="pcbi.1002336-Schildberger1">[67]</xref>, <xref ref-type="bibr" rid="pcbi.1002336-Li1">[68]</xref> and spatial learning <xref ref-type="bibr" rid="pcbi.1002336-Mizunami1">[69]</xref>, <xref ref-type="bibr" rid="pcbi.1002336-Mizunami2">[70]</xref>. Farris and Schulmeister <xref ref-type="bibr" rid="pcbi.1002336-Farris1">[71]</xref> present compelling evidence that large mushroom bodies receiving visual input are associated with a behavioural ecology that relies heavily on spatial learning. Furthermore, recent research by Stieb et al. <xref ref-type="bibr" rid="pcbi.1002336-Stieb1">[72]</xref> implicates the mushroom bodies in the behavioural transition from working inside the nest to foraging outside. In light of our model it would be interesting to evaluate the potential of the mushroom bodies for familiarity discrimination or recognition memory.</p>
        <p>The pseudocolour plots in <xref ref-type="fig" rid="pcbi-1002336-g003">Figure 3</xref> indicate how familiarity could provide another source of information for making routes more robust. If an agent was able to follow a combination of the gradient of the familiarity and the heading of the most familiar direction this would have the effect of drawing the recapitulated paths back onto the habitual route. While this gradient is apparent in the plots that are obtained by sampling from a dense grid of points, it is less obvious how an ant might extract this information, since it would be necessary to sample at least three non-collinear points whilst maintaining the most familiar heading. For a flying insect this would be much less of a problem. The familiarity gradient alone will only serve to draw paths back onto the route and will therefore not produce route following behaviour. However, preliminary results indicate that performance is more robust when the direction indicated by the most familiar view is combined with the familiarity gradient.</p>
        <p>We have shown how a familiarity metric could in principle be used to guide successful route navigation; the proposed motor program is however not realistic. Although ants have been observed performing scanning behaviours such as we have used, in general they proceed in a far more purposeful manner when on or near their habitual routes. One issue that we need to address therefore is how familiarity of views could be used in a way that is more consistent with the fine-grained movements that ants actually perform. In order to do this we will need to simulate an environment in which behavioural experiments have been conducted and record in fine detail the movements of ants during their foraging career.</p>
      </sec>
      <sec id="s3b">
        <title>Holistic representations of visual knowledge</title>
        <p>In our second set of experiments we train a network with the views experienced during a learning walk and along a route. There is no requirement for specific views to be selected and following training the network provides a holistic representation of visual information rather than a set of discrete views. The network in fact holds a holistic representation of all the visual information needed for the agent to get to a particular goal, as shown by our replication of multiple route learning. We have previously shown that other neural network models are also able to holistically encode this information <xref ref-type="bibr" rid="pcbi.1002336-Baddeley1">[55]</xref>, <xref ref-type="bibr" rid="pcbi.1002336-Baddeley2">[73]</xref>. However the particular elegance of the Infomax procedure is that each view is presented to the network once and then discarded.</p>
        <p>The consensus view amongst biologists is that ants do not hold spatial information in a unitary cognitive map <xref ref-type="bibr" rid="pcbi.1002336-Wehner4">[12]</xref>, <xref ref-type="bibr" rid="pcbi.1002336-Wehner10">[74]</xref>–<xref ref-type="bibr" rid="pcbi.1002336-Collett10">[76]</xref>. Indeed experiments have shown that the memories required to get to one goal (e.g. the nest) are insulated from the memories required to get to a second goal (e.g. a regular feeding site) <xref ref-type="bibr" rid="pcbi.1002336-Wehner2">[4]</xref>, <xref ref-type="bibr" rid="pcbi.1002336-Harris1">[77]</xref>. Indeed, if food-bound and nest-ward routes do not overlap then ants captured as they try to get to their nest are effectively lost if they are placed on their familiar food-bound route <xref ref-type="bibr" rid="pcbi.1002336-Wehner2">[4]</xref>. Our model could account for this if the motivational state of the animal formed part of the input to the familiarity network. In this way, views would appear familiar only within the correct motivational context.</p>
      </sec>
      <sec id="s3c">
        <title>Learning walks and behavioural modulation of learning</title>
        <p>One of the key properties of this model is that route guidance and place search come from the same mechanism. This comes from incorporating the views experienced during a learning walk into the overall task. Learning walks (and flights in bees and wasps) are a form of active vision where the insect shapes its own perception in a way that is beneficial for learning. This principle is demonstrated by our design of an artificial learning walk. If the views on the outbound sections of the learning walk are made to be more variable than those on the inbound sections, then the inbound views will be learned preferentially. A simple way to achieve this is to have curved outbound routes and straight inbound routes (see the <xref ref-type="sec" rid="s4">Materials and Methods</xref>), a learning walk scheme that performed well. We imagine that when we have an understanding of how real learning walks are structured by the environment, performance will be improved and search paths will more closely resemble those that have been observed in ants.</p>
        <p>Another more complex way to modulate learning would be to turn-off learning when not heading towards the nest. This would require some sort of input from the PI system and interestingly, recent detailed descriptions of learning walks in <italic>Ocymyrmex</italic> <xref ref-type="bibr" rid="pcbi.1002336-Mller3">[34]</xref> highlight that PI is likely to be used to ensure ants look at the nest at discrete points during their learning walks. However, these learning walks are still compatible with either behavioural or cognitive modulation of learning. The use of PI might only be used to structure the learning walks and allow the ant to accurately face its nest thereby facilitating behavioural modulation of learning <xref ref-type="bibr" rid="pcbi.1002336-Graham2">[52]</xref>.</p>
      </sec>
      <sec id="s3d">
        <title>Conclusion</title>
        <p>We have presented a parsimonious model of visual navigation that uses the interaction of sensori-motor constraints with a holistic route memory, to drive visual navigation. The model captures many of the observed properties of ant navigation and importantly visual navigation is independent of odometric or compass information. Additionally, in the model one does not need to specify when or what to learn, nor separate routes into sequences of waypoints, thus the model is a proof of concept that navigation in complex visual environments can be achieved without those processes. Our principal goal in this research project is to understand the likely and viable mechanisms underpinning insect navigation. Therefore our next step will be to evaluate the model using fine-grained recordings of ants learning and performing routes in their natural habitat.</p>
      </sec>
    </sec>
    <sec id="s4" sec-type="materials|methods">
      <title>Materials and Methods</title>
      <sec id="s4a">
        <title>The simulation environment</title>
        <p>To create the environments used in our experiments, a distant panorama of trees and bushes was generated and uniformly distributed densities of tussock-like objects were created over a central <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e009" xlink:type="simple"/></inline-formula> region. While the placement of the tussocks was performed by sampling from a uniform distribution, environments that did not contain many tussocks in the vicinity of the training paths were rejected. In some of the experiments additional 3D objects such as large trees and a building were added within the central region. The environment is intended to produce panoramic views that are typical of the natural environment of the Australian desert ant <italic>Melophorus bagoti</italic> (See <xref ref-type="bibr" rid="pcbi.1002336-Graham1">[7]</xref>, <xref ref-type="bibr" rid="pcbi.1002336-Wystrach1">[8]</xref>, <xref ref-type="bibr" rid="pcbi.1002336-Cheng1">[37]</xref>, <xref ref-type="bibr" rid="pcbi.1002336-Schwarz1">[78]</xref> for example images of this environment). <xref ref-type="fig" rid="pcbi-1002336-g008">Figure 8</xref> shows an overview of a typical environment together with a series of views along a route. Notice how variable the views are and also how insignificant the large tree and the building (the solid black objects in <xref ref-type="fig" rid="pcbi-1002336-g008">Figure 8B</xref>) can be from the perspective of an ant. This is easiest to see in <xref ref-type="fig" rid="pcbi-1002336-g008">Figures 8D and E</xref> taken from the middle section of the route where the house, which is NE of the ant (i.e. just over half way along the image; notice the triangular roof in the high-resolution image) blends in to a tussock.</p>
        <fig id="pcbi-1002336-g008" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002336.g008</object-id>
          <label>Figure 8</label>
          <caption>
            <title>The simulation environment.</title>
            <p>A,B) Two views of a typical simulated environment used in our experiments. In B the small squares indicate the positions from which the views that are shown in C are taken. C) Five example views taken approximately 2 m apart along a typical route used for learning. The views are oriented so that North (straight up in B) is at the centre of the unwrapped images. D) Typical high-resolution view of the world from an ant's perspective. E) Low-resolution representation of the view shown in D.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002336.g008" xlink:type="simple"/>
        </fig>
        <p>The simulated environment, programmed in MATLAB, consists of objects formed from flat black triangular patches as described below and rendered at a high resolution (<xref ref-type="fig" rid="pcbi-1002336-g008">Figure 8D</xref>), prior to being re-sampled at the low resolution of the simulated visual system (<xref ref-type="fig" rid="pcbi-1002336-g008">Figure 8C,E</xref>). This allows for subtle changes to be registered in response to small movements as would be the case for an ant with a low resolution visual system acting in the real world. This means the resultant view is composed of grey-scale values when a pixel is neither completely covered by sky nor completely covered by an object. In our simulated environment nearby objects are rendered in three dimensions whereas objects at a distance greater than 20 m from the route are flat but oriented so as to be maximally visible.</p>
        <sec id="s4a1">
          <title>Simulating tussocks, trees and bushes</title>
          <p><xref ref-type="fig" rid="pcbi-1002336-g009">Figure 9</xref> shows how the tussocks that form the majority of the objects in the simulated world are constructed. Each tussock is made from a base model consisting of 26 triangular patches that form an inverted cone shape. The vertices of the base model are randomly perturbed and rescaled to produce a variety of similar shaped objects at different scales that approximate the grass tussocks that are typical of the desert ants' natural environment.</p>
          <fig id="pcbi-1002336-g009" position="float">
            <object-id pub-id-type="doi">10.1371/journal.pcbi.1002336.g009</object-id>
            <label>Figure 9</label>
            <caption>
              <title>Constructing tussocks from a base model.</title>
              <p>A) Side and top view of the base model. B) Side and top view of randomly perturbed base model forming a tussock.</p>
            </caption>
            <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002336.g009" xlink:type="simple"/>
          </fig>
          <p><xref ref-type="fig" rid="pcbi-1002336-g010">Figure 10</xref> shows tree and bush objects and a typical panorama, as used in the experiments, prior to being down-sampled to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e010" xlink:type="simple"/></inline-formula>. By placing objects sufficiently far away (greater than 20 m), the view of them does not change significantly over the scale of the routes thereby providing a stable frame of reference. The trees and bushes were generated from flat triangular patches oriented so as to be maximally visible from the region of the world where the tussocks and training paths were located. A set of four different base <italic>tree trunks</italic> were used that were randomly flipped and rescaled to provide variation. The leaves of both the bushes and trees were generated from a base template containing a large number of triangular patches. A subset of these patches was randomly chosen for each tree or bush. The environment used in <xref ref-type="fig" rid="pcbi-1002336-g004">Figures 4</xref> and <xref ref-type="fig" rid="pcbi-1002336-g005">5</xref> contained 50 bushes and trees positioned at a uniformly distributed random distance in the range [20–50 m] and random azimuthal angle from the centre of the training route.</p>
          <fig id="pcbi-1002336-g010" position="float">
            <object-id pub-id-type="doi">10.1371/journal.pcbi.1002336.g010</object-id>
            <label>Figure 10</label>
            <caption>
              <title>Trees, bushes and the distant panorama.</title>
              <p>A) Randomly generated tree. B) Randomly generated bush. C) Randomly generated distant panorama.</p>
            </caption>
            <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002336.g010" xlink:type="simple"/>
          </fig>
        </sec>
      </sec>
      <sec id="s4b">
        <title>The simulated visual system</title>
        <p>Once an environment consisting of triangular patches has been created, a panoramic view from any position within the environment can be generated as follows. We first change the origin of the world to coincide with the position of the simulated ant by subtracting the current x, y and z coordinates of the ant from the set of vertices, X, Y and Z that define the triangular patches. The set of vertices [X, Y, Z] are then converted into spherical coordinates [<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e011" xlink:type="simple"/></inline-formula>] that represent the azimuth, elevation and radial distance. The radial information is discarded and the patches re-plotted in 2D giving the required binary panoramic view (<xref ref-type="fig" rid="pcbi-1002336-g008">Figure 8D</xref>) which is stored as a high-resolution [size <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e012" xlink:type="simple"/></inline-formula>] binary matrix. The final step is to reduce the resolution of this image to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e013" xlink:type="simple"/></inline-formula>, which represents the approximate sampling resolution of the compound eyes of <italic>Melophorus bagoti</italic> workers <xref ref-type="bibr" rid="pcbi.1002336-Schwarz1">[78]</xref>. The binary matrix is resized to [<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e014" xlink:type="simple"/></inline-formula>] using the <italic>imresize</italic> function in MATLAB and the average value of each [<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e015" xlink:type="simple"/></inline-formula>] block is then used as the value of the corresponding pixel in the low resolution representation. This averaging results in values in the range [0,1], with values between the two extremes indicating the fraction of sky and objects covered by a pixel in the original high resolution image [<xref ref-type="fig" rid="pcbi-1002336-g008">Figure 8E</xref>].</p>
      </sec>
      <sec id="s4c">
        <title>Training route generation</title>
        <p>The routes shown in <xref ref-type="fig" rid="pcbi-1002336-g008">Figure 8</xref> and used in the first sets of experiments (reported in <xref ref-type="fig" rid="pcbi-1002336-g001">Figures 1</xref> and <xref ref-type="fig" rid="pcbi-1002336-g003">3</xref>) are return paths taken from a paper by Muser et al. <xref ref-type="bibr" rid="pcbi.1002336-Muser1">[33]</xref> that describes the foraging ecology of <italic>Melophorus bagoti</italic>. While we have no knowledge of the real environment from which these paths were recorded we assume that the overall straightness of the paths is somewhat typical and that they therefore represent a reasonable example of the sort of paths that these ants must learn.</p>
        <p>In subsequent experiments, paths were generated iteratively starting from the end point of the outbound route using a combination of path integration and obstacle avoidance. Path integration was approximated by centring a Gaussian distribution with a standard deviation of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e016" xlink:type="simple"/></inline-formula> on the correct homeward direction and sampling from this distribution. Obstacle avoidance was incorporated into the path generation scheme by modulating the Gaussian distribution used for path integration by multiplying it by the proportion of sky visible in each direction, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e017" xlink:type="simple"/></inline-formula> (effectively the inverse of the height of the skyline; <xref ref-type="fig" rid="pcbi-1002336-g011">Figure 11A,B</xref>), raised to the power of 4, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e018" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pcbi-1002336-g011">Figure 11C</xref>). The resulting modulated Gaussian (<xref ref-type="fig" rid="pcbi-1002336-g011">Figure 11E</xref>) was renormalized and sampled from to determine a movement direction and a 4 cm step was taken in this direction. Training images are collected after every step. The obstacle avoidance modulation has the effect of biasing movements towards lower portions of the horizon while preventing completely movements towards objects that fill the entire visual field in the vertical direction. Due to the sampling involved in this process, individual paths between two locations will vary slightly allowing the collection of subtly different sets of images describing a route. A return path was considered complete when the distance to the nest was less than 4 cm.</p>
        <fig id="pcbi-1002336-g011" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002336.g011</object-id>
          <label>Figure 11</label>
          <caption>
            <title>Path integration modulated by obstacle avoidance.</title>
            <p>A,B,C) Obstacle avoidance is achieved by biasing movements towards low points on the horizon. D) A Gaussian distribution is centred on the home direction. E) The Gaussian is multiplied by the proportion of sky raised to the power of 4 and then normalised. This distribution is then sampled from to determine a movement direction.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002336.g011" xlink:type="simple"/>
        </fig>
      </sec>
      <sec id="s4d">
        <title>Learning walks</title>
        <p>Where learning walks were added to the training routes, we sampled views from pre-specified paths around the nest. Ants generally walk slower during their learning walks and so samples were taken every 2 cm along the paths as opposed to the 4 cm sampling that was used for generating the route data. These views are added to the start of the set of route views used to train the network in the order that they appear, beginning at the nest. The learning walk in <xref ref-type="fig" rid="pcbi-1002336-g002">Figure 2B</xref> is taken from <xref ref-type="bibr" rid="pcbi.1002336-Muser1">[33]</xref> but see also <xref ref-type="bibr" rid="pcbi.1002336-Mller3">[34]</xref> for another route shape that could have similar properties. The artificial learning walks were generated using a circular path with a radius of 0.5 m for the outbound section and a straight path for the inbound section (<xref ref-type="fig" rid="pcbi-1002336-g012">Figure 12</xref>). This is inspired by data from the learning flights of bumblebees whose early learning flights contain many loops with an inward portion oriented directly at the nest [A. Philippides, personal observation].</p>
        <fig id="pcbi-1002336-g012" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002336.g012</object-id>
          <label>Figure 12</label>
          <caption>
            <title>Artificial learning walks.</title>
            <p>The artificial learning walks are structured so that the outbound sections of the paths are curved while the returns are straight. Behavioural modulation of learning is achieved as views are only consistent during the straight inbound sections.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002336.g012" xlink:type="simple"/>
        </fig>
      </sec>
      <sec id="s4e">
        <title>The motor model and scanning routine</title>
        <p>In the experiments that we report using a perfect memory system, route recapitulation is performed using a complete <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e019" xlink:type="simple"/></inline-formula> scan of the environment (in steps of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e020" xlink:type="simple"/></inline-formula>) at each timestep. Normally distributed noise with a standard deviation of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e021" xlink:type="simple"/></inline-formula> is added to the preferred direction of movement and a 10 cm step is made in this direction (<xref ref-type="fig" rid="pcbi-1002336-g013">Figure 13</xref>).</p>
        <fig id="pcbi-1002336-g013" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002336.g013</object-id>
          <label>Figure 13</label>
          <caption>
            <title>The effects of noise.</title>
            <p>A) A random walk with normally distributed noise with a standard deviation of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e022" xlink:type="simple"/></inline-formula> added to the current heading at each timestep and a stepsize of 10 cm. B) A directed walk with a fixed heading of 0 and normally distributed noise with a standard deviation of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e023" xlink:type="simple"/></inline-formula> added at each timestep with a stepsize of 10 cm.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002336.g013" xlink:type="simple"/>
        </fig>
        <p>In the experiments that we report using the Infomax model we employ a slightly more realistic scanning routine during route recapitulation and instead of performing full <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e024" xlink:type="simple"/></inline-formula> scans we limit the scans to the frontal <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e025" xlink:type="simple"/></inline-formula> in steps of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e026" xlink:type="simple"/></inline-formula> relative to the current heading. We did this to make the scans more similar to those that real ants produce which are rarely as large as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e027" xlink:type="simple"/></inline-formula>. This had a negligible effect on performance except that it made it impossible to follow a path that had any turns greater than <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e028" xlink:type="simple"/></inline-formula> as were present in the Muser et al. learning walk in <xref ref-type="fig" rid="pcbi-1002336-g002">Figure 2B</xref>. As before, normally distributed noise with a standard deviation of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e029" xlink:type="simple"/></inline-formula> is added to the preferred direction of movement and a 10 cm step is made in this direction. However, when generating the pseudocolor plots in <xref ref-type="fig" rid="pcbi-1002336-g004">Figures 4</xref> and <xref ref-type="fig" rid="pcbi-1002336-g005">5</xref>, we did not have a current heading and so performed a full <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e030" xlink:type="simple"/></inline-formula> scan to generate an assumed movement direction.</p>
      </sec>
      <sec id="s4f">
        <title>Navigating with a perfect memory</title>
        <p>For the perfect memory system each of the views experienced along a training path was stored. we then calculated a familiarity metric as minus the minimum of the sum squared difference in pixel values between the current view and each of the stored views, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e031" xlink:type="simple"/></inline-formula>.<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e032" xlink:type="simple"/><label>(1)</label></disp-formula></p>
        <p>The maximum familiarity score across all rotated versions of the current view will be obtained for the most similar stored view and the direction from which this maximum was attained determines the next movement to make. In this setting, if the simulated ant does not stray from the training path then it is guaranteed to choose the correct direction to move at each timestep. This is because the most similar view will always be the one that was stored at that location while facing in the direction required to recapitulate the route.</p>
      </sec>
      <sec id="s4g">
        <title>Familiarity and Infomax</title>
        <p>In order to perform familiarity discrimination we chose to use a neural network model that was specifically designed to perform this task <xref ref-type="bibr" rid="pcbi.1002336-Lulham1">[59]</xref>. The architecture consists of an input layer and a novelty layer with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e033" xlink:type="simple"/></inline-formula> activation functions (<xref ref-type="fig" rid="pcbi-1002336-g014">Figure 14</xref>). The number of input units is equal to the dimensionality of the input which in our case is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e034" xlink:type="simple"/></inline-formula>, the number of pixels in a down-sampled view of the world. The number of novelty units is arbitrary and here we follow <xref ref-type="bibr" rid="pcbi.1002336-Lulham1">[59]</xref> and use the same number of novelty units as inputs. We found that using as few as 200 novelty units can work well in many instances. We did not explore this aspect of the problem in any detail since we were more interested in the behavioural consequences of a familiarity driven approach. The network is fully connected by feedforward connections <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e035" xlink:type="simple"/></inline-formula>. Weights are initialised randomly from a uniform distribution in the range <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e036" xlink:type="simple"/></inline-formula> and then normalised so that the mean of the weights feeding into each novelty unit is 0 and the standard deviation is 1. The network is trained using the Infomax principle <xref ref-type="bibr" rid="pcbi.1002336-Bell1">[79]</xref> adjusting the weights so as to maximise the information that the novelty units provide about the input, by following the gradient of the mutual information. The core update equation (4) in our learning scheme performs gradient ascent using the natural gradient <xref ref-type="bibr" rid="pcbi.1002336-Amari1">[80]</xref> of the mutual information over the weights <xref ref-type="bibr" rid="pcbi.1002336-Lee1">[81]</xref> (use of the natural gradient avoids the computationally expensive calculation of the inverse of the entire weight matrix). Since two novelty units that are correlated carry the same information, adjusting weights to maximise information will tend to decorrelate the activities of the novelty units and the algorithm can thus be used to extract independent components from the training data <xref ref-type="bibr" rid="pcbi.1002336-Lee1">[81]</xref>. We choose to use this approach mainly because it only requires a single pass through the data. This means that each view is experienced just once and then discarded. While with a limited amount of data the algorithm is unlikely to converge to a particularly good set of independent components, it is enough that the components that are extracted provide a more suitable decomposition of the training data than of an arbitrary input. During learning the activation of each of the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e037" xlink:type="simple"/></inline-formula> novelty units <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e038" xlink:type="simple"/></inline-formula> is computed as:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e039" xlink:type="simple"/><label>(2)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e040" xlink:type="simple"/></inline-formula> is the value of the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e041" xlink:type="simple"/></inline-formula> input and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e042" xlink:type="simple"/></inline-formula> is the number of input units. The output <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e043" xlink:type="simple"/></inline-formula> of the novelty units is then given by:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e044" xlink:type="simple"/><label>(3)</label></disp-formula>The weights are adjusted using the following learning rule:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e045" xlink:type="simple"/><label>(4)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e046" xlink:type="simple"/></inline-formula> is the learning rate and is set as 0.01 for this paper. Finally, the response of the network to the presentation of an unseen N-dimensional input <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e047" xlink:type="simple"/></inline-formula> is computed as<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e048" xlink:type="simple"/><label>(5)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e049" xlink:type="simple"/></inline-formula> denotes the absolute value. The network response could be viewed as an output layer but as it is a function of the activations of the novelty units, we follow <xref ref-type="bibr" rid="pcbi.1002336-Lulham1">[59]</xref> and do not represent it with another layer (<xref ref-type="fig" rid="pcbi-1002336-g014">Figure 14</xref>). As noted above, in this paper we set <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e050" xlink:type="simple"/></inline-formula> and the network is trained with each training view presented just once to the network in the order in which it is experienced in training. In <xref ref-type="bibr" rid="pcbi.1002336-Lulham1">[59]</xref> the authors use <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002336.e051" xlink:type="simple"/></inline-formula> together with a threshold that must be determined empirically to determine whether the input is novel or familiar. For our purposes it is not necessary to determine a threshold as we only need to choose the most familiar input from a limited number of possibilities i.e. the views experienced during a single scan of the environment.</p>
        <fig id="pcbi-1002336-g014" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002336.g014</object-id>
          <label>Figure 14</label>
          <caption>
            <title>The Infomax model.</title>
            <p>Circles represent units and arrows denote connections between the input units on the left and the novelty units on the right. There is no output from the network as such since the response of the network is a function of novelty unit activations. Following <xref ref-type="bibr" rid="pcbi.1002336-Lulham1">[59]</xref> we therefore do not draw an output layer.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002336.g014" xlink:type="simple"/>
        </fig>
        <p>The difference between the way an image difference function and a neural network trained using an Infomax principle represent familiarity will be subtle. In essence, the difference is manifest in the way the information is stored. For image differences, each stored view defines a single point in an n-dimensional space, with n equal to the dimension of the images (n = 90×17 = 1530) and the image difference function gives the squared Euclidean distance of an input image from one of these stored points. This requires all of the views to be stored and so memory load increases as more views are experienced. The Infomax approach instead decomposes each view into a fixed number of components (determined by the number of hidden units in the network) which remains constant, independent of the number of views experienced. The Infomax measure is more abstract and reflects whether a test input is well described in terms of the learned components that the hidden units represent. By decomposing the input in this way it is possible compress redundant data resulting in more efficient memory storage.</p>
      </sec>
    </sec>
  </body>
  <back>
    <ack>
      <p>We thank Patrick Schultheiss and Antoine Wystrach for the photograph of a <italic>Melophorus bagoti</italic> forager used in the online article.</p>
    </ack>
    <ref-list>
      <title>References</title>
      <ref id="pcbi.1002336-Collett1">
        <label>1</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Collett</surname><given-names>TS</given-names></name><name name-style="western"><surname>Dillmann</surname><given-names>E</given-names></name><name name-style="western"><surname>Giger</surname><given-names>A</given-names></name><name name-style="western"><surname>Wehner</surname><given-names>R</given-names></name></person-group>             <year>1992</year>             <article-title>Visual landmarks and route following in desert ants.</article-title>             <source>J Comp Physiol A</source>             <volume>170</volume>             <fpage>435</fpage>             <lpage>442</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Wehner1">
        <label>2</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Wehner</surname><given-names>R</given-names></name><name name-style="western"><surname>Michel</surname><given-names>B</given-names></name><name name-style="western"><surname>Antonsen</surname><given-names>P</given-names></name></person-group>             <year>1996</year>             <article-title>Visual navigation in insects: Coupling of egocentric and geocentric information.</article-title>             <source>J Exp Biol</source>             <volume>199</volume>             <fpage>129</fpage>             <lpage>140</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Kohler1">
        <label>3</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kohler</surname><given-names>M</given-names></name><name name-style="western"><surname>Wehner</surname><given-names>R</given-names></name></person-group>             <year>2005</year>             <article-title>Idiosyncratic route-based memories in desert ants, <italic>Melophorus bagoti</italic>: How do they interact with path-integration vectors?</article-title>             <source>Neurobiol Learn Mem</source>             <volume>83</volume>             <fpage>1</fpage>             <lpage>12</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Wehner2">
        <label>4</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Wehner</surname><given-names>R</given-names></name><name name-style="western"><surname>Boyer</surname><given-names>M</given-names></name><name name-style="western"><surname>Loertscher</surname><given-names>F</given-names></name><name name-style="western"><surname>Sommer</surname><given-names>S</given-names></name><name name-style="western"><surname>Menzi</surname><given-names>U</given-names></name></person-group>             <year>2006</year>             <article-title>Ant navigation: One-way routes rather than maps.</article-title>             <source>Curr Biol</source>             <volume>16</volume>             <fpage>75</fpage>             <lpage>79</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Narendra1">
        <label>5</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Narendra</surname><given-names>A</given-names></name></person-group>             <year>2007</year>             <article-title>Homing strategies of the Australian desert ant <italic>Melophorus bagoti</italic>. II. Interaction of the path integrator with visual cue information.</article-title>             <source>J Exp Biol</source>             <volume>210</volume>             <fpage>1804</fpage>             <lpage>1812</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Sommer1">
        <label>6</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Sommer</surname><given-names>S</given-names></name><name name-style="western"><surname>von Beeren</surname><given-names>C</given-names></name><name name-style="western"><surname>Wehner</surname><given-names>R</given-names></name></person-group>             <year>2008</year>             <article-title>Multiroute memories in desert ants.</article-title>             <source>Proc Natl Acad Sci USA</source>             <volume>105</volume>             <fpage>317</fpage>             <lpage>322</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Graham1">
        <label>7</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Graham</surname><given-names>P</given-names></name><name name-style="western"><surname>Cheng</surname><given-names>K</given-names></name></person-group>             <year>2009</year>             <article-title>Ants use the panoramic skyline as a visual cue during navigation.</article-title>             <source>Curr Biol</source>             <volume>19</volume>             <fpage>R935</fpage>             <lpage>R937</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Wystrach1">
        <label>8</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Wystrach</surname><given-names>A</given-names></name><name name-style="western"><surname>Schwarz</surname><given-names>S</given-names></name><name name-style="western"><surname>Schultheiss</surname><given-names>P</given-names></name><name name-style="western"><surname>Beugnon</surname><given-names>G</given-names></name><name name-style="western"><surname>Cheng</surname><given-names>K</given-names></name></person-group>             <year>2011</year>             <article-title>Views, landmarks, and routes: How do desert ants negotiate an obstacle course?</article-title>             <source>J Comp Physiol A</source>             <volume>197</volume>             <fpage>167</fpage>             <lpage>79</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Wehner3">
        <label>9</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Wehner</surname><given-names>R</given-names></name></person-group>             <year>2003</year>             <article-title>Desert ant navigation: How miniature brains solve complex tasks. Karl von Frisch lecture.</article-title>             <source>J Comp Physiol A</source>             <volume>189</volume>             <fpage>579</fpage>             <lpage>588</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Chittka1">
        <label>10</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Chittka</surname><given-names>L</given-names></name><name name-style="western"><surname>Skorupski</surname><given-names>P</given-names></name></person-group>             <year>2011</year>             <article-title>Information processing in miniature brains.</article-title>             <source>Proc R Soc Lond B</source>             <volume>278</volume>             <fpage>885</fpage>             <lpage>888</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Menzel1">
        <label>11</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Menzel</surname><given-names>R</given-names></name><name name-style="western"><surname>Giurfa</surname><given-names>M</given-names></name></person-group>             <year>2001</year>             <article-title>Cognitive architecture of a mini-brain: The honeybee.</article-title>             <source>Trends Cogn Sci</source>             <volume>5</volume>             <fpage>62</fpage>             <lpage>71</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Wehner4">
        <label>12</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Wehner</surname><given-names>R</given-names></name></person-group>             <year>2009</year>             <article-title>The architecture of the desert ant's navigational toolkit (Hymenoptera: Formi- cidae).</article-title>             <source>Myrmecol News</source>             <volume>12</volume>             <fpage>85</fpage>             <lpage>96</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Shettleworth1">
        <label>13</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Shettleworth</surname><given-names>SJ</given-names></name></person-group>             <year>2010</year>             <source>Cognition, Evolution, and Behavior. 2nd edition</source>             <publisher-loc>New York</publisher-loc>             <publisher-name>Oxford University Press</publisher-name>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Webb1">
        <label>14</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Webb</surname><given-names>B</given-names></name></person-group>             <year>2001</year>             <article-title>Can robots make good models of biological behaviour?</article-title>             <source>Behav Brain Sci</source>             <volume>24</volume>             <fpage>1050</fpage>             <lpage>1094</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Webb2">
        <label>15</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Webb</surname><given-names>B</given-names></name></person-group>             <year>2009</year>             <article-title>Animals versus animats: Or why not model the real iguana?</article-title>             <source>Adapt Behav</source>             <volume>17</volume>             <fpage>269</fpage>             <lpage>286</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Cartwright1">
        <label>16</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Cartwright</surname><given-names>BA</given-names></name><name name-style="western"><surname>Collett</surname><given-names>TS</given-names></name></person-group>             <year>1983</year>             <article-title>Landmark learning in bees.</article-title>             <source>J Comp Physiol A</source>             <volume>151</volume>             <fpage>521543</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Cruse1">
        <label>17</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Cruse</surname><given-names>H</given-names></name><name name-style="western"><surname>Wehner</surname><given-names>R</given-names></name></person-group>             <year>2011</year>             <article-title>No need for a cognitive map: Decentralized memory for insect naviga- tion.</article-title>             <source>PLoS Comput Biol</source>             <volume>7</volume>             <fpage>e1002009</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Lambrinos1">
        <label>18</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Lambrinos</surname><given-names>D</given-names></name><name name-style="western"><surname>Möller</surname><given-names>R</given-names></name><name name-style="western"><surname>Pfeifer</surname><given-names>R</given-names></name><name name-style="western"><surname>Wehner</surname><given-names>R</given-names></name></person-group>             <year>1998</year>             <article-title>Landmark navigation without snapshots: The average landmark vector model.</article-title>             <person-group person-group-type="editor"><name name-style="western"><surname>Elsner</surname><given-names>N</given-names></name><name name-style="western"><surname>Wehner</surname><given-names>R</given-names></name></person-group>             <source>Proc Neurobiol Conf Göttingen</source>             <publisher-loc>Stuttgart</publisher-loc>             <publisher-name>Georg Thieme Verlag</publisher-name> <!--===== Restructure page-count as size[@units="page"] =====--><size units="page">30a</size>           </element-citation>
      </ref>
      <ref id="pcbi.1002336-Franz1">
        <label>19</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Franz</surname><given-names>M</given-names></name><name name-style="western"><surname>Schölkopf</surname><given-names>B</given-names></name><name name-style="western"><surname>Georg</surname><given-names>P</given-names></name><name name-style="western"><surname>Mallot</surname><given-names>H</given-names></name><name name-style="western"><surname>Bülthoff</surname><given-names>H</given-names></name></person-group>             <year>1998</year>             <article-title>Learning view graphs for robot navigation.</article-title>             <source>Auton Robot</source>             <volume>5</volume>             <fpage>111</fpage>             <lpage>125</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Franz2">
        <label>20</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Franz</surname><given-names>M</given-names></name><name name-style="western"><surname>Schölkopf</surname><given-names>B</given-names></name><name name-style="western"><surname>Mallot</surname><given-names>H</given-names></name><name name-style="western"><surname>Bülthoff</surname><given-names>H</given-names></name></person-group>             <year>1998</year>             <article-title>Where did I take that snapshot? Scene-based homing by image matching.</article-title>             <source>Biol Cybern</source>             <volume>79</volume>             <fpage>191</fpage>             <lpage>202</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Zeil1">
        <label>21</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Zeil</surname><given-names>J</given-names></name><name name-style="western"><surname>Hofmann</surname><given-names>M</given-names></name><name name-style="western"><surname>Chahl</surname><given-names>J</given-names></name></person-group>             <year>2003</year>             <article-title>Catchment areas of panoramic snapshots in outdoor scenes.</article-title>             <source>J Opt Soc Am A</source>             <volume>20</volume>             <fpage>450</fpage>             <lpage>469</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Vardy1">
        <label>22</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Vardy</surname><given-names>A</given-names></name><name name-style="western"><surname>Möller</surname><given-names>R</given-names></name></person-group>             <year>2005</year>             <article-title>Biologically plausible visual homing methods based on optical flow techniques.</article-title>             <source>Connect Sci</source>             <volume>17</volume>             <fpage>47</fpage>             <lpage>89</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Mller1">
        <label>23</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Möller</surname><given-names>R</given-names></name><name name-style="western"><surname>Vardy</surname><given-names>A</given-names></name></person-group>             <year>2006</year>             <article-title>Local visual homing by matched-filter descent in image distances.</article-title>             <source>Biol Cybern</source>             <volume>95</volume>             <fpage>413</fpage>             <lpage>430</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Strzl1">
        <label>24</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Stürzl</surname><given-names>W</given-names></name><name name-style="western"><surname>Mallot</surname><given-names>H</given-names></name></person-group>             <year>2006</year>             <article-title>Efficient visual homing based on Fourier transformed panoramic images.</article-title>             <source>Robot Auton Syst</source>             <volume>54</volume>             <fpage>300</fpage>             <lpage>313</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Strzl2">
        <label>25</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Stürzl</surname><given-names>W</given-names></name><name name-style="western"><surname>Zeil</surname><given-names>J</given-names></name></person-group>             <year>2007</year>             <article-title>Depth, contrast and view-based homing in outdoor scenes.</article-title>             <source>Biol Cybern</source>             <volume>96</volume>             <fpage>519</fpage>             <lpage>531</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Mller2">
        <label>26</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Möller</surname><given-names>R</given-names></name><name name-style="western"><surname>Vardy</surname><given-names>A</given-names></name><name name-style="western"><surname>Gerstmayr</surname><given-names>L</given-names></name><name name-style="western"><surname>Röben</surname><given-names>F</given-names></name><name name-style="western"><surname>Kreft</surname><given-names>S</given-names></name></person-group>             <year>2008</year>             <article-title>Neuroethological concepts at work: Insect-inspired methods for visual robot navigation.</article-title>             <source>Biological Approaches for Engineering</source>             <fpage>91</fpage>             <lpage>94</lpage>             <comment>Institute of Sound and Vibration Research, University of Southampton</comment>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Vardy2">
        <label>27</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Vardy</surname><given-names>A</given-names></name></person-group>             <year>2006</year>             <article-title>Long-range visual homing.</article-title>             <fpage>220</fpage>             <lpage>226</lpage>             <comment>In: IEEE International Conference on Robotics and Biomimetics</comment>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Smith1">
        <label>28</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Smith</surname><given-names>L</given-names></name><name name-style="western"><surname>Philippides</surname><given-names>A</given-names></name><name name-style="western"><surname>Graham</surname><given-names>P</given-names></name><name name-style="western"><surname>Baddeley</surname><given-names>B</given-names></name><name name-style="western"><surname>Husbands</surname><given-names>P</given-names></name></person-group>             <year>2007</year>             <article-title>Linked local navigation for visual route guidance.</article-title>             <source>Adapt Behav</source>             <volume>15</volume>             <fpage>257</fpage>             <lpage>271</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Harrison1">
        <label>29</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Harrison</surname><given-names>JF</given-names></name><name name-style="western"><surname>Fewell</surname><given-names>JH</given-names></name><name name-style="western"><surname>Stiller</surname><given-names>FM</given-names></name><name name-style="western"><surname>Breed</surname><given-names>MD</given-names></name></person-group>             <year>1989</year>             <article-title>Effects of experience on use of orientation cues in the giant tropical ant.</article-title>             <source>Anim Behav</source>             <volume>37</volume>             <fpage>869</fpage>             <lpage>871</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Klotz1">
        <label>30</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Klotz</surname><given-names>JH</given-names></name></person-group>             <year>1987</year>             <article-title>Topographic orientation in two speicies of ants (Hymenoptera: Formicidae).</article-title>             <source>Insect Soc</source>             <volume>34</volume>             <fpage>236</fpage>             <lpage>251</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Andel1">
        <label>31</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Andel</surname><given-names>D</given-names></name><name name-style="western"><surname>Wehner</surname><given-names>R</given-names></name></person-group>             <year>2004</year>             <article-title>Path integration in desert ants, <italic>Cataglyphis</italic>: How to make a homing ant run away from home.</article-title>             <source>Proc R Soc Lond B</source>             <volume>271</volume>             <fpage>1485</fpage>             <lpage>1489</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Collett2">
        <label>32</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Collett</surname><given-names>TS</given-names></name><name name-style="western"><surname>Graham</surname><given-names>P</given-names></name><name name-style="western"><surname>Durier</surname><given-names>V</given-names></name></person-group>             <year>2003</year>             <article-title>Route learning by insects.</article-title>             <source>Curr Opin Neurobiol</source>             <volume>13</volume>             <fpage>718</fpage>             <lpage>725</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Muser1">
        <label>33</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Muser</surname><given-names>B</given-names></name><name name-style="western"><surname>Sommer</surname><given-names>S</given-names></name><name name-style="western"><surname>Wolf</surname><given-names>H</given-names></name><name name-style="western"><surname>Wehner</surname><given-names>R</given-names></name></person-group>             <year>2005</year>             <article-title>Foraging ecology of the thermophilic Australian desert ant, <italic>Melophorus bagoti</italic>.</article-title>             <source>Austral J Zool</source>             <volume>53</volume>             <fpage>301</fpage>             <lpage>311</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Mller3">
        <label>34</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Müller</surname><given-names>M</given-names></name><name name-style="western"><surname>Wehner</surname><given-names>R</given-names></name></person-group>             <year>2010</year>             <article-title>Path integration provides a scaffold for landmark learning in desert ants.</article-title>             <source>Curr Biol</source>             <volume>20</volume>             <fpage>1368</fpage>             <lpage>1371</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Wehner5">
        <label>35</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Wehner</surname><given-names>R</given-names></name><name name-style="western"><surname>Meier</surname><given-names>C</given-names></name><name name-style="western"><surname>Zollikofer</surname><given-names>C</given-names></name></person-group>             <year>2004</year>             <article-title>The ontogeny of foraging behaviour in desert ants, <italic>Cataglyphis bicolor</italic>.</article-title>             <source>Ecol Entomol</source>             <volume>29</volume>             <fpage>240</fpage>             <lpage>250</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Mller4">
        <label>36</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Müller</surname><given-names>M</given-names></name><name name-style="western"><surname>Wehner</surname><given-names>R</given-names></name></person-group>             <year>1988</year>             <article-title>Path integration in desert ants, <italic>Cataglyphis fortis</italic>.</article-title>             <source>Proc Natl Acad Sci U S A</source>             <volume>85</volume>             <fpage>5287</fpage>             <lpage>5290</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Cheng1">
        <label>37</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Cheng</surname><given-names>K</given-names></name><name name-style="western"><surname>Narendra</surname><given-names>A</given-names></name><name name-style="western"><surname>Sommer</surname><given-names>S</given-names></name><name name-style="western"><surname>Wehner</surname><given-names>R</given-names></name></person-group>             <year>2009</year>             <article-title>Traveling in clutter: Navigation in the Central Australian desert ant <italic>Melophorus bagoti</italic>.</article-title>             <source>Behav Process</source>             <volume>80</volume>             <fpage>261</fpage>             <lpage>268</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Collett3">
        <label>38</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Collett</surname><given-names>TS</given-names></name><name name-style="western"><surname>Collett</surname><given-names>M</given-names></name><name name-style="western"><surname>Wehner</surname><given-names>R</given-names></name></person-group>             <year>2001</year>             <article-title>The guidance of desert ants by extended landmarks.</article-title>             <source>J Exp Biol</source>             <volume>204</volume>             <fpage>1635</fpage>             <lpage>1639</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Collett4">
        <label>39</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Collett</surname><given-names>M</given-names></name></person-group>             <year>2010</year>             <article-title>How desert ants use a visual landmark for guidance along a habitual route.</article-title>             <source>Proc Natl Acad Sci U S A</source>             <volume>107</volume>             <fpage>11638</fpage>             <lpage>11643</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Collett5">
        <label>40</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Collett</surname><given-names>M</given-names></name><name name-style="western"><surname>Collett</surname><given-names>TS</given-names></name><name name-style="western"><surname>Bisch</surname><given-names>S</given-names></name><name name-style="western"><surname>Wehner</surname><given-names>R</given-names></name></person-group>             <year>1998</year>             <article-title>Local and global vectors in desert ant navigation.</article-title>             <source>Nature</source>             <volume>394</volume>             <fpage>269</fpage>             <lpage>272</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Collett6">
        <label>41</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Collett</surname><given-names>M</given-names></name><name name-style="western"><surname>Collett</surname><given-names>T</given-names></name></person-group>             <year>2009</year>             <article-title>Local and global navigational coordinate systems in desert ants.</article-title>             <source>J Exp Biol</source>             <volume>212</volume>             <fpage>901</fpage>             <lpage>905</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Wehner6">
        <label>42</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Wehner</surname><given-names>R</given-names></name><name name-style="western"><surname>Raber</surname><given-names>F</given-names></name></person-group>             <year>1979</year>             <article-title>Visual spatial memory in desert ants, <italic>Cataglyphis bicolor</italic> (Hymenoptera: Formicidae).</article-title>             <source>Cell Mol Life Sci</source>             <volume>35</volume>             <fpage>1569</fpage>             <lpage>1571</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Narendra2">
        <label>43</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Narendra</surname><given-names>A</given-names></name><name name-style="western"><surname>Si</surname><given-names>A</given-names></name><name name-style="western"><surname>Sulikowski</surname><given-names>D</given-names></name><name name-style="western"><surname>Cheng</surname><given-names>K</given-names></name></person-group>             <year>2007</year>             <article-title>Learning, retention and coding of nest-associated visual cues by the Australian desert ant <italic>Melophorus bagoti</italic>.</article-title>             <source>Behav Ecol Sociobiol</source>             <volume>61</volume>             <fpage>1543</fpage>             <lpage>1553</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Wehner7">
        <label>44</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Wehner</surname><given-names>R</given-names></name><name name-style="western"><surname>Müller</surname><given-names>M</given-names></name></person-group>             <year>2010</year>             <article-title>Piloting in desert ants: pinpointing the goal by discrete landmarks.</article-title>             <source>J Exp Biol</source>             <volume>213</volume>             <fpage>4174</fpage>             <lpage>4179</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Mangan1">
        <label>45</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Mangan</surname><given-names>M</given-names></name></person-group>             <year>2011</year>             <article-title>Visual homing in field crickets and desert ants: A comparative behavioural and modelling study.</article-title>             <comment>Ph.D. thesis, University of Edinburgh, UK</comment>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Cartwright2">
        <label>46</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Cartwright</surname><given-names>B</given-names></name><name name-style="western"><surname>Collett</surname><given-names>T</given-names></name></person-group>             <year>1987</year>             <article-title>Landmark maps for honeybees.</article-title>             <source>Biol Cybern</source>             <volume>57</volume>             <fpage>85</fpage>             <lpage>93</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Philippides1">
        <label>47</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Philippides</surname><given-names>A</given-names></name><name name-style="western"><surname>Baddeley</surname><given-names>B</given-names></name><name name-style="western"><surname>Cheng</surname><given-names>K</given-names></name><name name-style="western"><surname>Graham</surname><given-names>P</given-names></name></person-group>             <year>2011</year>             <article-title>How might ants use panoramic views for route navigation?</article-title>             <source>J Exp Biol</source>             <volume>214</volume>             <fpage>445</fpage>             <lpage>451</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Collett7">
        <label>48</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Collett</surname><given-names>TS</given-names></name></person-group>             <year>1995</year>             <article-title>Making learning easy: The acquisition of information during orientation flights of social wasps.</article-title>             <source>J Comp Physiol A</source>             <volume>177</volume>             <fpage>737</fpage>             <lpage>747</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Collett8">
        <label>49</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Collett</surname><given-names>TS</given-names></name><name name-style="western"><surname>Rees</surname><given-names>J</given-names></name></person-group>             <year>1997</year>             <article-title>View-based navigation in Hymenoptera: Multiple strategies of landmark guidance in the approach to a feeder.</article-title>             <source>J Comp Physiol A</source>             <volume>181</volume>             <fpage>47</fpage>             <lpage>58</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-HempeldeIbarra1">
        <label>50</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hempel de Ibarra</surname><given-names>N</given-names></name><name name-style="western"><surname>Philippides</surname><given-names>A</given-names></name><name name-style="western"><surname>Riabinina</surname><given-names>O</given-names></name><name name-style="western"><surname>Collett</surname><given-names>T</given-names></name></person-group>             <year>2009</year>             <article-title>Preferred viewing directions of bumblebees (<italic>Bombus terrestris L.</italic>) when learning and approaching their nest site.</article-title>             <source>J Exp Biol</source>             <volume>212</volume>             <fpage>3193</fpage>             <lpage>3204</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Labrosse1">
        <label>51</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Labrosse</surname><given-names>F</given-names></name></person-group>             <year>2006</year>             <article-title>The visual compass: Performance and limitations of an appearance-based method.</article-title>             <source>J Field Robot</source>             <volume>23</volume>             <fpage>913</fpage>             <lpage>941</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Graham2">
        <label>52</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Graham</surname><given-names>P</given-names></name><name name-style="western"><surname>Philippides</surname><given-names>A</given-names></name><name name-style="western"><surname>Baddeley</surname><given-names>B</given-names></name></person-group>             <year>2010</year>             <article-title>Animal cognition: Multi-modal interactions in ant learning.</article-title>             <source>Curr Biol</source>             <volume>20</volume>             <fpage>R639</fpage>             <lpage>R640</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Basten1">
        <label>53</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Basten</surname><given-names>K</given-names></name><name name-style="western"><surname>Mallot</surname><given-names>HA</given-names></name></person-group>             <year>2011</year>             <article-title>Simulated visual homing in desert ant natural environments: efficiency of skyline cues.</article-title>             <source>Biol Cybern</source>             <volume>102</volume>             <fpage>413</fpage>             <lpage>425</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Smith2">
        <label>54</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Smith</surname><given-names>L</given-names></name><name name-style="western"><surname>Philippides</surname><given-names>A</given-names></name><name name-style="western"><surname>Graham</surname><given-names>P</given-names></name><name name-style="western"><surname>Husbands</surname><given-names>P</given-names></name></person-group>             <year>2008</year>             <article-title>Linked local visual navigation and robust- ness to motor noise and route displacement.</article-title>             <source>SAB '08: Proceedings of the 10th International Conference on Simulation of Adaptive Behavior</source>             <publisher-loc>Berlin, Heidelberg</publisher-loc>             <publisher-name>Springer-Verlag</publisher-name>             <fpage>179</fpage>             <lpage>188</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Baddeley1">
        <label>55</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Baddeley</surname><given-names>B</given-names></name><name name-style="western"><surname>Graham</surname><given-names>P</given-names></name><name name-style="western"><surname>Philippides</surname><given-names>A</given-names></name><name name-style="western"><surname>Husbands</surname><given-names>P</given-names></name></person-group>             <year>2011</year>             <article-title>Holistic visual encoding of ant-like routes: Navigation without waypoints.</article-title>             <source>Adapt Behav</source>             <volume>19</volume>             <fpage>3</fpage>             <lpage>15</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Wehner8">
        <label>56</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Wehner</surname><given-names>R</given-names></name><name name-style="western"><surname>Fukushi</surname><given-names>T</given-names></name><name name-style="western"><surname>Wehner</surname><given-names>S</given-names></name></person-group>             <year>1992</year>             <article-title>Rotatory components of movement in high speed desert ants, <italic>Cataglyphis bombycina</italic>.</article-title>             <comment>In: Proceedings of the 20th Göttingen Neurobiology Conference</comment> <!--===== Restructure page-count as size[@units="page"] =====--><size units="page">20:303</size>           </element-citation>
      </ref>
      <ref id="pcbi.1002336-Wehner9">
        <label>57</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Wehner</surname><given-names>R</given-names></name></person-group>             <year>1994</year>             <article-title>The polarization-vision project: Championing organismic biology.</article-title>             <source>Fortschr Zool</source>             <volume>39</volume>             <fpage>103</fpage>             <lpage>143</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Graham3">
        <label>58</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Graham</surname><given-names>P</given-names></name><name name-style="western"><surname>Collett</surname><given-names>TS</given-names></name></person-group>             <year>2002</year>             <article-title>View-based navigation in insects: How wood ants (<italic>Formica rufa L.</italic>) look at and are guided by extended landmarks.</article-title>             <source>J Exp Biol</source>             <volume>205</volume>             <fpage>2499</fpage>             <lpage>2509</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Lulham1">
        <label>59</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Lulham</surname><given-names>A</given-names></name><name name-style="western"><surname>Bogacz</surname><given-names>R</given-names></name><name name-style="western"><surname>Vogt</surname><given-names>S</given-names></name><name name-style="western"><surname>Brown</surname><given-names>MW</given-names></name></person-group>             <year>2011</year>             <article-title>An infomax algorithm can perform both famil- iarity discrimination and feature extraction in a single network.</article-title>             <source>Neural Comput</source>             <volume>23</volume>             <fpage>909</fpage>             <lpage>926</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Amit1">
        <label>60</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Amit</surname><given-names>D</given-names></name></person-group>             <year>1989</year>             <source>Modelling brain function: The world of attractor networks</source>             <publisher-loc>Cambridge</publisher-loc>             <publisher-name>Cambridge University Press</publisher-name>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Steck1">
        <label>61</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Steck</surname><given-names>K</given-names></name><name name-style="western"><surname>Hansson</surname><given-names>B</given-names></name><name name-style="western"><surname>Knaden</surname><given-names>M</given-names></name></person-group>             <year>2009</year>             <article-title>Smells like home: Desert ants, <italic>Cataglyphis fortis</italic>, use olfactory landmarks to pinpoint the nest.</article-title>             <source>Front Zool</source>             <volume>6</volume>             <fpage>5</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Seidl1">
        <label>62</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Seidl</surname><given-names>T</given-names></name><name name-style="western"><surname>Wehner</surname><given-names>R</given-names></name></person-group>             <year>2006</year>             <article-title>Visual and tactile learning of ground structures in desert ants.</article-title>             <source>J Exp Biol</source>             <volume>209</volume>             <fpage>3336</fpage>             <lpage>44</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-McGuire1">
        <label>63</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>McGuire</surname><given-names>S</given-names></name><name name-style="western"><surname>Le</surname><given-names>P</given-names></name><name name-style="western"><surname>Davis</surname><given-names>R</given-names></name></person-group>             <year>2001</year>             <article-title>The role of <italic>Drosophila</italic> mushroom body signaling in olfactory memory.</article-title>             <source>Science</source>             <volume>293</volume>             <fpage>1330</fpage>             <lpage>1333</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-PerezOrive1">
        <label>64</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Perez-Orive</surname><given-names>J</given-names></name><name name-style="western"><surname>Mazor</surname><given-names>O</given-names></name><name name-style="western"><surname>Turner</surname><given-names>GC</given-names></name><name name-style="western"><surname>Cassenaer</surname><given-names>S</given-names></name><name name-style="western"><surname>Wilson</surname><given-names>RI</given-names></name><etal/></person-group>             <year>2002</year>             <article-title>Oscillations and spars- ening of odor representations in the mushroom body.</article-title>             <source>Science</source>             <volume>297</volume>             <fpage>359</fpage>             <lpage>365</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Blum1">
        <label>65</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Blum</surname><given-names>AL</given-names></name><name name-style="western"><surname>Li</surname><given-names>W</given-names></name><name name-style="western"><surname>Cressy</surname><given-names>M</given-names></name><name name-style="western"><surname>Dubnau</surname><given-names>J</given-names></name></person-group>             <year>2009</year>             <article-title>Short- and long-term memory in <italic>Drosophila</italic> require cAMP signaling in distinct neuron types.</article-title>             <source>Curr Biol</source>             <volume>19</volume>             <fpage>1341</fpage>             <lpage>1350</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-vanSwinderen1">
        <label>66</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>van Swinderen</surname><given-names>B</given-names></name><name name-style="western"><surname>Brembs</surname><given-names>B</given-names></name></person-group>             <year>2010</year>             <article-title>Attention-like deficit and hyperactivity in a <italic>Drosophila</italic> memory mutant.</article-title>             <source>J Neurosci</source>             <volume>30</volume>             <fpage>1003</fpage>             <lpage>1014</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Schildberger1">
        <label>67</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Schildberger</surname><given-names>K</given-names></name></person-group>             <year>1984</year>             <article-title>Multimodal interneurons in the cricket brain: Properties of identified ex- trinsic mushroom body cells.</article-title>             <source>J Comp Physiol A</source>             <volume>154</volume>             <fpage>71</fpage>             <lpage>79</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Li1">
        <label>68</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>Y</given-names></name><name name-style="western"><surname>Strausfeld</surname><given-names>N</given-names></name></person-group>             <year>1999</year>             <article-title>Multimodal efferent and recurrent neurons in the medial lobes of cock- roach mushroom bodies.</article-title>             <source>J Comp Neurol</source>             <volume>409</volume>             <fpage>647</fpage>             <lpage>63</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Mizunami1">
        <label>69</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Mizunami</surname><given-names>M</given-names></name><name name-style="western"><surname>Weibrecht</surname><given-names>JM</given-names></name><name name-style="western"><surname>Strausfeld</surname><given-names>NJ</given-names></name></person-group>             <year>1993</year>             <article-title>A new role for the insect mushroom bod- ies: Place memory and motor control.</article-title>             <source>Proceedings of the workshop on “Locomotion Control in Legged Invertebrates” on Biological neural networks in invertebrate neuroethology and robotics</source>             <publisher-loc>San Diego, CA, USA</publisher-loc>             <publisher-name>Academic Press Professional, Inc</publisher-name>             <fpage>199</fpage>             <lpage>225</lpage>             <comment>Available: <ext-link ext-link-type="uri" xlink:href="http://portal.acm.org/citation.cfm?id=169157.169186" xlink:type="simple">http://portal.acm.org/citation.cfm?id=169157.169186</ext-link></comment>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Mizunami2">
        <label>70</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Mizunami</surname><given-names>M</given-names></name><name name-style="western"><surname>Weibrecht</surname><given-names>JM</given-names></name><name name-style="western"><surname>Strausfeld</surname><given-names>NJ</given-names></name></person-group>             <year>1998</year>             <article-title>Mushroom bodies of the cockroach: Their participation in place memory.</article-title>             <source>J Comp Neurol</source>             <volume>402</volume>             <fpage>520</fpage>             <lpage>537</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Farris1">
        <label>71</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Farris</surname><given-names>SM</given-names></name><name name-style="western"><surname>Schulmeister</surname><given-names>S</given-names></name></person-group>             <year>2011</year>             <article-title>Parasitoidism, not sociality, is associated with the evolution of elaborate mushroom bodies in the brains of Hymenopteran insects.</article-title>             <source>Proc R Soc Lond B</source>             <volume>278</volume>             <fpage>940</fpage>             <lpage>951</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Stieb1">
        <label>72</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Stieb</surname><given-names>SM</given-names></name><name name-style="western"><surname>Muenz</surname><given-names>TS</given-names></name><name name-style="western"><surname>Wehner</surname><given-names>R</given-names></name><name name-style="western"><surname>Rössler</surname><given-names>W</given-names></name></person-group>             <year>2010</year>             <article-title>Visual experience and age affect synaptic organization in the mushroom bodies of the desert ant <italic>Cataglyphis fortis</italic>.</article-title>             <source>Dev Neurobiol</source>             <volume>70</volume>             <fpage>408</fpage>             <lpage>23</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Baddeley2">
        <label>73</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Baddeley</surname><given-names>B</given-names></name><name name-style="western"><surname>Graham</surname><given-names>P</given-names></name><name name-style="western"><surname>Philippides</surname><given-names>A</given-names></name><name name-style="western"><surname>Husbands</surname><given-names>P</given-names></name></person-group>             <year>2011</year>             <article-title>Models of visually guided routes in ants: Embodiment simplifies route acquisition.</article-title>             <person-group person-group-type="editor"><name name-style="western"><surname>Jeschke</surname><given-names>S</given-names></name><name name-style="western"><surname>Liu</surname><given-names>H</given-names></name><name name-style="western"><surname>Schilberg</surname><given-names>D</given-names></name></person-group>             <source>Proceedings of the International Conference on Intelligent Robotics and Applications (ICIRA) Part II, Lecture Notes in Artificial Intelligence</source>             <publisher-loc>Heidelberg</publisher-loc>             <publisher-name>Springer-Verlag, volume 7102</publisher-name>             <fpage>75</fpage>             <lpage>84</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Wehner10">
        <label>74</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Wehner</surname><given-names>R</given-names></name><name name-style="western"><surname>Menzel</surname><given-names>R</given-names></name></person-group>             <year>1990</year>             <article-title>Do insects have cognitive maps?</article-title>             <source>Annu Rev Neurosci</source>             <volume>13</volume>             <fpage>403</fpage>             <lpage>414</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Collett9">
        <label>75</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Collett</surname><given-names>TS</given-names></name><name name-style="western"><surname>Graham</surname><given-names>P</given-names></name><name name-style="western"><surname>Harris</surname><given-names>RA</given-names></name><name name-style="western"><surname>Hempel de Ibarra</surname><given-names>N</given-names></name></person-group>             <year>2006</year>             <article-title>Navigational memories in ants and bees: Memory retrieval when selecting and following routes.</article-title>             <source>Adv Stud Behav</source>             <volume>36</volume>             <fpage>123</fpage>             <lpage>172</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Collett10">
        <label>76</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Collett</surname><given-names>M</given-names></name><name name-style="western"><surname>Collett</surname><given-names>TS</given-names></name></person-group>             <year>2006</year>             <article-title>Insect navigation: No map at the end of the trail?</article-title>             <source>Curr Biol</source>             <volume>16</volume>             <fpage>48</fpage>             <lpage>51</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Harris1">
        <label>77</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Harris</surname><given-names>RA</given-names></name><name name-style="western"><surname>Hempel de Ibarra</surname><given-names>N</given-names></name><name name-style="western"><surname>Graham</surname><given-names>P</given-names></name><name name-style="western"><surname>Collett</surname><given-names>T</given-names></name></person-group>             <year>2005</year>             <article-title>Ant navigation: Priming of visual route memories.</article-title>             <source>Nature</source>             <volume>438</volume>             <fpage>302</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Schwarz1">
        <label>78</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Schwarz</surname><given-names>S</given-names></name><name name-style="western"><surname>Narendra</surname><given-names>A</given-names></name><name name-style="western"><surname>Zeil</surname><given-names>J</given-names></name></person-group>             <year>2011</year>             <article-title>The properties of the visual system in the Australian desert ant <italic>Melophorus bagoti</italic>.</article-title>             <source>Arthropod Struct Dev</source>             <volume>40</volume>             <fpage>128</fpage>             <lpage>134</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Bell1">
        <label>79</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Bell</surname><given-names>A</given-names></name><name name-style="western"><surname>Sejnowski</surname><given-names>T</given-names></name></person-group>             <year>1995</year>             <article-title>An information-maximization approach to blind separation and blind deconvolution.</article-title>             <source>Neural Comput</source>             <volume>7</volume>             <fpage>1129</fpage>             <lpage>1159</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Amari1">
        <label>80</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Amari</surname><given-names>S</given-names></name><name name-style="western"><surname>Cichocki</surname><given-names>A</given-names></name><name name-style="western"><surname>Yang</surname><given-names>HH</given-names></name></person-group>             <year>1996</year>             <article-title>A new learning algorithm for blind signal separation.</article-title>             <source>Advances in Neural Information Processing Systems</source>             <publisher-name>MIT Press</publisher-name>             <fpage>757</fpage>             <lpage>763</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002336-Lee1">
        <label>81</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Lee</surname><given-names>TW</given-names></name><name name-style="western"><surname>Girolami</surname><given-names>M</given-names></name><name name-style="western"><surname>Sejnowski</surname><given-names>TJ</given-names></name></person-group>             <year>1999</year>             <article-title>Independent component analysis using an extended infomax algorithm for mixed subgaussian and supergaussian sources.</article-title>             <source>Neural Comput</source>             <volume>11</volume>             <fpage>417</fpage>             <lpage>441</lpage>          </element-citation>
      </ref>
    </ref-list>
    
  </back>
</article>
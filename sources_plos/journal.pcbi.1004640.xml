<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article article-type="research-article" dtd-version="3.0" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-14-01811</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1004640</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Where’s the Noise? Key Features of Spontaneous Activity and Neural Variability Arise through Learning in a Deterministic Network</article-title>
<alt-title alt-title-type="running-head">Key Features of Neural Variability Arise from Deterministic Learning</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<name name-style="western">
<surname>Hartmann</surname> <given-names>Christoph</given-names></name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Lazar</surname> <given-names>Andreea</given-names></name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Nessler</surname> <given-names>Bernhard</given-names></name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Triesch</surname> <given-names>Jochen</given-names></name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
</contrib-group>
<aff id="aff001">
<label>1</label>
<addr-line>Frankfurt Institute for Advanced Studies, Johann Wolfgang Goethe University, Frankfurt am Main, Germany</addr-line>
</aff>
<aff id="aff002">
<label>2</label>
<addr-line>International Max Planck Research School for Neural Circuits, Max Planck Institute for Brain Research, Frankfurt am Main, Germany</addr-line>
</aff>
<aff id="aff003">
<label>3</label>
<addr-line>Ernst Strüngmann Institute (ESI) for Neuroscience in Cooperation with Max-Planck-Society, Frankfurt am Main, Germany</addr-line>
</aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Bethge</surname> <given-names>Matthias</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>University of Tübingen and Max Planck Institute for Biologial Cybernetics, GERMANY</addr-line>
</aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<fn fn-type="con" id="contrib001">
<p>Conceived and designed the experiments: CH AL BN JT. Performed the experiments: CH. Analyzed the data: CH. Contributed reagents/materials/analysis tools: AL. Wrote the paper: CH AL BN JT.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">chartmann@fias.uni-frankfurt.de</email></corresp>
</author-notes>
<pub-date pub-type="collection">
<month>12</month>
<year>2015</year>
</pub-date>
<pub-date pub-type="epub">
<day>29</day>
<month>12</month>
<year>2015</year>
</pub-date>
<volume>11</volume>
<issue>12</issue>
<elocation-id>e1004640</elocation-id>
<history>
<date date-type="received">
<day>3</day>
<month>10</month>
<year>2014</year>
</date>
<date date-type="accepted">
<day>2</day>
<month>11</month>
<year>2015</year>
</date>
</history>
<permissions>
<copyright-year>2015</copyright-year>
<copyright-holder>Hartmann et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1004640"/>
<abstract>
<p>Even in the absence of sensory stimulation the brain is spontaneously active. This background “noise” seems to be the dominant cause of the notoriously high trial-to-trial variability of neural recordings. Recent experimental observations have extended our knowledge of trial-to-trial variability and spontaneous activity in several directions: 1. Trial-to-trial variability systematically decreases following the onset of a sensory stimulus or the start of a motor act. 2. Spontaneous activity states in sensory cortex outline the region of evoked sensory responses. 3. Across development, spontaneous activity aligns itself with typical evoked activity patterns. 4. The spontaneous brain activity prior to the presentation of an ambiguous stimulus predicts how the stimulus will be interpreted. At present it is unclear how these observations relate to each other and how they arise in cortical circuits. Here we demonstrate that all of these phenomena can be accounted for by a deterministic self-organizing recurrent neural network model (SORN), which learns a predictive model of its sensory environment. The SORN comprises recurrently coupled populations of excitatory and inhibitory threshold units and learns via a combination of spike-timing dependent plasticity (STDP) and homeostatic plasticity mechanisms. Similar to balanced network architectures, units in the network show irregular activity and variable responses to inputs. Additionally, however, the SORN exhibits sequence learning abilities matching recent findings from visual cortex and the network’s spontaneous activity reproduces the experimental findings mentioned above. Intriguingly, the network’s behaviour is reminiscent of sampling-based probabilistic inference, suggesting that correlates of sampling-based inference can develop from the interaction of STDP and homeostasis in deterministic networks. We conclude that key observations on spontaneous brain activity and the variability of neural responses can be accounted for by a simple deterministic recurrent neural network which learns a predictive model of its sensory environment via a combination of generic neural plasticity mechanisms.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author Summary</title>
<p>Neural recordings seem very noisy. If the exact same stimulus is shown to an animal multiple times, the neural response will vary substantially. In fact, the activity of a single neuron shows many features of a random process. Furthermore, the spontaneous activity occurring in the absence of any sensory stimulus, which is usually considered a kind of background noise, often has a magnitude comparable to the activity evoked by stimulus presentation and interacts with sensory inputs in interesting ways. Here we show that the key features of neural variability and spontaneous activity can all be accounted for by a simple and completely deterministic neural network learning a predictive model of its sensory inputs. The network’s deterministic dynamics give rise to structured but variable responses matching key experimental findings obtained in different mammalian species with different recording techniques. Our results suggest that the notorious variability of neural recordings and the complex features of spontaneous brain activity could reflect the dynamics of a largely deterministic but highly adaptive network learning a predictive model of its sensory environment.</p>
</abstract>
<funding-group>
<funding-statement>CH and JT received funding by the LOEWE-Program Neural Coordination Research Focus Frankfurt (NeFF). CH, JT and BN received funding by the Quandt foundation. AL received funding by the Deutsche Forschungsgemeinschaft (DFG). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="8"/>
<table-count count="0"/>
<page-count count="35"/>
</counts>
<custom-meta-group>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>The corresponding code is available on github: <ext-link ext-link-type="uri" xlink:href="https://github.com/chrhartm/SORN" xlink:type="simple">https://github.com/chrhartm/SORN</ext-link>.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Our brains are always active, even when we rest or sleep. This may seem somewhat surprising given the high metabolic costs associated with neural activity [<xref ref-type="bibr" rid="pcbi.1004640.ref001">1</xref>]. It seems there should be some important function associated with such spontaneous brain activity to justify the associated metabolic expense. It might be that keeping the brain spontaneously active is much like keeping the engine of your car running while waiting at a red light—allowing you to take off faster once the light turns green. On the other hand, without the constantly reverberating neural activity, wouldn’t we be like automata that only jump to action if triggered by an external event? Maybe spontaneous brain activity, rather than being some form of “noise” that keeps the engine running, is the very core on which our minds are constructed.</p>
<p>The problem of spontaneous activity is closely tied to the notoriously high trial-to-trial variability of cortical responses to identical stimuli [<xref ref-type="bibr" rid="pcbi.1004640.ref002">2</xref>]. Such variability is commonly interpreted as resulting from internal noise. However, while neurons seem to be quite noisy under frequently used laboratory conditions (DC input currents and room temperature), the noise is absent [<xref ref-type="bibr" rid="pcbi.1004640.ref003">3</xref>] or reduced [<xref ref-type="bibr" rid="pcbi.1004640.ref004">4</xref>–<xref ref-type="bibr" rid="pcbi.1004640.ref006">6</xref>] in more realistic conditions, and cannot account for the full trial-to-trial variability of neural responses [<xref ref-type="bibr" rid="pcbi.1004640.ref007">7</xref>,<xref ref-type="bibr" rid="pcbi.1004640.ref076">76</xref>]. Instead, spontaneous activity prior to stimulus onset seems to be the underlying cause of trial-to-trial variability. This was shown by Arieli et al. in a seminal study [<xref ref-type="bibr" rid="pcbi.1004640.ref008">8</xref>] almost 20 years ago using voltage-sensitive dye imaging (VSDI). They demonstrated that trial-to-trial variability can be almost perfectly predicted from the spontaneous activity prior to stimulus onset through a simple linear combination of the spontaneous activity prior to stimulus onset and the stimulus-triggered-average response. They concluded that “the effect of a stimulus might be likened to the additional ripples caused by tossing a stone into a wavy sea.” This encouraged many follow-up studies shedding new light on the relation between spontaneous activity and evoked sensory responses (see [<xref ref-type="bibr" rid="pcbi.1004640.ref009">9</xref>] for review). Of particular interest are the following four recent findings:</p>
<list list-type="order">
<list-item><p>Trial-to-trial variability in neural recordings systematically decreases following the onset of a sensory stimulus or the start of a motor act [<xref ref-type="bibr" rid="pcbi.1004640.ref010">10</xref>]: The authors of this study analysed recordings from seven different macaque brain regions such as V1, MT, or PMd and found a significant decrease in variability with stimulus onset for all of the ten different data sets they considered. Variability was measured as the Fano factor (variance/mean) over trials for each neuron and condition. A number of additional studies suggest that attention has a similar effect in both primates and rodents (see [<xref ref-type="bibr" rid="pcbi.1004640.ref011">11</xref>] for review).</p></list-item>
<list-item><p>These highly variable spontaneous activity states in sensory cortex outline the region of evoked sensory responses. One of the first studies demonstrating this analysed VSDI data from cat visual cortex during stimulation with gratings [<xref ref-type="bibr" rid="pcbi.1004640.ref012">12</xref>]. They found that individual frames of the spontaneous and evoked activity had almost the same amplitude and a similarly good match to the averaged orientation maps. In a later study, rats were presented with natural tones and pure tones while recording auditory cortex activity with tetrodes [<xref ref-type="bibr" rid="pcbi.1004640.ref013">13</xref>]. The authors found that spontaneous activity outlined the region of evoked sensory responses produced by natural sounds and pure tones.</p></list-item>
<list-item><p>This alignment between spontaneous activity and typical evoked activity patterns is increasing during development. There is accumulating evidence that sensory stimulation has a lasting effect on spontaneous activity [<xref ref-type="bibr" rid="pcbi.1004640.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1004640.ref015">15</xref>], most probably through learning. This effect can also be tracked over development: [<xref ref-type="bibr" rid="pcbi.1004640.ref016">16</xref>] compared spontaneous multi-unit activity of ferret V1 to evoked activity in response to natural and artificial stimuli at different ages. They found that the match between spontaneous and evoked activity increases for all stimuli over development but increases most for natural stimuli. A recent control with blindfolded ferrets corroborates this finding [<xref ref-type="bibr" rid="pcbi.1004640.ref017">17</xref>]. Interestingly, [<xref ref-type="bibr" rid="pcbi.1004640.ref012">12</xref>] had already shown that activity patterns in cat visual cortex corresponding to horizontal and vertical orientations occur more frequently in spontaneous activity—matching their prominence in natural scenes [<xref ref-type="bibr" rid="pcbi.1004640.ref018">18</xref>].</p></list-item>
<list-item><p>The spontaneous brain activity prior to the presentation of an ambiguous stimulus predicts how the stimulus will be interpreted. This was demonstrated for both monkeys [<xref ref-type="bibr" rid="pcbi.1004640.ref019">19</xref>] and humans [<xref ref-type="bibr" rid="pcbi.1004640.ref020">20</xref>]. In the latter study, subjects were shown an ambiguous face-vase stimulus while their brain activity was monitored with fMRI. Interestingly, the subject’s decisions (face or vase) could be predicted from activity in the fusiform face area (FFA) prior to stimulus onset. These findings complement the one by [<xref ref-type="bibr" rid="pcbi.1004640.ref008">8</xref>] showing that evoked VSDI responses in cat visual cortex can be predicted almost perfectly from the spontaneous activity prior to stimulus onset and the average response to the stimulus. Taken together, these studies suggest that spontaneous activity can bias perceptual decisions.</p></list-item></list>
<p>The findings on neural variability and spontaneous activity discussed above raise three important questions. First, do these findings reflect independent phenomena or are they somehow related? Second, what neurophysiological mechanisms give rise to these findings? Third, is there a functional meaning to these findings and, if so, what is it?</p>
<p>There are two complementary ways of approaching these questions: bottom-up and top-down. A bottom-approach may try to identify a minimal network model whose mechanisms are modelled after biological findings that is able to reproduce the observed effects and explain how they are rooted in basic physiological mechanisms. A top-down or normative approach will start with an assumed function and investigate whether and how (approximately) optimal solutions to this function resemble the observed physiological findings. In the end, the goal is always to reconcile both views into a unified picture. Our approach follows the bottom-up route.</p>
<p>We hypothesize that three properties of cortical circuits might underlie all these findings on spontaneous activity and neural variability:</p>
<list list-type="order">
<list-item>
<p>Recurrent connectivity shapes the structure of spontaneous activity and determines the relationship between spontaneous and evoked activity patterns.</p>
</list-item>
<list-item>
<p>Neural plasticity is responsible for structuring recurrent connectivity such that spontaneous activity matches the statistics of evoked activity. In functional terms this corresponds to the network learning a predictive model of its sensory environment.</p>
</list-item>
<list-item>
<p>Homeostatic mechanisms keep spontaneous and evoked activity in a healthy dynamic regime where learning and inference are possible.</p>
</list-item>
</list>
<p>Evidence for the first property comes from a range of studies. First of all, neural structures that do not receive recurrent input, such as the retina, display much lower response variability [<xref ref-type="bibr" rid="pcbi.1004640.ref021">21</xref>, <xref ref-type="bibr" rid="pcbi.1004640.ref022">22</xref>] suggesting that neural variability is induced by fluctuations of recurrent input. Second, there is anatomical evidence that V1 receives less than 5% bottom-up input synapses and more than 95% of synapses stem from neurons within V1 and higher-level areas [<xref ref-type="bibr" rid="pcbi.1004640.ref023">23</xref>]. Retrograde labelling and paired recordings show that neurons responding to the same grating or natural stimulus are both more likely to be connected and have stronger connections than expected by chance, suggesting that these recurrent connections enforce specific neural populations to be coactive [<xref ref-type="bibr" rid="pcbi.1004640.ref024">24</xref>, <xref ref-type="bibr" rid="pcbi.1004640.ref025">25</xref>]. Another link between anatomy and function was obtained by comparing long-distance axonal projections and spontaneous activity patterns [<xref ref-type="bibr" rid="pcbi.1004640.ref026">26</xref>]. The authors found that spontaneous and evoked activity followed the axonal pathways. Similar results were obtained by comparing resting state activity in fMRI and anatomical pathways determined by diffusion tensor imaging [<xref ref-type="bibr" rid="pcbi.1004640.ref027">27</xref>]. Finally, purely functional studies show that the order of activation of individual cells is similar during spontaneous and evoked activity suggesting that it is constrained by the underlying recurrent connectivity [<xref ref-type="bibr" rid="pcbi.1004640.ref028">28</xref>]. Taken together, there is broad evidence that recurrent connectivity shapes the common structure of spontaneous and evoked activity.</p>
<p>Second, evidence from developmental studies suggests that the statistics of features in the visual world get translated into cortical connectivity by means of Hebbian plasticity [<xref ref-type="bibr" rid="pcbi.1004640.ref029">29</xref>, <xref ref-type="bibr" rid="pcbi.1004640.ref030">30</xref>]. A recent study demonstrates that such self-organization is still present in adult animals as early as in V1 [<xref ref-type="bibr" rid="pcbi.1004640.ref031">31</xref>]: In this experiment, adult mice were stimulated with repeated sequences of gratings of different orientations. The authors then recorded activity from neurons in V1 and found that the circuit formed a predictive representation of these spatiotemporal sequences. In particular, the circuit “recognized” a sequence by responding stronger to it than to the reversed sequence and showed predictive behaviour by “filling in” activity when parts of the sequence were left out. Pharmacological controls suggest that the underlying plasticity was local to V1.</p>
<p>Together with the observation that the statistics of spontaneous activity match the statistics of the environment of the organism [<xref ref-type="bibr" rid="pcbi.1004640.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1004640.ref014">14</xref>–<xref ref-type="bibr" rid="pcbi.1004640.ref016">16</xref>], this suggests that the statistics of the environment are stored in the recurrent connectivity of the neural circuit and that the structure of spontaneous activity is simply an image of the learnt circuit structure that reveals itself when the network receives no external drive.</p>
<p>Evidence for the third property comes mainly from computational neuroscience studies. While it is known that homeostatic plasticity is essential to restore a balance between excitation and inhibition after perturbation by different forms of input deprivation (reviewed in [<xref ref-type="bibr" rid="pcbi.1004640.ref032">32</xref>]), there are only few experimental studies on the direct interaction between homeostasis and learning (see, e.g., [<xref ref-type="bibr" rid="pcbi.1004640.ref033">33</xref>, <xref ref-type="bibr" rid="pcbi.1004640.ref034">34</xref>]). Theoretical studies on neural plasticity, on the other hand, have long argued that homeostasis is needed to “tame the beast” of Hebbian learning by enforcing stable network dynamics [<xref ref-type="bibr" rid="pcbi.1004640.ref035">35</xref>]. These theoretical predictions are consistent with clinical findings from different brain pathologies. For example, dysfunctional homeostasis has been linked to autism spectrum disorder and intellectual disabilities [<xref ref-type="bibr" rid="pcbi.1004640.ref036">36</xref>].</p>
<p>To test if these three properties are indeed sufficient to account for the many findings on spontaneous activity and neural variability, we capture them in a minimal neural network model: The self-organizing recurrent neural network (SORN, [<xref ref-type="bibr" rid="pcbi.1004640.ref037">37</xref>]) is a network of interconnected excitatory and inhibitory populations of McCulloch &amp; Pitts model neurons. These neurons have binary states determined by thresholding the input, are updated synchronously, and are fully deterministic. The excitatory neurons are recurrently connected and receive structured input sequences. A binarized form of spike-timing dependent plasticity (STDP) shapes these recurrent excitatory connections. The network dynamics are kept in check by two forms of homeostatic plasticity: Synaptic normalization ensures that the summed synaptic weights from and onto each neuron stay the same during STDP. Intrinsic plasticity regulates the thresholds of the excitatory neurons on a slow timescale to avoid silent or overly active neurons. SORN networks have been shown to have powerful sequence learning abilities. For example, on challenging sequence learning tasks involving hidden states and long temporal dependencies they greatly outperform analogous reservoir architectures without plasticity in the recurrent network [<xref ref-type="bibr" rid="pcbi.1004640.ref037">37</xref>]. More recently, they have also been shown to produce state-of-the-art results in learning artificial grammars with their performance resembling that of human subjects [<xref ref-type="bibr" rid="pcbi.1004640.ref038">38</xref>]. Furthermore, such networks have also been shown to capture experimental data on the statistics and fluctuations of synaptic efficacies [<xref ref-type="bibr" rid="pcbi.1004640.ref039">39</xref>]. These features make them interesting candidates for modelling experimental findings on spontaneous activity and neural variability.</p>
<p>In the following we show how the SORN model reproduces the key findings on spontaneous activity and neural response variability discussed above. To capture the essence of the experimental situations above, we define two learning tasks: a <italic>sequence learning task</italic> and an <italic>inference task</italic>. Both are deliberately simple compared to previous SORN studies [<xref ref-type="bibr" rid="pcbi.1004640.ref037">37</xref>, <xref ref-type="bibr" rid="pcbi.1004640.ref038">38</xref>] but suffice to capture the key findings. The <italic>sequence learning task</italic> is inspired by [<xref ref-type="bibr" rid="pcbi.1004640.ref031">31</xref>] and consists of presenting the network with one or more discrete sequences of input stimuli. After replicating this study, which demonstrated the learning of predictive models in V1 of adult mice, we use similar tasks to study the similarity of spontaneous and evoked activity. The <italic>inference task</italic> is inspired by [<xref ref-type="bibr" rid="pcbi.1004640.ref020">20</xref>], where subjects are presented with an ambiguous face-vase stimulus and their FFA activity is used to predict their perceptions. Apart from replicating this specific result, the trial structure of this task allows us to study the effect of spontaneous activity on evoked activity.</p>
<p>By carefully analysing the SORN’s behaviour in these two tasks, we show how it readily reproduces the key experimental findings on spontaneous activity and neural variability without requiring any internal noise. On the other hand, adding small amounts of noise to the network produces similar findings (see <xref ref-type="sec" rid="sec017">Discussion</xref>). Taken together, our results suggest that the experimental findings on neural variability reflect the dynamics of a largely deterministic but highly adaptive cortical network learning a predictive model of its sensory environment. Our findings also support the claim that the notorious variability of neural responses is largely due to spontaneous network dynamics. It is noteworthy that a simple model such as the SORN can account for such a diverse set of findings that were independently obtained in a range of different species with a range of different recording techniques (multi-electrode and single cell recordings, optical imaging, functional magnetic resonance imaging) in a number of different labs. It suggests that the SORN model as a minimal instantiation of the three properties introduced above captures some fundamental principles of cortical learning and information processing in a distilled form.</p>
</sec>
<sec id="sec002" sec-type="results">
<title>Results</title>
<sec id="sec003">
<title>Basic model properties</title>
<p>We begin by characterizing some dynamic properties of the network. For this, we stimulate the network with random alternations of ten letters, where each letter presentation corresponds to stimulating a subset of excitatory neurons (see <xref ref-type="sec" rid="sec020">Methods</xref> for a detailed description of the model and stimulation paradigms). After the fraction of excitatory to excitatory connections converges, we deactivate STDP and stop stimulation to observe the spontaneous activity. This spontaneous activity develops as the intrinsic plasticity of each neuron shifts the excitability thresholds to compensate for the missing input.</p>
<p><xref ref-type="fig" rid="pcbi.1004640.g001">Fig 1b and 1c</xref> shows that the activity of individual neurons of the network is well described by an exponential inter-spike interval (ISI) distribution and can be summarized by a coefficient of variation distributed around 1. These indicate that the individual neurons fire irregularly with Poissonian statistics, a key feature of neural variability in neocortex [<xref ref-type="bibr" rid="pcbi.1004640.ref010">10</xref>, <xref ref-type="bibr" rid="pcbi.1004640.ref040">40</xref>]. Additionally, while the network converges to a stable fraction of connections, the individual weights keep fluctuating (<xref ref-type="fig" rid="pcbi.1004640.g001">Fig 1d and 1e</xref>) as observed experimentally [<xref ref-type="bibr" rid="pcbi.1004640.ref041">41</xref>]. Finally, the network approaches a lognormal-like weight distribution after learning (<xref ref-type="fig" rid="pcbi.1004640.g001">Fig 1f</xref>), which is a documented property of cortical circuits [<xref ref-type="bibr" rid="pcbi.1004640.ref042">42</xref>]. Taken together, these results demonstrate that some essential features of neocortex taken as evidence for a “noisy” brain are readily captured by our deterministic model.</p>
<fig id="pcbi.1004640.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004640.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Basic properties of the network match experimental findings.</title>
<p>(a) The Self-Organizing Recurrent Neural Network (SORN) consists of recurrently connected excitatory (blue) and inhibitory (red) deterministic McCulloch &amp; Pitts threshold neurons. Each input letter (black boxes) stimulates an excitatory subpopulation. The excitatory recurrent connections are shaped by spike-timing dependent plasticity and synaptic normalization. The excitatory thresholds are regulated by intrinsic plasticity (see <xref ref-type="sec" rid="sec020">Methods</xref> for details). (b) Raster plot of spontaneous activity (no external input) after stimulating the network with ten randomly alternating letters during plasticity. (c) The inter-spike-interval (ISI) distribution of a randomly selected neuron during spontaneous activity is well-fitted by an exponential apart from very small ISIs. (c, inset) The distribution of coefficients of variation (CVs) of the ISIs clusters around one, as expected for exponential ISI distributions, compatible with the experimentally observed Poisson-like spiking [<xref ref-type="bibr" rid="pcbi.1004640.ref010">10</xref>, <xref ref-type="bibr" rid="pcbi.1004640.ref040">40</xref>]. (d) The fraction of excitatory-to-excitatory connections converges to a stable fraction. (e) Individual weights fluctuate despite the global convergence as observed experimentally [<xref ref-type="bibr" rid="pcbi.1004640.ref041">41</xref>]. (f) After self-organization, i.e. at the end of (d), the binned distribution of excitatory-to-excitatory synaptic weights (dots) is well fit by a lognormal distribution (solid line, cp., e.g., [<xref ref-type="bibr" rid="pcbi.1004640.ref042">42</xref>]).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004640.g001" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec004">
<title>Learning spatiotemporal sequences</title>
<p>Next, we replicate the sequence learning paradigm from [<xref ref-type="bibr" rid="pcbi.1004640.ref031">31</xref>]. In their study, the authors stimulated mice with a discrete set of gratings of different orientations. For example, they stimulated their mice with the sequence “ABCD”, which refers to four distinct gratings presented in succession. They then recorded activity from neurons in V1 and found that the circuit formed a representation of these spatiotemporal sequences.</p>
<p>We modelled this experiment by stimulating our network with a similar set of stimuli. We model visual input to V1 by stimulating a small subpopulation of our excitatory units when a stimulus is presented. This subpopulation can be thought of as having receptive fields that align with the grating in the original study.</p>
<p>To replicate the first experiment from [<xref ref-type="bibr" rid="pcbi.1004640.ref031">31</xref>], we stimulated our network with the sequence “ABCD” during an initial period of self-organization. After the stimulation, we deactivated STDP, stopped the stimulation, and ran the network only with intrinsic plasticity to get a period of spontaneous activity, similar to the sleep phase in the original study. Finally, we tested the network with either “ABCD” (same sequence) or “DCBA” (reversed sequence). The network matched the effects reported in <xref ref-type="fig" rid="pcbi.1004640.g001">Fig 1</xref> of [<xref ref-type="bibr" rid="pcbi.1004640.ref031">31</xref>] in that it responded with a higher mean rate to “ABCD” than to “DCBA” indicating that the trained sequence was “recognized” (<xref ref-type="fig" rid="pcbi.1004640.g002">Fig 2a</xref>). In a control experiment we trained the network on all permutations of the original sequence (i.e. “ABCD”, “ABDC”, …, “DCBA”) and similar to the matching control from [<xref ref-type="bibr" rid="pcbi.1004640.ref031">31</xref>], the mean rate was similar for both test sequences.</p>
<fig id="pcbi.1004640.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004640.g002</object-id>
<label>Fig 2</label>
<caption>
<title>The network learns a predictive model mimicking [<xref ref-type="bibr" rid="pcbi.1004640.ref031">31</xref>].</title>
<p>Similar to [<xref ref-type="bibr" rid="pcbi.1004640.ref031">31</xref>], we stimulated the network either with the sequence “ABCD” (experiment) or with all permutations of this sequence (control). After a period of self-organization, the network was tested with the sequences “ABCD” and “DCBA”. (a) Mean firing rates (“sequence magnitude”) for both test sequences. (b) For the experimental condition, the network was also tested with the sequences “ABCD”, “A_CD”, and “E_CD”. Error bars represent SEM over 20 independent realizations. ⋆ indicates <italic>p</italic> &lt; 0.05 for a two-sided t-test assuming independent samples and identical variances.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004640.g002" xlink:type="simple"/>
</fig>
<p>In a further experiment in [<xref ref-type="bibr" rid="pcbi.1004640.ref031">31</xref>], the authors then showed that V1 can “predict” upcoming sequence items by training the mice with “ABCD” and testing with “ABCD”, “A_CD” and “E_CD”. They showed that V1 responded more strongly to the first two test sequences than to the third one and more strongly to a “B” or a blank following an “A” than to the blank after an “E” (cp. Fig 4 of [<xref ref-type="bibr" rid="pcbi.1004640.ref031">31</xref>]). As before, our simulations qualitatively replicate these results (<xref ref-type="fig" rid="pcbi.1004640.g002">Fig 2b</xref>). Note that much more sophisticated sequence learning abilities in SORN have already been demonstrated in [<xref ref-type="bibr" rid="pcbi.1004640.ref037">37</xref>, <xref ref-type="bibr" rid="pcbi.1004640.ref038">38</xref>].</p>
<p>These two experiments demonstrate that our simple model captures key experimental findings on the physiology of sequence learning. With this as a backdrop, we can investigate the properties and interactions of spontaneous and evoked activity in similar learning experiments in the next sections.</p>
</sec>
<sec id="sec005">
<title>Structured spontaneous activity</title>
<p>Spontaneous activity is structured in space and time [<xref ref-type="bibr" rid="pcbi.1004640.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1004640.ref013">13</xref>] and revisits those states, i.e. neuronal activation patterns, more often that correspond to overrepresented features in natural stimuli, such as horizontal and vertical bars in [<xref ref-type="bibr" rid="pcbi.1004640.ref012">12</xref>]. It has been proposed that this is a result from adapting the spontaneous activity to the statistics of the evoked activity during development [<xref ref-type="bibr" rid="pcbi.1004640.ref016">16</xref>].</p>
<p>In order to model these findings, we adapted the sequence learning paradigm: During an initial self-organization phase, we stimulate the network with random alternations of two sequences: “ABCD” and “EFGH” with different relative probabilities. In a second phase, we deactivate STDP to study the evoked activity of the adapted network. Finally, we stop the input and observe the network’s spontaneous activity. Due to the intrinsic plasticity in the model, our network compensates for the missing input and produces spontaneous activity in the absence of noise.</p>
<sec id="sec006">
<title>Spontaneous activity is structured in space and time</title>
<p>As a first step, we want to get a better understanding of the spontaneous network dynamics by visualizing the activity of the 200 simulated excitatory neurons in three dimensions. For this, we apply principal component analysis to project the 200-dimensional spontaneous and evoked binary activity vectors to the first three principal components (PCs) of the evoked activity. These three components usually account for 40–50% of the variability. The evoked activity (points) captures the properties of the input by forming one activity cluster for each position in the input sequences (“A” and “E”, “B” and “F”, …) (<xref ref-type="fig" rid="pcbi.1004640.g003">Fig 3a</xref>). We believe that the very similar transition structure is responsible for this: both “D” and “H” transition to either “A” or “E”. Since the neurons coding for “D” and “H” will only have a small subset of overlapping projections but these postsynaptic neurons have to code for both “A” or “E”, “A” and “E” should look similar. A similar argument applies for the following letters. Despite the overlap in the first PCs, both sequences can be clearly separated in later PCs (<xref ref-type="supplementary-material" rid="pcbi.1004640.s003">S3 Fig</xref>). We observe a trend that letters later in the word separate “easier”, i.e. in earlier PCs. For example, “H” and “D” separate in PC4, “G” and “C” in PC9, “B” and “F” in PC11, and “A” and “E” in PC 15 for this simulation. This is probably due to small differences at the beginning accumulating through the recurrent structure to larger differences towards the end of the word. In addition to the learnt structure, the spontaneous activity (lines) closely follows the structure of the evoked activity. This observed spontaneous replay of evoked sequences is similar to [<xref ref-type="bibr" rid="pcbi.1004640.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1004640.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1004640.ref043">43</xref>]. The authors of [<xref ref-type="bibr" rid="pcbi.1004640.ref012">12</xref>] showed with optical imaging in cat area 18 that spontaneous activity is highly structured and smoothly varies over time (in their case it smoothly switches between neighbouring orientations). They also observe that spontaneous activity preferentially visits states that correspond to features that occur more often in nature (in their case horizontal and vertical bars). We demonstrate an abstract version of the latter point below.</p>
<fig id="pcbi.1004640.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004640.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Spontaneous and evoked activity align through self-organization.</title>
<p>The network was stimulated with the words “ABCD” (67%) and “EFGH” (33%). (a) The spontaneous activity follows the spatiotemporal trajectories of the evoked states in the PCA projection. (b) In the multidimensional scaling projection, the evoked activity (red) follows the spontaneous outline (black) and avoids the shuffled spontaneous states (blue) (cp. Fig 6c of [<xref ref-type="bibr" rid="pcbi.1004640.ref013">13</xref>]). (c) The evoked states are closer to the spontaneous states than to the shuffled spontaneous states: As in Fig 6 of [<xref ref-type="bibr" rid="pcbi.1004640.ref013">13</xref>], the distance from evoked states to the closest spontaneous states (D_spont) is smaller than the distance to the closest shuffled spontaneous state (D_shuff). The red dashed line shows equality. (d) Spontaneous activity becomes more similar to evoked activity during learning: After self-organizing to “ABCD” and “EFGH” with identical probabilities, spontaneous activity was compared to the evoked activity from the imprinted sequences (natural) or the two control sequences “EDCBA” and “FGH” (control) with Kullback-Leibler divergence. New networks were generated for each training time and condition. Error bars represent SEM over 50 independent realizations. ⋆ indicates <italic>p</italic> &lt; 0.05 for a t-test assuming independent samples and identical variances.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004640.g003" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec007">
<title>Spontaneous activity outlines sensory responses</title>
<p>Next, we tested if the SORN model captures the finding of [<xref ref-type="bibr" rid="pcbi.1004640.ref013">13</xref>] that “spontaneous events outline the realm of possible sensory responses”. To model the conditions of the original experiment, we compared spontaneous activity to evoked activity from only 5 randomly selected letters from the original words. This captures the fact that only a subset of the “lifetime experience” of stimuli was presented during the experiment. As in [<xref ref-type="bibr" rid="pcbi.1004640.ref013">13</xref>], 150 randomly selected spontaneous activity vectors of the excitatory units, their shuffled versions, and 150 of the just described evoked events were then reduced from the high-dimensional activity patterns of excitatory neurons to 2D by multidimensional scaling (MDS). Simply put, this method uses all variability in the data to represent the distances between data points in their high-dimensional space (neural activity vectors) in the plotted two dimensions as well as possible. This is in contrast to the previous 3D-PCA plots, which only consider the variability in the first three principal components. Our results indicate that the spontaneous activity outlines the evoked activity while the shuffled activity does not capture its structure (<xref ref-type="fig" rid="pcbi.1004640.g003">Fig 3b</xref>). Similar to the experimental study, we confirm this by showing that evoked activity states are significantly closer to the spontaneous activity states than to the shuffled spontaneous ones (<xref ref-type="fig" rid="pcbi.1004640.g003">Fig 3c</xref>).</p>
</sec>
<sec id="sec008">
<title>Spontaneous activity adapts to evoked activity</title>
<p>Given the previous results, the question arises how these phenomena are related to the network self-organization. For this, we compared the effect of learning to results from [<xref ref-type="bibr" rid="pcbi.1004640.ref016">16</xref>]. They showed that during development, the distance between the distribution of spontaneous activity and the distribution of evoked activity decreases. Interestingly, the distance decreases both for stimuli that the animal was exposed to during development (natural movies) and to artificial stimuli (gratings and bars), but the reduction is less pronounced for the artificial stimuli. We try to capture the essentials of this experiment by presenting the same two sequences during the self-organization phase. After learning, we then either present the same sequences (natural condition) or the two control sequences “EDCBA” and “HGF” (control condition) for as many steps as the number of bins in the original paper. We chose this specific control condition because it has a different structure while still stimulating the same input units, similar to the control conditions in the original study. In both conditions, the sequences are presented with equal probability. The evoked network states were then compared to the spontaneous states using the KL-divergence. Our model shows a qualitatively similar behaviour in that the KL-divergence between the distribution of evoked responses in the natural condition and the distribution of spontaneous responses decreases during learning (<xref ref-type="fig" rid="pcbi.1004640.g003">Fig 3d</xref>). This decrease is larger compared to the decrease observed for the reversed sequence.</p>
<p>Taken together, these results show that in our simple model the spontaneous network activity outlines the possible sensory responses after self-organization. It is important to note that none of these effects occur in a random network without plasticity (see [<xref ref-type="bibr" rid="pcbi.1004640.ref037">37</xref>] for sample network dynamics of the SORN without plasticity).</p>
</sec>
<sec id="sec009">
<title>Self-organization captures stimulus probabilities</title>
<p>Having compared our model dynamics to qualitative features of spontaneous activity, we next performed a quantitative analysis on how the learnt sequences are represented in the network. In order to do so, we assign to each spontaneous state a stimulus letter based on the stimulus of the closest matching evoked network state (see <xref ref-type="sec" rid="sec020">Methods</xref> for details). From this, we compute the frequency of word-occurrence in the spontaneous activity. The spontaneous states resemble the evoked states in two ways (<xref ref-type="fig" rid="pcbi.1004640.g004">Fig 4a and 4b</xref>): First, the letters that were presented more often in the evoked activity also occur more often in the spontaneous activity. Second, the transition between states occurs in the correct temporal direction while reversed transitions rarely occur in the spontaneous activity. By varying the probability of each sequence during self-organization, we can quantify how these priors are captured by the spontaneous activity. As one can see in <xref ref-type="fig" rid="pcbi.1004640.g004">Fig 4c and 4d</xref>, the probability of the words and letters approximate their frequency during learning. However, we observe a tendency to overrepresent the more frequent stimuli. Additionally, the frequency of letters increases towards the end of the more frequent word while it decreases towards the end of the less frequent word. This is due to spontaneous switching between the two words: the more frequent word is more robust and activity switches less often to the less frequent word than the other way round. We further explore this issue in the section Network Analysis below.</p>
<fig id="pcbi.1004640.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004640.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Different priors are learnt by the network.</title>
<p>During self-organization, the sequences “ABCD” and “EFGH” were randomly interleaved with frequencies of 67% and 33%, respectively. This is reflected in the relative occurrence of (a) each letter and (b) each word in the spontaneous activity. For different priors during self-organization, this results in the frequencies in (c) for each letter and in (d) for each word. Both show overlearning effects in that their frequencies are biased in favour of the word that was shown more often. The reversing trend and high variance for the extreme priors (0.1 and 0.9) can be accounted for by pathological network dynamics for some simulations with these priors. The letter frequency is the observed frequency in the evoked activity while the word frequency was normalized over the total number of observed words (“ABCD”, “EFGH”, “DCBA”, and “HGFE”) to yield better comparison over different realizations. Error bars represent SEM over 20 independent realizations.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004640.g004" xlink:type="simple"/>
</fig>
</sec>
</sec>
<sec id="sec010">
<title>Interaction between spontaneous activity and evoked activity</title>
<p>After observing the properties of spontaneous activity, we next investigate the interaction between spontaneous activity and evoked activity in an inference task with trial-like interleaved spontaneous and evoked activity. By inference task, we mean that the task involves integrating previously acquired knowledge with an ambiguous sensory input to arrive at a unique interpretation of that stimulus. This non-formal usage of the term inference has a long tradition going back at least to Hermann von Helmholtz who used the German expression “unbewusster Schluss”, which is usually translated as unconscious inference.</p>
<p>This task is used to model the studies demonstrating that the neural variability significantly drops at the onset of a stimulus [<xref ref-type="bibr" rid="pcbi.1004640.ref010">10</xref>], that the evoked activity can be linearly predicted from the spontaneous activity [<xref ref-type="bibr" rid="pcbi.1004640.ref008">8</xref>], and that the spontaneous activity before stimulus onset predicts the decisions when a noisy [<xref ref-type="bibr" rid="pcbi.1004640.ref019">19</xref>] or ambiguous [<xref ref-type="bibr" rid="pcbi.1004640.ref020">20</xref>] stimulus is presented. We model these findings by training our networks on a task inspired by [<xref ref-type="bibr" rid="pcbi.1004640.ref020">20</xref>]. In their setting, an ambiguous face-vase stimulus is immediately followed by a mask. After the mask, the subjects have to decide whether they perceived a face or a vase. This trial structure allows us to study the interaction between spontaneous activity before stimulus onset and the evoked activity following the presentation of a stimulus.</p>
<p>We model the task as follows: during training, the network is presented with two randomly alternating input sequences represented as “AXXX_ _ _ …” and “BXXX_ _ _ …” with different probabilities. “A” and “B” stand for the face and vase, respectively, the common “XXX” for the mask, and “_ _ _ …” for periods without input corresponding to a blank screen. During the initial self-organization the network learns to represent these sequences and their prior probabilities. After self-organizing to these stimuli, STDP is switched off and a linear classifier is trained to postdict whether “A” or “B” has been presented based on the neural activity at the first blank stimulus, “_”. We define the network “decision” as the postdiction of this classifier for either “A” or “B” similar to subjects’ “decision” whether they just saw a face or a vase. The mask ensures that the decision is based on an internal representation and not simply on a direct input-output mapping. During subsequent testing, the network is stimulated with ambiguous mixtures of “A” and “B”, which we indicate as “A/B”, followed by the mask. Similar to human subjects reporting on their ambiguous percept, the network then has to decide with the classifier for “A” or “B” in light of the ambiguity of “A/B” and the prior probabilities of “A” and “B” during training. Different levels of ambiguity are modelled by stimulating <italic>f</italic><sub>A</sub> × 10 input units of “A” and (1 − <italic>f</italic><sub>A</sub>) × 10 input units of “B” where <italic>f</italic><sub>A</sub> is a fraction. Further model details are given in the Methods.</p>
<p>As in the previous section, we will first investigate the qualitative behaviour of the model self-organizing to these stimuli and compare them to the experimental findings. Thereafter, we will describe how the network performs inference for the ambiguous stimuli.</p>
<sec id="sec011">
<title>Stimulus onset quenches variability</title>
<p>First, we replicate the “widespread cortical phenomenon” that the “stimulus onset quenches variability” [<xref ref-type="bibr" rid="pcbi.1004640.ref010">10</xref>]: While the neural activity and the activity in this model is in general highly variable and shows signatures of a Poisson process (cp. <xref ref-type="fig" rid="pcbi.1004640.g001">Fig 1</xref>), we observe a drop in variability measured by the Fano factor (FF) in response to stimulus onset (<xref ref-type="fig" rid="pcbi.1004640.g005">Fig 5</xref>). We also found that this effect is significantly stronger when the respective stimulus had a higher presentation probability (<xref ref-type="fig" rid="pcbi.1004640.g005">Fig 5c and 5d</xref>). Furthermore, the stimulus that was presented more often also elicits a higher mean firing rate. A similar effect was observed for MT responses to moving gratings [<xref ref-type="bibr" rid="pcbi.1004640.ref044">44</xref>]: the Fano Factor decreased most for the preferred direction, i.e. for the direction with the highest mean rate.</p>
<fig id="pcbi.1004640.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004640.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Stimulus onset quenches variability.</title>
<p>(a) and (b) Sample spike trains from two representative neurons aligned to the stimulus presentation (shaded area). (c) and (d) The population average of the Fano factor (FF) decreases with stimulus onset. The FF is only computed for units that do not receive direct sensory input. These results mimic Fig 5 of [<xref ref-type="bibr" rid="pcbi.1004640.ref010">10</xref>]. FFs, mean rates and variances are for causal moving windows of 5 time steps. (c) was computed for the presentation of stimulus “AXXX_ _ _ …” during the test phase after being presented with a probability of 0.1 during self-organization. (d) In turn, “BXXX_ _ _ …” had a probability of 0.9 in the same experiment. Error bars represent SEM over 20 independent realizations.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004640.g005" xlink:type="simple"/>
</fig>
<p>Across all stimuli, the drop of the FF is accompanied by a rise of the mean firing rate (<xref ref-type="fig" rid="pcbi.1004640.g005">Fig 5c</xref>). To control for this, we performed a “mean matching” analysis as suggested in [<xref ref-type="bibr" rid="pcbi.1004640.ref010">10</xref>] (see <xref ref-type="sec" rid="sec020">Methods</xref> for details). <xref ref-type="supplementary-material" rid="pcbi.1004640.s004">S4 Fig</xref> shows a mean-matched decrease of the FF at stimulus onset.</p>
</sec>
<sec id="sec012">
<title>Spontaneous activity predicts evoked activity and decisions</title>
<p>Next, we test our model on two similar findings: First, the authors of [<xref ref-type="bibr" rid="pcbi.1004640.ref008">8</xref>] found that the optical imaging response evoked by simple bar stimuli is almost identical to the sum of the spontaneous activity prior to stimulus onset and the average stimulus-triggered response. Second, the original study that we model here [<xref ref-type="bibr" rid="pcbi.1004640.ref020">20</xref>] found that spontaneous activity prior to stimulus onset predicts the decision of the subjects. Thus, spontaneous activity influences the evoked response at the level of neural responses and behavioural decisions.</p>
<p>We model these experiments by training simple linear classifiers either to predict the evoked spiking of individual cells from the spontaneous activity immediately before stimulus presentation, or to predict the decision of the network after the presentation of stimuli with different ambiguities. These are compared to a baseline prediction from a “control classifier” that is based on shuffled spontaneous activity.</p>
<p>We find that the spontaneous activity prior to stimulus onset allows prediction of the evoked activity (<xref ref-type="fig" rid="pcbi.1004640.g006">Fig 6a</xref>) and the final decision (<xref ref-type="fig" rid="pcbi.1004640.g006">Fig 6b</xref>) in a linear manner. These two complementary experiments demonstrate that the network’s spontaneous activity prior to the stimulus contains significant information about subsequent evoked responses and perceptual decisions as demonstrated experimentally in [<xref ref-type="bibr" rid="pcbi.1004640.ref008">8</xref>] and [<xref ref-type="bibr" rid="pcbi.1004640.ref020">20</xref>].</p>
<fig id="pcbi.1004640.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004640.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Spontaneous activity predicts evoked activity and decisions.</title>
<p>The network self-organizes during repeated presentations of the sequences “AXXX_ _ _ …” (33%) and “BXXX_ _ _ …” (67%) with blank intervals in between. In the test phase, an ambiguous mix of cue “A” and cue “B” is presented (“A/BXXX_ _ _ …”, shaded area) and the network decides at the first “_” with a linear classifier if either A or B was the start of the sequence. (a) Trial-to-trial variability of the evoked activity patterns during the test phase is well predicted from activity prior to stimulus onset. The figure shows the correlation between the variable evoked activity patterns at different time steps after stimulus onset and a linear prediction of these based on the stimulus and either the spontaneous activity state prior to stimulus onset (blue) or trial-shuffled spontaneous activity (baseline, grey). Similar to Fig 4 in [<xref ref-type="bibr" rid="pcbi.1004640.ref008">8</xref>], the decay of the correlation is exponential-like. The correlation drops further as new stimuli are presented (hatched area). Due to variable inter-trial-intervals, the hatched area covers the entire area were stimulation is possible. (b) The decisions of the network can be predicted from spontaneous activity before stimulus onset. The plot shows the accuracy of predicted network decisions (“A” vs. “B”) at the green dashed line from activity surrounding the decision. Separate classifiers were trained for each of the 11 ambiguity classes (e.g. 20%A) and time step surrounding the decision. The grey line corresponds to predictions from trial-shuffled activity. Predictions in (b) are averaged over all priors of <xref ref-type="fig" rid="pcbi.1004640.g007">Fig 7c</xref>. Error bars represent SEM over 20 independent realizations.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004640.g006" xlink:type="simple"/>
</fig>
<p>The initial trial-shuffled baseline prediction in <xref ref-type="fig" rid="pcbi.1004640.g006">Fig 6a</xref> follows a trend similar to the inverted Fano Factor (<xref ref-type="fig" rid="pcbi.1004640.g005">Fig 5</xref>): it initially increases and then decreases. This is because a more stereotypical response will be both predicted more easily and have a lower variability. The tail of the prediction then decays further due to the fading of memory in these networks [<xref ref-type="bibr" rid="pcbi.1004640.ref037">37</xref>]. As new stimuli are presented (hatched area), the predictability drops even further since the next stimulation is independent of the previous one. In experimental settings, where one does not have access to the full network state, the unobserved states would have a similar effect to our new inputs: the predictability would decay due to variability that one does not have access to. So even for purely spontaneous activity after stimulation, one would expect a quick decay of predictability due to inputs to the circuit from brain areas that were not recorded.</p>
<p>Please note that the baseline in <xref ref-type="fig" rid="pcbi.1004640.g006">Fig 6b</xref> is above 50%. This is because the decisions of the network are usually biased towards “A” or “B” similar to human subjects being biased to perceive more faces or vases in the face-vase experiment. This bias can be exploited by the control classifier by always predicting the more likely decision and thereby getting above-50% accuracy. Also note that the stimulus onset triggers an increase in predictability. This is due to the nature of stimulation: for the same ambiguous stimulus, different neurons are stimulated at each trial, which influences the decision to be predicted.</p>
<p>Taken together, all these results show that the complex dynamics of a very simple self-organizing recurrent neural network suffice to reproduce key features of the interaction of spontaneous and evoked activity.</p>
</sec>
<sec id="sec013">
<title>Network dynamics is reminiscent of sampling-based inference</title>
<p>The core of Bayesian learning and inference is the probabilistically correct combination of the hitherto observed experience—which we have already identified as prior in the previous spontaneous activity experiment—with a current stimulus <italic>s</italic>, which is the new instantaneous evidence in Bayesian terminology. To which extent does the self-organized learning of our model and the subsequent response evoked by a stimulus reflect the Bayesian inference capabilities of the brain as investigated in a number of experiments (see, e.g. [<xref ref-type="bibr" rid="pcbi.1004640.ref045">45</xref>], but also see [<xref ref-type="bibr" rid="pcbi.1004640.ref046">46</xref>])? Specifically, we want to investigate to which extent the input-output behaviour of SORN is reminiscent of sampling-based inference.</p>
<p>Before comparing the behaviour of the SORN to a probabilistic inference process we have to reason about the idea where we locate the stochastic component in the deterministic recurrent network. The definition of the SORN implies that its state is deterministic given the current input <italic>and the full internal state of the previous time step</italic>. From the perspective of an external experimenter, however, the internal state is unknown, which leads to a pseudo-stochastic relation between the actual stimulus and the later readout. In the Methods we derive a probabilistic model that reflects this source of uncertainty by formalizing the input stimulation as noisy binary channels. The probabilistic inference is then modelled as a Naive Bayes classifier that gets its evidences from these noisy channels. Note that the probabilistic model is conceived such that it has no <italic>a priori</italic> knowledge about the labels of the channels or their relation to the population “A” or “B”, but it gains this knowledge from a learning phase similar to the SORN model with its subsequent linear classifier. As the result of the probabilistic model we use the posterior probability of the response variable “A” given the ambiguous stimulus <italic>s</italic> with respect to the learned prior <italic>p</italic>(A), or more precisely the probability function <italic>p</italic>(A|<italic>f</italic><sub>A</sub>) that directly relates the fraction <italic>f</italic><sub>A</sub> of ambiguity in <italic>s</italic> to that posterior probability.</p>
<p>Importantly, we are not looking for an explicit representation of this posterior probability in our SORN model (as suggested by [<xref ref-type="bibr" rid="pcbi.1004640.ref047">47</xref>]). Instead, we follow the idea of the sampling hypothesis [<xref ref-type="bibr" rid="pcbi.1004640.ref045">45</xref>, <xref ref-type="bibr" rid="pcbi.1004640.ref048">48</xref>] and interpret the binary decision of the SORN for “A” or “B” as a one-shot sample from this posterior probability distribution <italic>p</italic>(A|<italic>f</italic><sub>A</sub>) upon the one-shot presentation of the stimulus <italic>s</italic>. Upon every new presentation of the same stimulus <italic>s</italic> we expect to get a new sample from the same posterior. Thus we can experimentally measure the (binary) empirical distribution of the network’s stochastic answers and compare those results with the posterior according to the probabilistic model above.</p>
<p>The experimentally observed fractions of decisions for either “A” or “B” (blue and green lines in <xref ref-type="fig" rid="pcbi.1004640.g007">Fig 7a</xref>) approximate the Bayesian posterior <italic>p</italic>(A|<italic>f</italic><sub>A</sub>) and <italic>p</italic>(B|<italic>f</italic><sub>A</sub>) (grey dashed lines) for different ambiguity fractions <italic>f</italic><sub>A</sub> after convergence with learned priors of <italic>p</italic>(A) = 0.33 and <italic>p</italic>(B) = 0.67. We compare the results with an identical setting in which the STDP was turned off, but IP left on, to disentangle the respective effects (<xref ref-type="fig" rid="pcbi.1004640.g007">Fig 7b</xref>). The parameters of the probabilistic model were independently fitted to the simulation without STDP. In order to get a compact overview on the inference behaviour of the model across different values of the priors we especially observe the point of intersection of the blue and the green line and ask, which is the mixture fraction <italic>f</italic><sub>A</sub> of the two stimuli “A” and “B” that is necessary in order to counterbalance the prior such that the probability of the model’s response for “A” and “B” are both 50%. We plot these neutral values of <italic>f</italic><sub>A</sub> across different priors from <italic>p</italic>(A) = 10% to <italic>p</italic>(A) = 90%, both for the full model (blue line in <xref ref-type="fig" rid="pcbi.1004640.g007">Fig 7c</xref>) and for the case where STDP was turned off during the learning phase, leaving only IP for the adaptation of the excitabilities (<xref ref-type="fig" rid="pcbi.1004640.g007">Fig 7d</xref>). We compare them to the corresponding solutions of <italic>p</italic>(A|<italic>f</italic><sub>A</sub>) = 0.5 from the probabilistic model (grey dashed line). Note that we always train the readout classifiers for the classes “A” and “B” with an equal number of positive and negative examples regardless of the prior, in order to avoid a trivial classification bias.</p>
<fig id="pcbi.1004640.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004640.g007</object-id>
<label>Fig 7</label>
<caption>
<title>Prior and ambiguous information is combined in network decisions.</title>
<p>(a) As in <xref ref-type="fig" rid="pcbi.1004640.g006">Fig 6</xref>, the network self-organizes during repeated presentations of the sequences “AXXX_ _ _ …” (33%) and “BXXX_ _ _ …” (67%) with blank intervals in between. In the test phase, an ambiguous mix of cue “A” and cue “B” is presented (“A/BXXX_ _ _ …”) and the network decides at the first “_” with a linear classifier if either A or B was the start of the sequence. The fraction of decisions for “A” or “B” at the first blank state “_” approximates the integration of cue likelihood and prior stimulus probability as expected from the probabilistic model (grey dashed line) for the given prior (<italic>p</italic>(A) = 0.33). The probabilistic model was fitted by grid search over its two parameters to the parameters that had the smallest accumulated error over all priors. (b) For the “Only IP” condition, STDP was deactivated during the self-organization phase and a new probabilistic model was fitted. (c, d) The intersections of the decisions for different priors for our simulations (blue line) and the probabilistic model (grey dashed). The performance was evaluated for the same simulation as Figs <xref ref-type="fig" rid="pcbi.1004640.g005">5</xref> and <xref ref-type="fig" rid="pcbi.1004640.g006">6</xref>. Error bars represent SEM over 20 independent realizations.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004640.g007" xlink:type="simple"/>
</fig>
<p>The result clearly reflects the correct incorporation of the prior—learned by self-organisation with STDP—into the activity upon an ambiguous stimulus. The homeostatic adaptation alone (IP only) only accounts for a small part of this adaptation capability, but provides a bias towards the right behaviour.</p>
<p>Two factors interact in the network in order to learn the above likelihoods and the model. First, firing thresholds of the input units are regulated by intrinsic plasticity. This entails that the “A”-neurons will not fire every time “A” is presented because they might have fired too frequently in the past. Second, input units (and neurons further downstream) for stimulus “A” can be active when the network is presented with stimulus “B” due to ongoing spontaneous activity. These two mechanisms ensure that ambiguous activations of the input populations are already present during the self-organization and learning phase. During the test-phase with ambiguous stimuli, the ongoing spontaneous activity will again lead to suppression or enhancement of “A” or “B” by either adding additional activity or suppressing activity. This can happen either directly through enhanced ongoing excitation or inhibition or indirectly through previous over- or under-activity leading to higher or lower thresholds. This effect of spontaneous activity on network decisions is the reason the decisions can be predicted from spontaneous activity in <xref ref-type="fig" rid="pcbi.1004640.g006">Fig 6</xref>.</p>
<p>Together, these results demonstrate that the network not only captures the experimentally observed interactions of spontaneous and evoked activity, it also integrates prior and ambiguous information while doing so. While the resulting behaviour looks sampling-like it is not clear if this model can learn more complex probability distributions. However, the ability of SORN models to solve much more complex sequence learning tasks is well documented (see, e.g., [<xref ref-type="bibr" rid="pcbi.1004640.ref037">37</xref>, <xref ref-type="bibr" rid="pcbi.1004640.ref038">38</xref>] and <xref ref-type="sec" rid="sec017">Discussion</xref> for details).</p>
</sec>
</sec>
<sec id="sec014">
<title>Network analysis</title>
<p>Given all these data, the question arises how the underlying mechanisms interact to give rise to this variety of features. To better understand the dynamics of the neurons, we determine the conditional probability for neuron <italic>x</italic><sub><italic>i</italic></sub> to spike given that neuron <italic>x</italic><sub><italic>j</italic></sub> spiked at the prior time step when no input is presented. This will elucidate both how the excitatory connectivity affects the network dynamics and how the network dynamics affect the connectivity via STDP.</p>
<sec id="sec015">
<title>Single-unit analysis</title>
<p>We can see in <xref ref-type="fig" rid="pcbi.1004640.g008">Fig 8a</xref> that the conditional probability of neuron <italic>x</italic><sub><italic>i</italic></sub> spiking given that neuron <italic>x</italic><sub><italic>j</italic></sub> spiked at the previous time step (<italic>p</italic>(<italic>x</italic><sub><italic>i</italic></sub>(<italic>t</italic> + 1) = 1|<italic>x</italic><sub><italic>j</italic></sub>(<italic>t</italic>) = 1)) grows roughly linearly with the synaptic weight <inline-formula id="pcbi.1004640.e001"><alternatives><graphic id="pcbi.1004640.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e001" xlink:type="simple"/><mml:math display="inline" id="M1"><mml:msubsup><mml:mi>W</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mrow><mml:mi>E</mml:mi> <mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> between both neurons except for saturation effects: <inline-formula id="pcbi.1004640.e002"><alternatives><graphic id="pcbi.1004640.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e002" xlink:type="simple"/><mml:math display="inline" id="M2"><mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo>|</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≈</mml:mo> <mml:mi>κ</mml:mi> <mml:msubsup><mml:mi>W</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mrow><mml:mi>E</mml:mi> <mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>. This relation, as simple as it might seem, immediately breaks down if IP or SN are deactivated (<xref ref-type="supplementary-material" rid="pcbi.1004640.s006">S6 Fig</xref>): While the general and intuitive trend persists that high weights imply higher conditional firing probabilities, the linear relation vanishes. The conditional probabilities in these figures were always computed for the spontaneous phase after self-organization to avoid effects from the input.</p>
<fig id="pcbi.1004640.g008" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004640.g008</object-id>
<label>Fig 8</label>
<caption>
<title>Self-organization imprints stimulus properties in the network.</title>
<p>(a) The conditional probability of <italic>x</italic><sub><italic>i</italic></sub> spiking given that <italic>x</italic><sub><italic>j</italic></sub> just spiked (<italic>p</italic>(<italic>x</italic><sub><italic>i</italic></sub>(<italic>t</italic> + 1) = 1|<italic>x</italic><sub><italic>j</italic></sub>(<italic>t</italic>) = 1)) is roughly proportional to their synaptic connection <inline-formula id="pcbi.1004640.e003"><alternatives><graphic id="pcbi.1004640.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e003" xlink:type="simple"/><mml:math display="inline" id="M3"><mml:msubsup><mml:mi>W</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mrow><mml:mi>E</mml:mi> <mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> except for saturation effects for very large weights. (b) The firing probabilities of each neuron relative to stimulus onset. The network develops sequential activity patterns during the presentation of both sequences (top and middle) and during spontaneous activity (aligned to spontaneous states corresponding to “C”, bottom). Neurons were sorted according to their maximal firing probability relative to the sequence “ABCD”. (c) The prediction of transition probabilities during spontaneous activity from the singular value decomposition of <bold>W</bold><sup><italic>EE</italic></sup>. (d) The actual transition probabilities during spontaneous activity show intermediate switching between the two sequences probably due to variability introduced by intrinsic plasticity (see <xref ref-type="sec" rid="sec017">Discussion</xref> for details).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004640.g008" xlink:type="simple"/>
</fig>
<p>This relation between connection strength and firing probability interacts with STDP (but does not result from it, see <xref ref-type="supplementary-material" rid="pcbi.1004640.s006">S6 Fig</xref>): Given two reciprocal weights <italic>W</italic><sub><italic>ij</italic></sub> and <italic>W</italic><sub><italic>ji</italic></sub> with <italic>W</italic><sub><italic>ij</italic></sub> &gt; <italic>W</italic><sub><italic>ji</italic></sub>, the average weight update will be (given the target firing rate from the intrinsic plasticity, <italic>H</italic><sub>IP</sub>)
<disp-formula id="pcbi.1004640.e004"><alternatives><graphic id="pcbi.1004640.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e004" xlink:type="simple"/><mml:math display="block" id="M4"><mml:mtext>E</mml:mtext><mml:mo stretchy="false">[</mml:mo><mml:mo>Δ</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">]</mml:mo><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mtext>STDP</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mtext> </mml:mtext><mml:mo>−</mml:mo><mml:mtext> </mml:mtext></mml:mrow></mml:mrow><mml:mrow> <mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow><mml:mo> </mml:mo></mml:math></alternatives> <label>(1)</label></disp-formula> <disp-formula id="pcbi.1004640.e005"><alternatives><graphic id="pcbi.1004640.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e005" xlink:type="simple"/><mml:math display="block" id="M5"><mml:mtable><mml:mtr><mml:mtd><mml:mrow/></mml:mtd><mml:mtd><mml:mrow><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mtext>STDP</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>|</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow/></mml:mtd><mml:mtd><mml:mrow><mml:mtext>     </mml:mtext><mml:mrow> <mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>|</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(2)</label></disp-formula> <disp-formula id="pcbi.1004640.e006"><alternatives><graphic id="pcbi.1004640.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e006" xlink:type="simple"/><mml:math display="block" id="M6"><mml:mtable><mml:mtr><mml:mtd><mml:mrow/></mml:mtd><mml:mtd><mml:mrow><mml:mtext> </mml:mtext><mml:mo>≈</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>η</mml:mi> <mml:mtext>STDP</mml:mtext></mml:msub> <mml:mfenced close=")" open="(" separators=""><mml:mi>κ</mml:mi> <mml:msubsup><mml:mi>W</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mrow><mml:mi>E</mml:mi> <mml:mi>E</mml:mi></mml:mrow></mml:msubsup> <mml:msub><mml:mi>H</mml:mi> <mml:mtext>IP</mml:mtext></mml:msub> <mml:mo>-</mml:mo> <mml:mi>κ</mml:mi> <mml:msubsup><mml:mi>W</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>i</mml:mi></mml:mrow> <mml:mrow><mml:mi>E</mml:mi> <mml:mi>E</mml:mi></mml:mrow></mml:msubsup> <mml:msub><mml:mi>H</mml:mi> <mml:mtext>IP</mml:mtext></mml:msub></mml:mfenced></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(3)</label></disp-formula>
<disp-formula id="pcbi.1004640.e007"><alternatives><graphic id="pcbi.1004640.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e007" xlink:type="simple"/><mml:math display="block" id="M7"><mml:mrow><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mtext>STDP</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>κ</mml:mi><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mtext>IP</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives> <label>(4)</label></disp-formula>
<disp-formula id="pcbi.1004640.e008"><alternatives><graphic id="pcbi.1004640.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e008" xlink:type="simple"/><mml:math display="block" id="M8"><mml:mo>&gt;</mml:mo> <mml:mrow><mml:mspace width="3.33333pt"/><mml:mn>0</mml:mn> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(5)</label></disp-formula></p>
<p>We observe that the expected weight update is directly proportional to the weight difference. In the likely case of the reciprocal weight being 0, it is directly proportional to the weight. This leads to the rich-get-richer behaviour of synaptic strengths as observed in a prevous version of the SORN [<xref ref-type="bibr" rid="pcbi.1004640.ref039">39</xref>]. Basically, a high weight increases the firing probability of the postsynaptic neuron upon presynaptic activation, which further increases the weight <xref ref-type="disp-formula" rid="pcbi.1004640.e007">Eq (4)</xref>, and so on. Another key factor for the rich-get-richer behaviour is synaptic normalization, as described in [<xref ref-type="bibr" rid="pcbi.1004640.ref039">39</xref>].</p>
<p>Apart from the skewed weight distribution, it eventually also leads to a sequential activation of neurons as observed in neocortex [<xref ref-type="bibr" rid="pcbi.1004640.ref028">28</xref>], in a previous version of the SORN [<xref ref-type="bibr" rid="pcbi.1004640.ref049">49</xref>], and in the current study (<xref ref-type="fig" rid="pcbi.1004640.g008">Fig 8b</xref>).</p>
<p>Next, we analyse the impact of input structure on the STDP dynamics. For this, we consider the case where an excitatory neuron <italic>x</italic><sub><italic>A</italic></sub> receives external input with the frequency <italic>p</italic>(<italic>A</italic>). Furthermore, we assume that this neuron projects to a second excitatory input-receiving neuron <italic>x</italic><sub><italic>B</italic></sub> with a very small weight, i.e. <inline-formula id="pcbi.1004640.e009"><alternatives><graphic id="pcbi.1004640.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e009" xlink:type="simple"/><mml:math display="inline" id="M9"><mml:mrow><mml:msubsup><mml:mi>W</mml:mi> <mml:mrow><mml:mi>B</mml:mi> <mml:mi>A</mml:mi></mml:mrow> <mml:mrow><mml:mi>E</mml:mi> <mml:mi>E</mml:mi></mml:mrow></mml:msubsup> <mml:mo>&lt;</mml:mo> <mml:mi>ϵ</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>, so that the impact of the weight on the firing probabilities can be neglected. Finally, we assume that there is no reverse projection from <italic>x</italic><sub><italic>B</italic></sub> to <italic>x</italic><sub><italic>A</italic></sub>, i.e. <italic>x</italic><sub><italic>B</italic></sub>(<italic>t</italic>) is assumed to be approximately independent from <italic>x</italic><sub><italic>A</italic></sub>(<italic>t</italic> + 1). This neuron receives input from the next letter in the input word, “B”. We further assume that the stimuli are presented infrequently enough so that the intrinsic plasticity does not interfere with the activation of input-receiving neurons when the corresponding input is presented, i.e. <italic>p</italic>(<italic>A</italic>) ≪ <italic>H</italic><sub>IP</sub>. This ensures that whenever <italic>x</italic><sub><italic>A</italic></sub> is activated by the input, <italic>x</italic><sub><italic>B</italic></sub> will be active in the subsequent time step with a probability close to 1. In this case, we have
<disp-formula id="pcbi.1004640.e010"><alternatives><graphic id="pcbi.1004640.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e010" xlink:type="simple"/><mml:math display="block" id="M10"><mml:mrow><mml:mtext>E</mml:mtext><mml:mo stretchy="false">[</mml:mo><mml:mo>Δ</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">]</mml:mo><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mtext>STDP</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mn>1</mml:mn><mml:mo>|</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mtext> </mml:mtext><mml:mo>−</mml:mo><mml:mtext> </mml:mtext><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mn>1</mml:mn><mml:mo>|</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></alternatives> <label>(6)</label></disp-formula> <disp-formula id="pcbi.1004640.e011"><alternatives><graphic id="pcbi.1004640.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e011" xlink:type="simple"/><mml:math display="block" id="M11"><mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mtext>STDP</mml:mtext></mml:mrow></mml:msub><mml:mtext> </mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mtext>IP</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>×</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mtext>IP</mml:mtext></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mtext>IP</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>×</mml:mo><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mtext>IP</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mtext>IP</mml:mtext></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi>H</mml:mi><mml:mrow><mml:mtext>IP</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives> <label>(7)</label></disp-formula> <disp-formula id="pcbi.1004640.e012"><alternatives><graphic id="pcbi.1004640.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e012" xlink:type="simple"/><mml:math display="block" id="M12"><mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mtext>STDP</mml:mtext></mml:mrow></mml:msub><mml:mtext> </mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mtext>IP</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives> <label>(8)</label></disp-formula> <disp-formula id="pcbi.1004640.e013"><alternatives><graphic id="pcbi.1004640.e013g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e013" xlink:type="simple"/><mml:math display="block" id="M13"><mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mtext>STDP</mml:mtext></mml:mrow></mml:msub><mml:mtext> </mml:mtext><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mtext>IP</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(9)</label></disp-formula></p>
<p>The first term in <xref ref-type="disp-formula" rid="pcbi.1004640.e011">Eq 7</xref> corresponds to the conditional probability of firing when the firing of <italic>x</italic><sub><italic>A</italic></sub> is due to the stimulus, which will by assumption also lead to an activation of <italic>x</italic><sub><italic>B</italic></sub> with probability 1, or due to the chance event that a spontaneously driven spike in <italic>x</italic><sub><italic>A</italic></sub> is followed by a spontaneously driven spike in <italic>x</italic><sub><italic>B</italic></sub>, which is <italic>H</italic><sub>IP</sub>. These spontaneously driven spikes can either be due to recurrent activations from spontaneous activity in presynaptic units or due to the threshold of the unit being lowered below the current drive by intrinsic plasticity. Both probabilities are combined according to their relative occurrence: <inline-formula id="pcbi.1004640.e014"><alternatives><graphic id="pcbi.1004640.e014g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e014" xlink:type="simple"/><mml:math display="inline" id="M14"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mi>A</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msub><mml:mi>H</mml:mi> <mml:mtext>IP</mml:mtext></mml:msub></mml:mfrac> <mml:mo>×</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> for the stimulus-driven case and (<inline-formula id="pcbi.1004640.e015"><alternatives><graphic id="pcbi.1004640.e015g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e015" xlink:type="simple"/><mml:math display="inline" id="M15"><mml:mrow><mml:mfrac><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>H</mml:mi> <mml:mtext>IP</mml:mtext></mml:msub> <mml:mo>-</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>A</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:msub><mml:mi>H</mml:mi> <mml:mtext>IP</mml:mtext></mml:msub></mml:mfrac> <mml:mo>×</mml:mo> <mml:msub><mml:mi>H</mml:mi> <mml:mtext>IP</mml:mtext></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>) for the recurrently driven one.</p>
<p>We observe that the expected weight change is directly proportional to <italic>p</italic>(<italic>A</italic>). As a result of this, if we consider two stimuli with different frequencies, the weights will grow stronger for the more frequent stimulus. In fact, they are directly proportional so that a stimulus that is twice as frequent will have a twice as strongly growing weight in the network. Taking into account the proportionality between the weight and the conditional firing probability and assuming initially random weights, this means that on average the more frequently presented stimulus during learning will also be associated with stronger weights and have a higher probability of recall. It is important to keep in mind that this specific case assumes that <italic>x</italic><sub><italic>A</italic></sub> receives direct input. Weights between pairs with only indirect input on <italic>x</italic><sub><italic>A</italic></sub> will be corrupted from unreliable activation of the presynaptic direct-input neurons of <italic>x</italic><sub><italic>A</italic></sub>.</p>
<p>The above proportionality will break down if the weights become strong enough to have a strong impact on firing probabilities. This case will again result in rich-get-richer behaviour. This will lead to the overrepresentation of probabilities (“overlearning”) as observed in <xref ref-type="fig" rid="pcbi.1004640.g004">Fig 4</xref>. Nevertheless, the Figure also shows that despite this overrepresentation, the network does not completely abolish the more infrequent stimulus at convergence since the input still has an effect in driving the neuron and thereby the learning.</p>
</sec>
<sec id="sec016">
<title>Population analysis</title>
<p>Having analysed the interactions of single neurons, it is important to know if these results generalize to the population as a whole. More specifically:</p>
<list list-type="order">
<list-item>
<p>Can STDP imprint the sequential input structure in the recurrent excitatory connectivity?</p>
</list-item>
<list-item>
<p>Does the excitatory connectivity correspond to the observed transition probabilities of the network states when it is running without input?</p>
</list-item>
</list>
<p>We analyse these question by simplifying the excitatory network dynamics to a linear dynamical system:</p>
<disp-formula id="pcbi.1004640.e016"><alternatives><graphic id="pcbi.1004640.e016g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e016" xlink:type="simple"/><mml:math display="block" id="M16"><mml:mrow><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:msup><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>W</mml:mi></mml:mstyle><mml:mrow><mml:mi>E</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives><label>(10)</label></disp-formula>
<p>We then apply singular-value decomposition (SVD) to the recurrent weight matrix:</p>
<disp-formula id="pcbi.1004640.e017">
<alternatives>
<graphic id="pcbi.1004640.e017g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e017" xlink:type="simple"/>
<mml:math display="block" id="M17"><mml:mrow><mml:msup><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>W</mml:mi></mml:mstyle><mml:mrow><mml:mi>E</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mo> </mml:mo><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>U</mml:mi><mml:mi>Σ</mml:mi></mml:mstyle><mml:msup><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>V</mml:mi></mml:mstyle><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>T</mml:mi></mml:mstyle></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives>
<label>(11)</label>
</disp-formula>
<p>Because <bold>U</bold> and <bold>V</bold> are orthonormal and <bold>Σ</bold> diagonal, we have
<disp-formula id="pcbi.1004640.e018"><alternatives><graphic id="pcbi.1004640.e018g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e018" xlink:type="simple"/><mml:math display="block" id="M18"><mml:mrow><mml:msub><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>u</mml:mi></mml:mstyle><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>σ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>U</mml:mi><mml:mi>Σ</mml:mi></mml:mstyle><mml:msup><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>V</mml:mi></mml:mstyle><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>T</mml:mi></mml:mstyle></mml:msup><mml:msub><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>v</mml:mi></mml:mstyle><mml:mi>i</mml:mi></mml:msub><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:msup><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>W</mml:mi></mml:mstyle><mml:mrow><mml:mi>E</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>v</mml:mi></mml:mstyle><mml:mi>i</mml:mi></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(12)</label></disp-formula>
where <bold>u</bold><sub><italic>i</italic></sub> and <bold>v</bold><sub><italic>i</italic></sub> are column-vectors of <bold>U</bold> and <bold>V</bold> and <italic>σ</italic><sub><italic>i</italic></sub> is the corresponding singular value in <bold>Σ</bold>. By comparing Eqs (<xref ref-type="disp-formula" rid="pcbi.1004640.e016">10</xref>) and (<xref ref-type="disp-formula" rid="pcbi.1004640.e018">12</xref>), one can see that the vectors <bold>v</bold><sub><italic>i</italic></sub> and <bold>u</bold><sub><italic>i</italic></sub> <italic>σ</italic><sub><italic>i</italic></sub> define transitions similar to <bold>x</bold>(<italic>t</italic>) and <bold>x</bold>(<italic>t</italic> + 1). We therefore analyse the behaviour of learned connections by matching each vector <bold>v</bold><sub><italic>i</italic></sub> and <bold>u</bold><sub><italic>i</italic></sub> to their closest matching evoked state. This is done by taking the maximum of the dot product between the vector and the last 2500 evoked activity states of the training phase. Thereby we get from transitions between vectors to transitions between input letters. By scaling each transition by its singular value <italic>σ</italic><sub><italic>i</italic></sub> and normalizing to 1, we can predict the transition probabilities.</p>
<p>In <xref ref-type="fig" rid="pcbi.1004640.g008">Fig 8c</xref>, the result of this analysis is applied to the sequence learning task. When compared to the actual transitions during spontaneous activity in <xref ref-type="fig" rid="pcbi.1004640.g008">Fig 8d</xref>, one can see that the SVD-analysis approximates the actual transition probabilities. This entails that STDP can indeed imprint the input structure in the weight matrix and that these probabilities are correctly represented during spontaneous activity. The corresponding results for the inference tasks can be found in <xref ref-type="supplementary-material" rid="pcbi.1004640.s005">S5 Fig</xref>. Scatter plots for the spontaneous and predicted transitions can be found in <xref ref-type="supplementary-material" rid="pcbi.1004640.s007">S7 Fig</xref>.</p>
<p>Taken together, these analyses explain why and how the network activity acquires the stimulation structure in <xref ref-type="fig" rid="pcbi.1004640.g003">Fig 3</xref> and how the input priors can be both imprinted into the network connectivity (cp. <xref ref-type="fig" rid="pcbi.1004640.g004">Fig 4</xref>) and utilized during testing (cp. <xref ref-type="fig" rid="pcbi.1004640.g007">Fig 7</xref>).</p>
</sec>
</sec>
</sec>
<sec id="sec017" sec-type="conclusions">
<title>Discussion</title>
<p>We have shown that key properties of neural variability emerge in a simple deterministic network of recurrently connected spiking neurons that learns a predictive model of its sensory environment. These key properties include the decrease of trial-to-trial variability with stimulus onset [<xref ref-type="bibr" rid="pcbi.1004640.ref010">10</xref>], the outlining of evoked responses by spontaneous activity [<xref ref-type="bibr" rid="pcbi.1004640.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1004640.ref013">13</xref>], the adaptation of spontaneous activity towards average evoked activity over training [<xref ref-type="bibr" rid="pcbi.1004640.ref016">16</xref>] and the prediction of evoked activity and perceptual decisions on the basis of spontaneous activity [<xref ref-type="bibr" rid="pcbi.1004640.ref008">8</xref>, <xref ref-type="bibr" rid="pcbi.1004640.ref020">20</xref>]. While we are not the first to model these effects, we are, to the best of our knowledge, the first to account for all these effects in unison and in such a simple model. For example, constrained balanced networks can capture the decline of the Fano factor [<xref ref-type="bibr" rid="pcbi.1004640.ref050">50</xref>, <xref ref-type="bibr" rid="pcbi.1004640.ref051">51</xref>]. However, these models do not employ learning and therefore cannot account for the other properties of neural variability treated here (but see [<xref ref-type="bibr" rid="pcbi.1004640.ref052">52</xref>]).</p>
<p>We hypothesized that three properties of cortical circuits lie at the heart of the above phenomena: 1. Recurrent connectivity shapes the structure of spontaneous activity and determines the relationship between spontaneous and evoked activity patterns. 2. Neural plasticity is responsible for structuring recurrent connectivity such that spontaneous activity matches the statistics of evoked activity. In functional terms this corresponds to the network learning a predictive model of its sensory environment. 3. Homeostatic mechanisms keep spontaneous and evoked activity in a healthy dynamic regime where learning and inference are possible. To test whether these properties are indeed sufficient to reproduce the above phenomena, we chose a bottom-up modelling approach.</p>
<p>We implemented a minimal network model embodying these properties and found that the network does reproduce the key experimental observations on neural variability and spontaneous activity. The model we chose is an instance of the family of self-organizing recurrent neural network (SORN) models. It is important to highlight that the network that formed the basis for the present work had been developed in a completely different context and with a very different goal. The SORN was originally introduced by [<xref ref-type="bibr" rid="pcbi.1004640.ref037">37</xref>] who showed that it is superior to a conventional reservoir computing approach when learning sequences with high-order Markovian structure. This was shown to be due to the unsupervised learning of the input structure with the same combination of plasticity rules used in the present work. Recently, [<xref ref-type="bibr" rid="pcbi.1004640.ref039">39</xref>] showed that a very similar network reproduces biological data on synaptic weight statistics and fluctuations. Their model accounted for both the lognormal-like distribution of excitatory-excitatory synaptic connection strengths (<xref ref-type="fig" rid="pcbi.1004640.g001">Fig 1f</xref>) and the fluctuations of individual synaptic efficacies over time. More recently, a different group independently validated this model on a grammar-learning task and found that the SORN displayed behaviour similar to humans learning the same grammars [<xref ref-type="bibr" rid="pcbi.1004640.ref038">38</xref>].</p>
<p>The specific implementation of SORN that we have used is only slightly different from the original version [<xref ref-type="bibr" rid="pcbi.1004640.ref037">37</xref>] in two ways: First, we made use of a presynaptic normalization in this study. This means that not only is the sum of incoming connection weights to a neuron normalized, but also the sum of all outgoing connection strengths is normalized. We find that this makes the model somewhat more robust. Mathematically speaking, normalizing the connections from both sides yields a weight matrix that is a linear combination of permutation matrices. This implies that in a linear dynamical system, the total activity would always be preserved, which gives an intuition as to why the nonlinear SORN model is more robust with this mechanism. While presynaptic normalization is well-known in the computational literature (see, e.g., [<xref ref-type="bibr" rid="pcbi.1004640.ref053">53</xref>]), there seem to be few biological experiments addressing the issue. We are aware of early studies on the “conservation of axonal arbor”[<xref ref-type="bibr" rid="pcbi.1004640.ref054">54</xref>, <xref ref-type="bibr" rid="pcbi.1004640.ref055">55</xref>] suggesting that presynaptic normalization may be possible. Second, instead of using the same target firing rate for all neurons for the intrinsic plasticity, we introduced slightly different firing rates for each neuron. As for the presynaptic normalization, we found that this increases the robustness of the network dynamics: because each neuron has to fire with a slightly different rate, the emergence of repetitive activity patterns is discouraged and the network activity becomes more variable.</p>
<p>The simplicity and abstract nature of the SORN model allowed us to reproduce data on the interaction between spontaneous and evoked activity obtained from multi-electrode recordings over optical imaging to even fMRI. This generality allows us to predict that the phenomena that so far have only been reported for slowly-varying imaging data (e.g [<xref ref-type="bibr" rid="pcbi.1004640.ref008">8</xref>, <xref ref-type="bibr" rid="pcbi.1004640.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1004640.ref020">20</xref>]) are also present on the spiking level. We predict that the population spiking activity prior to stimulus onset can be used to predict evoked spiking activity and perceptual decisions. We also predict that spontaneous spike patterns are shaped by learning and reflect the presentation probabilities of associated stimuli. Another concrete prediction is that the Fano factor decreases more strongly at stimulus onset for stimuli that have a higher probability of occurrence (<xref ref-type="fig" rid="pcbi.1004640.g005">Fig 5</xref>). In line with this prediction, a recent study has demonstrated that the Fano Factor decreases most for the preferred direction when analysing MT responses to moving gratings [<xref ref-type="bibr" rid="pcbi.1004640.ref044">44</xref>].</p>
<p>A less straight-forward effect is the overlearning found in <xref ref-type="fig" rid="pcbi.1004640.g004">Fig 4</xref> and analysed at the end of the Results: due to the influence of recurrent reactivation of already learnt sequences on the learning process, very frequent stimuli will tend to have a reinforcing influence during learning and thereby become overrepresented in the network. This in turn suppresses infrequent stimuli. This simple interaction seems to be an inevitable feature of learning in recurrent networks. We speculate that sequence learning <italic>in vivo</italic> (as e.g. in [<xref ref-type="bibr" rid="pcbi.1004640.ref031">31</xref>]) also may not stop at the exact relative probability but tend to overrepresent very frequent stimuli.</p>
<p>Obviously, the model also has a number of limitations. The abstract nature of the model (memory-less threshold units operating in discrete time) makes it difficult to perform detailed comparisons to specific data sets. For example, while we showed that the spontaneous activity obtained in the model is highly structured and influences the evoked activity, we did not, say, attempt to reproduce the exact time course of the measured BOLD activity in the fusiform-face-area. Also, while there is evidence for the model’s plasticity mechanisms in neocortex and hippocampus (see <xref ref-type="sec" rid="sec020">Methods</xref>), we find that mainly unidirectional connections develop in the model due to the asymmetric STDP rule. This seems to be at odds with data on above-chance bidirectional connections (e.g. [<xref ref-type="bibr" rid="pcbi.1004640.ref056">56</xref>], but see [<xref ref-type="bibr" rid="pcbi.1004640.ref057">57</xref>]).</p>
<p>Another critical point are the Fano factor values we observe in the model. While [<xref ref-type="bibr" rid="pcbi.1004640.ref050">50</xref>, <xref ref-type="bibr" rid="pcbi.1004640.ref051">51</xref>] succeeded in capturing the effect that most recordings in [<xref ref-type="bibr" rid="pcbi.1004640.ref010">10</xref>] show Fano factors above 1, we only observed Fano factors around 1 in the model. One possible explanation for this is suggested by the recent double-Poissonian model proposed in [<xref ref-type="bibr" rid="pcbi.1004640.ref040">40</xref>]. They demonstrated that the additional variability can be accounted for by a second, slowly varying factor such as the attentional state or levels of neuromodulation. Another study recently suggested that recurrent input not only from the local population but also from more distant brain areas leads to increased variability [<xref ref-type="bibr" rid="pcbi.1004640.ref022">22</xref>]. Since such processes are missing in our model, we also do not observe this additional variability.</p>
<sec id="sec018">
<title>Relation to sampling theories</title>
<p>We chose a bottom-up modelling approach to address the question of the origin of neural variability and spontaneous activity. Ultimately, our goal is to reconcile such an approach with top-down functional approaches. Several features of neural variability and spontaneous activity have an elegant interpretation in terms of sampling theories of perceptual inference [<xref ref-type="bibr" rid="pcbi.1004640.ref045">45</xref>, <xref ref-type="bibr" rid="pcbi.1004640.ref048">48</xref>]. In such theories, neural activity is interpreted as samples from a posterior probability distribution over the states of certain variables of interest given a sensory input. Correspondingly, spontaneous activity in the absence of sensory input is interpreted as samples from a prior probability distribution over these variables. This view elegantly captures several of the key experimental observations. For example, in this view the decrease in response variability after stimulus onset simply reflects that the posterior distribution over properties of the stimulus once it has been observed will be “narrower” compared to the prior distribution before stimulus presentation. The same holds for the outlining of evoked responses by spontaneous activity.</p>
<p>We showed that a fully deterministic SORN model can exhibit certain features expected from sampling-based inference (see, e.g., [<xref ref-type="bibr" rid="pcbi.1004640.ref045">45</xref>]). It may appear surprising that the behaviour of a fully deterministic network exhibits certain features of a probabilistic sampling strategy, but recent work has shown that Boltzmann Machines can be approximated by a sufficiently chaotic system [<xref ref-type="bibr" rid="pcbi.1004640.ref058">58</xref>]. It is well-known that such chaos can arise in deterministic neural networks similar to the SORN, for example by balanced excitation and inhibition [<xref ref-type="bibr" rid="pcbi.1004640.ref059">59</xref>]. Previous work with SORN models has also shown that they can exhibit dynamics close to the critical transition point between ordered and chaotic dynamics [<xref ref-type="bibr" rid="pcbi.1004640.ref060">60</xref>]. In principle, therefore, it cannot be ruled out that the SORN can be related to network implementations of sampling algorithms.</p>
<p>Hence, it is insightful to contrast our study with top-down modeling studies that tried to construct neural implementations of the sampling theory. Most prominently, the authors of [<xref ref-type="bibr" rid="pcbi.1004640.ref061">61</xref>] showed in a rigorous analysis that in a feed-forward-like structure with winner-take-all circuits, STDP can be used to approximate a sampling-version of expectation maximization and thereby learn a generative model of the input. Similarly, [<xref ref-type="bibr" rid="pcbi.1004640.ref062">62</xref>] demonstrated that Markov chain Monte Carlo sampling can be approximated with symmetrically connected spiking neurons. A different group showed that spatio-temporal patterns can be entrained in a network with an artificial importance-sampling rule [<xref ref-type="bibr" rid="pcbi.1004640.ref063">63</xref>]. A more biological approximation of this again resembles STDP. Finally, the model in [<xref ref-type="bibr" rid="pcbi.1004640.ref061">61</xref>] was recently extended to demonstrate that sequence learning in a Hidden Markov Model can again be approximated by using only a local STDP rule [<xref ref-type="bibr" rid="pcbi.1004640.ref064">64</xref>]. Therefore, recent top-down modelling studies demonstrate that STDP is a good candidate to learn appropriate weights to represent statistics of the input (see also [<xref ref-type="bibr" rid="pcbi.1004640.ref065">65</xref>]). This suggests that it may be possible to reconcile the bottom-up model presented here with top-down approaches for probabilistic inference by sampling, leading to a more complete understanding of neural variability and spontaneous activity. In this context it is worth pointing out that the top-down models discussed above make heavy use of intrinsic noise to achieve these sampling-effects (but see [<xref ref-type="bibr" rid="pcbi.1004640.ref066">66</xref>]). Our results, together with [<xref ref-type="bibr" rid="pcbi.1004640.ref058">58</xref>], suggest that this may not be necessary.</p>
</sec>
<sec id="sec019">
<title>How noisy is the brain?</title>
<p>In fact, our work casts some doubt on the heavy use of noise in other network models where it is used to stabilize networks in irregular regimes or to avoid oscillations or epileptic-like behaviour. This practice is usually justified by referring to data on neural variability in the cortex. Here we demonstrated that key findings on neural variability can be accounted for by a completely deterministic network learning a model of its sensory environment. Additionally, there is experimental evidence suggesting that action potential generation is highly deterministic and synaptic transmission becomes essentially deterministic as long as experiments are performed under realistic conditions [<xref ref-type="bibr" rid="pcbi.1004640.ref003">3</xref>–<xref ref-type="bibr" rid="pcbi.1004640.ref005">5</xref>]. Therefore, we propose that the common practice to make heavy use of noise in neural simulations should not be taken as the gold standard. Nevertheless, we also tested the robustness of our results to noise by adding Gaussian white noise with zero mean on the excitatory units and tracking the amount of spikes added and suppressed by the noise. We found that setting the variance of the noise to disturb up to 10% of the activity does not relevantly alter the results presented here.</p>
<p>So just how noisy is the brain? What do our results imply for the amount of noise we should expect to find in the brain? And what processes deserve to be called “noise” in the first place? From an information theoretic perspective, a natural assumption when theorizing about sensory processing is that the brain is trying to maximize the conditional mutual information <inline-formula id="pcbi.1004640.e019"><alternatives><graphic id="pcbi.1004640.e019g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e019" xlink:type="simple"/><mml:math display="inline" id="M19"><mml:mrow><mml:mtext>MI</mml:mtext> <mml:mo>(</mml:mo> <mml:mi>W</mml:mi> <mml:mo>;</mml:mo> <mml:mi>R</mml:mi> <mml:mo>|</mml:mo> <mml:mi>S</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> between sequences of states of the outside world <italic>W</italic> (or relevant parts thereof) and the internal representation <italic>R</italic> of this state sequence in terms of spatio-temporal cortical activity patterns, given the animal’s current brain state <italic>S</italic>. Conditioning on <italic>S</italic> expresses that the spatio-temporal activity patterns elicited by sensory inputs will depend on the current brain state of the animal, which is the product of its life-long experience and recent history of interaction with its environment. In any case, this mutual information can be decomposed as <inline-formula id="pcbi.1004640.e020"><alternatives><graphic id="pcbi.1004640.e020g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e020" xlink:type="simple"/><mml:math display="inline" id="M20"><mml:mrow><mml:mtext>MI</mml:mtext> <mml:mo>(</mml:mo> <mml:mi>W</mml:mi> <mml:mo>;</mml:mo> <mml:mi>R</mml:mi> <mml:mo>|</mml:mo> <mml:mi>S</mml:mi> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:mi>H</mml:mi> <mml:mo>(</mml:mo> <mml:mi>R</mml:mi> <mml:mo>|</mml:mo> <mml:mi>S</mml:mi> <mml:mo>)</mml:mo> <mml:mo>-</mml:mo> <mml:mi>H</mml:mi> <mml:mo>(</mml:mo> <mml:mi>R</mml:mi> <mml:mo>|</mml:mo> <mml:mi>W</mml:mi> <mml:mo>,</mml:mo> <mml:mi>S</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. Thus, in order to maximize <inline-formula id="pcbi.1004640.e021"><alternatives><graphic id="pcbi.1004640.e021g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e021" xlink:type="simple"/><mml:math display="inline" id="M21"><mml:mrow><mml:mtext>MI</mml:mtext> <mml:mo>(</mml:mo> <mml:mi>W</mml:mi> <mml:mo>;</mml:mo> <mml:mi>R</mml:mi> <mml:mo>|</mml:mo> <mml:mi>S</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> the brain should try to maximize the entropy of its internal representation of the world <italic>H</italic>(<italic>R</italic>|<italic>S</italic>) while at the same time trying to minimize the conditional entropy of this representation given the future sequence of states of the world and its current brain state <italic>H</italic>(<italic>R</italic>|<italic>W</italic>, <italic>S</italic>). Maximizing the first term also implies maximizing a lower bound of <italic>H</italic>(<italic>R</italic>), which means that the brain should make use of a maximally rich and diverse set of responses that, to an observer who does not have access to the true state of the world and the full brain state, should look like noise. In fact, the more efficient the code, the more the brain activity should look like noise. We speculate that this is the true reason why the activities of neurons are often so well-described by simple stochastic models. Minimizing the second term means that the ideal encoding should be deterministic, i.e., <italic>R</italic> is a deterministic function of <italic>W</italic> and <italic>S</italic>, because then <italic>H</italic>(<italic>R</italic>|<italic>W</italic>, <italic>S</italic>) reaches its smallest possible value of zero. Put simply, the best coding mechanism will have as little intrinsic noise as possible. Note that this does not imply that the neural response to a repeated stimulus will necessarily be the same (or even similar!). It only implies that it is a deterministic function of the current sensory input and the animal’s constantly evolving brain state. On the surface, the great response variability of neurons in sensory cortices seems to be at odds with the idea of a deterministic encoding. However, our results show that there exists a simple way of learning a fully deterministic coding scheme that is consistent with the key features of neural response variability observed in the brain. This raises the possibility that the brain may be using a highly efficient deterministic coding strategy and that for many years neuroscientists have mistaken this deterministic neural code for an inefficient and noisy one.</p>
</sec>
</sec>
<sec id="sec020" sec-type="materials|methods">
<title>Methods</title>
<sec id="sec021">
<title>Model</title>
<p>Our model is based on the self-organizing recurrent neural network (SORN) [<xref ref-type="bibr" rid="pcbi.1004640.ref037">37</xref>]. Pilot studies related to the work presented here have been presented at a conference [<xref ref-type="bibr" rid="pcbi.1004640.ref067">67</xref>]. For more detailed information and a validation of the results, the code is available on github: <ext-link ext-link-type="uri" xlink:href="https://github.com/chrhartm/SORN" xlink:type="simple">https://github.com/chrhartm/SORN</ext-link>.</p>
<sec id="sec022">
<title>Network setup</title>
<p>The network consists of a population of <italic>N</italic><sup><italic>E</italic></sup> = 200 excitatory and <italic>N</italic><sup><italic>I</italic></sup> = 0.2 × <italic>N</italic><sup><italic>E</italic></sup> = 40 inhibitory McCulloch &amp; Pitts threshold neurons [<xref ref-type="bibr" rid="pcbi.1004640.ref068">68</xref>]. The connections between the neurons are described by weight matrices where, for example, <inline-formula id="pcbi.1004640.e022"><alternatives><graphic id="pcbi.1004640.e022g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e022" xlink:type="simple"/><mml:math display="inline" id="M22"><mml:msubsup><mml:mi mathvariant="bold">W</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mrow><mml:mi>E</mml:mi> <mml:mi>I</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> is the connection from the <italic>j</italic><sup>th</sup> inhibitory neuron to the <italic>i</italic><sup>th</sup> excitatory neuron. We model the excitatory to excitatory connections as a sparse matrix with a directed connection probability of <italic>p</italic><sup><italic>EE</italic></sup> = 0.1 and no excitatory autapses <inline-formula id="pcbi.1004640.e023"><alternatives><graphic id="pcbi.1004640.e023g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e023" xlink:type="simple"/><mml:math display="inline" id="M23"><mml:msubsup><mml:mi mathvariant="bold">W</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>i</mml:mi></mml:mrow> <mml:mrow><mml:mi>E</mml:mi> <mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>. <bold>W</bold><sup><italic>EI</italic></sup> as well as <bold>W</bold><sup><italic>IE</italic></sup> are dense connection matrices. We do not model connections within the inhibitory population. All weights are randomly drawn from the interval [0,1] and then normalized by the synaptic normalization described below.</p>
<p>The input to the network is modelled as a series of binary vectors <bold>u</bold>(<italic>t</italic>) where at each time step <italic>t</italic> during input presentation all units are zero except for one. For better readability we assign an arbitrary letter to each such state when describing different input sequences later on. The letter “_” corresponds to presenting no input. Each input unit <italic>u</italic><sub><italic>i</italic></sub> projects to <italic>N</italic><sup><italic>U</italic></sup> = 10 excitatory neurons with the constant weight <italic>w</italic><sup><italic>in</italic></sup> = 0.5. These randomly selected and possibly overlapping projections are represented by the input weight matrix <bold>W</bold><sup><italic>EU</italic></sup>.</p>
<p>At each discrete time step <italic>t</italic>, these variables contribute to the binary excitatory state <bold>x</bold>(<italic>t</italic>) ∈ {0, 1}<sup><italic>N</italic><sup><italic>E</italic></sup></sup> and inhibitory state <bold>y</bold>(<italic>t</italic>) ∈ {0, 1}<sup><italic>N</italic><sup><italic>I</italic></sup></sup> as follows:</p>
<disp-formula id="pcbi.1004640.e024">
<alternatives>
<graphic id="pcbi.1004640.e024g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e024" xlink:type="simple"/>
<mml:math display="block" id="M24">
<mml:mstyle mathsize="normal" mathvariant="bold">
<mml:mi>x</mml:mi>
</mml:mstyle>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>t</mml:mi>
<mml:mo>+</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:mo>Θ</mml:mo>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:msup>
<mml:mstyle mathsize="normal" mathvariant="bold">
<mml:mi>W</mml:mi>
</mml:mstyle>
<mml:mrow>
<mml:mi>E</mml:mi>
<mml:mi>E</mml:mi>
</mml:mrow>
</mml:msup>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>t</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mstyle mathsize="normal" mathvariant="bold">
<mml:mi>x</mml:mi>
</mml:mstyle>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>t</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>−</mml:mo>
<mml:msup>
<mml:mstyle mathsize="normal" mathvariant="bold">
<mml:mi>W</mml:mi>
</mml:mstyle>
<mml:mrow>
<mml:mi>E</mml:mi>
<mml:mi>I</mml:mi>
</mml:mrow>
</mml:msup>
<mml:mstyle mathsize="normal" mathvariant="bold">
<mml:mi>y</mml:mi>
</mml:mstyle>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>t</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>+</mml:mo>
<mml:msup>
<mml:mstyle mathsize="normal" mathvariant="bold">
<mml:mi>W</mml:mi>
</mml:mstyle>
<mml:mrow>
<mml:mi>E</mml:mi>
<mml:mi>U</mml:mi>
</mml:mrow>
</mml:msup>
<mml:mstyle mathsize="normal" mathvariant="bold">
<mml:mi>u</mml:mi>
</mml:mstyle>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>t</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>−</mml:mo>
<mml:msup>
<mml:mstyle mathsize="normal" mathvariant="bold">
<mml:mi>T</mml:mi>
</mml:mstyle>
<mml:mi>E</mml:mi>
</mml:msup>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>t</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:math>
</alternatives>
<label>(13)</label>
</disp-formula>
<disp-formula id="pcbi.1004640.e025">
<alternatives>
<graphic id="pcbi.1004640.e025g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e025" xlink:type="simple"/>
<mml:math display="block" id="M25">
<mml:mstyle mathsize="normal" mathvariant="bold">
<mml:mi>y</mml:mi>
</mml:mstyle>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>t</mml:mi>
<mml:mo>+</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:mo>Θ</mml:mo>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:msup>
<mml:mstyle mathsize="normal" mathvariant="bold">
<mml:mi>W</mml:mi>
</mml:mstyle>
<mml:mrow>
<mml:mi>I</mml:mi>
<mml:mi>E</mml:mi>
</mml:mrow>
</mml:msup>
<mml:mstyle mathsize="normal" mathvariant="bold">
<mml:mi>x</mml:mi>
</mml:mstyle>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>t</mml:mi>
<mml:mo>+</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>+</mml:mo>
<mml:msup>
<mml:mstyle mathsize="normal" mathvariant="bold">
<mml:mi>W</mml:mi>
</mml:mstyle>
<mml:mrow>
<mml:mi>I</mml:mi>
<mml:mi>U</mml:mi>
</mml:mrow>
</mml:msup>
<mml:mstyle mathsize="normal" mathvariant="bold">
<mml:mi>u</mml:mi>
</mml:mstyle>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>t</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>−</mml:mo>
<mml:msup>
<mml:mstyle mathsize="normal" mathvariant="bold">
<mml:mi>T</mml:mi>
</mml:mstyle>
<mml:mi>I</mml:mi>
</mml:msup>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>.</mml:mo>
</mml:math>
</alternatives>
<label>(14)</label>
</disp-formula>
<p>Here, Θ(<bold>a</bold>) is the element-wise heaviside step function, which maps activations <bold>a</bold> to binary spikes if the activation is positive. <bold>T</bold><sup><italic>E</italic></sup>(<italic>t</italic>) and <bold>T</bold><sup><italic>I</italic></sup> are the thresholds of all neurons and are crucial in regulating the spiking. They are evenly spaced in the interval (0, 0.5) for the excitatory thresholds and <inline-formula id="pcbi.1004640.e026"><alternatives><graphic id="pcbi.1004640.e026g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e026" xlink:type="simple"/><mml:math display="inline" id="M26"><mml:mrow><mml:mo>(</mml:mo> <mml:mn>0</mml:mn> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>T</mml:mi> <mml:mrow><mml:mi>m</mml:mi> <mml:mi>a</mml:mi> <mml:mi>x</mml:mi></mml:mrow> <mml:mi>i</mml:mi></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> for the inhibitory ones.</p>
<p>
<inline-formula id="pcbi.1004640.e027">
<alternatives>
<graphic id="pcbi.1004640.e027g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e027" xlink:type="simple"/>
<mml:math display="inline" id="M27">
<mml:msubsup>
<mml:mi>T</mml:mi>
<mml:mrow>
<mml:mi>m</mml:mi>
<mml:mi>a</mml:mi>
<mml:mi>x</mml:mi>
</mml:mrow>
<mml:mi>i</mml:mi>
</mml:msubsup>
</mml:math>
</alternatives>
</inline-formula> directly influences the amount of inhibition. <inline-formula id="pcbi.1004640.e028"><alternatives><graphic id="pcbi.1004640.e028g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e028" xlink:type="simple"/><mml:math display="inline" id="M28"><mml:msubsup><mml:mi>T</mml:mi> <mml:mrow><mml:mi>m</mml:mi> <mml:mi>a</mml:mi> <mml:mi>x</mml:mi></mml:mrow> <mml:mi>i</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> presents a trade-off between fine-grained inhibition and a broad dynamic range: for a low <inline-formula id="pcbi.1004640.e029"><alternatives><graphic id="pcbi.1004640.e029g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e029" xlink:type="simple"/><mml:math display="inline" id="M29"><mml:msubsup><mml:mi>T</mml:mi> <mml:mrow><mml:mi>m</mml:mi> <mml:mi>a</mml:mi> <mml:mi>x</mml:mi></mml:mrow> <mml:mi>i</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>, the additional excitation needed to activate one more inhibitory neuron is small, leading to a more fine-grained response to excitatory fluctuations, which is in general favourable because it helps to avoid pathological behaviour. However, a low <inline-formula id="pcbi.1004640.e030"><alternatives><graphic id="pcbi.1004640.e030g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e030" xlink:type="simple"/><mml:math display="inline" id="M30"><mml:msubsup><mml:mi>T</mml:mi> <mml:mrow><mml:mi>m</mml:mi> <mml:mi>a</mml:mi> <mml:mi>x</mml:mi></mml:mrow> <mml:mi>i</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> sets a low bound on the maximal amount of inhibition: it is easier to activate all inhibitory neurons and thereby saturate the possible inhibitory response. Therefore, in cases with high fluctuations in excitation, such as trial-like settings with a high rate increase at stimulus onset, a high <inline-formula id="pcbi.1004640.e031"><alternatives><graphic id="pcbi.1004640.e031g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e031" xlink:type="simple"/><mml:math display="inline" id="M31"><mml:msubsup><mml:mi>T</mml:mi> <mml:mrow><mml:mi>m</mml:mi> <mml:mi>a</mml:mi> <mml:mi>x</mml:mi></mml:mrow> <mml:mi>i</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> is necessary. Please note that the average amount of inhibition will have no effect on the average amount of excitation since the average excitatory activity in the network is regulated by the intrinsic plasticity. <inline-formula id="pcbi.1004640.e032"><alternatives><graphic id="pcbi.1004640.e032g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e032" xlink:type="simple"/><mml:math display="inline" id="M32"><mml:msubsup><mml:mi>T</mml:mi> <mml:mrow><mml:mi>m</mml:mi> <mml:mi>a</mml:mi> <mml:mi>x</mml:mi></mml:mrow> <mml:mi>i</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> is set to <inline-formula id="pcbi.1004640.e033"><alternatives><graphic id="pcbi.1004640.e033g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e033" xlink:type="simple"/><mml:math display="inline" id="M33"><mml:mrow><mml:msubsup><mml:mi>T</mml:mi> <mml:mrow><mml:mi>m</mml:mi> <mml:mi>a</mml:mi> <mml:mi>x</mml:mi></mml:mrow> <mml:mi>i</mml:mi></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>35</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> for the first tasks and to <inline-formula id="pcbi.1004640.e034"><alternatives><graphic id="pcbi.1004640.e034g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e034" xlink:type="simple"/><mml:math display="inline" id="M34"><mml:mrow><mml:msubsup><mml:mi>T</mml:mi> <mml:mrow><mml:mi>m</mml:mi> <mml:mi>a</mml:mi> <mml:mi>x</mml:mi></mml:mrow> <mml:mi>i</mml:mi></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> for the inference task with its trial structure. If <inline-formula id="pcbi.1004640.e035"><alternatives><graphic id="pcbi.1004640.e035g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e035" xlink:type="simple"/><mml:math display="inline" id="M35"><mml:msubsup><mml:mi>T</mml:mi> <mml:mrow><mml:mi>m</mml:mi> <mml:mi>a</mml:mi> <mml:mi>x</mml:mi></mml:mrow> <mml:mi>i</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> is set to 1, excitation and inhibition are balanced: For a given fraction of excitatory activity <inline-formula id="pcbi.1004640.e036"><alternatives><graphic id="pcbi.1004640.e036g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e036" xlink:type="simple"/><mml:math display="inline" id="M36"><mml:mrow><mml:mover><mml:mi>x</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:msup><mml:mi>N</mml:mi> <mml:mi>E</mml:mi></mml:msup></mml:mfrac> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn></mml:mrow> <mml:msup><mml:mi>N</mml:mi> <mml:mi>E</mml:mi></mml:msup></mml:munderover> <mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, each inhibitory neuron receives on average <inline-formula id="pcbi.1004640.e037"><alternatives><graphic id="pcbi.1004640.e037g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e037" xlink:type="simple"/><mml:math display="inline" id="M37"><mml:mrow><mml:mn>1</mml:mn> <mml:mo>×</mml:mo> <mml:mover><mml:mi>x</mml:mi> <mml:mo>¯</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula> excitatory input because synaptic normalization ensures that the summed excitatory incoming weight is 1. This in turn activates the fraction <inline-formula id="pcbi.1004640.e038"><alternatives><graphic id="pcbi.1004640.e038g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e038" xlink:type="simple"/><mml:math display="inline" id="M38"><mml:mrow><mml:mover><mml:mi>y</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:msup><mml:mi>N</mml:mi> <mml:mi>I</mml:mi></mml:msup></mml:mfrac> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn></mml:mrow> <mml:msup><mml:mi>N</mml:mi> <mml:mi>I</mml:mi></mml:msup></mml:munderover> <mml:msub><mml:mi>y</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≈</mml:mo> <mml:mn>1</mml:mn> <mml:mo>×</mml:mo> <mml:mover><mml:mi>x</mml:mi> <mml:mo>¯</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula> of inhibitory neurons, because the thresholds of the inhibitory units are uniformly distributed in the interval (0, 1) by assumption. It is important to note that at no point any noise is added to the network. The only external variability is the random alternation of input words, as described in the Results.</p>
<p>The excitatory thresholds as well as <bold>W</bold><sup><italic>EE</italic></sup>(<italic>t</italic>) are adapted over time by three plasticity mechanisms. The state <bold>x</bold>(0) is randomly initialized with probabilities <bold>T</bold><sup><italic>E</italic></sup>(0) and <bold>y</bold>(0) is initially set to 0.</p>
</sec>
<sec id="sec023">
<title>Plasticity mechanisms</title>
<p>The network employs three different kinds of plasticity: Spike-timing dependent plasticity (STDP) [<xref ref-type="bibr" rid="pcbi.1004640.ref069">69</xref>–<xref ref-type="bibr" rid="pcbi.1004640.ref071">71</xref>] extracts structure from the input by shaping the weights within the excitatory population. This is counterbalanced by two forms of homeostatic plasticity: intrinsic plasticity (IP) [<xref ref-type="bibr" rid="pcbi.1004640.ref072">72</xref>, <xref ref-type="bibr" rid="pcbi.1004640.ref073">73</xref>] and synaptic normalization (SN) [<xref ref-type="bibr" rid="pcbi.1004640.ref032">32</xref>, <xref ref-type="bibr" rid="pcbi.1004640.ref033">33</xref>, <xref ref-type="bibr" rid="pcbi.1004640.ref074">74</xref>]. All these mechanisms are known to co-occur in the hippocampus and neocortex.</p>
<p>STDP strengthens the connection <inline-formula id="pcbi.1004640.e039"><alternatives><graphic id="pcbi.1004640.e039g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e039" xlink:type="simple"/><mml:math display="inline" id="M39"><mml:msubsup><mml:mi>W</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mrow><mml:mi>E</mml:mi> <mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> from unit <italic>j</italic> to unit <italic>i</italic> whenever a spike in <italic>i</italic> directly follows a spike in <italic>j</italic> (i.e. <italic>j</italic> helped to trigger <italic>i</italic>) and is weakened whenever a spike in <italic>i</italic> precedes a spike in <italic>j</italic>. This results in the following update equation (with <italic>η</italic><sub>STDP</sub> = 0.001):</p>
<disp-formula id="pcbi.1004640.e040">
<alternatives>
<graphic id="pcbi.1004640.e040g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e040" xlink:type="simple"/>
<mml:math display="block" id="M40">
<mml:mtable displaystyle="true">
<mml:mtr>
<mml:mtd columnalign="right">
<mml:mrow>
<mml:mo>Δ</mml:mo>
<mml:msup>
<mml:mi mathvariant="bold">W</mml:mi>
<mml:mrow>
<mml:mi>E</mml:mi>
<mml:mi>E</mml:mi>
</mml:mrow>
</mml:msup>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>t</mml:mi>
<mml:mo>+</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mi>η</mml:mi>
<mml:mtext>STDP</mml:mtext>
</mml:msub>
<mml:mfenced close=")" open="(" separators="">
<mml:mi mathvariant="bold">x</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>t</mml:mi>
<mml:mo>+</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mi mathvariant="bold">x</mml:mi>
<mml:msup>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>t</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mi>T</mml:mi>
</mml:msup>
<mml:mo>-</mml:mo>
<mml:mi mathvariant="bold">x</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>t</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mi mathvariant="bold">x</mml:mi>
<mml:msup>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>t</mml:mi>
<mml:mo>+</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mi>T</mml:mi>
</mml:msup>
</mml:mfenced>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:math>
</alternatives>
<label>(15)</label>
</disp-formula>
<p>The authors of [<xref ref-type="bibr" rid="pcbi.1004640.ref033">33</xref>] showed in an electron microscopy study that the summed synaptic area per <italic>μm</italic> of dendrite is similar before and after long-term potentiation while the synaptic area per synapse increases and the number of synapses per <italic>μm</italic> decreases. This indicates that plasticity redistributes weights to avoid uncontrolled growth. This is modelled by normalizing all incoming connections of a neuron to 1—a process called synaptic normalization (SN). In addition to this postsynaptic normalization, there is also evidence for presynaptic normalization or “conservation of axonal arbor”[<xref ref-type="bibr" rid="pcbi.1004640.ref054">54</xref>, <xref ref-type="bibr" rid="pcbi.1004640.ref055">55</xref>]. These studies suggest that all outgoing connections are redistributed to achieve a constant total weight. This is modelled by normalizing all outgoing connections of a neuron to 1. Together, these mechanisms result in the following iterative weight update:</p>
<disp-formula id="pcbi.1004640.e041">
<alternatives>
<graphic id="pcbi.1004640.e041g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e041" xlink:type="simple"/>
<mml:math display="block" id="M41">
<mml:mtable displaystyle="true">
<mml:mtr>
<mml:mtd columnalign="right">
<mml:mrow>
<mml:msubsup>
<mml:mi>W</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mi>j</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>E</mml:mi>
<mml:mi>E</mml:mi>
</mml:mrow>
</mml:msubsup>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>t</mml:mi>
<mml:mo>+</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>←</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>9</mml:mn>
<mml:mo>×</mml:mo>
<mml:msubsup>
<mml:mi>W</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mi>j</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>E</mml:mi>
<mml:mi>E</mml:mi>
</mml:mrow>
</mml:msubsup>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>t</mml:mi>
<mml:mo>+</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>+</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>×</mml:mo>
<mml:mfrac>
<mml:msubsup>
<mml:mi>W</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mi>j</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>E</mml:mi>
<mml:mi>E</mml:mi>
</mml:mrow>
</mml:msubsup>
<mml:mrow>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>5</mml:mn>
<mml:mo>×</mml:mo>
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>k</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
</mml:mrow>
<mml:msup>
<mml:mi>N</mml:mi>
<mml:mi>E</mml:mi>
</mml:msup>
</mml:munderover>
<mml:msubsup>
<mml:mi>W</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mi>k</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>E</mml:mi>
<mml:mi>E</mml:mi>
</mml:mrow>
</mml:msubsup>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>t</mml:mi>
<mml:mo>+</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>+</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>5</mml:mn>
<mml:mo>×</mml:mo>
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>k</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
</mml:mrow>
<mml:msup>
<mml:mi>N</mml:mi>
<mml:mi>E</mml:mi>
</mml:msup>
</mml:munderover>
<mml:msubsup>
<mml:mi>W</mml:mi>
<mml:mrow>
<mml:mi>k</mml:mi>
<mml:mi>j</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>E</mml:mi>
<mml:mi>E</mml:mi>
</mml:mrow>
</mml:msubsup>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>t</mml:mi>
<mml:mo>+</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:mfrac>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:math>
</alternatives>
<label>(16)</label>
</disp-formula>
<p>At the same time, there are a variety of regulatory mechanisms that control neural firing at different time scales such as absolute and relative refractory periods, spike rate adaptation and intrinsic plasticity [<xref ref-type="bibr" rid="pcbi.1004640.ref032">32</xref>, <xref ref-type="bibr" rid="pcbi.1004640.ref073">73</xref>]. Here, we abstract from those by using a simple homeostatic regulation of the spike threshold at a single time scale (<italic>η</italic><sub>IP</sub> = 0.001). This intrinsic plasticity (IP) rule regulates the individual thresholds so that on average, the excitatory neurons will fire according to their target rates <bold>H</bold><sub>IP</sub>:</p>
<disp-formula id="pcbi.1004640.e042">
<alternatives>
<graphic id="pcbi.1004640.e042g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e042" xlink:type="simple"/>
<mml:math display="block" id="M42">
<mml:mtable displaystyle="true">
<mml:mtr>
<mml:mtd columnalign="right">
<mml:mrow>
<mml:msup>
<mml:mi mathvariant="bold">T</mml:mi>
<mml:mi>E</mml:mi>
</mml:msup>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>t</mml:mi>
<mml:mo>+</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:msup>
<mml:mi mathvariant="bold">T</mml:mi>
<mml:mi>E</mml:mi>
</mml:msup>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>t</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mi>η</mml:mi>
<mml:mtext>IP</mml:mtext>
</mml:msub>
<mml:mfenced close=")" open="(" separators="">
<mml:mi mathvariant="bold">x</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>t</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>-</mml:mo>
<mml:msub>
<mml:mi mathvariant="bold">H</mml:mi>
<mml:mtext>IP</mml:mtext>
</mml:msub>
</mml:mfenced>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:math>
</alternatives>
<label>(17)</label>
</disp-formula>
<p>The target rates are uniformly drawn from the interval (<italic>H</italic><sub>IP</sub> − <italic>ϵ</italic><sub>IP</sub>, <italic>H</italic><sub>IP</sub> + <italic>ϵ</italic><sub>IP</sub>) = (0.1 − 0.01, 0.1 + 0.01). The resulting diversity in firing rates helps to prevent pathological network activity.</p>
<p>The inhibitory connections are scaled during the initialization phase so that the sum of excitatory weights received by each inhibitory unit and the sum of inhibitory weights received by each excitatory unit is 1.</p>
<p>The STDP and IP rules are only operating on the excitatory neurons for two reasons. First, by restricting plasticity to only the excitatory population, the model becomes simpler and thereby easier to understand and interpret. Second, there are fewer data on plasticity in inhibitory neurons (but see [<xref ref-type="bibr" rid="pcbi.1004640.ref039">39</xref>]).</p>
</sec>
<sec id="sec024">
<title>Stimulation paradigm</title>
<p>The stimulation paradigm is very similar across all tasks and can be divided into three phases:</p>
<p>In the <italic>self-organization phase</italic>, the network is stimulated with input patterns or sequences for <italic>T</italic><sub><italic>plastic</italic></sub> = 50000 steps. During this time, all plasticity mechanisms are active and the network can self-organize in the presence of the given input. We represent the input vectors by letters. For example, the stimulation paradigm can then be a random alternation of the words “ABCD” and “EFGH”. After this, STDP is switched off so that the properties of the learnt connections can be studied without interference from continued changes to the weights. This is done during a training and testing phase.</p>
<p>In the <italic>training phase</italic>, the stimuli are kept identical to observe the properties of the network under the self-organization conditions and training appropriate readouts for <italic>T</italic><sub>train</sub> = 20000 steps. For the model of the sequence prediction of [<xref ref-type="bibr" rid="pcbi.1004640.ref031">31</xref>], we do not show stimuli in this phase corresponding to the “sleep”.</p>
<p>Then, during the <italic>testing phase</italic>, we either observe the spontaneous activity while the network is not stimulated, or we test our readout on data generated by stimulating the network with appropriate stimuli for <italic>T</italic><sub>test</sub> = 50000 steps.</p>
<p>For these phases, the intrinsic plasticity is still active to ensure stable average activity. After each phase, the activity state is shuffled in accordance with [<xref ref-type="bibr" rid="pcbi.1004640.ref075">75</xref>]. To simulate the trial-like structure of the inference task, we chose to have blank periods between each stimulus presentation. The length of these periods was drawn from a uniform distribution over the interval [<xref ref-type="bibr" rid="pcbi.1004640.ref010">10</xref>, <xref ref-type="bibr" rid="pcbi.1004640.ref015">15</xref>] time steps. For the model of the sequence learning study (<xref ref-type="fig" rid="pcbi.1004640.g002">Fig 2</xref>), we used a fixed delay of 10 time steps because the experiment only had fixed inter-trial delays [<xref ref-type="bibr" rid="pcbi.1004640.ref031">31</xref>].</p>
</sec>
</sec>
<sec id="sec025">
<title>Analysis methods</title>
<p>In this study, we compare the behaviour of our model to a variety of experimentally reported results. While our network is operating on a timescale of roughly 25ms (the width of a typical STDP-window) and on the spiking level with rates around 4Hz, the experimental data are fMRI-BOLD signals, optical imaging data and multi-unit activity spike trains and have effects on time scales that range between milliseconds and seconds. Comparing these partly very different data can therefore sometimes be only done on an abstract and qualitative level. In the following section, we outline how each comparison was performed.</p>
<sec id="sec026">
<title>Principal component analysis and multidimensional scaling</title>
<p>For the principal component analysis (PCA) of the spontaneous and evoked states, we did a PCA of the last 2500 steps of the training phase. We then projected these states in the subspace defined by the first three components of the PCA and also projected the same amount of spontaneous activity states in the same subspace. The spontaneous states were taken from the end of the testing phase to avoid artifacts due to the re-adaptation of the thresholds after cutting the input.</p>
<p>Multidimensional scaling (MDS) was performed as closely as possible to the method used in [<xref ref-type="bibr" rid="pcbi.1004640.ref013">13</xref>]. As in that paper, we used 150 points of spontaneous, shuffled spontaneous and evoked samples. Further following the paper, we shuffled the spontaneous activity of each neuron individually over time so that neurons kept their rate but lost their timing. The samples were chosen randomly from the end of the training and testing phase. We did not subsample our neurons to the 45 that they recorded from because the distances between individual activity patterns become too similar in that case. This did not happen for their study because they used rates instead of spikes. To account for the fact that [<xref ref-type="bibr" rid="pcbi.1004640.ref013">13</xref>] only showed a subset of all the stimuli that the network was exposed to during its development we also only used a randomly chosen subset (5 letters) of the stimuli that we presented in the self-organization phase. We used the same Matlab function for MDS as the one used in the original paper (with Kruskal’s normalized stress1 criterion).</p>
</sec>
<sec id="sec027">
<title>KL-divergence of spontaneous and evoked activity</title>
<p>To replicate the results of [<xref ref-type="bibr" rid="pcbi.1004640.ref016">16</xref>], we recorded spontaneous and evoked activity for the same number of time steps (750.000) and randomly subsampled 16 units from our network. Please note that due to an exponential increase in possible patterns with the number of units, more units would have soon become infeasible to analyse with conventional methods. We also excluded the first 5000 steps of each phase to account for adaptation after changes in the stimulation paradigm. To compute the KL-divergence we first have to estimate the probabilitiy <italic>p</italic>(<italic>x</italic>) for each pattern <italic>x</italic> from the set of the 2<sup>16</sup> possible patterns <italic>X</italic>. In order to do so, we created a bin for each pattern and simply counted the occurrence of each pattern. Additionally, we started with a non-informative prior by assuming that each pattern <italic>x</italic> ∈ <italic>X</italic> was already observed once. This initial prior is necessary since KL-divergence is only defined for non-zero probabilities. After normalizing, we then computed the KL-divergence between evoked and spontaneous activity according to
<disp-formula id="pcbi.1004640.e043"><alternatives><graphic id="pcbi.1004640.e043g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e043" xlink:type="simple"/><mml:math display="block" id="M43"><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mtext>evoked</mml:mtext><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mtext>spont</mml:mtext><mml:mo stretchy="false">)</mml:mo><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mtext> KL</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>P</mml:mi><mml:mrow><mml:mtext>evoked</mml:mtext></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>P</mml:mi><mml:mrow><mml:mtext>spont</mml:mtext></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:math></alternatives> <label>(18)</label></disp-formula> <disp-formula id="pcbi.1004640.e044"><alternatives><graphic id="pcbi.1004640.e044g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e044" xlink:type="simple"/><mml:math display="block" id="M44"><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:mi>X</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msup><mml:mi>P</mml:mi><mml:mrow><mml:mtext>evoked</mml:mtext></mml:mrow></mml:msup></mml:mrow></mml:mstyle><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>×</mml:mo><mml:mtext>log</mml:mtext><mml:mfrac><mml:mrow><mml:msup><mml:mi>P</mml:mi><mml:mrow><mml:mtext>evoked</mml:mtext></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msup><mml:mi>P</mml:mi><mml:mrow><mml:mtext>spont</mml:mtext></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:math></alternatives> <label>(19)</label></disp-formula></p>
</sec>
<sec id="sec028">
<title>Pattern analysis</title>
<p>Evoked and spontaneous activity patterns may rarely be exactly equal. In order to relate spontaneous activity patterns to evoked activity patterns, we use the following method. We assigned to each spontaneous state the letter corresponding to the best-matching evoked activity state. If, for example, <bold>x</bold>(<italic>t</italic>) had the smallest Hamming distance to an evoked state when the letter “A” was shown, then <bold>x</bold>(<italic>t</italic>) was labelled as corresponding to input letter “A”. To avoid biases, the collection of evoked and spontaneous states used for the comparison was always obtained from the end of the training and testing phase (the last 2500 steps). The data was further reduced by ignoring blank periods and ensuring that each letter was represented equally often in the data set.</p>
</sec>
<sec id="sec029">
<title>Inference analysis</title>
<p>To quantify the network’s behaviour in the inference task, we trained output units based on the randomly alternating presentation of the stimuli “AXXX_ _ _ …” and “BXXX_ _ _ …”, where “A”, “B”, and “X” each refer to a subpopulation of excitatory neurons that are stimulated whenever the letter is presented. At the presentation of “_”, no neurons receive external inputs. These stimuli model a decision task where subjects were presented with the ambiguous face-vase stimulus and had to decide whether they perceived a face or a vase after a mask [<xref ref-type="bibr" rid="pcbi.1004640.ref020">20</xref>]. “A” and “B” represent the face or vase, the following “X”s are identical for both stimuli and thereby act as a mask and delay.</p>
<p>To read out the model decisions after the mask, we trained a linear readout in a supervised way with least-squares regression. We performed two regressions from all neurons at the step when “_” is presented to predict either “A” or “B” (based on the recurrently maintained information of “A” or “B” that should still be present in the network). In the test phase, when ambiguous mixtures of “A” and “B” are presented, the network decision is set to “A” when the readout for “A” is larger than for “B” and the other way round. The regression target was set to 0 for all other letters from the training data, since these should not correspond to a “sampling” of “A” or “B”. The regression was performed on 20000 steps of evoked activity while STDP is turned off. To avoid any biases, we took equal amounts of activity samples for each letter from the end of training.</p>
<p>In the test-phase, the ambiguous face-vase stimulus is modelled by stimulating the network with a mix of “A” and “B”. This is done by using <inline-formula id="pcbi.1004640.e045"><alternatives><graphic id="pcbi.1004640.e045g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e045" xlink:type="simple"/><mml:math display="inline" id="M45"><mml:mrow><mml:msub><mml:mi>f</mml:mi> <mml:mi mathvariant="normal">A</mml:mi></mml:msub> <mml:mo>×</mml:mo> <mml:msubsup><mml:mi>N</mml:mi> <mml:mi>E</mml:mi> <mml:mi>U</mml:mi></mml:msubsup> <mml:mo>=</mml:mo> <mml:msub><mml:mi>f</mml:mi> <mml:mi mathvariant="normal">A</mml:mi></mml:msub> <mml:mo>×</mml:mo> <mml:mn>10</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> input units of “A” and <inline-formula id="pcbi.1004640.e046"><alternatives><graphic id="pcbi.1004640.e046g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e046" xlink:type="simple"/><mml:math display="inline" id="M46"><mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>f</mml:mi> <mml:mi mathvariant="normal">A</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>×</mml:mo> <mml:msubsup><mml:mi>N</mml:mi> <mml:mi>E</mml:mi> <mml:mi>U</mml:mi></mml:msubsup> <mml:mo>=</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>f</mml:mi> <mml:mi mathvariant="normal">A</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>×</mml:mo> <mml:mn>10</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> input units of “B”. Here, we assume that stimulus ambiguity can be modelled by the fraction of activated “A” units, <italic>f</italic><sub>A</sub>. The specific units selected for the ambiguous stimulus are redrawn at every stimulus presentation. To have well-defined ambiguities, we ensure for this task that the input populations of “A” and “B” do not overlap. As in the original study, the delay between stimuli is random. We model this by randomly adding between 0 and 5 delay steps to the fixed delay of 10 steps during testing (see stimulation paradigm for details).</p>
</sec>
<sec id="sec030">
<title>Probabilistic model</title>
<p>A detailed inspection of the input populations for the inputs “A” and “B” reveals the root of the stochastic behaviour of SORN: One input neuron, say the first neuron of the population <italic>P</italic><sub>A</sub> representing input “A”, may be stimulated, i.e. its input set to <italic>w</italic><sup><italic>in</italic></sup> = 0.5, but still that very neuron does not fire in this time step due to a stronger inhibition it receives via the recurrent connections and/or a higher activation threshold due to previous activity. Obviously, the information that the neuron was stimulated by the input in this time step is lost. On the other side the neuron might get active due to the excitatory recurrent input from the network and/or a drop of its threshold due to long inactivity, no matter if there is an external stimulation or not. Also in this case the stimulus had no changing effect on the evolution of the future states of the network and thus that information is lost. In a little more complex but similar way we can reason about the propagation of the effect of this one input stimulus through the network over time until the delayed readout tries to identify if population <italic>P</italic><sub>A</sub> or population <italic>P</italic><sub>B</sub> was stimulated. From an information theoretic viewpoint we can formalize this uncertainty as a noisy binary channel, which is fully characterized by two parameters <italic>θ</italic><sub>0|0</sub> and <italic>θ</italic><sub>1|1</sub>, or shorter <italic>θ</italic><sub>0</sub>, <italic>θ</italic><sub>1</sub>, denoting the probability that a non-stimulus (0) and a stimulus (1) is received correctly. The probabilities of a wrong transmission are implicitly defined as well, since <italic>θ</italic><sub>1|0</sub> = 1 − <italic>θ</italic><sub>0</sub> and <italic>θ</italic><sub>0|1</sub> = 1 − <italic>θ</italic><sub>1</sub>.</p>
<p>Based on this channel perspective we can define a simple Naive Bayesian classifier that receives those noisy inputs for population <italic>P</italic><sub>A</sub> and <italic>P</italic><sub>B</sub>, denoted by <bold>a</bold> = {<italic>a</italic><sub>1</sub>, …, <italic>a</italic><sub>10</sub>} and <bold>b</bold> = {<italic>b</italic><sub>1</sub>, …, <italic>b</italic><sub>10</sub>}, during both the learning and the testing phase, assuming <italic>N</italic><sup><italic>U</italic></sup> = 10 input units as defined in the SORN description above. It is straightforward to derive the parameters of such a Naive Bayes analytically, as there are only two training cases: When the sequence “AXXX___…” is presented in the learning phase, all neurons that belong to the population <italic>P</italic><sub>A</sub> receive an input stimulation, whereas all neurons of the <italic>P</italic><sub>B</sub> population do not receive any stimulus. Thus, according to our channel model all <italic>a</italic><sub><italic>i</italic></sub> have a probability of <italic>θ</italic><sub>1</sub> of being 1 and all <italic>b</italic><sub><italic>i</italic></sub> have a probability of 1 − <italic>θ</italic><sub>0</sub> of being 1, i.e. <italic>p</italic>(<italic>a</italic><sub><italic>i</italic></sub> = 1|A) = <italic>θ</italic><sub>1</sub> and <italic>p</italic>(<italic>b</italic><sub><italic>i</italic></sub> = 1|A) = 1 − <italic>θ</italic><sub>0</sub>. In the second case, when the “BXXX___…”-sequence is presented, the whole <italic>P</italic><sub>B</sub>-population is stimulated and the <italic>P</italic><sub>A</sub>-population is left alone, thus in our probabilistic model <italic>p</italic>(<italic>b</italic><sub><italic>i</italic></sub> = 1|B) = <italic>θ</italic><sub>1</sub> and <italic>p</italic>(<italic>a</italic><sub><italic>i</italic></sub> = 1|B) = 1 − <italic>θ</italic><sub>0</sub>. The prior <italic>p</italic>(A) just reflects how often the “AXXX___…”-sequence is presented to the model during learning as compared to the “BXXX___…”-sequence. The conditional probabilities together with the prior <italic>p</italic>(A) and <italic>p</italic>(B) = 1 − <italic>p</italic>(A) fully define the Naive Bayes model up to the two free parameters <italic>θ</italic><sub>1</sub> and <italic>θ</italic><sub>0</sub>. We will derive these parameters by fitting the probabilistic model to the experimentally derived results from the SORN network.</p>
<p>Given certain evidence vectors <bold>a</bold> and <bold>b</bold> we can derive the posterior probability of the Naive Bayes model according to Bayes’ rule as
<disp-formula id="pcbi.1004640.e047"><alternatives><graphic id="pcbi.1004640.e047g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e047" xlink:type="simple"/><mml:math display="block" id="M47"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>A</mml:mtext><mml:mo>|</mml:mo><mml:mi mathvariant="bold">a</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mtext>A</mml:mtext><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">a</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">b</mml:mi><mml:mo>|</mml:mo><mml:mtext>A</mml:mtext></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mtext>A</mml:mtext><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">a</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">b</mml:mi><mml:mo>|</mml:mo><mml:mtext>A</mml:mtext></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mtext>B</mml:mtext><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">a</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">b</mml:mi><mml:mo>|</mml:mo><mml:mtext>B</mml:mtext></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives> <label>(20)</label></disp-formula>
where the likelihood <italic>p</italic>(<bold>a</bold>,<bold>b</bold>|A) can be expressed explicitly in terms of the above defined parameters
<disp-formula id="pcbi.1004640.e048"><alternatives><graphic id="pcbi.1004640.e048g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e048" xlink:type="simple"/><mml:math display="block" id="M48"><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">a</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">b</mml:mi><mml:mo>|</mml:mo><mml:mtext>A</mml:mtext><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:munderover><mml:mi>p</mml:mi></mml:mstyle><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mtext>A</mml:mtext><mml:mo stretchy="false">)</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:munderover><mml:mi>p</mml:mi></mml:mstyle><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mtext>A</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:math></alternatives> <label>(21)</label></disp-formula> <disp-formula id="pcbi.1004640.e049"><alternatives><graphic id="pcbi.1004640.e049g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e049" xlink:type="simple"/><mml:math display="block" id="M49"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd/><mml:mtd><mml:mrow><mml:mo>=</mml:mo> <mml:msubsup><mml:mi>θ</mml:mi> <mml:mn>1</mml:mn> <mml:msub><mml:mi>n</mml:mi> <mml:mi>a</mml:mi></mml:msub></mml:msubsup> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>θ</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mn>10</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>n</mml:mi> <mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:msup> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>θ</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:msub><mml:mi>n</mml:mi> <mml:mi>b</mml:mi></mml:msub></mml:msup> <mml:msubsup><mml:mi>θ</mml:mi> <mml:mn>0</mml:mn> <mml:mrow><mml:mn>10</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>n</mml:mi> <mml:mi>b</mml:mi></mml:msub></mml:mrow></mml:msubsup> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(22)</label></disp-formula>
where <inline-formula id="pcbi.1004640.e050"><alternatives><graphic id="pcbi.1004640.e050g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e050" xlink:type="simple"/><mml:math display="inline" id="M50"><mml:mrow><mml:msub><mml:mi>n</mml:mi> <mml:mi>a</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msubsup><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mn>10</mml:mn></mml:msubsup> <mml:msub><mml:mi>a</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1004640.e051"><alternatives><graphic id="pcbi.1004640.e051g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e051" xlink:type="simple"/><mml:math display="inline" id="M51"><mml:mrow><mml:msub><mml:mi>n</mml:mi> <mml:mi>b</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msubsup><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mn>10</mml:mn></mml:msubsup> <mml:msub><mml:mi>b</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> are the sums of active evidences received from population <italic>P</italic><sub>A</sub> and <italic>P</italic><sub>B</sub>, respectively. Note that <bold>a</bold> and <bold>b</bold> and thus also <italic>n</italic><sub><italic>a</italic></sub> and <italic>n</italic><sub><italic>b</italic></sub> refer to the evidences as seen by the Naive Bayes classifier which result from the hypothetical noisy transmission channels of the external activations. The posterior in terms of <italic>n</italic><sub><italic>a</italic></sub> and <italic>n</italic><sub><italic>b</italic></sub> reads
<disp-formula id="pcbi.1004640.e052"><alternatives><graphic id="pcbi.1004640.e052g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e052" xlink:type="simple"/><mml:math display="block" id="M52"><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mtext>A</mml:mtext><mml:mo>|</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi>b</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mtext>A</mml:mtext><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mi>θ</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:msubsup><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mn>10</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>b</mml:mi></mml:msub></mml:mrow></mml:msup><mml:msubsup><mml:mi>θ</mml:mi><mml:mn>0</mml:mn><mml:mrow><mml:mn>10</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi>b</mml:mi></mml:msub></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mtext>A</mml:mtext><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mi>θ</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:msubsup><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mn>10</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>b</mml:mi></mml:msub></mml:mrow></mml:msup><mml:msubsup><mml:mi>θ</mml:mi><mml:mn>0</mml:mn><mml:mrow><mml:mn>10</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi>b</mml:mi></mml:msub></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mtext>B</mml:mtext><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:msup><mml:msubsup><mml:mi>θ</mml:mi><mml:mn>0</mml:mn><mml:mrow><mml:mn>10</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>θ</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>b</mml:mi></mml:msub></mml:mrow></mml:msubsup><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mn>10</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi>b</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:math></alternatives> <label>(23)</label></disp-formula></p>
<p>Note that the binomial factors that would appear in <italic>p</italic>(<italic>n</italic><sub><italic>a</italic></sub>, <italic>n</italic><sub><italic>b</italic></sub>|A) are reduced in the above fraction. In order to evaluate the whole probabilistic model we also have to evaluate the noisy channels. In our experiments we always stimulate a certain (random) fraction <italic>f</italic><sub>A</sub> of neurons of population <italic>P</italic><sub>A</sub> and a (random) fraction of (1 − <italic>f</italic><sub>A</sub>) neurons of population <italic>P</italic><sub>B</sub>. The resulting evidence vectors <bold>a</bold> and <bold>b</bold> are characterized by the respective distributions of <italic>n</italic><sub><italic>a</italic></sub> and <italic>n</italic><sub><italic>b</italic></sub>:
<disp-formula id="pcbi.1004640.e053"><alternatives><graphic id="pcbi.1004640.e053g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e053" xlink:type="simple"/><mml:math display="block" id="M53"><mml:msub><mml:mi>n</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>~</mml:mo><mml:mi>B</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>10</mml:mn><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:msub><mml:mrow/><mml:mtext>A</mml:mtext></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>B</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>10</mml:mn><mml:mo>−</mml:mo><mml:mn>10</mml:mn><mml:msub><mml:mi>f</mml:mi><mml:mtext>A</mml:mtext></mml:msub><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:math></alternatives> <label>(24)</label></disp-formula> <disp-formula id="pcbi.1004640.e054"><alternatives><graphic id="pcbi.1004640.e054g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e054" xlink:type="simple"/><mml:math display="block" id="M54"><mml:msub><mml:mi>n</mml:mi><mml:mi>b</mml:mi></mml:msub><mml:mtext> </mml:mtext><mml:mo>~</mml:mo><mml:mtext> </mml:mtext><mml:mi>B</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>10</mml:mn><mml:mo>−</mml:mo><mml:mn>10</mml:mn><mml:msub><mml:mi>f</mml:mi><mml:mtext>A</mml:mtext></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>B</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>10</mml:mn><mml:msub><mml:mi>f</mml:mi><mml:mtext>A</mml:mtext></mml:msub><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:math></alternatives> <label>(25)</label></disp-formula>
where <italic>B</italic>(., .) is the binomial distribution. We obtain the resulting probability from the probabilistic model upon stimulation with a stimulus with ambiguity <italic>f</italic><sub>A</sub> by taking the expectation of the posterior <xref ref-type="disp-formula" rid="pcbi.1004640.e052">Eq (23)</xref> over the possible realizations of <italic>n</italic><sub><italic>a</italic></sub> and <italic>n</italic><sub><italic>b</italic></sub>, i.e.
<disp-formula id="pcbi.1004640.e055"><alternatives><graphic id="pcbi.1004640.e055g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e055" xlink:type="simple"/><mml:math display="block" id="M55"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>A</mml:mtext><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mtext>A</mml:mtext></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo>〈</mml:mo> <mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>A</mml:mtext><mml:mo>|</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi>b</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>〉</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi>b</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives> <label>(26)</label></disp-formula></p>
<p>This function still depends on <italic>θ</italic><sub>1</sub> and <italic>θ</italic><sub>0</sub>. In order to determine those parameter values we consider the full experiment in the SORN model and evaluate the decision curves over <italic>f</italic><sub>A</sub> (<xref ref-type="fig" rid="pcbi.1004640.g007">Fig 7a</xref>) for all different values of the prior during training (10% to 90%). Every such curve is the result of an average of 20 realizations of the—stochastically created—SORN model. Then we find those two parameter values <italic>θ</italic><sub>1</sub> and <italic>θ</italic><sub>0</sub> that fit all those 9 curves the best, in the sense of the least sum of the mean squared deviations. For the sake of simplicity the optimization is carried out by an exhaustive grid search in the range of 0.05, …, 0.95 with step size 0.05. The result of the search delivered the values <italic>θ</italic><sub>1</sub> = 0.85 and <italic>θ</italic><sub>0</sub> = 0.45 for the full SORN and <italic>θ</italic><sub>1</sub> = 0.95 and <italic>θ</italic><sub>0</sub> = 0.3 for the “Only IP” condition.</p>
</sec>
<sec id="sec031">
<title>Fano factor analysis</title>
<p>The Fano factor is defined as <inline-formula id="pcbi.1004640.e056"><alternatives><graphic id="pcbi.1004640.e056g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e056" xlink:type="simple"/><mml:math display="inline" id="M56"><mml:mfrac><mml:msup><mml:mi>σ</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mi>μ</mml:mi></mml:mfrac></mml:math></alternatives></inline-formula>. When applied to spike trains, the windowed variance <italic>σ</italic><sup>2</sup> and mean <italic>μ</italic> are taken over trials for each neuron, condition and time step. It is then interpreted as the variability of the data. For a Poisson process, which describes the irregular spiking of neurons in many cases quite well, the Fano factor is 1 due to the variance and mean being equal for this process.</p>
<p>We tried to keep our analysis of the Fano factor close to [<xref ref-type="bibr" rid="pcbi.1004640.ref010">10</xref>]. As in the original paper, the FFs were obtained by weighted regression between the spiking mean and variance over trials. To compute these two, we used a causal sliding window with a width of 5 time steps, i.e. the sum of the spikes in the past four time steps and the time step to be analysed. Together with the IP parameters, this entails a rate of 0.5 spikes per bin on average. This is comparable to the conditions of the original paper: most experiments have a rate on the order of <inline-formula id="pcbi.1004640.e057"><alternatives><graphic id="pcbi.1004640.e057g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e057" xlink:type="simple"/><mml:math display="inline" id="M57"><mml:mrow><mml:mn>10</mml:mn> <mml:mfrac><mml:mtext>spikes</mml:mtext> <mml:mi mathvariant="normal">s</mml:mi></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula> and a bin size of 50ms. One should note that due to the weighted regression and the averaging over many neurons, the resulting Fano Factor does not have to be identical to the ratio of the mean variance and the mean firing rate.</p>
<p>To control for an effect of the mean firing rate on the Fano factor, we also performed the “mean matching” analysis from [<xref ref-type="bibr" rid="pcbi.1004640.ref010">10</xref>]. We found that this method discards around two thirds of the data, comparable to the original study. Therefore, we only see it as a control and focussed on the real FF for the discussion.</p>
</sec>
<sec id="sec032">
<title>Prediction of evoked activity and decisions</title>
<p>For our last comparisons, we aimed to show that the spontaneous activity in this network can be used both to predict the following evoked activity [<xref ref-type="bibr" rid="pcbi.1004640.ref008">8</xref>] and to predict the decision of the network as for example in [<xref ref-type="bibr" rid="pcbi.1004640.ref019">19</xref>, <xref ref-type="bibr" rid="pcbi.1004640.ref020">20</xref>].</p>
<p>The former was done in a similar way as the inference: For each combination of stimulus condition <italic>c</italic> and time step Δ<italic>t</italic><sub><italic>a</italic></sub> after stimulus onset <italic>t</italic><sub>on</sub>, we trained a linear readout that maps <bold>x</bold><sup><italic>c</italic></sup>(<italic>t</italic><sub>on</sub> − 1) to <bold>x</bold><sup><italic>c</italic></sup>(<italic>t</italic><sub>on</sub> − 1 + Δ<italic>t</italic><sub><italic>a</italic></sub>). The match between the predicted evoked activity and the actual evoked activity <bold>x</bold><sup><italic>c</italic></sup>(<italic>t</italic><sub>on</sub> − 1 + Δ<italic>t</italic><sub><italic>a</italic></sub>) was then calculated by taking the pearson correlation between both states. We allowed a bias term in the regression by appending a constant to each <bold>x</bold><sup><italic>c</italic></sup>(<italic>t</italic><sub>on</sub> − 1) vector. To asses the impact of the spontaneous activity on the prediction, we compared this performance to doing the same regression from shuffled spiking patterns over trials. By shuffling over trials, the statistics of the individual patterns persist, but their relation to the decision vanishes. Since this still includes the bias term, this control can capture average effects but has to deal with the same number of parameters as the original regression. Therefore, if the spontaneous activity prior to stimulus onset contains information about the following evoked activity, the prediction based on the spontaneous activity should be better, i.e. correlate more with the true activity, than the one based on the shuffled spike trains. Also, both predictions should overlap for very late states since the information from the spontaneous activity should be “washed out” by then.</p>
<p>To predict the decision of the network, we also used this regression approach. For this, we divided the <italic>T</italic><sub>test</sub> steps of network activity with decisions into two halves—one for training the readouts to predict the decision for “A” and “B” and one for testing its performance. For each step before stimulus onset and a given stimulus, an individual readout was trained. The prediction was then defined as the higher readout. We evaluate the quality of this prediction by comparing it to the actual decisions of the network and computing the agreement between both for the testing data. These actual decisions are usually biased towards one of the two alternatives, either due to the prior of the stimulus in the self-organization phase or due to the initial structure of the network. This bias can be exploited by the bias term in the readout mentioned above to get above-50% performance for the baseline comparison, where again trial-shuffled spiking data plus a bias term is used to predict decisions.</p>
</sec>
</sec>
</sec>
<sec id="sec033">
<title>Supporting Information</title>
<supplementary-material id="pcbi.1004640.s001" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004640.s001" xlink:type="simple">
<label>S1 Fig</label>
<caption>
<title>Basic properties of the network from a representative trial of the sequence learning task.</title>
<p>(a) A sample of spikes after plasticity. (b) The inter-spike-interval (ISI) distribution of a randomly selected neuron during spontaneous activity is well-fitted by an exponential after accounting for the periodic structure of the task. (c) The distribution of coefficients of variation (CVs) of the ISIs is on average slightly smaller than for the random letters (cp. <xref ref-type="fig" rid="pcbi.1004640.g001">Fig 1</xref>). (d) The fraction of excitatory-to-excitatory connections initially converges to a stable fraction, then decreases again. The network behaviour does not change despite the transient decrease. (e) Individual weights fluctuate despite the global periods of convergence. (f) After self-organization, the binned distribution of excitatory-to-excitatory synaptic weights (dots) is well fit by a lognormal distribution (solid line).</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004640.s002" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004640.s002" xlink:type="simple">
<label>S2 Fig</label>
<caption>
<title>Basic properties of the network from a representative trial of the inference task.</title>
<p>(a) A sample of spikes during the test phase. Stimuli were presented in the shaded areas. (b) The inter-spike-interval (ISI) distribution of a randomly selected neuron during spontaneous activity reflects the trial-like structure during learning with pauses between activity bursts. (c) The distribution of coefficients of variation (CVs) of the ISIs clusters around one. (d) The fraction of excitatory-to-excitatory connections converges to a stable fraction. (e) Individual weights fluctuate despite the global convergence. (f) After self-organization, the binned distribution of excitatory-to-excitatory synaptic weights (dots) deviates from a lognormal distribution (solid line).</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004640.s003" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004640.s003" xlink:type="simple">
<label>S3 Fig</label>
<caption>
<title>Sequences separate at higher principal components.</title>
<p>In the simulation of <xref ref-type="fig" rid="pcbi.1004640.g003">Fig 3a</xref>, the network was stimulated with the words “ABCD” (67%) and “EFGH” (33%) and evoked (dots) and spontaneous (lines) activity were projected into the principal component space of the evoked activity. Here, we display the 4th, 9th, and 11th principal component (PC) from that simulation. In each dimension, one letter of the two sequences clearly separates. The less variability is explained by the PC (i.e. the higher the PC number), the earlier the letter occurs in the sequence. As argued in the text, this effect might be due to small differences at the beginning accumulating through the recurrent structure to larger differences towards the end of the word. As expected from the other results in <xref ref-type="fig" rid="pcbi.1004640.g003">Fig 3</xref>, the spontaneous activity follows the structure of the sequences. For example, it transitions from blue to green (“B” to “C”) or from gold to pink (“F” to “G”) but not from blue to pink or form gold to green. This causes the opposing triangles of spontaneous activity in the plot.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004640.s004" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004640.s004" xlink:type="simple">
<label>S4 Fig</label>
<caption>
<title>Mean-matched Fano factors.</title>
<p>To control for effects of the mean, we computed the Fano factors with the mean-matching method proposed by [<xref ref-type="bibr" rid="pcbi.1004640.ref010">10</xref>]. This was done for both (a) the inference task and (b) the sequence learning task. As in the original paper, we averaged over all conditions. Therefore, we cannot distinguish between stimuli as we did in <xref ref-type="fig" rid="pcbi.1004640.g005">Fig 5</xref>. Both conditions used the same prior as in Figs <xref ref-type="fig" rid="pcbi.1004640.g003">3</xref> and <xref ref-type="fig" rid="pcbi.1004640.g007">7</xref>. Please note that the sequence task does not have a trial structure but the network is continuously stimulated. Therefore, there is on average no rate change in raw activity at the onset of each stimulus. Error envelopes are SEM over 20 independent realizations.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004640.s005" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004640.s005" xlink:type="simple">
<label>S5 Fig</label>
<caption>
<title>Network analysis for the inference task.</title>
<p>(a) The conditional probability of spiking <italic>p</italic>(<italic>x</italic><sub><italic>i</italic></sub>(<italic>t</italic> + 1) = 1|<italic>x</italic><sub><italic>j</italic></sub>(<italic>t</italic>) = 1) is directly proportional to its synaptic weight <inline-formula id="pcbi.1004640.e058"><alternatives><graphic id="pcbi.1004640.e058g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004640.e058" xlink:type="simple"/><mml:math display="inline" id="M58"><mml:msubsup><mml:mi>W</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mrow><mml:mi>E</mml:mi> <mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>. (b) The firing probabilities of each neuron relative to stimulus onset. The network develops sequential activity patterns during the presentation of both sequences (top and middle). Neurons were sorted according to their maximal firing probability relative to the sequence “AXXX_ _ _ …”. (c) The prediction of transition probabilities during spontaneous activity from the singular value decomposition of <bold>W</bold><sup><italic>EE</italic></sup>. (d) The actual transition probabilities during spontaneous activity. Please note the prominent “_” to “_” transitions reflecting the blank periods during training.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004640.s006" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004640.s006" xlink:type="simple">
<label>S6 Fig</label>
<caption>
<title>IP and SN are essential for healthy network dynamics.</title>
<p>(a) Conditional firing probabilities from <xref ref-type="fig" rid="pcbi.1004640.g008">Fig 8a</xref>. (b) The original simulation without STDP demonstrates that STDP is not necessary for the linear relation between synapse strength and firing probability. Also, STDP leads to stronger weights. (c) The original simulation without IP shows that IP is essential for maintaining correct firing probabilities. (d) The same holds true for a simulation without synaptic normalization. Both (c) and (d) also show incorrectly learnt weight matrices and pathological network dynamics (see [<xref ref-type="bibr" rid="pcbi.1004640.ref037">37</xref>] for effects of excluding IP or SN on network dynamics).</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004640.s007" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004640.s007" xlink:type="simple">
<label>S7 Fig</label>
<caption>
<title>Spontaneous transitions vs. SVD prediction.</title>
<p>(a) The transition probabilities between letters during spontaneous activity and its estimates from singular value decomposition are plotted for the sequence learning task. The green line is the fitted linear regression. The individual transition probabilities are shown in <xref ref-type="fig" rid="pcbi.1004640.g008">Fig 8c and 8d</xref>. (b) The same plot for the data from the inference task (<xref ref-type="supplementary-material" rid="pcbi.1004640.s005">S5c and S5d Fig</xref>) shows a worse match. This is due to more spontaneous activity during training and the thereby less constrained excitatory weight matrix. This results both in smaller transition probabilities during spontaneous activity and a more ambiguous SVD analysis of the weight matrix.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="pcbi.1004640.ref001">
<label>1</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Laughlin</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>de Ruyter van Steveninck</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Anderson</surname> <given-names>J</given-names></name>. <article-title>The metabolic cost of neural information</article-title>. <source>Nature Neuroscience</source>. <year>1998</year>;<volume>1</volume>(<issue>1</issue>):<fpage>36</fpage>–<lpage>41</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/236" xlink:type="simple">10.1038/236</ext-link></comment> <object-id pub-id-type="pmid">10195106</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref002">
<label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Faisal</surname> <given-names>AA</given-names></name>, <name name-style="western"><surname>Selen</surname> <given-names>LPJ</given-names></name>, <name name-style="western"><surname>Wolpert</surname> <given-names>DM</given-names></name>. <article-title>Noise in the nervous system</article-title>. <source>Nature Reviews Neuroscience</source>. <year>2008</year>;<volume>9</volume>(<issue>4</issue>):<fpage>292</fpage>–<lpage>303</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nrn2258" xlink:type="simple">10.1038/nrn2258</ext-link></comment> <object-id pub-id-type="pmid">18319728</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref003">
<label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Mainen</surname> <given-names>ZF</given-names></name>, <name name-style="western"><surname>Sejnowski</surname> <given-names>TJ</given-names></name>. <article-title>Reliability of spike timing in neocortical neurons</article-title>. <source>Science</source>. <year>1995</year>;<volume>268</volume>(<issue>5216</issue>):<fpage>1503</fpage>–<lpage>6</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.7770778" xlink:type="simple">10.1126/science.7770778</ext-link></comment> <object-id pub-id-type="pmid">7770778</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref004">
<label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schneidman</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Freedman</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Segev</surname> <given-names>I</given-names></name>. <article-title>Ion channel stochasticity may be critical in determining the reliability and precision of spike timing</article-title>. <source>Neural Computation</source>. <year>1998</year>;<volume>10</volume>(<issue>7</issue>):<fpage>1679</fpage>–<lpage>703</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/089976698300017089" xlink:type="simple">10.1162/089976698300017089</ext-link></comment> <object-id pub-id-type="pmid">9744892</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref005">
<label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hardingham</surname> <given-names>NR</given-names></name>, <name name-style="western"><surname>Larkman</surname> <given-names>AU</given-names></name>. <article-title>Rapid report: the reliability of excitatory synaptic transmission in slices of rat visual cortex in vitro is temperature dependent</article-title>. <source>The Journal of Physiology</source>. <year>1998</year>;<volume>507</volume>:<fpage>249</fpage>–<lpage>56</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1111/j.1469-7793.1998.249bu.x" xlink:type="simple">10.1111/j.1469-7793.1998.249bu.x</ext-link></comment> <object-id pub-id-type="pmid">9490846</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref006">
<label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>DeWeese</surname> <given-names>MR</given-names></name>, <name name-style="western"><surname>Wehr</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Zador</surname> <given-names>AM</given-names></name>. <article-title>Binary spiking in auditory cortex</article-title>. <source>The Journal of Neuroscience</source>. <year>2003</year>;<volume>23</volume>(<issue>21</issue>):<fpage>7940</fpage>–<lpage>9</lpage>. <object-id pub-id-type="pmid">12944525</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref007">
<label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Softky</surname> <given-names>WR</given-names></name>, <name name-style="western"><surname>Koch</surname> <given-names>C</given-names></name>. <article-title>The highly irregular firing of cortical cells is inconsistent with temporal integration of random EPSPs</article-title>. <source>The Journal of Neuroscience</source>. <year>1993</year>;<volume>13</volume>(<issue>1</issue>):<fpage>334</fpage>–<lpage>50</lpage>. <object-id pub-id-type="pmid">8423479</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref008">
<label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Arieli</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Sterkin</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Grinvald</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Aertsen</surname> <given-names>A</given-names></name>. <article-title>Dynamics of ongoing activity: explanation of the large variability in evoked cortical responses</article-title>. <source>Science</source>. <year>1996</year>;<volume>273</volume>(<issue>5283</issue>):<fpage>1868</fpage>–<lpage>71</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.273.5283.1868" xlink:type="simple">10.1126/science.273.5283.1868</ext-link></comment> <object-id pub-id-type="pmid">8791593</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref009">
<label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ringach</surname> <given-names>DL</given-names></name>. <article-title>Spontaneous and driven cortical activity: implications for computation</article-title>. <source>Current Opinion in Neurobiology</source>. <year>2009</year>;<volume>19</volume>(<issue>4</issue>):<fpage>439</fpage>–<lpage>444</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.conb.2009.07.005" xlink:type="simple">10.1016/j.conb.2009.07.005</ext-link></comment> <object-id pub-id-type="pmid">19647992</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref010">
<label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Churchland</surname> <given-names>MM</given-names></name>, <name name-style="western"><surname>Yu</surname> <given-names>BM</given-names></name>, <name name-style="western"><surname>Cunningham</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Sugrue</surname> <given-names>LP</given-names></name>, <name name-style="western"><surname>Cohen</surname> <given-names>MR</given-names></name>, <name name-style="western"><surname>Corrado</surname> <given-names>GS</given-names></name>, <etal>et al</etal>. <article-title>Stimulus onset quenches neural variability: a widespread cortical phenomenon</article-title>. <source>Nature Neuroscience</source>. <year>2010</year>;<volume>13</volume>(<issue>3</issue>):<fpage>369</fpage>–<lpage>378</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.2501" xlink:type="simple">10.1038/nn.2501</ext-link></comment> <object-id pub-id-type="pmid">20173745</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref011">
<label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Harris</surname> <given-names>KD</given-names></name>, <name name-style="western"><surname>Thiele</surname> <given-names>A</given-names></name>. <article-title>Cortical state and attention</article-title>. <source>Nature Reviews Neuroscience</source>. <year>2011</year>;<volume>12</volume>(<issue>9</issue>):<fpage>509</fpage>–<lpage>23</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nrn3084" xlink:type="simple">10.1038/nrn3084</ext-link></comment> <object-id pub-id-type="pmid">21829219</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref012">
<label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kenet</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Bibitchkov</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Tsodyks</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Grinvald</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Arieli</surname> <given-names>A</given-names></name>. <article-title>Spontaneously emerging cortical representations of visual attributes</article-title>. <source>Nature</source>. <year>2003</year>;<volume>425</volume>(<issue>6961</issue>):<fpage>954</fpage>–<lpage>6</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature02078" xlink:type="simple">10.1038/nature02078</ext-link></comment> <object-id pub-id-type="pmid">14586468</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref013">
<label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Luczak</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Barthó</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Harris</surname> <given-names>KD</given-names></name>. <article-title>Spontaneous events outline the realm of possible sensory responses in neocortical populations</article-title>. <source>Neuron</source>. <year>2009</year>;<volume>62</volume>(<issue>3</issue>):<fpage>413</fpage>–<lpage>25</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2009.03.014" xlink:type="simple">10.1016/j.neuron.2009.03.014</ext-link></comment> <object-id pub-id-type="pmid">19447096</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref014">
<label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Han</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Caporale</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Dan</surname> <given-names>Y</given-names></name>. <article-title>Reverberation of recent visual experience in spontaneous cortical waves</article-title>. <source>Neuron</source>. <year>2008</year>;<volume>60</volume>(<issue>2</issue>):<fpage>321</fpage>–<lpage>7</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2008.08.026" xlink:type="simple">10.1016/j.neuron.2008.08.026</ext-link></comment> <object-id pub-id-type="pmid">18957223</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref015">
<label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Lewis</surname> <given-names>CM</given-names></name>, <name name-style="western"><surname>Baldassarre</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Committeri</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Romani</surname> <given-names>GL</given-names></name>, <name name-style="western"><surname>Corbetta</surname> <given-names>M</given-names></name>. <article-title>Learning sculpts the spontaneous activity of the resting human brain</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2009</year>;<volume>106</volume>(<issue>41</issue>):<fpage>17558</fpage>–<lpage>63</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.0902455106" xlink:type="simple">10.1073/pnas.0902455106</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref016">
<label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Berkes</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Orban</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Lengyel</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Jozsef</surname> <given-names>F</given-names></name>. <article-title>Spontaneous Cortical Activity Reveals Hallmarks of an Optimal Internal Model of the Environment</article-title>. <source>Science</source>. <year>2011</year>;<volume>331</volume>(<issue>6013</issue>):<fpage>83</fpage>–<lpage>7</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.1195870" xlink:type="simple">10.1126/science.1195870</ext-link></comment> <object-id pub-id-type="pmid">21212356</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref017">
<label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Savin</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Berkes</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Chiu</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Fiser</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Lengyel</surname> <given-names>M</given-names></name>. <article-title>Similarity between spontaneous and sensory-evoked activity does suggest learning in the cortex</article-title>. In: <source>Cosyne</source>; <year>2013</year>.</mixed-citation>
</ref>
<ref id="pcbi.1004640.ref018">
<label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Betsch</surname> <given-names>BY</given-names></name>, <name name-style="western"><surname>Einhäuser</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Körding</surname> <given-names>KP</given-names></name>, <name name-style="western"><surname>König</surname> <given-names>P</given-names></name>. <article-title>The world from a cat’s perspective—Statistics of natural videos</article-title>. <source>Biological Cybernetics</source>. <year>2004</year>;<volume>90</volume>(<issue>1</issue>):<fpage>41</fpage>–<lpage>50</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s00422-003-0434-6" xlink:type="simple">10.1007/s00422-003-0434-6</ext-link></comment> <object-id pub-id-type="pmid">14762723</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref019">
<label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Supèr</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>van der Togt</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Henk</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Lamme</surname> <given-names>V</given-names></name>. <article-title>Internal state of monkey primary visual cortex (V1) predicts figureground perception</article-title>. <source>The Journal of Neuroscience</source>. <year>2003</year>;<volume>23</volume>(<issue>8</issue>):<fpage>3407</fpage>–<lpage>3414</lpage>. <object-id pub-id-type="pmid">12716948</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref020">
<label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hesselmann</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Kell</surname> <given-names>CA</given-names></name>, <name name-style="western"><surname>Eger</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Kleinschmidt</surname> <given-names>A</given-names></name>. <article-title>Spontaneous local variations in ongoing neural activity bias perceptual decisions</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2008</year>;<volume>105</volume>(<issue>31</issue>):<fpage>10984</fpage>–<lpage>9</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.0712043105" xlink:type="simple">10.1073/pnas.0712043105</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref021">
<label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Uzzell</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Chichilnisky</surname> <given-names>E</given-names></name>. <article-title>Precision of spike trains in primate retinal ganglion cells</article-title>. <source>Journal of Neurophysiology</source>. <year>2004</year>;<volume>92</volume>(<issue>2</issue>):<fpage>780</fpage>–<lpage>789</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.01171.2003" xlink:type="simple">10.1152/jn.01171.2003</ext-link></comment> <object-id pub-id-type="pmid">15277596</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref022">
<label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Scholvinck</surname> <given-names>ML</given-names></name>, <name name-style="western"><surname>Saleem</surname> <given-names>AB</given-names></name>, <name name-style="western"><surname>Benucci</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Harris</surname> <given-names>KD</given-names></name>, <name name-style="western"><surname>Carandini</surname> <given-names>M</given-names></name>. <article-title>Cortical State Determines Global Variability and Correlations in Visual Cortex</article-title>. <source>Journal of Neuroscience</source>. <year>2015</year>;<volume>35</volume>(<issue>1</issue>):<fpage>170</fpage>–<lpage>178</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.4994-13.2015" xlink:type="simple">10.1523/JNEUROSCI.4994-13.2015</ext-link></comment> <object-id pub-id-type="pmid">25568112</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref023">
<label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Binzegger</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Douglas</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Martin</surname> <given-names>KA</given-names></name>. <article-title>A quantitative map of the circuit of cat primary visual cortex</article-title>. <source>The Journal of Neuroscience</source>. <year>2004</year>;<volume>24</volume>(<issue>39</issue>):<fpage>8441</fpage>–<lpage>53</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.1400-04.2004" xlink:type="simple">10.1523/JNEUROSCI.1400-04.2004</ext-link></comment> <object-id pub-id-type="pmid">15456817</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref024">
<label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bosking</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Zhang</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Schofield</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Fitzpatrick</surname> <given-names>D</given-names></name>. <article-title>Orientation selectivity and the arrangement of horizontal connections in tree shrew striate cortex</article-title>. <source>The Journal of Neuroscience</source>. <year>1997</year>;<volume>17</volume>(<issue>6</issue>):<fpage>2112</fpage>–<lpage>2127</lpage>. <object-id pub-id-type="pmid">9045738</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref025">
<label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Cossell</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Iacaruso</surname> <given-names>MF</given-names></name>, <name name-style="western"><surname>Muir</surname> <given-names>DR</given-names></name>, <name name-style="western"><surname>Houlton</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Sader</surname> <given-names>EN</given-names></name>, <name name-style="western"><surname>Ko</surname> <given-names>H</given-names></name>, <etal>et al</etal>. <article-title>Functional organization of excitatory synaptic strength in primary visual cortex</article-title>. <source>Nature</source>. <year>2015</year>;<volume>518</volume>(<issue>7539</issue>):<fpage>399</fpage>–<lpage>403</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature14182" xlink:type="simple">10.1038/nature14182</ext-link></comment> <object-id pub-id-type="pmid">25652823</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref026">
<label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Mohajerani</surname> <given-names>MH</given-names></name>, <name name-style="western"><surname>Chan</surname> <given-names>AW</given-names></name>, <name name-style="western"><surname>Mohsenvand</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Ledue</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Liu</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>McVea</surname> <given-names>DA</given-names></name>, <etal>et al</etal>. <article-title>Spontaneous cortical activity alternates between motifs defined by regional axonal projections</article-title>. <source>Nature Neuroscience</source>. <year>2013</year>;<volume>16</volume>(<issue>10</issue>):<fpage>1426</fpage>–<lpage>1435</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.3499" xlink:type="simple">10.1038/nn.3499</ext-link></comment> <object-id pub-id-type="pmid">23974708</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref027">
<label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Skudlarski</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Jagannathan</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Calhoun</surname> <given-names>VD</given-names></name>, <name name-style="western"><surname>Hampson</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Skudlarska</surname> <given-names>BA</given-names></name>, <name name-style="western"><surname>Pearlson</surname> <given-names>G</given-names></name>. <article-title>Measuring brain connectivity: Diffusion tensor imaging validates resting state temporal correlations</article-title>. <source>NeuroImage</source>. <year>2008</year>;<volume>43</volume>(<issue>3</issue>):<fpage>554</fpage>–<lpage>561</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuroimage.2008.07.063" xlink:type="simple">10.1016/j.neuroimage.2008.07.063</ext-link></comment> <object-id pub-id-type="pmid">18771736</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref028">
<label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Luczak</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Barthó</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Marguet</surname> <given-names>SL</given-names></name>, <name name-style="western"><surname>Buzsáki</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Harris</surname> <given-names>KD</given-names></name>. <article-title>Sequential structure of neocortical spontaneous activity in vivo</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2007</year>;<volume>104</volume>(<issue>1</issue>):<fpage>347</fpage>–<lpage>52</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.0605643104" xlink:type="simple">10.1073/pnas.0605643104</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref029">
<label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Singer</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Tretter</surname> <given-names>F</given-names></name>. <article-title>Unusually large receptive fields in cats with restricted visual experience</article-title>. <source>Experimental Brain Research</source>. <year>1976</year>;<volume>26</volume>(<issue>2</issue>):<fpage>171</fpage>–<lpage>184</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/BF00238281" xlink:type="simple">10.1007/BF00238281</ext-link></comment> <object-id pub-id-type="pmid">976399</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref030">
<label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Lowel</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Singer</surname> <given-names>W</given-names></name>. <article-title>Selection of intrinsic horizontal connections in the visual cortex by correlated neuronal activity</article-title>. <source>Science</source>. <year>1992</year>;<volume>255</volume>(<issue>5041</issue>):<fpage>209</fpage>–<lpage>212</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.1372754" xlink:type="simple">10.1126/science.1372754</ext-link></comment> <object-id pub-id-type="pmid">1372754</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref031">
<label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gavornik</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Bear</surname> <given-names>MF</given-names></name>. <article-title>Learned spatiotemporal sequence recognition and prediction in primary visual cortex</article-title>. <source>Nature Neuroscience</source>. <year>2014</year>;<volume>17</volume>(<issue>5</issue>):<fpage>732</fpage>–<lpage>7</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.3683" xlink:type="simple">10.1038/nn.3683</ext-link></comment> <object-id pub-id-type="pmid">24657967</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref032">
<label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Turrigiano</surname> <given-names>G</given-names></name>. <article-title>Too many cooks? Intrinsic and synaptic homeostatic mechanisms in cortical circuit refinement</article-title>. <source>Annual Review of Neuroscience</source>. <year>2011</year>;<volume>34</volume>:<fpage>89</fpage>–<lpage>103</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1146/annurev-neuro-060909-153238" xlink:type="simple">10.1146/annurev-neuro-060909-153238</ext-link></comment> <object-id pub-id-type="pmid">21438687</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref033">
<label>33</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bourne</surname> <given-names>JN</given-names></name>, <name name-style="western"><surname>Harris</surname> <given-names>KM</given-names></name>. <article-title>Coordination of size and number of excitatory and inhibitory synapses results in a balanced structural plasticity along mature hippocampal CA1 dendrites during LTP</article-title>. <source>Hippocampus</source>. <year>2011</year>;<volume>21</volume>(<issue>4</issue>):<fpage>354</fpage>–<lpage>73</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/hipo.20768" xlink:type="simple">10.1002/hipo.20768</ext-link></comment> <object-id pub-id-type="pmid">20101601</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref034">
<label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Vitureira</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Goda</surname> <given-names>Y</given-names></name>. <article-title>The interplay between hebbian and homeostatic synaptic plasticity</article-title>. <source>Journal of Cell Biology</source>. <year>2013</year>;<volume>203</volume>(<issue>2</issue>):<fpage>175</fpage>–<lpage>186</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1083/jcb.201306030" xlink:type="simple">10.1083/jcb.201306030</ext-link></comment> <object-id pub-id-type="pmid">24165934</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref035">
<label>35</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Abbott</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Nelson</surname> <given-names>S</given-names></name>. <article-title>Synaptic plasticity: taming the beast</article-title>. <source>Nature Neuroscience</source>. <year>2000</year>;<volume>3</volume>:<fpage>1178</fpage>–<lpage>83</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/81453" xlink:type="simple">10.1038/81453</ext-link></comment> <object-id pub-id-type="pmid">11127835</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref036">
<label>36</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Wondolowski</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Dickman</surname> <given-names>D</given-names></name>. <article-title>Emerging links between homeostatic synaptic plasticity and neurological disease</article-title>. <source>Frontiers in Cellular Neuroscience</source>. <year>2013</year>;<volume>7</volume>(<issue>November</issue>):<fpage>223</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fncel.2013.00223" xlink:type="simple">10.3389/fncel.2013.00223</ext-link></comment> <object-id pub-id-type="pmid">24312013</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref037">
<label>37</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Lazar</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Pipa</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Triesch</surname> <given-names>J</given-names></name>. <article-title>SORN: A Self-Organizing Recurrent Neural Network</article-title>. <source>Frontiers in Computational Neuroscience</source>. <year>2009</year>;<volume>3</volume>(<issue>October</issue>):<fpage>9</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004640.ref038">
<label>38</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Duarte</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Seriès</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Morrison</surname> <given-names>A</given-names></name>. <article-title>Self-Organized Artificial Grammar Learning in Spiking Neural Networks</article-title>. In: <source>Proceedings of the 36th Annual Conference of the Cognitive Science Society</source>; <year>2014</year>. p. <fpage>427</fpage>–<lpage>432</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004640.ref039">
<label>39</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Zheng</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Dimitrakakis</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Triesch</surname> <given-names>J</given-names></name>. <article-title>Network Self-organization Explains the Statistics and Dynamics of Synaptic Connection Strengths in Cortex</article-title>. <source>PLoS Computational Biology</source>. <year>2013</year>;<volume>9</volume>(<issue>1</issue>):<fpage>e1002848</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1002848" xlink:type="simple">10.1371/journal.pcbi.1002848</ext-link></comment> <object-id pub-id-type="pmid">23300431</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref040">
<label>40</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Goris</surname> <given-names>RL</given-names></name>, <name name-style="western"><surname>Movshon</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Simoncelli</surname> <given-names>EP</given-names></name>. <article-title>Partitioning neuronal variability</article-title>. <source>Nature Neuroscience</source>. <year>2014</year>;<volume>17</volume>(<issue>6</issue>):<fpage>858</fpage>–<lpage>865</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.3711" xlink:type="simple">10.1038/nn.3711</ext-link></comment> <object-id pub-id-type="pmid">24777419</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref041">
<label>41</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Yasumatsu</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Matsuzaki</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Miyazaki</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Noguchi</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Kasai</surname> <given-names>H</given-names></name>. <article-title>Principles of long-term dynamics of dendritic spines</article-title>. <source>The Journal of Neuroscience</source>. <year>2008</year>;<volume>28</volume>(<issue>50</issue>):<fpage>13592</fpage>–<lpage>608</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.0603-08.2008" xlink:type="simple">10.1523/JNEUROSCI.0603-08.2008</ext-link></comment> <object-id pub-id-type="pmid">19074033</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref042">
<label>42</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Buzsáki</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Mizuseki</surname> <given-names>K</given-names></name>. <article-title>The log-dynamic brain: how skewed distributions affect network operations</article-title>. <source>Nature Reviews Neuroscience</source>. <year>2014</year>;<volume>15</volume>(<issue>4</issue>):<fpage>264</fpage>–<lpage>78</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nrn3687" xlink:type="simple">10.1038/nrn3687</ext-link></comment> <object-id pub-id-type="pmid">24569488</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref043">
<label>43</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Carr</surname> <given-names>MF</given-names></name>, <name name-style="western"><surname>Jadhav</surname> <given-names>SP</given-names></name>, <name name-style="western"><surname>Frank</surname> <given-names>LM</given-names></name>. <article-title>Hippocampal replay in the awake state: a potential substrate for memory consolidation and retrieval</article-title>. <source>Nature Neuroscience</source>. <year>2011</year>;<volume>14</volume>(<issue>2</issue>):<fpage>147</fpage>–<lpage>53</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.2732" xlink:type="simple">10.1038/nn.2732</ext-link></comment> <object-id pub-id-type="pmid">21270783</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref044">
<label>44</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ponce-Alvarez</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Thiele</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Albright</surname> <given-names>TD</given-names></name>, <name name-style="western"><surname>Stoner</surname> <given-names>GR</given-names></name>, <name name-style="western"><surname>Deco</surname> <given-names>G</given-names></name>. <article-title>Stimulus-dependent variability and noise correlations in cortical MT neurons</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2013</year>;<volume>110</volume>(<issue>32</issue>):<fpage>13162</fpage>–<lpage>13167</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.1300098110" xlink:type="simple">10.1073/pnas.1300098110</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref045">
<label>45</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Fiser</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Berkes</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Orban</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Lengyel</surname> <given-names>M</given-names></name>. <article-title>Statistically optimal perception and learning: from behavior to neural representations</article-title>. <source>Trends in Cognitive Sciences</source>. <year>2010</year>;<volume>14</volume>(<issue>3</issue>):<fpage>119</fpage>–<lpage>130</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.tics.2010.01.003" xlink:type="simple">10.1016/j.tics.2010.01.003</ext-link></comment> <object-id pub-id-type="pmid">20153683</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref046">
<label>46</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bowers</surname> <given-names>JS</given-names></name>, <name name-style="western"><surname>Davis</surname> <given-names>CJ</given-names></name>. <article-title>Bayesian just-so stories in psychology and neuroscience</article-title>. <source>Psychological Bulletin</source>. <year>2012</year>;<volume>138</volume>(<issue>3</issue>):<fpage>389</fpage>–<lpage>414</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/a0026450" xlink:type="simple">10.1037/a0026450</ext-link></comment> <object-id pub-id-type="pmid">22545686</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref047">
<label>47</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Pouget</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Beck</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Ma</surname> <given-names>WJ</given-names></name>, <name name-style="western"><surname>Latham</surname> <given-names>PE</given-names></name>. <article-title>Probabilistic brains: knowns and unknowns</article-title>. <source>Nature Neuroscience</source>. <year>2013</year>;<volume>16</volume>(<issue>9</issue>):<fpage>1170</fpage>–<lpage>1178</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.3495" xlink:type="simple">10.1038/nn.3495</ext-link></comment> <object-id pub-id-type="pmid">23955561</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref048">
<label>48</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Hoyer</surname> <given-names>PO</given-names></name>, <name name-style="western"><surname>Hyvarinen</surname> <given-names>A</given-names></name>. <chapter-title>Interpreting neural response variability as Monte Carlo sampling of the posterior</chapter-title>. In: <source>Advances in Neural Information Processing Systems</source>; <year>2003</year>. p. <fpage>293</fpage>–<lpage>300</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004640.ref049">
<label>49</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Zheng</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Triesch</surname> <given-names>J</given-names></name>. <article-title>Robust development of synfire chains from multiple plasticity mechanisms</article-title>. <source>Frontiers in Computational Neuroscience</source>. <year>2014</year>;<volume>8</volume>(<issue>June</issue>):<fpage>66</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fncom.2014.00066" xlink:type="simple">10.3389/fncom.2014.00066</ext-link></comment> <object-id pub-id-type="pmid">25071537</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref050">
<label>50</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Litwin-Kumar</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Doiron</surname> <given-names>B</given-names></name>. <article-title>Slow dynamics and high variability in balanced cortical networks with clustered connections</article-title>. <source>Nature Neuroscience</source>. <year>2012</year>;<volume>15</volume>(<issue>11</issue>):<fpage>1498</fpage>–<lpage>1505</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.3220" xlink:type="simple">10.1038/nn.3220</ext-link></comment> <object-id pub-id-type="pmid">23001062</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref051">
<label>51</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Farkhooi</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Froese</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Muller</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Menzel</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Nawrot</surname> <given-names>MP</given-names></name>. <article-title>Cellular adaptation facilitates sparse and reliable coding in sensory pathways</article-title>. <source>PLoS Computational Biology</source>. <year>2013</year>;<volume>9</volume>(<issue>10</issue>):<fpage>e1003251</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1003251" xlink:type="simple">10.1371/journal.pcbi.1003251</ext-link></comment> <object-id pub-id-type="pmid">24098101</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref052">
<label>52</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Litwin-Kumar</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Doiron</surname> <given-names>B</given-names></name>. <article-title>Formation and maintenance of neuronal assemblies through synaptic plasticity</article-title>. <source>Nature Communications</source>. <year>2014</year>;<volume>5</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/ncomms6319" xlink:type="simple">10.1038/ncomms6319</ext-link></comment> <object-id pub-id-type="pmid">25395015</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref053">
<label>53</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Choe</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Miikkulainen</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Cormack</surname> <given-names>LK</given-names></name>. <article-title>Effects of presynaptic and postsynaptic resource redistribution in Hebbian weight adaptation</article-title>. <source>Neurocomputing</source>. <year>2000</year>;<volume>32–33</volume>:<fpage>77</fpage>–<lpage>82</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0925-2312(00)00146-6" xlink:type="simple">10.1016/S0925-2312(00)00146-6</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref054">
<label>54</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Devor</surname> <given-names>M</given-names></name>. <article-title>Neuroplasticity in the rearrangement of olfactory tract fibers after neonatal transection in hamsters</article-title>. <source>The Journal of Comparative Neurology</source>. <year>1976</year>;<volume>166</volume>(<issue>1</issue>):<fpage>49</fpage>–<lpage>72</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/cne.901660105" xlink:type="simple">10.1002/cne.901660105</ext-link></comment> <object-id pub-id-type="pmid">1262549</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref055">
<label>55</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Sabel</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Schneider</surname> <given-names>G</given-names></name>. <article-title>The principle of “conservation of total axonal arborizations”: massive compensatory sprouting in the hamster subcortical visual system after early tectal lesions</article-title>. <source>Experimental Brain Research</source>. <year>1988</year>;<volume>73</volume>(<issue>3</issue>):<fpage>505</fpage>–<lpage>518</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/BF00406608" xlink:type="simple">10.1007/BF00406608</ext-link></comment> <object-id pub-id-type="pmid">3224660</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref056">
<label>56</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Song</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Sjöström</surname> <given-names>PJ</given-names></name>, <name name-style="western"><surname>Reigl</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Nelson</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Chklovskii</surname> <given-names>DB</given-names></name>. <article-title>Highly nonrandom features of synaptic connectivity in local cortical circuits</article-title>. <source>PLoS Biology</source>. <year>2005</year>;<volume>3</volume>(<issue>3</issue>):<fpage>e68</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pbio.0030068" xlink:type="simple">10.1371/journal.pbio.0030068</ext-link></comment> <object-id pub-id-type="pmid">15737062</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref057">
<label>57</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Lefort</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Tomm</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Floyd Sarria</surname> <given-names>JC</given-names></name>, <name name-style="western"><surname>Petersen</surname> <given-names>CC</given-names></name>. <article-title>The excitatory neuronal network of the C2 barrel column in mouse primary somatosensory cortex</article-title>. <source>Neuron</source>. <year>2009</year>;<volume>61</volume>(<issue>2</issue>):<fpage>301</fpage>–<lpage>16</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2008.12.020" xlink:type="simple">10.1016/j.neuron.2008.12.020</ext-link></comment> <object-id pub-id-type="pmid">19186171</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref058">
<label>58</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Suzuki</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Imura</surname> <given-names>JI</given-names></name>, <name name-style="western"><surname>Horio</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Aihara</surname> <given-names>K</given-names></name>. <article-title>Chaotic Boltzmann machines</article-title>. <source>Scientific Reports</source>. <year>2013</year>;<volume>3</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/srep01610" xlink:type="simple">10.1038/srep01610</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref059">
<label>59</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>van Vreeswijk</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Sompolinsky</surname> <given-names>H</given-names></name>. <article-title>Chaos in neuronal networks with balanced excitatory and inhibitory activity</article-title>. <source>Science</source>. <year>1996</year>;<volume>274</volume>(<issue>5293</issue>):<fpage>1724</fpage>–<lpage>6</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.274.5293.1724" xlink:type="simple">10.1126/science.274.5293.1724</ext-link></comment> <object-id pub-id-type="pmid">8939866</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref060">
<label>60</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Eser</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Zheng</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Triesch</surname> <given-names>J</given-names></name>. <article-title>Nonlinear Dynamics Analysis of a Self-organizing Recurrent Neural Network</article-title>. <source>PLoS ONE</source>. <year>2013</year>;<volume>9</volume>(<issue>1</issue>):<fpage>e86962</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0086962" xlink:type="simple">10.1371/journal.pone.0086962</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref061">
<label>61</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Nessler</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Pfeiffer</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Buesing</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Maass</surname> <given-names>W</given-names></name>. <article-title>Bayesian computation emerges in generic cortical microcircuits through spike-timing-dependent plasticity</article-title>. <source>PLoS Computational Biology</source>. <year>2013</year>;<volume>9</volume>(<issue>4</issue>):<fpage>e1003037</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1003037" xlink:type="simple">10.1371/journal.pcbi.1003037</ext-link></comment> <object-id pub-id-type="pmid">23633941</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref062">
<label>62</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Buesing</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Bill</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Nessler</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Maass</surname> <given-names>W</given-names></name>. <article-title>Neural dynamics as sampling: a model for stochastic computation in recurrent networks of spiking neurons</article-title>. <source>PLoS Computational Biology</source>. <year>2011</year>;<volume>7</volume>(<issue>11</issue>):<fpage>e1002211</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1002211" xlink:type="simple">10.1371/journal.pcbi.1002211</ext-link></comment> <object-id pub-id-type="pmid">22096452</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref063">
<label>63</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Brea</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Senn</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Pfister</surname> <given-names>JP</given-names></name>. <article-title>Matching recall and storage in sequence learning with spiking neural networks</article-title>. <source>The Journal of Neuroscience</source>. <year>2013</year>;<volume>33</volume>(<issue>23</issue>):<fpage>9565</fpage>–<lpage>75</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.4098-12.2013" xlink:type="simple">10.1523/JNEUROSCI.4098-12.2013</ext-link></comment> <object-id pub-id-type="pmid">23739954</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref064">
<label>64</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kappel</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Nessler</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Maass</surname> <given-names>W</given-names></name>. <article-title>STDP Installs in Winner-Take-All Circuits an Online Approximation to Hidden Markov Model Learning</article-title>. <source>PLoS Computational Biology</source>. <year>2014</year>;<volume>10</volume>(<issue>3</issue>):<fpage>e1003511</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1003511" xlink:type="simple">10.1371/journal.pcbi.1003511</ext-link></comment> <object-id pub-id-type="pmid">24675787</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref065">
<label>65</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Savin</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Joshi</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Triesch</surname> <given-names>J</given-names></name>. <article-title>Independent component analysis in spiking neurons</article-title>. <source>PLoS Computational Biology</source>. <year>2010</year>;<volume>6</volume>(<issue>4</issue>):<fpage>e1000757</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1000757" xlink:type="simple">10.1371/journal.pcbi.1000757</ext-link></comment> <object-id pub-id-type="pmid">20421937</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref066">
<label>66</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Bourdoukan</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Barrett</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Machens</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Deneve</surname> <given-names>S</given-names></name>. <chapter-title>Learning optimal spike-based representations</chapter-title>. In: <source>Advances in Neural Information Processing Systems</source>; <year>2012</year>. p. <fpage>2285</fpage>–<lpage>2293</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004640.ref067">
<label>67</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Lazar</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Pipa</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Triesch</surname> <given-names>J</given-names></name>. <article-title>Emerging Bayesian priors in a self-organizing recurrent network</article-title>. In: <source>Artificial Neural Networks and Machine Learning ICANN</source>; <year>2011</year>. p. <fpage>127</fpage>–<lpage>134</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004640.ref068">
<label>68</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>McCulloch</surname> <given-names>WS</given-names></name>, <name name-style="western"><surname>Pitts</surname> <given-names>W</given-names></name>. <article-title>A logical calculus of the ideas immanent in nervous activity</article-title>. <source>The bulletin of mathematical biophysics</source>. <year>1943</year>;<volume>5</volume>(<issue>4</issue>):<fpage>115</fpage>–<lpage>133</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/BF02478259" xlink:type="simple">10.1007/BF02478259</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref069">
<label>69</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gerstner</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Kempter</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>van Hemmen</surname> <given-names>JL</given-names></name>, <name name-style="western"><surname>Wagner</surname> <given-names>H</given-names></name>. <article-title>A neuronal learning rule for sub-millisecond temporal coding</article-title>. <source>Nature</source>. <year>1996</year>;<volume>383</volume>(<issue>6595</issue>):<fpage>76</fpage>–<lpage>81</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/383076a0" xlink:type="simple">10.1038/383076a0</ext-link></comment> <object-id pub-id-type="pmid">8779718</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref070">
<label>70</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Markram</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Lübke</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Frotscher</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Sakmann</surname> <given-names>B</given-names></name>. <article-title>Regulation of synaptic efficacy by coincidence of postsynaptic APs and EPSPs</article-title>. <source>Science</source>. <year>1997</year>;<volume>275</volume>(<issue>5297</issue>):<fpage>213</fpage>–<lpage>5</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.275.5297.213" xlink:type="simple">10.1126/science.275.5297.213</ext-link></comment> <object-id pub-id-type="pmid">8985014</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref071">
<label>71</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bi</surname> <given-names>GQ</given-names></name>, <name name-style="western"><surname>Poo</surname> <given-names>MM</given-names></name>. <article-title>Synaptic modifications in cultured hippocampal neurons: dependence on spike timing, synaptic strength, and postsynaptic cell type</article-title>. <source>The Journal of Neuroscience</source>. <year>1998</year>;<volume>18</volume>(<issue>24</issue>):<fpage>10464</fpage>–<lpage>72</lpage>. <object-id pub-id-type="pmid">9852584</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref072">
<label>72</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Desai</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Rutherford</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Turrigiano</surname> <given-names>G</given-names></name>. <article-title>Plasticity in the intrinsic excitability of cortical pyramidal neurons</article-title>. <source>Nature Neuroscience</source>. <year>1999</year>;<volume>2</volume>(<issue>6</issue>):<fpage>515</fpage>–<lpage>20</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/9165" xlink:type="simple">10.1038/9165</ext-link></comment> <object-id pub-id-type="pmid">10448215</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref073">
<label>73</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Triesch</surname> <given-names>J</given-names></name>. <article-title>Synergies between intrinsic and synaptic plasticity mechanisms</article-title>. <source>Neural Computation</source>. <year>2007</year>;<volume>19</volume>(<issue>4</issue>):<fpage>885</fpage>–<lpage>909</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/neco.2007.19.4.885" xlink:type="simple">10.1162/neco.2007.19.4.885</ext-link></comment> <object-id pub-id-type="pmid">17348766</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref074">
<label>74</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Turrigiano</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Leslie</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Desai</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Rutherford</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Nelson</surname> <given-names>S</given-names></name>. <article-title>Activity-dependent scaling of quantal amplitude in neocortical neurons</article-title>. <source>Nature</source>. <year>1998</year>;<volume>391</volume>(<issue>6670</issue>):<fpage>892</fpage>–<lpage>896</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/36103" xlink:type="simple">10.1038/36103</ext-link></comment> <object-id pub-id-type="pmid">9495341</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref075">
<label>75</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Toutounji</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Pipa</surname> <given-names>G</given-names></name>. <article-title>Spatiotemporal Computations of an Excitable and Plastic Brain: Neuronal Plasticity Leads to Noise-Robust and Noise-Constructive Computations</article-title>. <source>PLoS Computational Biology</source>. <year>2014</year>;<volume>10</volume>(<issue>3</issue>):<fpage>e1003512</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1003512" xlink:type="simple">10.1371/journal.pcbi.1003512</ext-link></comment> <object-id pub-id-type="pmid">24651447</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004640.ref076">
<label>76</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Masquelier</surname> <given-names>T</given-names></name>. <article-title>Neural variability, or lack thereof</article-title>. <source>Frontiers in computational neuroscience</source>, Frontiers Media SA <year>2013</year>;<volume>7</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fncom.2013.00007" xlink:type="simple">10.3389/fncom.2013.00007</ext-link></comment></mixed-citation>
</ref>
</ref-list>
</back>
</article>
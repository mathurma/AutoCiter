<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
<front>
<journal-meta><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id><journal-id journal-id-type="pmc">ploscomp</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS Computational Biology</journal-title></journal-title-group><issn pub-type="ppub">1553-734X</issn><issn pub-type="epub">1553-7358</issn><publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="publisher-id">08-PLCB-RA-0960R2</article-id><article-id pub-id-type="doi">10.1371/journal.pcbi.1000495</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline"><subject>Neuroscience/Sensory Systems</subject><subject>Neuroscience/Theoretical Neuroscience</subject><subject>Neuroscience/Natural and Synthetic Vision</subject></subj-group></article-categories><title-group><article-title>A Structured Model of Video Reproduces Primary Visual Cortical Organisation</article-title><alt-title alt-title-type="running-head">Structured Model Reproduces V1 Organisation</alt-title></title-group><contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Berkes</surname><given-names>Pietro</given-names></name><xref ref-type="aff" rid="aff1"/><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref><xref ref-type="fn" rid="fn1"><sup>¤</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Turner</surname><given-names>Richard E.</given-names></name><xref ref-type="aff" rid="aff1"/></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Sahani</surname><given-names>Maneesh</given-names></name><xref ref-type="aff" rid="aff1"/><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
</contrib-group><aff id="aff1">          <addr-line>Gatsby Computational Neuroscience Unit, London, United Kingdom</addr-line>       </aff><contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Kording</surname><given-names>Konrad</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group><aff id="edit1">Northwestern University, United States of America</aff><author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">berkes@brandeis.edu</email> (PB); <email xlink:type="simple">maneesh@gatsby.ucl.ac.uk</email> (MS)</corresp>
<fn fn-type="current-aff" id="fn1"><label>¤</label><p>Current address: Volen Center for Complex Systems, Brandeis University, Waltham, Massachusetts, United States of America</p></fn>
<fn fn-type="con"><p>Conceived and designed the experiments: PB RET MS. Performed the experiments: PB. Analyzed the data: PB. Wrote the paper: PB RET MS.</p></fn>
<fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn></author-notes><pub-date pub-type="collection"><month>9</month><year>2009</year></pub-date><pub-date pub-type="epub"><day>4</day><month>9</month><year>2009</year></pub-date><volume>5</volume><issue>9</issue><elocation-id>e1000495</elocation-id><history>
<date date-type="received"><day>27</day><month>10</month><year>2008</year></date>
<date date-type="accepted"><day>31</day><month>7</month><year>2009</year></date>
</history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2009</copyright-year><copyright-holder>Berkes et al</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract>
<p>The visual system must learn to infer the presence of objects and features in the world from the images it encounters, and as such it must, either implicitly or explicitly, model the way these elements interact to create the image. Do the response properties of cells in the mammalian visual system reflect this constraint? To address this question, we constructed a probabilistic model in which the identity and attributes of simple visual elements were represented explicitly and learnt the parameters of this model from unparsed, natural video sequences. After learning, the behaviour and grouping of variables in the probabilistic model corresponded closely to functional and anatomical properties of simple and complex cells in the primary visual cortex (V1). In particular, feature identity variables were activated in a way that resembled the activity of complex cells, while feature attribute variables responded much like simple cells. Furthermore, the grouping of the attributes within the model closely parallelled the reported anatomical grouping of simple cells in cat V1. Thus, this generative model makes explicit an interpretation of complex and simple cells as elements in the segmentation of a visual scene into basic independent features, along with a parametrisation of their moment-by-moment appearances. We speculate that such a segmentation may form the initial stage of a hierarchical system that progressively separates the identity and appearance of more articulated visual elements, culminating in view-invariant object recognition.</p>
</abstract><abstract abstract-type="summary"><title>Author Summary</title>
<p>When we look at a visual scene, neurons in our eyes “fire” short, electrical pulses in a pattern that encodes information about the visual world. This pattern passes through a series of processing stages within the brain, eventually leading to cells whose firing encodes high-level aspects of the scene, such as the identity of a visible object regardless of its position, apparent size or angle. Remarkably, features of these firing patterns, at least at the earlier stages of the pathway, can be predicted by building “efficient” codes for natural images: that is, codes based on models of the statistical properties of the environment. In this study, we have taken a first step towards extending this theoretical success to describe later stages of processing, building a model that extracts a structured representation in much the same way as does the visual system. The model describes discrete, persistent visual elements, whose appearance varies over time—a simplified version of a world built of objects that move and rotate. We show that when fit to natural image sequences, features of the “code” implied by this model match many aspects of processing in the first cortical stage of the visual system, including: the individual firing patterns of types of cells known as “simple” and “complex”; the distribution of coding properties over these cells; and even how these properties depend on the cells' physical proximity. The model thus brings us closer to understanding the functional principles behind the organisation of the visual system.</p>
</abstract><funding-group><funding-statement>This work has been supported by the Gatsby Charitable Foundation. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="16"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>It is well established that the receptive fields (RFs) of neurons in the early visual cortex depend on the statistics of sensory input and can be modified by perturbations of those statistics during development <xref ref-type="bibr" rid="pcbi.1000495-Hubel1">[1]</xref>–<xref ref-type="bibr" rid="pcbi.1000495-Tanaka1">[6]</xref>. This relationship has been studied theoretically in many ways. Phenomenological models have focused on the mechanisms of synaptic plasticity and axon-guidance, giving mathematical or computational accounts of how Hebbian-like learning rules may combine with sensory stimulation to drive the formation of cortical response properties <xref ref-type="bibr" rid="pcbi.1000495-vonderMalsburg1">[7]</xref>–<xref ref-type="bibr" rid="pcbi.1000495-Kayser1">[12]</xref>. Constrained optimality approaches look beyond the details of the synaptic learning rule, and ask whether the observed pattern of cortical responses has been selected to optimise a functional objective. Many early studies of this type were founded on the information-theoretic ideas of efficient coding and redundancy reduction <xref ref-type="bibr" rid="pcbi.1000495-Attneave1">[13]</xref>,<xref ref-type="bibr" rid="pcbi.1000495-Barlow1">[14]</xref>, and proposed that RFs had adapted to maximise the transmission of information from the periphery <xref ref-type="bibr" rid="pcbi.1000495-Bell1">[15]</xref>–<xref ref-type="bibr" rid="pcbi.1000495-Barlow2">[18]</xref>. More recent work has generalised this approach to consider other possible objective functions with different representational or metabolic benefits. Two established alternatives are the <italic>sparseness</italic> and <italic>temporal stability</italic> objective functions. In the sparse-coding view neuronal properties are optimised so that neurons remain silent most of the time, responding vigorously to only a limited subset of all stimuli <xref ref-type="bibr" rid="pcbi.1000495-Olshausen1">[19]</xref>–<xref ref-type="bibr" rid="pcbi.1000495-Rehn1">[21]</xref>. Thus every image is represented by relatively few active neurons. Such a representation makes it easy to detect “suspicious coincidences” <xref ref-type="bibr" rid="pcbi.1000495-Field1">[22]</xref> and reduces energy consumption <xref ref-type="bibr" rid="pcbi.1000495-Vincent1">[23]</xref>. It can also be related to the older objective of information efficiency <xref ref-type="bibr" rid="pcbi.1000495-Olshausen1">[19]</xref>. Under the temporal stability objective, neuronal RFs are adapted so that their output firing rates vary slowly in time <xref ref-type="bibr" rid="pcbi.1000495-Fldik1">[24]</xref>–<xref ref-type="bibr" rid="pcbi.1000495-Berkes1">[26]</xref>. To achieve stability, neurons must learn to be insensitive to typical rapid transformations of their input, leading to invariant representations that simplify recognition tasks <xref ref-type="bibr" rid="pcbi.1000495-Wiskott1">[27]</xref>.</p>
<p>The generative modelling approach takes a complementary functional view. It is based on the Helmholtzian account of perception as inverse inference (sometimes called analysis-by-synthesis). That is, that the goal of the perceptual system is to infer from sensation the environmental causes most likely to be responsible for producing the sensory experience <xref ref-type="bibr" rid="pcbi.1000495-Rao1">[28]</xref>,<xref ref-type="bibr" rid="pcbi.1000495-Yuille1">[29]</xref>. In this view, sensory cortex implicitly embodies a model of how external causes interact to form the sensory input (a <italic>causal generative model</italic>); given a particular sensory experience, cortical processing inverts the model to infer the most likely causes of the sensory activity. Mathematically, this corresponds to an application of Bayes' rule. This general view that the brain carries out or approximates some form of probabilistic inference is supported by a number of psychophysical, anatomical, and physiological results (see <xref ref-type="bibr" rid="pcbi.1000495-Lee1">[30]</xref>,<xref ref-type="bibr" rid="pcbi.1000495-Friston1">[31]</xref> for reviews).</p>
<p>Many models that have been formulated in terms of the optimisation of an objective function could also be viewed as implementing inference within an appropriate generative model: the assumptions and structure of the model are implicit in the objective function. Thus, recoding based on the sparseness objective corresponds to inference within a generative model in which a number of independent, sparsely active causes combine linearly to form the image <xref ref-type="bibr" rid="pcbi.1000495-Olshausen2">[20]</xref>. Similarly, the goal of redundancy reduction has led to models in which divisive normalisation reduces second-order dependence between linear recodings of an image <xref ref-type="bibr" rid="pcbi.1000495-Schwartz1">[32]</xref>; in the generative view, this corresponds to joint modulation of the variances of otherwise independent sparse causes <xref ref-type="bibr" rid="pcbi.1000495-Wainwright1">[33]</xref>,<xref ref-type="bibr" rid="pcbi.1000495-Karklin1">[34]</xref>. Finally, the temporal stability objective corresponds to a model with causes that are independent of one another, but stable or predictable in time <xref ref-type="bibr" rid="pcbi.1000495-Turner1">[35]</xref>.</p>
<p>A remarkable success of these functional models, whether formulated generatively or in terms of a representational objective function, is that, when used to learn an appropriate representation from a set of natural images, they yield elements that mirror a number of response properties of primary visual cortical neurons (though some notable discrepancies do remain <xref ref-type="bibr" rid="pcbi.1000495-vanHateren1">[16]</xref>). However, despite this success, the generative models involved match only the lowest-level statistics of natural images. Images generated from the learnt models have naturalistic textural properties, but none of the higher-level structure of the natural world. If this approach is to provide insight into higher processing within the visual cortex then appropriate structure must be introduced to the models.</p>
<p>In the present study we focused on one basic structural aspect of the environment: The visual world is largely composed of discrete objects, which each contributes a set of discrete visual features to the image. Moreover, the objects, and therefore their associated features, usually remain in view for some time, although their precise appearances might change gradually due to changes in viewpoint, lighting or in the object's position. We thus formulated a model in which the <italic>identity</italic> of the visual elements present was signalled by a set of binary-valued variables, while their appearances each evolved separately under the control of continuous <italic>attribute</italic> variables. This independent control of appearance stands in contrast to a related idea of “content” and “style” <xref ref-type="bibr" rid="pcbi.1000495-Tenenbaum1">[36]</xref>,<xref ref-type="bibr" rid="pcbi.1000495-Grimes1">[37]</xref> where the transformation of appearance is usually shared across the image or image patch. This comparison is taken up in greater detail in the <xref ref-type="sec" rid="s3">Discussion</xref>.</p>
<p>We fitted this model to natural video images, without using any additional information about which elements were present or what their transformations might be. We found that the model naturally learned biologically plausible features, with low dimensional manifolds of attributes. Many aspects of the learnt representation corresponded closely to both anatomical and functional observations regarding simple and complex cells in the primary visual cortex (V1). Thus, the model offers a functional interpretation for the presence of two main classes of cells in V1. Complex cells represent the probability of presence of an oriented feature, while simple cells parametrise the precise appearance of the feature in the visual input. We speculate that a similar representation in the form of feature identities and attributes may continue up the visual hierarchy, ultimately contributing to view-independent object recognition.</p>
</sec><sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>The identity/attribute model</title>
<p><xref ref-type="fig" rid="pcbi-1000495-g001">Figure 1A</xref> illustrates the intuitions that underlie the general structure of the model. The image at each point in time—represented by a vector <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e001" xlink:type="simple"/></inline-formula> shown at the bottom of the figure—is composed from a set of visual elements illustrated by the objects in the top row. Only a small subset of all the possible elements contributes to any one image. The <italic>identity</italic> of these active elements is represented by a set of binary-valued variables <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e002" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e003" xlink:type="simple"/></inline-formula> means that the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e004" xlink:type="simple"/></inline-formula>th element appears in the image at time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e005" xlink:type="simple"/></inline-formula>. If active, the form of the element in the image may vary; for instance the object may appear at any position or orientation. Each element is thus associated with a set of possible contributions to the image, which form a manifold embedded within the space of all possible images. The configuration of element <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e006" xlink:type="simple"/></inline-formula> at time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e007" xlink:type="simple"/></inline-formula> is then specified by a vector <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e008" xlink:type="simple"/></inline-formula>, with dimensionality equal to that of the manifold. We call the elements of this vector, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e009" xlink:type="simple"/></inline-formula>, the <italic>attributes</italic> of the visual element. The shape of the manifold is described by a function <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e010" xlink:type="simple"/></inline-formula>, which maps this attribute vector to the partial image it describes. For concreteness, consider the rightmost panel of <xref ref-type="fig" rid="pcbi-1000495-g001">Figure 1A</xref>, which represents a model for a beverage can. The fact that the variable <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e011" xlink:type="simple"/></inline-formula> takes the value <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e012" xlink:type="simple"/></inline-formula> indicates that the object is present in the image at time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e013" xlink:type="simple"/></inline-formula>. The arrow indicates the point (encoded by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e014" xlink:type="simple"/></inline-formula>) on the manifold where the can has a particular position and viewpoint in the input visual space. If one of the attribute variables were to correspond to the orientation of the can, changing its value would trace a trajectory on the manifold, which would result in a rotation of the object in the image space.</p>
<fig id="pcbi-1000495-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000495.g001</object-id><label>Figure 1</label><caption>
<title>Illustration of the identity/attribute model.</title>
<p>A) Each visual element is represented by a binary-valued identity variable <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e015" xlink:type="simple"/></inline-formula> that indicates its presence or absence, and by a manifold formed by the set of its possible configurations. A vector of attribute variables <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e016" xlink:type="simple"/></inline-formula> identifies a point on the manifold, and thus a partial image <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e017" xlink:type="simple"/></inline-formula>. Partial images corresponding to the active elements are combined through a function <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e018" xlink:type="simple"/></inline-formula> and corrupted by noise <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e019" xlink:type="simple"/></inline-formula> to generate observations <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e020" xlink:type="simple"/></inline-formula>. B) The simplified model with linear mappings.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000495.g001" xlink:type="simple"/></fig>
<p>The set of partial images associated with all of the active elements then combine through a function <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e021" xlink:type="simple"/></inline-formula>, which could in principle implement occlusion, illuminant reflection, or other complex interactions, to yield the image:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e022" xlink:type="simple"/><label>(1)</label></disp-formula>where we have included an additive, independent noise term <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e023" xlink:type="simple"/></inline-formula>.</p>
<p>In this abstract form the model is very powerful, and provides an intuitively satisfying generative structure for images. Unfortunately, for manifolds and combination functions modelling the appearance of entire complex objects and the interactions between them as illustrated in <xref ref-type="fig" rid="pcbi-1000495-g001">Figure 1A</xref>, the task of inferring the elements and their appearances from natural data is intractable. To explore the potential of the framework we adopted a simplified form of the model, taking the mappings <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e024" xlink:type="simple"/></inline-formula> to be linear (equivalently, we defined the attribute manifolds to be hyperplanes) and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e025" xlink:type="simple"/></inline-formula> to sum its arguments. This allowed us to implement the selection of the active elements by multiplication:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e026" xlink:type="simple"/><label>(2)</label></disp-formula>where the <italic>basis vectors</italic> <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e027" xlink:type="simple"/></inline-formula> parametrise the linear manifold <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e028" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e029" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e030" xlink:type="simple"/></inline-formula> are the number of identity variables and the (maximum) dimensionality of each attribute manifold respectively. In this simpler form, we expect the visual elements to correspond to more elementary visual features, rather than to entire objects (<xref ref-type="fig" rid="pcbi-1000495-g001">Fig. 1B</xref>).</p>
<p>The complete probabilistic generative model for image sequences includes probability distributions over the identity and attribute variables. We chose distributions in which objects or features appeared independently of one another, and where the probability of appearance at time <italic>t</italic> depended on whether the same feature appeared at time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e031" xlink:type="simple"/></inline-formula>. The attributes of the feature evolved smoothly, again with a Markovian dependence on the preceding state. The formal definition of the probabilistic model is given in <xref ref-type="sec" rid="s4">Methods</xref>.</p>
<p>The parameters of the model specify the partial images generated by each feature (represented by the basis vectors <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e032" xlink:type="simple"/></inline-formula>), the probability of each feature being active, and the degree of smoothness with which the appearance of the feature evolves. All of these parameters were learnt by fitting the model to natural image sequences. In previous work on sparse coding the number of basis vectors or components needed has been explored outside of the model fitting procedure (for example <xref ref-type="bibr" rid="pcbi.1000495-Olshausen3">[38]</xref>; but see <xref ref-type="bibr" rid="pcbi.1000495-Berkes2">[39]</xref>). Crucially, here we were able to learn the dimensionalities of the model—the numbers of visual elements and associated attribute variables—from the data directly, using Bayesian techniques described below and in <xref ref-type="sec" rid="s4">Methods</xref>.</p>
<p>Probabilistic models are often fit by adjusting the parameters to maximise the probability given to the observed data—called the <italic>likelihood</italic> of the model. In practice, image models have often been fit by maximising the data probability under settings of both the parameters and the unobserved variables (in our case these would be the identity and attribute variables), a procedure which may be severely suboptimal <xref ref-type="bibr" rid="pcbi.1000495-Turner2">[40]</xref>. Here, we adopted an iterative procedure called Variational Bayes Expectation Maximisation (VBEM) <xref ref-type="bibr" rid="pcbi.1000495-Attias1">[41]</xref>,<xref ref-type="bibr" rid="pcbi.1000495-Beal1">[42]</xref> to learn an approximation to the full probability distribution over the parameters and unobserved variables implied by the data—known as the VB <italic>posterior</italic> distribution. This posterior provides a more robust estimate of the parameters, with concomitant estimates of uncertainty, and can be used to determine the appropriate dimensionality of the model directly.</p>
<p>More complex models can always be adjusted to give higher probability to any data set, and so the maximum likelihood approach would always favour a model with greater dimensionality. This effect can lead to <italic>overfitting</italic>, where an overly complex model is selected. However, because there are very many more possible parameter settings in a complex model, any one such parameter setting may actually be very improbable even though it might fit the data well. Thus, when considering the probabilities of parameter settings and models as in the Bayesian approach, a form of “Occam's Razor” comes into effect favouring descriptions complicated enough to capture the data well but no more so <xref ref-type="bibr" rid="pcbi.1000495-MacKay1">[43]</xref>. For models similar to the one developed here, one consequence of this “Occam's Razor” is that the posterior probability distributions on the values of any superfluous basis vectors concentrate tightly about 0, effectively pruning the basis dimension away, and leaving a simpler model. In this context, the effect has been called <italic>Automatic Relevance Determination</italic> or ARD <xref ref-type="bibr" rid="pcbi.1000495-Beal1">[42]</xref>,<xref ref-type="bibr" rid="pcbi.1000495-Bishop1">[44]</xref>.</p>
<p>Bayesian estimation is well-defined only if a <italic>prior</italic> distribution—that is, an initial probability distribution determined before seeing the data—is specified. The prior on the basis vectors was of a form often used with ARD, with a so-called hyperparameter determining the concentration about a mean value of 0. The prior distributions on the parameters that determine the temporal dependence of identity and attribute variables were broad enough not to influence the posterior distribution strongly. The exact definitions of the distributions over parameters, along with details of the fitting algorithm, are given in <xref ref-type="sec" rid="s4">Methods</xref>.</p>
</sec><sec id="s2b">
<title>The model fit to natural images</title>
<p>We used this model to investigate the visual elements that compose natural images, comparing features of the representation learnt by the model when fit to natural image sequences to the representation found in V1. The input data were a subset of the CatCam recordings <xref ref-type="bibr" rid="pcbi.1000495-Betsch1">[45]</xref>, which consist of several-minute-long video sequences recorded by a camera mounted on the head of a cat freely exploring a novel natural environment. Temporal changes in the CatCam videos are caused partly by moving objects, but mostly by the animal's own movement through the environment. Cats make few saccades and use only small eye movements to stabilise the image during locomotion <xref ref-type="bibr" rid="pcbi.1000495-Betsch1">[45]</xref>, so that the amplitude and frequency of spatial transformations in the videos (translation, rotation, and scaling) is similar to that experienced by the animals.</p>
<p>Computational constraints prevented us from modelling the entire video sequence. Instead, we fit the model to the time-series defined by the pixel intensities within fixed windows of size <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e033" xlink:type="simple"/></inline-formula> pixels over 50 frames. We initialised the model with 30 identity variables each associated with attribute manifolds of 6 dimensions and let the algorithm learn an appropriate model size by reducing the number of active attribute dimensions and identity variables by ARD. We performed a total of 500 VBEM iterations, at each iteration taking a new batch of 60 sequences of 50 frames, randomly selected from the entire dataset. Further computational details are given in <xref ref-type="sec" rid="s4">Methods</xref>.</p>
<p>Given an observed image sequence, the model could be used to infer a posterior probability distribution over the values of the identity and attribute variables at each point in time. We compared the means of these distributions to the firing rates of neurons in the visual cortex. The use of the mean was necessarily arbitrary, since there is no generally agreed theory linking probabilistic models to neural activity. The brain may well represent more than a single point from this distribution. For example, information about the uncertainty in that value would be necessary to weight alternative interpretations of the data. Once the model had been fit to the data, however, we found that the attribute variable distributions estimated from high-contrast stimuli were strongly concentrated around their means. Thus, many different choices of neural correlates would have given essentially identical results. It is also worth mentioning here that although the identity variables describe the presence or absence of a feature in the generative model and are thus binary-valued, the posterior probability of the feature being present (which is the same as the posterior mean of the binary identity variable) is continuous. Thus, neurons presumed to encode these posterior means would respond to stimuli with graded responses, which would take uncertainty about feature identity (e.g., under conditions of low contrast) into account.</p>
<p><xref ref-type="fig" rid="pcbi-1000495-g002">Figure 2A</xref> shows the VB posterior mean basis vectors learnt from the CatCam data. Each row displays the basis vectors of the attribute manifold corresponding to a single identity variable. Since the manifold was a hyperplane, the set of possible feature appearances was given by all linear combinations of the basis vectors (<xref ref-type="fig" rid="pcbi-1000495-g003">Fig. 3D</xref>). For every manifold, the mean basis vectors resembled Gabor wavelets with similar positions, orientations, and frequencies, but different phases (<xref ref-type="fig" rid="pcbi-1000495-g004">Fig. 4A–C</xref>). Thus every point on the manifold associated with a single feature corresponded to a Gabor-like image element with similar shape, orientation, and frequency, but variable phase and contrast. When presented with a drifting sine grating of orientation and frequency similar to that of the basis vectors, the probability of the feature being present <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e034" xlink:type="simple"/></inline-formula> was found to approach 1 rapidly, and then to remain constant, while the means of attribute variable distributions oscillated to track the position of the sine grating on the manifold, as illustrated in <xref ref-type="fig" rid="pcbi-1000495-g003">Figure 3</xref>. Attribute variables thus behaved much like simple cells in V1, in that they responded optimally to a grating-like stimulus and oscillated as its phase changed, while identity variables responded like complex cells, being insensitive to the phase of their optimal stimulus. In electrophysiological studies, the classification of neurons into simple and complex cells is done using a <italic>relative modulation</italic> index <xref ref-type="bibr" rid="pcbi.1000495-DeValois1">[46]</xref>,<xref ref-type="bibr" rid="pcbi.1000495-Skottun1">[47]</xref>, which is defined as the ratio of the response modulations (F1) to the mean firing rate (F0) in response to a grating with optimal orientation and frequency, but varying phase. Cells that respond to phase changes with large oscillations have relative modulation larger than 1 and are classified as simple cells, while cells that are invariant to a phase change are classified as complex cells. We computed the relative modulation for the posterior mean values of the variables in our model. All identity units were classified as complex (maximum F1/F0 ratio 0.28) and all attribute units that had not been pruned during learning were classified as simple (minimum F1/F0 ratio 1.45). The magnitude of relative modulations for attribute and identity units is comparable to that found in simple and complex cells in the primary visual cortex of macaque and cat, although the population distribution is narrower <xref ref-type="bibr" rid="pcbi.1000495-Skottun1">[47]</xref> (<xref ref-type="supplementary-material" rid="pcbi.1000495.s002">Fig. S2</xref>). By contrast to the standard energy model of complex cells <xref ref-type="bibr" rid="pcbi.1000495-Adelson1">[48]</xref>, here complex and simple cells did not form a hierarchy, but rather two parallel populations of cells with two different functional roles: the former coding for the presence of oriented features in its receptive fields, the latter parametrising local attributes of the features (primarily their phase).</p>
<fig id="pcbi-1000495-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000495.g002</object-id><label>Figure 2</label><caption>
<title>Basis vectors learnt from natural image sequences, and associated receptive field statistics.</title>
<p>A) The posterior mean basis vectors <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e035" xlink:type="simple"/></inline-formula> spanning the attribute manifold of identity <italic>i</italic> are shown in the <italic>i</italic> th row. Each basis vector has been normalised to improve visibility. Empty grey boxes indicate basis vectors that were pruned by the algorithm. Identity variables are sorted by decreasing spatial frequency and the basis vectors are sorted by increasing precision <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e036" xlink:type="simple"/></inline-formula> (see <xref ref-type="sec" rid="s4">Methods</xref>). The linear RFs corresponding to these basis vectors were visually indistinguishable from the vectors (<xref ref-type="supplementary-material" rid="pcbi.1000495.s001">Fig. S1</xref>). B,D) Distribution of preferred frequency and orientation of the RFs of attribute variables in the model. C) Distribution of preferred frequency of simple cells in area 17 of the cat visual cortex <xref ref-type="bibr" rid="pcbi.1000495-DeAngelis2">[55]</xref>. E) Joint distribution of preferred orientation and frequency in the model.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000495.g002" xlink:type="simple"/></fig><fig id="pcbi-1000495-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000495.g003</object-id><label>Figure 3</label><caption>
<title>Interpretation as complex and simple cells.</title>
<p>A) Basis vectors corresponding to one of the identity variables in the learnt model (row 14 in <xref ref-type="fig" rid="pcbi-1000495-g002">Fig. 2</xref>). B–D) Response to a drifting sine grating at the preferred orientation and frequency. The stimulus is presented starting at phase 0 deg, and removed after it reaches phase 180 deg. B) Response of the identity variable, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e037" xlink:type="simple"/></inline-formula>. C) Response of the attribute variables, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e038" xlink:type="simple"/></inline-formula>. D) Response of the attribute variables as in C, displayed as a trajectory over the 3D attribute manifold.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000495.g003" xlink:type="simple"/></fig><fig id="pcbi-1000495-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000495.g004</object-id><label>Figure 4</label><caption>
<title>Pairwise statistics of the RF properties of attribute variables and simple cells.</title>
<p>A–C) Distribution of orientation, frequency, and phase for RFs computed for pairs of attribute variables associated with the same identity variable. D–F) Similar plots for pairs of simple cell RFs recorded from the same electrode in area 17 of the cat visual cortex. Reproduced with permission from DeAngelis et al., 1999 <xref ref-type="bibr" rid="pcbi.1000495-DeAngelis1">[53]</xref>. Filled circles represent data from adult cats (N = 45), open circles from kittens (N = 21).</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000495.g004" xlink:type="simple"/></fig>
<p>To explore this connection further we compared the properties of simple cell RFs in V1 as reported in the physiological literature with the ‘RFs’ of the attribute variables. The RF of an attribute variable was defined by analogy to the conventional physiological definition. We fixed the posterior distribution over the parameters of the model to that estimated by VBEM from the natural data, and then examined the values of the attribute variables that were inferred given coloured Gaussian noise input. The RF was defined to be the best linear approximation to the mapping from this input to the inferred mean attribute value, a procedure equivalent to finding the “corrected spike-triggered average” or Wiener filter <xref ref-type="bibr" rid="pcbi.1000495-Marmarelis1">[49]</xref> (see <xref ref-type="sec" rid="s4">Methods</xref>). Although nonlinearities in the model and inference meant that these RFs differed slightly from the basis vectors associated with the attribute variables, we found them to be visually indistinguishable (<xref ref-type="supplementary-material" rid="pcbi.1000495.s001">Fig. S1</xref>). We then computed the orientation, spatial frequency and phase for the resulting RFs by fitting a Gabor function to each of the filters (<xref ref-type="sec" rid="s4">Methods</xref>; <xref ref-type="supplementary-material" rid="pcbi.1000495.s001">Fig. S1</xref>).</p>
<p><xref ref-type="fig" rid="pcbi-1000495-g004">Figure 4 (A–C)</xref> shows the orientation, frequency, and phase for each pair of RFs associated with the same identity variable (thus, a feature with a 4-dimensional attribute manifold contributed 6 points to each graph). In the visual cortex, neurons performing related computations appear to be co-located <xref ref-type="bibr" rid="pcbi.1000495-Mountcastle1">[50]</xref>,<xref ref-type="bibr" rid="pcbi.1000495-Pollen1">[51]</xref>. Since the responses of related neurons are highly dependent given a visual stimulus, this may reflect a computationally efficient solution that minimises wiring length <xref ref-type="bibr" rid="pcbi.1000495-Swindale1">[11]</xref>,<xref ref-type="bibr" rid="pcbi.1000495-Chklovskii1">[52]</xref>. We compared our data to the results reported in <xref ref-type="bibr" rid="pcbi.1000495-DeAngelis1">[53]</xref> for pairs of simple cells recorded from the same electrode in area 17 of the cat visual cortex (<xref ref-type="fig" rid="pcbi-1000495-g004">Fig. 4D–F</xref>). In both the model and physiological reports, the two orientations in each pair of RFs agreed very closely; the frequencies slightly less so; while no relation was apparent in phase.</p>
<p>The distribution of preferred frequencies and orientations in the RFs of attribute variables are shown in <xref ref-type="fig" rid="pcbi-1000495-g002">Figure 2 B,D</xref>. The distribution of frequencies is quite broad compared to that found in models based on sparse coding or independent component analysis (ICA) <xref ref-type="bibr" rid="pcbi.1000495-vanHateren1">[16]</xref>,<xref ref-type="bibr" rid="pcbi.1000495-Karklin2">[54]</xref>, where RF frequencies tend to cluster around the highest representable value, and compares well with the width of the distribution in simple cells (<xref ref-type="fig" rid="pcbi-1000495-g002">Fig. 2C</xref>) <xref ref-type="bibr" rid="pcbi.1000495-DeAngelis2">[55]</xref>. The joint distribution of orientation and frequency (<xref ref-type="fig" rid="pcbi-1000495-g002">Fig. 2E</xref>) covers the parameter space relatively homogeneously. Note that the CatCam image sequences have less high-frequency power at horizontal orientations, and this bias is reflected in the results. <xref ref-type="fig" rid="pcbi-1000495-g005">Figure 5</xref> shows the joint distribution of RF width and length in normalised units (number of cycles) in our model and for simple cell RFs as reported by Ringach <xref ref-type="bibr" rid="pcbi.1000495-Ringach1">[56]</xref>,<xref ref-type="bibr" rid="pcbi.1000495-Ringach2">[57]</xref> for area V1 in the macaque. The aspect ratios are similar in both cases (again, contrasting with typical sparse coding results <xref ref-type="bibr" rid="pcbi.1000495-Lcke1">[58]</xref>), although the model results tend to have larger RFs, possibly again due to the particular content of the video.</p>
<fig id="pcbi-1000495-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000495.g005</object-id><label>Figure 5</label><caption>
<title>Receptive field aspect ratio.</title>
<p>Comparison between the joint distribution of normalised RF width and length in our model (blue circles) and as reported by Ringach <xref ref-type="bibr" rid="pcbi.1000495-Ringach1">[56]</xref>,<xref ref-type="bibr" rid="pcbi.1000495-Ringach2">[57]</xref> for cells in area V1 in the macaque (red crosses).</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000495.g005" xlink:type="simple"/></fig>
<p>The model was initialised using a representation that contained 6-dimensional attribute manifolds for each feature. However, in the posterior distribution identified by VBEM, the probability of the basis vectors corresponding to many of these dimensions being non-zero vanished—that is, a model in which the image data were described using fewer dimensions was found to be more probable. In fact, the VB posterior representation was only slightly overcomplete, with 96 basis vectors representing an 81-dimensional input space, and with the dimensionality of most feature manifolds lying between 2 and 4 (<xref ref-type="fig" rid="pcbi-1000495-g006">Fig. 6A</xref>). Given the proposed identification of identity variables with complex cells, this gives a prediction for the dimensionality of the image-subspace to which a V1 complex cell should be sensitive. The subspace-dimensionality of a complex cell may be estimated by finding the number of eigenvalues of the spike-triggered covariance (STC) matrix <xref ref-type="bibr" rid="pcbi.1000495-Schwartz2">[59]</xref> that differ from the overall stimulus distribution. One study <xref ref-type="bibr" rid="pcbi.1000495-Touryan1">[60]</xref> has reported, for complex cells in the anaesthetised cat, a distribution of dimensionalities that peaked sharply at 2, with only a few complex cells being influenced by 1, 3, or 4 dimensions. A more recent paper published by the same group has found a broader distribution in the awake macaque <xref ref-type="bibr" rid="pcbi.1000495-Chen1">[61]</xref>. An analysis of the RFs of the identity variables made using an equivalent procedure revealed a comparable distribution for our results (<xref ref-type="fig" rid="pcbi-1000495-g006">Fig. 6B</xref>). (The number of significant eigenvectors returned by the STC analysis can be slightly different from the dimensionality of the attribute manifold because of the non-linear interactions with other variables in the model.) The model distribution is skewed slightly towards a larger number of stimulus dimensions; although this may be because the sample in <xref ref-type="bibr" rid="pcbi.1000495-Chen1">[61]</xref> included both simple and complex cells. A second study <xref ref-type="bibr" rid="pcbi.1000495-Rust1">[62]</xref> performed a similar analysis using spatio-temporal stimuli and found 2 to 8 significant dimensions for complex cells. This broad range of dimensionalities agrees qualitatively with our results. Unfortunately, quantitative comparison with this study is unreliable as the physiological RFs were identified in effectively one dimension of space, and one of time, while the basis vectors of the attribute manifolds span two spatial dimensions, without a temporal aspect.</p>
<fig id="pcbi-1000495-g006" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000495.g006</object-id><label>Figure 6</label><caption>
<title>Dimensionality of the attribute manifold.</title>
<p>A) Distribution of the dimensionality of the attribute manifold. Attribute filters with norm <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e039" xlink:type="simple"/></inline-formula> were taken to be active. B) Number of significant eigenvalue in an STC analysis as reported in <xref ref-type="bibr" rid="pcbi.1000495-Chen1">[61]</xref> (black) and for our model (blue). The analysis in <xref ref-type="bibr" rid="pcbi.1000495-Chen1">[61]</xref> did not distinguish between simple and complex cells.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000495.g006" xlink:type="simple"/></fig></sec><sec id="s2c">
<title>Temporal stability</title>
<p>A key aspect of our model is the temporal dependence of the identity and attribute variables. To ask what role this temporal structure had on the feature basis vectors found, we shuffled the order of frames in the CatCam database, and then refit the model using exactly the same procedure as before. When using unshuffled data, the learning process adapted the feature manifolds so that the inferred values of identity variables persisted in time, while the inferred attribute variables changed smoothly. In the shuffled data such a persistent and smooth representation cannot be found. Instead, learning adjusts the attribute manifolds so as to maximise the independence of the associated identity variables, grouping together attribute dimensions that tend to co-occur in single frames. This is similar in spirit to Independent Subspace Analysis <xref ref-type="bibr" rid="pcbi.1000495-Hyvrinen1">[63]</xref>, or to a Gaussian Scale Mixture model <xref ref-type="bibr" rid="pcbi.1000495-Wainwright1">[33]</xref> with shared binary-valued scale parameters <xref ref-type="bibr" rid="pcbi.1000495-Schwartz3">[64]</xref>.</p>
<p><xref ref-type="fig" rid="pcbi-1000495-g007">Figure 7</xref> shows the basis vectors and pairwise distributions of their properties found for the shuffled data. The VB posterior distribution concentrated on a more overcomplete representation (122 basis vectors representing 81 input dimensions) than for the unshuffled data. Some manifolds were pruned away entirely, while the majority of those that remained preserved the maximum dimensionality of 6. The basis vectors still resembled oriented features, although the fit of the linear RFs with Gabor wavelets was worse on average than that obtained for the unshuffled video, or seen in physiological data. The fractional error of fit (sum of squares of the residuals divided by the sum of squares of the RFs) was <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e040" xlink:type="simple"/></inline-formula> for simple cells <xref ref-type="bibr" rid="pcbi.1000495-DeAngelis1">[53]</xref>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e041" xlink:type="simple"/></inline-formula> for the model learnt from unshuffled data, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e042" xlink:type="simple"/></inline-formula> in this case (<xref ref-type="fig" rid="pcbi-1000495-g008">Fig. 8</xref>) (see <xref ref-type="supplementary-material" rid="pcbi.1000495.s001">Fig. S1</xref> and <xref ref-type="supplementary-material" rid="pcbi.1000495.s003">S3</xref>, for the reverse-correlation filters and Gabor fits). As shown in <xref ref-type="fig" rid="pcbi-1000495-g007">Figure 7 (b–d)</xref>, attribute variables associated with a single identity still agreed in orientation, but not in phase. However, in contrast to the model learnt from unshuffled sequences and to the physiological results, there was much poorer correspondence in spatial frequency (compare <xref ref-type="fig" rid="pcbi-1000495-g007">Fig. 7C</xref> to <xref ref-type="fig" rid="pcbi-1000495-g004">Fig. 4B,E</xref>). According to their relative modulation index, identity variables would still be classified as complex cells (maximum F1/F0 ratio 0.63), and attribute variables as simple cells (minimum F1/F0 ratio 1.34).</p>
<fig id="pcbi-1000495-g007" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000495.g007</object-id><label>Figure 7</label><caption>
<title>Basis vectors and statistics learnt from time-shuffled data.</title>
<p>A) Basis vectors <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e043" xlink:type="simple"/></inline-formula> as in <xref ref-type="fig" rid="pcbi-1000495-g002">Fig. 2</xref>. B–D) Distribution of orientation, frequency, and phase for pairs of attribute variables associated with the same feature. Cf. <xref ref-type="fig" rid="pcbi-1000495-g004">Fig. 4</xref>. (Data appear clumped in B because of the high-dimensionality of manifolds. Each 6-dimensional feature manifold contributes 15 points to the plot.)</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000495.g007" xlink:type="simple"/></fig><fig id="pcbi-1000495-g008" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000495.g008</object-id><label>Figure 8</label><caption>
<title>Distribution of the fractional error of fit.</title>
<p>Histogram of the fractional error of fit (sum of squares of the residuals divided by the sum of squares of the RFs) in simple cells as reported by DeAngelis <italic>et al.</italic> <xref ref-type="bibr" rid="pcbi.1000495-DeAngelis1">[53]</xref> (black), in the model trained with natural data (blue) and in the model trained with time-shuffled data (red).</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000495.g008" xlink:type="simple"/></fig>
<p>Despite finding a larger number of basis vectors, the model described a larger proportion of the shuffled data as noise, thereby fitting them more poorly. We evaluated the probability given to 50 new batches of 3000 frames each by the parameter distributions learnt from the shuffled and unshuffled data. As estimated by the VB approach, the probability assigned by the unshuffled model was more than <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e044" xlink:type="simple"/></inline-formula> times greater (more precisely, the free-energy—a lower bound on the log probability that is maximised by the VBEM algorithm—was larger by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e045" xlink:type="simple"/></inline-formula> NATS, i.e. between 1.7% and 4.5% greater; <xref ref-type="sec" rid="s4">Methods</xref>). Overall, when deprived of temporal structure in the observations, the algorithm converged to a worse model of the video, and one which was less similar to the physiological data.</p>
<p>It is interesting to note that despite these deficiencies in the representation learnt from shuffled sequences, the basis vectors of the attribute variables still resembled simple cell RFs. This observation stands in contrast to results from previous models of complex cells based on temporal stability, which had assumed a hierarchical organisation similar to the classical energy model <xref ref-type="bibr" rid="pcbi.1000495-Krding1">[25]</xref>,<xref ref-type="bibr" rid="pcbi.1000495-Berkes1">[26]</xref>. In those models the only signal available to shape the simple cell RFs derived from the temporal stability imposed on the corresponding complex cells. If this signal were removed by shuffling the input frames, the simple cells would be unable to develop any sort of organised response. In our model, however, the independence effect discussed above was still able to provide a learning signal for the attribute manifold in the absence of temporal stability. Thus, we predict that even if stimulus temporal correlations were disrupted during learning, for example by rearing animals in a strobe-lit environment, simple-cell responses would still emerge; although the receptive fields (defined by reverse correlation) would fit Gabor wavelets less accurately, and anatomical subunits would be less well-grouped in spatial frequency. In fact, experimental evidence from Area 17 in strobe-reared cat seems to support our results. After strobe rearing at an 8 Hz frequency, the spatial RF structure of simple cells in area 17 remained intact except for their width, which was found to increase; and for direction selectivity, which was mostly lost <xref ref-type="bibr" rid="pcbi.1000495-Humphrey1">[65]</xref>. Studies performed with lower strobe frequencies (0.67–2 Hz) found other changes in the RF properties, including an increase in the number of cells classified as non-oriented, a slight decrease in orientation selectivity, and a reduction of the frequency of binocular cells <xref ref-type="bibr" rid="pcbi.1000495-Cremieux1">[66]</xref>. In addition, given the increase in the dimensionality of the attribute manifold, we predict that an STC analysis of complex cells in strobe-reared animals would show a larger number of relevant dimensions.</p>
</sec></sec><sec id="s3">
<title>Discussion</title>
<p>We have investigated a new generative model for images which makes explicit the separation between the identity of a visual element and the attributes that determine its appearance. This structure within the model makes it possible to extract and bind together attributes that belong to the same visual element, and at the same time to construct an invariant representation of the element itself. We modelled identity with a set of binary-valued variables, each coding for the presence or absence of a different feature. Their appearances were described by manifolds, parametrised by a set of attribute variables. Both identity and attribute variables were assumed to exhibit temporal dependence within image sequences. We were also interested in determining the size of the model, i.e., the number of attribute and identity variables required to optimally describe the input data. This was achieved by performing a Bayesian analysis of the model, which avoids over-fitting and involves defining an appropriate prior distribution over the generating basis vectors. As a result, after convergence of an iterative algorithm, only the basis elements needed to effectively match the data remained active and all redundant attribute directions were pruned away, avoiding overfitting the image data. The algorithm was applied to natural image sequences in order to learn a low-level representation of visual scenes. The filters associated with the individual attribute variables were shown to have characteristics similar to those of simple cells in V1. The RFs of attributes associated with the same identity variable had similar positions, orientations, and frequencies, but different phases. As a consequence, the corresponding identity variable became invariant to phase change and behaved like a complex cell. In the standard energy model of complex cells and in several previous functional models, complex and simple cells form a hierarchy. Simple cells have the role of subunits and are regarded as an intermediate step on the way to the complex cell. Their phase-dependent information is then discarded as a first step towards the construction of an invariant representation. Here complex and simple cells do not form a hierarchy, but rather two parallel interacting populations of cells with two different functional roles: the first coding for the presence or absence of oriented features in its RFs, the latter describing local parameters of the features (mainly their phase). A formal analysis of the model reveals that, indeed, the interaction between identity and attribute variables in our model is richer than in the energy model. In addition to a quadratic term similar to the one in the energy model inside an exponential, the interaction includes a divisive normalisation term, and dependence on the statistics of natural input and the prior probability of the feature encoded by the identity variable being present (<xref ref-type="supplementary-material" rid="pcbi.1000495.s004">Text S1</xref>). Intriguingly, some physiological data <xref ref-type="bibr" rid="pcbi.1000495-Mechler1">[67]</xref> and biophysical models <xref ref-type="bibr" rid="pcbi.1000495-Mel1">[68]</xref>,<xref ref-type="bibr" rid="pcbi.1000495-Chance1">[69]</xref> have also suggested a non-hierarchical relationship between simple and complex cells. However, these results have suggested a spectrum of “simple-” to “complex-like” behaviour within a single population. By contrast, our view preserves the notion of two distinct classes of cell with different response property and computational role, but which are organised in parallel rather than hierarchical populations.</p>
<p>In <xref ref-type="sec" rid="s2">Results</xref>, we showed that properties of RFs learnt within our model agreed with a broad range of existing physiological data. A further aspect of the model could be tested if it were experimentally possible to identify and record simultaneously from a complex cell and the simple cells that form the subspace related to it. First, a direct consequence of the non-hierarchical organisation of complex and simple cells is that increasing the probability of a feature being present in the visual input by stimulating the complex cell should result in the corresponding simple cells becoming active (as they seek to describe the attributes of the feature whose presence has been asserted by activation of the complex cell). This is in contrast to the behaviour implied by the feed-forward energy model, where complex cells would not influence the activity of simple cells. A similar test might exploit the temporal persistence in the identity variable corresponding to the complex cell. Consider two sequences of visual stimuli which both end in a frame well-matched to the RF of one of the simple cells. If the preceding frames had matched the RFs of the other simple cells associated with the same complex cell, and therefore had activated the complex cell, the temporal persistence within the corresponding identity variable should maintain that activation and thereby facilitate the response in the simple cell. Conversely, if the preceding stimuli had fallen outside the feature manifold, the simple cell might be less strongly activated.</p>
<p>The computational power of a class of models similar to the one in this paper has been investigated by Tenenbaum and Freeman <xref ref-type="bibr" rid="pcbi.1000495-Tenenbaum1">[36]</xref>, and Grimes and Rao <xref ref-type="bibr" rid="pcbi.1000495-Grimes1">[37]</xref>. These models were based on the bilinear interaction between two sets of variables: <italic>content</italic> variables, which described the appearance of the input data (e.g., a prototypical handwritten digit, or the appearance of an image patch in a model of visual input), and <italic>style</italic> variables, which parametrised transformations of the content (e.g., the style of the digit or global translations of the patch). Tenenbaum and Freeman <xref ref-type="bibr" rid="pcbi.1000495-Tenenbaum1">[36]</xref> showed that the rich nonlinear interactions between these two factors facilitated classification and extrapolation in a series of experiments using spoken vowels, letters in different fonts, and faces in different poses. Grimes and Rao <xref ref-type="bibr" rid="pcbi.1000495-Grimes1">[37]</xref> assumed a sparse prior distribution over content and style variables, and applied the model to translated natural images. The learnt basis vectors were shown to represent oriented features and to be largely invariant to local translation. Although learning was based on natural images, content and style play mathematically symmetric roles within these models, and thus could not be identified from the images alone. Instead, the content and style variables were partially fixed, so that all that needed to be learnt were the corresponding basis vectors and transformations. In this paper, the semantic difference between the identity and attribute variables, and the temporal persistence assumption, meant that the model could be learned in a completely unsupervised fashion from natural movies. In our model, the input images result from the combination of multiple visual elements, identified by the identity variables. The appearance and transformation of each of these elements is separately encoded by the associated attribute variables. Thus, the role of the attributes is a combination of the role of content and style variables in the previous models.</p>
<p>In the model described here, the appearance manifolds associated with each feature are linear, and they combine additively to form the image. These choices are a matter of computational tractability, and have two main limitations. First, the additive combination function <italic>f</italic> is unable to model effects such as occlusion, shadowing, or reflective illumination. Linear models like sparse coding and ICA also assume the same kind of linear superposition, and it is unclear at this stage how much a more realistic <italic>f</italic> would influence the results at the level of small image patches <xref ref-type="bibr" rid="pcbi.1000495-Lcke2">[70]</xref>. Second, the linear feature manifolds do not allow global transformations of feature appearance, such as translation or rotation, to be captured by a single attribute dimension. Each attribute is, at best, able only to model a local, linearised version of the transform. However, global properties may still be approximated using several attribute dimensions, or by a hierarchical model in which a higher-order feature with a global translation attribute generates local features where needed at a lower level (cf. <xref ref-type="bibr" rid="pcbi.1000495-Ross1">[71]</xref>). Another simplification concerns the temporal aspect of V1 RFs. As in most computational models of V1 neurons, we did not attempt to match the temporal behaviour of early visual neurons, again because of computational constraints. Currently, the model defines a Markov temporal dependency for the variables in the model, which is intended to capture a simple timescale of persistence. This temporal model implicitly defines a spatio-temporal receptive field (STRF) for attribute and identity variables. However, the Markov assumption does not allow the model to express the more complex temporal behaviours observed in V1 neurons, such as direction selectivity. Instead, the resulting STRF is formed by the spatial RF, as shown in <xref ref-type="supplementary-material" rid="pcbi.1000495.s001">Fig. S1</xref> B, decaying exponentially in time. In previous work, temporally extended RFs have been modelled by augmenting the input data with the pixel intensities of patches at neighbouring times, and then building a model of the augmented data set <xref ref-type="bibr" rid="pcbi.1000495-Berkes1">[26]</xref>,<xref ref-type="bibr" rid="pcbi.1000495-vanHateren2">[72]</xref>. However, from a generative point of view this does not seem to be appropriate, as the model would independently generate pixel intensities in overlapping temporal windows, which would give multiple inconsistent proposals for the pixels values at any particular time. In our case, we would need to use a more complex model of temporal dependencies, for example by allowing temporal dependencies between attribute variables in the prior (i.e., by defining matrix <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e046" xlink:type="simple"/></inline-formula> in Eq. 9 to be full instead of diagonal, or by introducing a non-Markov structure).</p>
<p>It may be possible to extend the model developed here so as to represent more complex visual elements. One approach is illustrated in <xref ref-type="fig" rid="pcbi-1000495-g009">Figure 9:</xref> In the schematic, high-level identity variables may represent entire objects. These generate lower-order elements, like parts of an object or image features. For example, the activation of an identity variable corresponding to a face would activate, with high probability at the lower level, variables coding for the presence of eyes, nose, and mouth. Similarly, high-level attributes, like the size and viewpoint of the face, would influence low-level attributes such as the position of its individual parts, and may also determine which parts are visible. The hierarchy may then be repeated down to individual image features. Such a hierarchical organisation would be closely related to the hierarchical nature of the environment. The connections between higher-order and lower-order identity variables, for example, would encode whole-part relationships, while the connections between higher- and lower-order attributes would encode structural constraints between the individual parts necessary to form the whole. Such a structure would allow the visual system to benefit from the advantages of a recognition-by-components architecture, including the ability to reuse known parts to form novel objects, and to express the wide range of possible configurations of articulate objects <xref ref-type="bibr" rid="pcbi.1000495-Ross1">[71]</xref>,. The computer vision community has long been interested in the analysis of images for the categorisation and recognition of objects. A recent trend in the field has been to build hierarchical generative models of objects composed of sub-parts; this line of research has found that such a hierarchical representation can indeed increase the performance of the algorithm <xref ref-type="bibr" rid="pcbi.1000495-Zhu1">[74]</xref>–<xref ref-type="bibr" rid="pcbi.1000495-Sudderth2">[77]</xref>. These computer vision models generally start by describing the image using a standard, fixed set of features, and pre-specify the transformations that these can undergo; the object model may also be pre-specified <xref ref-type="bibr" rid="pcbi.1000495-Zhu1">[74]</xref> or may be learnt from data <xref ref-type="bibr" rid="pcbi.1000495-Sudderth1">[75]</xref>–<xref ref-type="bibr" rid="pcbi.1000495-Sudderth2">[77]</xref>. Moreover, categorisation is typically supervised. Our approach is in many ways complementary, in that it starts from the bottom up, and requires no supervision (see <xref ref-type="bibr" rid="pcbi.1000495-Lcke2">[70]</xref>,<xref ref-type="bibr" rid="pcbi.1000495-Jojic1">[78]</xref>,<xref ref-type="bibr" rid="pcbi.1000495-Williams1">[79]</xref> for comparable bottom-up computer vision approaches). Our results show that it is possible to learn simple but meaningful features from natural images, and at the same time learn the transformations that they are subject to in natural vision. It remains to be shown, however, whether our method can be extended successfully to represent more complex objects.</p>
<fig id="pcbi-1000495-g009" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000495.g009</object-id><label>Figure 9</label><caption>
<title>Schematic illustration of a two-layer identity/attributes hierarchy.</title>
<p>The dotted line represents cases where the attributes influence the presence of objects parts. For example, in the case a face seen from behind, nose, mouth, and eyes would not be visible and thus would not need to be generated.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000495.g009" xlink:type="simple"/></fig>
<p>Algorithms related to the temporal stability principle have also been applied with some success to learning a high-level object representation <xref ref-type="bibr" rid="pcbi.1000495-Wiskott1">[27]</xref>, <xref ref-type="bibr" rid="pcbi.1000495-Einhuser1">[80]</xref>–<xref ref-type="bibr" rid="pcbi.1000495-Stringer1">[82]</xref>. In <xref ref-type="bibr" rid="pcbi.1000495-Einhuser1">[80]</xref>,<xref ref-type="bibr" rid="pcbi.1000495-Stringer1">[82]</xref>, the representation is invariant to frequent transformations, such as translation, and the corresponding attribute information (e.g., position) is discarded. In <xref ref-type="bibr" rid="pcbi.1000495-Wiskott1">[27]</xref>,<xref ref-type="bibr" rid="pcbi.1000495-Franzius1">[81]</xref> it is shown that the representation learnt by the Slow Feature Analysis algorithm preserves the attribute information. However, the model does not make any semantic distinction between variables carrying these two kind of information, so that a readout system downstream of the sensory cortex would need an additional criterion in order to access them. We believe that the additional structure in our model will help in extracting a high-level representation of objects from natural scenes. Moreover, a readout system would have access to more structured information about the environment, and could access differentially the identity information – for example in recognition tasks, as identity is invariant to all possible appearances parametrised by the attributes – and the attributes – for example, to guide reaching behaviour.</p>
<p>In the <xref ref-type="sec" rid="s1">introduction</xref> we discussed how it is possible to interpret functional models based on constrained optimisation of an objective function from a generative perspective. From this point of view, concentrating on a single computational objective appears rather simplistic, given the complexity underlying any natural scene. We argued that by developing models in the generative framework, one is able to develop models of vision that are closer to the true visual generative process. A common critique of the generative approach is that it seeks to model every aspect of its input, while the visual system might be interested in extracting only a behaviourally relevant subset of the sensory information. This argument implicitly assumes that it would be easier and more useful for the visual system to extract only relevant information (e.g., object position) while ignoring “nuisance” information (e.g., light reflections). On the other hand, the representation formed by the visual system has to be used for many different tasks, and as such it is almost impossible to decide a priori which information should be discarded. A complete generative account of the visual data is more flexible as it identifies and separates all the different causal influences that contribute to the scene, and makes them available for context-specific processing. By contrast, a system that selectively discards parts of the visual signal might find it difficult to adapt when that discarded information became relevant (e.g., in an hypothetical task where light reflection predicts reward). Moreover, it is in principle possible to define <italic>partial</italic> generative descriptions of the visual signal. The key is that generative models explain their input probabilistically up to a certain level of “noise” (e.g., the term <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e047" xlink:type="simple"/></inline-formula> in Eq. 1). The noise term includes genuine noise in the input and more generally all aspects of the input that the model can not capture, or is not interested in capturing. Thus, by building a more complex model of noise, a generative model could selectively describe only the subset of aspects of the stimuli that it considers relevant: Suppose that in one task, all that was important was the identity of a visual feature, not its specific appearance. Then the attributes in our model would be regarded as “nuisance” variables. Ideal inference about the identities would proceed by integrating over the uncertainty in the “nuisance” variables – in essence, they would form part of a complex noise model. This integration may be explicit (and possibly approximate) as in our VB implementation. It may also be implicit in a model with a more flexible definition for the noise (e.g., by learning different noise parameters for different dimensions).</p>
<p>This paper has presented a first step toward including constraints regarding the structure of the visual environment in computational models of vision. By taking into account the conceptual distinction between identity and attributes of visual elements, we were able to match more closely the physiological and anatomical organisation of V1. Further steps in this direction will hopefully lead us toward the development of a more complete, probabilistic account of visual inference.</p>
</sec><sec id="s4">
      <title>Methods</title>

      <sec id="s4a">
         <title>Model specification</title>

         <p>The generative model describes the probability of a sequence <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e048" xlink:type="simple"/></inline-formula> of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e049" xlink:type="simple"/></inline-formula> image patches, each one described by a vector of pixel intensities <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e050" xlink:type="simple"/></inline-formula>, in terms of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e051" xlink:type="simple"/></inline-formula> binary-valued identity variables <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e052" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e053" xlink:type="simple"/></inline-formula> associated attribute vectors, each of dimensionality <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e054" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e055" xlink:type="simple"/></inline-formula>.</p>
         <p>The generative process maps these hidden identity and attribute variables to observations according to Eq. 2. Assuming Gaussian noise with variance <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e056" xlink:type="simple"/></inline-formula> along observed dimension <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e057" xlink:type="simple"/></inline-formula>, corresponding to a diagonal covariance matrix <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e058" xlink:type="simple"/></inline-formula>, the probability of observing an input sequence conditioned on a setting of the hidden variables is:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e059" xlink:type="simple"/><label>(3)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e060" xlink:type="simple"/></inline-formula> denotes a Gaussian distribution over <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e061" xlink:type="simple"/></inline-formula> with mean <bold><italic>μ</italic></bold> and covariance <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e062" xlink:type="simple"/></inline-formula>.</p>
         <p>The prior distributions over the variables were defined according to the intuitions described in the <xref ref-type="sec" rid="s1">introduction</xref>, namely that visual elements should appear independently of one another and for extended periods of time, and their appearances should vary smoothly. This was translated into a prior distribution over identity and attribute variables as follows. Identity variables were modelled as independent, binary Markov chains with initial-state probabilities <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e063" xlink:type="simple"/></inline-formula> and a transition matrix <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e064" xlink:type="simple"/></inline-formula> comprising probabilities <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e065" xlink:type="simple"/></inline-formula>:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e066" xlink:type="simple"/><label>(4)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e067" xlink:type="simple"/><label>(5)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e068" xlink:type="simple"/><label>(6)</label></disp-formula></p>
         <p>Our intuition that objects are persistent in time is respected when the probability of remaining in the current state is larger than that of switching, i.e. when the transition probabilities <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e069" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e070" xlink:type="simple"/></inline-formula> are larger than <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e071" xlink:type="simple"/></inline-formula>. While comparable results may have been obtained by setting these parameters to a suitable value, we chose to remain within the Bayesian approach and instead expressed our belief as a prior distribution over values of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e072" xlink:type="simple"/></inline-formula> (specified below). The attribute variables are continuous and their evolution was modelled by Linear State Space Models with initial variances <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e073" xlink:type="simple"/></inline-formula>, transition matrices <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e074" xlink:type="simple"/></inline-formula> and transition variances <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e075" xlink:type="simple"/></inline-formula>:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e076" xlink:type="simple"/><label>(7)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e077" xlink:type="simple"/><label>(8)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e078" xlink:type="simple"/></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e079" xlink:type="simple"/><label>(9)</label></disp-formula></p>
         <p>The matrices <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e080" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e081" xlink:type="simple"/></inline-formula> were defined to be diagonal, so that attributes were uncorrelated; and were related by the equation <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e082" xlink:type="simple"/></inline-formula>, so that the variance of the attribute variables was 1 in the prior <xref ref-type="bibr" rid="pcbi.1000495-Turner1">[35]</xref>. This imposed an absolute scale, eliminating rescaling degeneracy. Slowly-varying variables have a positive autocorrelation, and would thus have parameters <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e083" xlink:type="simple"/></inline-formula> between 0 and 1, with larger values corresponding to slower variables. Again, we expressed the belief in smoothness softly, by imposing a suitable prior distribution over these parameters (see below).</p>
         <p>The priors on the basis vectors <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e084" xlink:type="simple"/></inline-formula> were Gaussian, with precision hyperparameters <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e085" xlink:type="simple"/></inline-formula>:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e086" xlink:type="simple"/><label>(10)</label></disp-formula></p>
         <p>These zero-centred Gaussian prior distributions discouraged large components within the basis vectors. The widths of the distributions are set by the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e087" xlink:type="simple"/></inline-formula> which were learnt alongside the other parameters. This choice of prior <xref ref-type="bibr" rid="pcbi.1000495-Turner1">[35]</xref> leads to a pruning of basis vectors during learning, through ARD <xref ref-type="bibr" rid="pcbi.1000495-Beal1">[42]</xref>,<xref ref-type="bibr" rid="pcbi.1000495-Bishop1">[44]</xref>. Since the basis vectors of redundant attribute dimensions are free to match the prior, and as this is centred on the origin, they are driven to zero. The precision hyperparameter can then diverge to infinity, effectively eliminating the basis dimension from the model. As a result, only the dimensions of the attribute manifold that were required to describe the data without overfitting remained active after learning.</p>
         <p>For the remaining parameters we also chose conjugate priors. Conjugacy means that the posterior distribution has the same functional form as the prior, resulting in tractable integrals. Conjugate priors are intuitively equivalent to having previously observed a number of imaginary <italic>pseudo-observations</italic> under the model. By choosing the number of pseudo-observations we can regulate how informative the prior becomes. In summary, the prior over the image noise precision <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e088" xlink:type="simple"/></inline-formula> was taken to be a gamma distribution with parameters <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e089" xlink:type="simple"/></inline-formula>, the prior over the transition matrix <italic>T</italic> was Dirichlet with parameters <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e090" xlink:type="simple"/></inline-formula>, and the prior over <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e091" xlink:type="simple"/></inline-formula> was a nonstandard distribution (due to the coupling between mean and variance of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e092" xlink:type="simple"/></inline-formula>) in the exponential family that required 4 hyperparameters to be specified (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e093" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e094" xlink:type="simple"/></inline-formula>). The complete directed graphical model showing the dependencies between variables is depicted in <xref ref-type="fig" rid="pcbi-1000495-g010">Figure 10</xref>.</p>
         <fig id="pcbi-1000495-g010" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000495.g010</object-id><label>Figure 10</label>
            <caption>
               <title>Directed graphical model representing the distribution of a single video frame.</title>
               <p>Circles represent random variables, and squares represent hyperparameters; the grey-shaded circle represents the observed image; light grey nodes and symbols represent variables associated with neighbouring frames. The variables within the dashed rectangular box are those associated solely with the <italic>t</italic> th frame, and are replicated <italic>T</italic> times (the length of an input sequence) in the complete model.</p>
            </caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000495.g010" xlink:type="simple"/></fig>
      </sec>
      <sec id="s4b">
         <title>Learning algorithm</title>

         <p>In the Bayesian formulation the parameters of the model are formally equivalent to hidden variables, differing only in that their number does not increase with the number of data points. The goal of learning is then to infer the posterior joint distribution over variables and parameters given the data:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e095" xlink:type="simple"/><label>(11)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e096" xlink:type="simple"/></inline-formula> indicates the ensemble of all parameters and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e097" xlink:type="simple"/></inline-formula> all hyper-parameters (in the following for simplicity we will omit the dependence on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e098" xlink:type="simple"/></inline-formula>). Although this distribution is intractable (as in most non-trivial models), it is possible to use a <italic>structured variational approximation</italic> to obtain a tractable alternative. The idea is to introduce a new factored distribution <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e099" xlink:type="simple"/></inline-formula> in which some dependencies between the variables are neglected, while keeping the rest of the distribution intact. Learning proceeds by functional maximisation of the <italic>free energy</italic>, i.e., the lower bound on the marginal likelihood<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e100" xlink:type="simple"/><label>(12)</label></disp-formula></p>
         <p>The maximisation over <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e101" xlink:type="simple"/></inline-formula> can be understood as the minimisation of the Kullback-Leibler divergence between the factorised and the real posteriors <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e102" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pcbi.1000495-Beal1">[42]</xref>,<xref ref-type="bibr" rid="pcbi.1000495-Neal1">[83]</xref>.</p>
         <p>The key factorisation underlying the VBEM algorithm Beal2003 is the one between hidden variables and parameters<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e103" xlink:type="simple"/><label>(13)</label></disp-formula></p>
         <p>Given this basic factorisation, the algorithm proceeds in a way similar to Expectation Maximisation (EM) by iteratively inferring the hidden variable distribution <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e104" xlink:type="simple"/></inline-formula> given the observations and averaging over the parameters (E-Step); and the parameter distribution <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e105" xlink:type="simple"/></inline-formula> given the observations and averaging over the hidden variables (M-Step). We needed two further factorisations to achieve a tractable algorithm: one between the distribution over basis vectors and input noise, and one between different identity variables at different times (i.e., <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e106" xlink:type="simple"/></inline-formula>). Note that these approximations do not completely eliminate dependencies between the factorised variables, which still influence each other through their sufficient statistics (for example their means). In particular, the method is much less constraining than the commonly used approach of Maximum A Posteriori (MAP) estimation, where the entire posterior distribution is collapsed to a single point by taking the values of variables and parameters at the mode. Although the derivation of the learning equations requires long algebraic computations, they are derived from the VBEM setting without any noteworthy deviation, and are described in <xref ref-type="supplementary-material" rid="pcbi.1000495.s005">Text S2</xref>.</p>
      </sec>
      <sec id="s4c">
         <title>Computational details and hyperparameter values</title>

         <p>The input data to our model were taken from the CatCam videos <xref ref-type="bibr" rid="pcbi.1000495-Betsch1">[45]</xref>. Since some sections of the video contain recording defects (block artifacts or pixel saturation), we selected a subset that showed minimal distortion (labelled b0811lux in the dataset). Observations <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e107" xlink:type="simple"/></inline-formula> comprised the time-series of pixel intensities in fixed windows of size <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e108" xlink:type="simple"/></inline-formula> pixels. The windows were placed to cover (without overlap) the central <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e109" xlink:type="simple"/></inline-formula> region of the video. In this way we obtained a total of about 300,000 frames. The input data were preprocessed by removing the mean of each frame to eliminate global changes in luminance and to compensate for the camera's global gain control mechanism. The data were then reduced in dimensionality from 400 to 81 dimensions with equalised variances, using principal components analysis (PCA). Due to the self-similar structure of natural images <xref ref-type="bibr" rid="pcbi.1000495-Field1">[22]</xref>, this was spatially equivalent to applying the model to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e110" xlink:type="simple"/></inline-formula> patches. The resulting vectors, however, were smoother and easier to analyse, since the square shape of the pixels became less important. Moreover, starting with larger patches allowed us to capture the temporal correlations that arose during faster movements of the cat (e.g., fast head movements), which would have been impossible with small patch sizes. The variance equalisation (common in image modelling) helped with convergence. It is unlikely to have affected the final result as it is a linear operation for which the learning algorithm could easily compensate. This has been confirmed in a run performed without dimensionality reduction (<xref ref-type="supplementary-material" rid="pcbi.1000495.s006">Text S3</xref>).</p>
         <p>We initialised the model with 30 identity variables (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e111" xlink:type="simple"/></inline-formula>) and attribute manifolds of 6 dimensions (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e112" xlink:type="simple"/></inline-formula>) and let the algorithm learn the model size by reducing the number of active attribute dimensions by ARD hyperparameter optimisation. The mean of the basis vectors <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e113" xlink:type="simple"/></inline-formula> were initialised at random on the unit sphere, and the priors over the parameters were chosen to be non-informative for the input noise (1 pseudo-observation, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e114" xlink:type="simple"/></inline-formula>) and more informative for the dynamic parameters (2000 pseudo-observations), favouring persistent identity variables and slowly-varying attributes (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e115" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e116" xlink:type="simple"/></inline-formula>). (Although we have no reason to think that attribute variables should have different timescales, the small differences in the value of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e117" xlink:type="simple"/></inline-formula> kept the model from being degenerate, in the sense that every rotation of the identity subspace would otherwise be equally optimal.) We performed 500 VBEM iterations, at each iteration using a new batch of 60 sequences of 50 consecutive frames taken at random from the entire dataset. After 300 iterations we started learning the precision parameters <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e118" xlink:type="simple"/></inline-formula>, updating their values every 20 iterations.</p>
         <p>Parameters were identical for the fit to shuffled data, the only difference being that the selected frames were not consecutive in time. At the end of the VBEM iterations we compared the free energy of the original model to that of the time-shuffled model on a novel set of 50 batches of 3000 frames each, taken from the CatCam data as described above. The free energies were computed for each batch separately.</p>
         <p>We also ran one additional fit (not shown) to check that the results obtained for shuffled data were not strongly influenced by our choice of priors on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e119" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e120" xlink:type="simple"/></inline-formula>, for which we took <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e121" xlink:type="simple"/></inline-formula> with 1 pseudo-observation, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e122" xlink:type="simple"/></inline-formula> = 0.5 with 1 pseudo-observation. The results obtained were very close to those shown for the shuffled data.</p>
      </sec>
      <sec id="s4d">
         <title>RF fitting</title>

         <p>In order to compare the properties of the learnt units to those of cortical neurons we proceeded in a way similar to that reported in the experimental literature. In electrophysiological recordings one does not have access to the complete input-output function of a neuron, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e123" xlink:type="simple"/></inline-formula>, or to the equivalent of our basis functions, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e124" xlink:type="simple"/></inline-formula>. Typically, one computes the best linear approximation <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e125" xlink:type="simple"/></inline-formula> to the input-output function by spike-triggered averaging <xref ref-type="bibr" rid="pcbi.1000495-Marmarelis1">[49]</xref>,<xref ref-type="bibr" rid="pcbi.1000495-deRuytervanSteveninck1">[85]</xref>. We derived the linear RFs <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e126" xlink:type="simple"/></inline-formula> of the attribute variables by presenting coloured noise stimuli with the same spectrum as natural images and computing the correlation between stimulus and response. In practice, this was done by doing standard white-noise reverse correlation in the PCA space. Since the dimensionality of the image patches has been equalised for variance, white-noise stimuli in the PCA space have the same spectrum as natural images when projected back to the image space.</p>
         <p>Given coloured noise data <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e127" xlink:type="simple"/></inline-formula>, we inferred the posterior distribution of identity and attribute variable using the VBEM algorithm, where the distribution over parameters was kept fixed to the one inferred during the learning phase (i.e., we only performed the E-step of the algorithm). The signal was reverse-correlated with the mean of the distribution over each attribute variable,<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e128" xlink:type="simple"/><label>(14)</label></disp-formula></p>
         <p>For visualisation and analysis, the filters were projected back in image space using the pseudoinverse of the PCA matrix.</p>
         <p>Optimal parameters for the RFs derived in this way were computed by fitting a Gabor function to them. Gabor functions are defined as<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e129" xlink:type="simple"/><label>(15)</label></disp-formula>where<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e130" xlink:type="simple"/><label>(16)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e131" xlink:type="simple"/><label>(17)</label></disp-formula></p>
         <p>The parameters <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e132" xlink:type="simple"/></inline-formula> are the amplitude, coordinates of the centre, orientation, frequency, standard deviations of the axes of the Gaussian envelope, and phase of the grating. To avoid local minima we performed multiple fits starting at 10 different orientations between 0 and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e133" xlink:type="simple"/></inline-formula> and 10 different phases between 0 and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e134" xlink:type="simple"/></inline-formula>, and kept the parameters with minimal mean squared error for all 100 fits. Phase differences in the RFs of attribute variables (<xref ref-type="fig" rid="pcbi-1000495-g004">Fig. 4C</xref>, <xref ref-type="fig" rid="pcbi-1000495-g007">7D</xref>) were estimated by fixing the global orientation and frequency of an entire attribute manifold to the one of the best fitted RF (minimal mean squared error), and re-fitting only the phase parameter to the RFs of the other attribute variables. The normalised widths and lengths reported in <xref ref-type="fig" rid="pcbi-1000495-g005">Figure 5</xref> were defined as the product of the frequency of the Gabor function and the standard deviations of the axes of the Gaussian envelope, i.e., <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e135" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000495.e136" xlink:type="simple"/></inline-formula><xref ref-type="bibr" rid="pcbi.1000495-Ringach1">[56]</xref>.</p>
      </sec>
   </sec><sec id="s6">
<title>Supporting Information</title>
<supplementary-material id="pcbi.1000495.s001" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000495.s001" xlink:type="simple"><label>Figure S1</label><caption>
<p>Basis vectors, filters, and Gabor fit of the main experiment</p>
<p>(0.08 MB PDF)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1000495.s002" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000495.s002" xlink:type="simple"><label>Figure S2</label><caption>
<p>Comparison of the distribution of relative modulation in our results and in electrophysiological experiments</p>
<p>(0.01 MB PDF)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1000495.s003" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000495.s003" xlink:type="simple"><label>Figure S3</label><caption>
<p>Basis vectors, filters, and Gabor fit for the time-shuffled experiment</p>
<p>(0.08 MB PDF)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1000495.s004" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000495.s004" xlink:type="simple"><label>Text S1</label><caption>
<p>Relation to the energy model of complex cells</p>
<p>(0.03 MB PDF)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1000495.s005" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000495.s005" xlink:type="simple"><label>Text S2</label><caption>
<p>Technical details of the identity/attribute model</p>
<p>(0.17 MB PDF)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1000495.s006" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000495.s006" xlink:type="simple"><label>Text S3</label><caption>
<p>Effect of dimensionality reduction</p>
<p>(0.19 MB PDF)</p>
</caption></supplementary-material></sec></body>
<back>
<ack>
<p>We thank Peter Latham and Yee Whye Teh for valuable comments on the manuscript, and Jörg Lücke for help with <xref ref-type="fig" rid="pcbi-1000495-g005">Figure 5</xref>.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1000495-Hubel1"><label>1</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Hubel</surname><given-names>DH</given-names></name>
<name name-style="western"><surname>Wiesel</surname><given-names>TN</given-names></name>
</person-group>             <year>1963</year>             <article-title>Receptive fields of cells in striate cortex of very young, visually inexperienced kittens.</article-title>             <source>Journal of Neurophysiology</source>             <volume>26</volume>             <fpage>994</fpage>             <lpage>1002</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Hirsch1"><label>2</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Hirsch</surname><given-names>HVB</given-names></name>
<name name-style="western"><surname>Spinelli</surname><given-names>DN</given-names></name>
</person-group>             <year>1970</year>             <article-title>Visual experience modifies distribution of horizontally and vertically oriented receptive fields.</article-title>             <source>Science</source>             <volume>168</volume>             <fpage>869</fpage>             <lpage>871</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Blakemore1"><label>3</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Blakemore</surname><given-names>C</given-names></name>
<name name-style="western"><surname>Cooper</surname><given-names>GF</given-names></name>
</person-group>             <year>1970</year>             <article-title>Development of the brain depends on the visual environment.</article-title>             <source>Nature</source>             <volume>228</volume>             <fpage>477</fpage>             <lpage>478</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Miller1"><label>4</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Miller</surname><given-names>KD</given-names></name>
<name name-style="western"><surname>Erwin</surname><given-names>E</given-names></name>
<name name-style="western"><surname>Kayser</surname><given-names>A</given-names></name>
</person-group>             <year>1999</year>             <article-title>Is the development of orientation selectivity instructed by activity?</article-title>             <source>Journal of Neurobiology</source>             <volume>41</volume>             <fpage>44</fpage>             <lpage>57</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Sengpiel1"><label>5</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Sengpiel</surname><given-names>F</given-names></name>
<name name-style="western"><surname>Stawinski</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Bonhoeffer</surname><given-names>T</given-names></name>
</person-group>             <year>1999</year>             <article-title>Influence of experience on orientation maps in cat visual cortex.</article-title>             <source>Nature Neuroscience</source>             <volume>2</volume>             <fpage>727</fpage>             <lpage>732</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Tanaka1"><label>6</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Tanaka</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Ribot</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Imamura</surname><given-names>K</given-names></name>
<name name-style="western"><surname>Tani</surname><given-names>T</given-names></name>
</person-group>             <year>2006</year>             <article-title>Orientation-restricted continuous visual exposure induces marked reorganization of orientation maps in early life.</article-title>             <source>NeuroImage</source>             <volume>30</volume>             <fpage>462</fpage>             <lpage>477</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-vonderMalsburg1"><label>7</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>von der Malsburg</surname><given-names>C</given-names></name>
</person-group>             <year>1973</year>             <article-title>Self-organization of orientation sensitive cells in the striate cortex.</article-title>             <source>Kybernetik</source>             <volume>14</volume>             <fpage>85</fpage>             <lpage>100</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Linsker1"><label>8</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Linsker</surname><given-names>R</given-names></name>
</person-group>             <year>1986</year>             <article-title>From basic network principles to neural architecture (series).</article-title>             <source>Proceedings of the National Academy of Sciences of the United States of America</source>             <volume>83</volume>             <fpage>8390</fpage>             <lpage>8394</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Miller2"><label>9</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Miller</surname><given-names>KD</given-names></name>
<name name-style="western"><surname>Keller</surname><given-names>JB</given-names></name>
<name name-style="western"><surname>Stryker</surname><given-names>MP</given-names></name>
</person-group>             <year>1989</year>             <article-title>Ocular dominance column development: analysis and simulation.</article-title>             <source>Science</source>             <volume>245</volume>             <fpage>605</fpage>             <lpage>615</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Goodhill1"><label>10</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Goodhill</surname><given-names>GJ</given-names></name>
<name name-style="western"><surname>Willshaw</surname><given-names>DJ</given-names></name>
</person-group>             <year>1990</year>             <article-title>Application of the elastic net algorithm to the formation of ocular dominance stripes.</article-title>             <source>Network: Computation in Neural Systems</source>             <volume>1</volume>             <fpage>41</fpage>             <lpage>59</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Swindale1"><label>11</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Swindale</surname><given-names>NV</given-names></name>
</person-group>             <year>1996</year>             <article-title>The development of topography in the visual cortex: a review of models.</article-title>             <source>Network: Computation in Neural Systems</source>             <volume>7</volume>             <fpage>161</fpage>             <lpage>274</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Kayser1"><label>12</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kayser</surname><given-names>AS</given-names></name>
<name name-style="western"><surname>Miller</surname><given-names>KD</given-names></name>
</person-group>             <year>2002</year>             <article-title>Opponent inhibition: A developmental model of layer 4 of the neocortical circuit.</article-title>             <source>Neuron</source>             <volume>33</volume>             <fpage>131</fpage>             <lpage>142</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Attneave1"><label>13</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Attneave</surname><given-names>F</given-names></name>
</person-group>             <year>1954</year>             <article-title>Informational aspects of visual perception.</article-title>             <source>Psychological Review</source>             <volume>61</volume>             <fpage>183</fpage>             <lpage>193</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Barlow1"><label>14</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Barlow</surname><given-names>HB</given-names></name>
</person-group>             <year>1961</year>             <article-title>Possible principles underlying the transformations of sensory messages.</article-title>             <person-group person-group-type="editor">
<name name-style="western"><surname>Rosenblith</surname><given-names>WA</given-names></name>
</person-group>             <source>Sensory Communication</source>             <publisher-name>MIT Press</publisher-name>             <fpage>217</fpage>             <lpage>234</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Bell1"><label>15</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Bell</surname><given-names>AJ</given-names></name>
<name name-style="western"><surname>Sejnowski</surname><given-names>TJ</given-names></name>
</person-group>             <year>1997</year>             <article-title>The ‘independent components’ of natural scenes are edge filters.</article-title>             <source>Vision Research</source>             <volume>37</volume>             <fpage>3327</fpage>             <lpage>3338</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-vanHateren1"><label>16</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>van Hateren</surname><given-names>JH</given-names></name>
<name name-style="western"><surname>van der Schaaf</surname><given-names>A</given-names></name>
</person-group>             <year>1998</year>             <article-title>Independent component filters of natural images compared with simple cells in primary visual cortex.</article-title>             <source>Proceedings of the Royal Society London B</source>             <volume>265</volume>             <fpage>359</fpage>             <lpage>366</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Hoyer1"><label>17</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Hoyer</surname><given-names>PO</given-names></name>
<name name-style="western"><surname>Hyvärinen</surname><given-names>A</given-names></name>
</person-group>             <year>2000</year>             <article-title>Independent component analysis applied to feature extraction from colour and stereo images.</article-title>             <source>Network: Computation in Neural Systems</source>             <volume>11</volume>             <fpage>191</fpage>             <lpage>210</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Barlow2"><label>18</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Barlow</surname><given-names>H</given-names></name>
</person-group>             <year>2001</year>             <article-title>The exploitation of regularities in the environment by the brain.</article-title>             <source>Behavioral and Brain Sciences</source>             <volume>24</volume>             <fpage>602</fpage>             <lpage>607</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Olshausen1"><label>19</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Olshausen</surname><given-names>BA</given-names></name>
<name name-style="western"><surname>Field</surname><given-names>DJ</given-names></name>
</person-group>             <year>1996</year>             <article-title>Emergence of simple-cell receptive field properties by learning a sparse code for natural images.</article-title>             <source>Nature</source>             <volume>381</volume>             <fpage>607</fpage>             <lpage>609</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Olshausen2"><label>20</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Olshausen</surname><given-names>BA</given-names></name>
<name name-style="western"><surname>Field</surname><given-names>DJ</given-names></name>
</person-group>             <year>1997</year>             <article-title>Sparse coding with an overcomplete basis set: A strategy employed by V1?</article-title>             <source>Vision Research</source>             <volume>37</volume>             <fpage>3311</fpage>             <lpage>3325</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Rehn1"><label>21</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Rehn</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Sommer</surname><given-names>FT</given-names></name>
</person-group>             <year>2007</year>             <article-title>A network that uses few active neurones to code visual input predicts the diverse shapes of cortical receptive field.</article-title>             <source>Journal of Computational Neuroscience</source>             <volume>22</volume>             <fpage>135</fpage>             <lpage>146</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Field1"><label>22</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Field</surname><given-names>DJ</given-names></name>
</person-group>             <year>1994</year>             <article-title>What is the goal of sensory coding?</article-title>             <source>Neural Computation</source>             <volume>6</volume>             <fpage>559</fpage>             <lpage>601</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Vincent1"><label>23</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Vincent</surname><given-names>BT</given-names></name>
<name name-style="western"><surname>Baddeley</surname><given-names>RJ</given-names></name>
<name name-style="western"><surname>Troscianko</surname><given-names>T</given-names></name>
<name name-style="western"><surname>Gilchrist</surname><given-names>ID</given-names></name>
</person-group>             <year>2005</year>             <article-title>Is the early visual system optimised to be energy efficient?</article-title>             <source>Network: Computation in Neural Systems</source>             <volume>16</volume>             <fpage>175</fpage>             <lpage>190</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Fldik1"><label>24</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Földiák</surname><given-names>P</given-names></name>
</person-group>             <year>1991</year>             <article-title>Learning invariance from transformation sequences.</article-title>             <source>Neural Computation</source>             <volume>3</volume>             <fpage>194</fpage>             <lpage>200</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Krding1"><label>25</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Körding</surname><given-names>KP</given-names></name>
<name name-style="western"><surname>Kayser</surname><given-names>C</given-names></name>
<name name-style="western"><surname>Einhäuser</surname><given-names>W</given-names></name>
<name name-style="western"><surname>König</surname><given-names>P</given-names></name>
</person-group>             <year>2004</year>             <article-title>How are complex cell properties adapted to the statistics of natural scenes?</article-title>             <source>Journal of Neurophysiology</source>             <volume>91</volume>             <fpage>206</fpage>             <lpage>212</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Berkes1"><label>26</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Berkes</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Wiskott</surname><given-names>L</given-names></name>
</person-group>             <year>2005</year>             <article-title>Slow feature analysis yields a rich repertoire of complex cell properties.</article-title>             <source>Journal of Vision</source>             <volume>5</volume>             <fpage>579</fpage>             <lpage>602</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Wiskott1"><label>27</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Wiskott</surname><given-names>L</given-names></name>
<name name-style="western"><surname>Sejnowski</surname><given-names>T</given-names></name>
</person-group>             <year>2002</year>             <article-title>Slow feature analysis: Unsupervised learning of invariances.</article-title>             <source>Neural Computation</source>             <volume>14</volume>             <fpage>715</fpage>             <lpage>770</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Rao1"><label>28</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="editor">
<name name-style="western"><surname>Rao</surname><given-names>RPN</given-names></name>
<name name-style="western"><surname>Olshausen</surname><given-names>BA</given-names></name>
<name name-style="western"><surname>Lewicki</surname><given-names>MS</given-names></name>
</person-group>             <year>2002</year>             <source>Probabilistic models of the brain.</source>             <publisher-name>MIT Press</publisher-name>          </element-citation></ref>
<ref id="pcbi.1000495-Yuille1"><label>29</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Yuille</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Kersten</surname><given-names>D</given-names></name>
</person-group>             <year>2006</year>             <article-title>Vision as Bayesian inference: analysis by synthesis.</article-title>             <source>Trends in Cognitive Sciences</source>             <volume>10</volume>             <fpage>301</fpage>             <lpage>308</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Lee1"><label>30</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Lee</surname><given-names>TS</given-names></name>
<name name-style="western"><surname>Mumford</surname><given-names>D</given-names></name>
</person-group>             <year>2003</year>             <article-title>Hierarchical Bayesian inference in the visual cortex.</article-title>             <source>Journal of the Optical Society of America A</source>             <volume>20</volume>             <fpage>1434</fpage>             <lpage>1448</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Friston1"><label>31</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Friston</surname><given-names>K</given-names></name>
</person-group>             <year>2005</year>             <article-title>A theory of cortical responses.</article-title>             <source>Philosophical Transactions of the Royal Society B: Biological Sciences</source>             <volume>360</volume>             <fpage>815</fpage>             <lpage>836</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Schwartz1"><label>32</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Schwartz</surname><given-names>O</given-names></name>
<name name-style="western"><surname>Simoncelli</surname><given-names>EP</given-names></name>
</person-group>             <year>2001</year>             <article-title>Natural signal statistics and sensory gain control.</article-title>             <source>Nature Neuroscience</source>             <volume>4</volume>             <fpage>819</fpage>             <lpage>825</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Wainwright1"><label>33</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Wainwright</surname><given-names>MJ</given-names></name>
<name name-style="western"><surname>Simoncelli</surname><given-names>EP</given-names></name>
</person-group>             <year>2000</year>             <article-title>Scale mixtures of Gaussians and the statistics of natural images.</article-title>             <source>Advances in Neural Information Processing Systems</source>             <fpage>855</fpage>             <lpage>861</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Karklin1"><label>34</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Karklin</surname><given-names>Y</given-names></name>
<name name-style="western"><surname>Lewicki</surname><given-names>MS</given-names></name>
</person-group>             <year>2005</year>             <article-title>A hierarchical Bayesian model for learning non-linear statistical regularities in non-stationary natural signals.</article-title>             <source>Neural Computation</source>             <volume>17</volume>             <fpage>397</fpage>             <lpage>423</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Turner1"><label>35</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Turner</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Sahani</surname><given-names>M</given-names></name>
</person-group>             <year>2007</year>             <article-title>Amaximum likelihood algorithm for SFA.</article-title>             <source>Neural Computation</source>             <volume>19</volume>             <fpage>1022</fpage>             <lpage>1038</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Tenenbaum1"><label>36</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Tenenbaum</surname><given-names>JB</given-names></name>
<name name-style="western"><surname>Freeman</surname><given-names>WT</given-names></name>
</person-group>             <year>2000</year>             <article-title>Separating style and content with bilinear models.</article-title>             <source>Neural Computation</source>             <volume>12</volume>             <fpage>1247</fpage>             <lpage>1283</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Grimes1"><label>37</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Grimes</surname><given-names>DB</given-names></name>
<name name-style="western"><surname>Rao</surname><given-names>RPN</given-names></name>
</person-group>             <year>2005</year>             <article-title>Bilinear sparse coding for invariant vision.</article-title>             <source>Neural Computation</source>             <volume>17</volume>             <fpage>47</fpage>             <lpage>73</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Olshausen3"><label>38</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Olshausen</surname><given-names>BA</given-names></name>
<name name-style="western"><surname>Millman</surname><given-names>KJ</given-names></name>
</person-group>             <year>2000</year>             <article-title>Learning sparse codes with a mixture-of-Gaussians prior.</article-title>             <person-group person-group-type="editor">
<name name-style="western"><surname>Solla</surname><given-names>SA</given-names></name>
<name name-style="western"><surname>Leen</surname><given-names>TK</given-names></name>
<name name-style="western"><surname>Müller</surname><given-names>KR</given-names></name>
</person-group>             <source>Advances in Neural Information Processing Systems</source>             <publisher-loc>Cambridge, MA</publisher-loc>             <publisher-name>MIT Press</publisher-name>             <fpage>841</fpage>             <lpage>847</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Berkes2"><label>39</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Berkes</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Turner</surname><given-names>RE</given-names></name>
<name name-style="western"><surname>Sahani</surname><given-names>M</given-names></name>
</person-group>             <year>2008</year>             <article-title>On sparsity and overcompleteness in image models.</article-title>             <person-group person-group-type="editor">
<name name-style="western"><surname>Platt</surname><given-names>JC</given-names></name>
<name name-style="western"><surname>Koller</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Singer</surname><given-names>Y</given-names></name>
<name name-style="western"><surname>Roweis</surname><given-names>S</given-names></name>
</person-group>             <source>Advances in Neural Information Processing Systems</source>             <volume>volume 20</volume>             <publisher-loc>Cambridge, MA</publisher-loc>             <publisher-name>MIT Press</publisher-name>          </element-citation></ref>
<ref id="pcbi.1000495-Turner2"><label>40</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Turner</surname><given-names>RE</given-names></name>
<name name-style="western"><surname>Berkes</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Sahani</surname><given-names>M</given-names></name>
</person-group>             <year>2008</year>             <article-title>Two problems with variational Expectation Maximisation in timeseries models.</article-title>             <comment>Technical Report GCNU-TR-2008-001, Gatsby Computational Neuroscience Unit, UCL</comment>          </element-citation></ref>
<ref id="pcbi.1000495-Attias1"><label>41</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Attias</surname><given-names>H</given-names></name>
</person-group>             <year>2000</year>             <article-title>Inferring parameters and structure of graphical models by variational Bayes.</article-title>             <person-group person-group-type="editor">
<name name-style="western"><surname>Solla</surname><given-names>SA</given-names></name>
<name name-style="western"><surname>Leen</surname><given-names>TK</given-names></name>
<name name-style="western"><surname>Müller</surname><given-names>KR</given-names></name>
</person-group>             <source>Advances in Neural Information Processing Systems</source>             <volume>volume 12</volume>             <publisher-loc>Cambridge, MA</publisher-loc>             <publisher-name>MIT Press</publisher-name>          </element-citation></ref>
<ref id="pcbi.1000495-Beal1"><label>42</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Beal</surname><given-names>MJ</given-names></name>
</person-group>             <year>2003</year>             <article-title>Variational algorithms for approximate Bayesian inference.</article-title>             <comment>Ph.D. thesis, Gatsby Computational Neuroscience Unit, University College London</comment>          </element-citation></ref>
<ref id="pcbi.1000495-MacKay1"><label>43</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>MacKay</surname><given-names>DJC</given-names></name>
</person-group>             <year>2003</year>             <article-title>Information Theory, Inference, and Learning Algorithms.</article-title>             <publisher-name>Cambridge University Press</publisher-name>             <comment>URL <ext-link ext-link-type="uri" xlink:href="http://www.cambridge.org/0521642981" xlink:type="simple">http://www.cambridge.org/0521642981</ext-link>. Available from <ext-link ext-link-type="uri" xlink:href="http://www.inference.phy.cam.ac.uk/mackay/itila/" xlink:type="simple">http://www.inference.phy.cam.ac.uk/mackay/itila/</ext-link></comment>          </element-citation></ref>
<ref id="pcbi.1000495-Bishop1"><label>44</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Bishop</surname><given-names>CM</given-names></name>
</person-group>             <year>1999</year>             <article-title>Variational principal components.</article-title>             <fpage>509</fpage>             <lpage>514</lpage>             <comment>In: Artificial Neural Networks – ICANN 99. Berlin/Heidelberg: Springer, Lecture Notes in Computer Science</comment>          </element-citation></ref>
<ref id="pcbi.1000495-Betsch1"><label>45</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Betsch</surname><given-names>BY</given-names></name>
<name name-style="western"><surname>Einhäuser</surname><given-names>W</given-names></name>
<name name-style="western"><surname>Körding</surname><given-names>KP</given-names></name>
<name name-style="western"><surname>König</surname><given-names>P</given-names></name>
</person-group>             <year>2004</year>             <article-title>The world from a cat's perspective – statistics of natural videos.</article-title>             <source>Biological Cybernetics</source>             <volume>90</volume>             <fpage>41</fpage>             <lpage>50</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-DeValois1"><label>46</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>De Valois</surname><given-names>RL</given-names></name>
<name name-style="western"><surname>Albrecht</surname><given-names>DG</given-names></name>
<name name-style="western"><surname>Thorell</surname><given-names>LG</given-names></name>
</person-group>             <year>1982</year>             <article-title>Spatial frequency selectivity of cells in macaque visual cortex.</article-title>             <source>Vision Research</source>             <volume>22</volume>             <fpage>545</fpage>             <lpage>559</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Skottun1"><label>47</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Skottun</surname><given-names>BC</given-names></name>
<name name-style="western"><surname>De Valois</surname><given-names>RL</given-names></name>
<name name-style="western"><surname>Grosof</surname><given-names>DH</given-names></name>
<name name-style="western"><surname>Movshon</surname><given-names>JA</given-names></name>
<name name-style="western"><surname>Albrecht</surname><given-names>DG</given-names></name>
<etal/></person-group>             <year>1991</year>             <article-title>Classifying simple and complex cells on the basis of response modulation.</article-title>             <source>Vision Research</source>             <volume>31</volume>             <fpage>1079</fpage>             <lpage>1086</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Adelson1"><label>48</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Adelson</surname><given-names>EH</given-names></name>
<name name-style="western"><surname>Bergen</surname><given-names>JR</given-names></name>
</person-group>             <year>1985</year>             <article-title>Spatiotemporal energy models for the perception of motion.</article-title>             <source>Journal Optical Society of America A</source>             <volume>2</volume>             <fpage>284</fpage>             <lpage>299</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Marmarelis1"><label>49</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Marmarelis</surname><given-names>PZ</given-names></name>
<name name-style="western"><surname>Marmarelis</surname><given-names>VZ</given-names></name>
</person-group>             <year>1978</year>             <article-title>Analysis of physiological systems: The white-noise approach.</article-title>             <publisher-loc>New York</publisher-loc>             <publisher-name>Plenum Press</publisher-name>          </element-citation></ref>
<ref id="pcbi.1000495-Mountcastle1"><label>50</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Mountcastle</surname><given-names>VB</given-names></name>
</person-group>             <year>1957</year>             <article-title>Modality and topographic properties of single neurons of cat's somatic sensory cortex.</article-title>             <source>Journal of Neurophysiology</source>             <volume>20</volume>             <fpage>408</fpage>             <lpage>34</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Pollen1"><label>51</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Pollen</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Ronner</surname><given-names>S</given-names></name>
</person-group>             <year>1981</year>             <article-title>Phase relationship between adjacent simple cells in the visual cortex.</article-title>             <source>Science</source>             <volume>212</volume>             <fpage>1409</fpage>             <lpage>1411</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Chklovskii1"><label>52</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Chklovskii</surname><given-names>DB</given-names></name>
<name name-style="western"><surname>Schikorski</surname><given-names>T</given-names></name>
<name name-style="western"><surname>Stevens</surname><given-names>CF</given-names></name>
</person-group>             <year>2002</year>             <article-title>Wiring optimization in cortical circuits.</article-title>             <source>Neuron</source>             <volume>34</volume>             <fpage>341</fpage>             <lpage>347</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-DeAngelis1"><label>53</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>DeAngelis</surname><given-names>GC</given-names></name>
<name name-style="western"><surname>Ghose</surname><given-names>GM</given-names></name>
<name name-style="western"><surname>Ohzawa</surname><given-names>I</given-names></name>
<name name-style="western"><surname>Freeman</surname><given-names>RD</given-names></name>
</person-group>             <year>1999</year>             <article-title>Functional micro-organization of primary visual cortex: Receptive field analysis of nearby neurons.</article-title>             <source>Journal of Neuroscience</source>             <volume>19</volume>             <fpage>4046</fpage>             <lpage>4064</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Karklin2"><label>54</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Karklin</surname><given-names>Y</given-names></name>
<name name-style="western"><surname>Lewicki</surname><given-names>MS</given-names></name>
</person-group>             <year>2006</year>             <article-title>Is early vision optimized for extracting higher-order dependencies?</article-title>             <source>Advances in Neural Information Processing Systems 18.</source>             <publisher-name>MIT Press</publisher-name>          </element-citation></ref>
<ref id="pcbi.1000495-DeAngelis2"><label>55</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>DeAngelis</surname><given-names>GC</given-names></name>
<name name-style="western"><surname>Ohzawa</surname><given-names>I</given-names></name>
<name name-style="western"><surname>Freeman</surname><given-names>RD</given-names></name>
</person-group>             <year>1993</year>             <article-title>Spatiotemporal organization of simple-cell receptive fields in the cat's striate cortex. I. General characteristics and postnatal development.</article-title>             <source>Journal of Neurophysiology</source>             <volume>69</volume>             <fpage>1091</fpage>             <lpage>1117</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Ringach1"><label>56</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Ringach</surname><given-names>D</given-names></name>
</person-group>             <year>2002</year>             <article-title>Spatial structure and symmetry of simple-cell receptive fields in macaque primary visual cortex.</article-title>             <source>Journal of Neurophysiology</source>             <volume>88</volume>             <fpage>455</fpage>             <lpage>463</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Ringach2"><label>57</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Ringach</surname><given-names>DL</given-names></name>
</person-group>             <year>2002</year>             <article-title>Database 2: Shape of simple-cells receptive fields in macaque V1.</article-title>             <comment><ext-link ext-link-type="uri" xlink:href="http://web.mac.com/darioringach/lab/Data_Code.html" xlink:type="simple">http://web.mac.com/darioringach/lab/Data_Code.html</ext-link></comment>          </element-citation></ref>
<ref id="pcbi.1000495-Lcke1"><label>58</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Lücke</surname><given-names>J</given-names></name>
</person-group>             <year>2007</year>             <article-title>A dynamical model for receptive field self-organization in V1 cortical columns.</article-title>             <fpage>389</fpage>             <lpage>398</lpage>             <comment>In: Artificial Neural Networks – ICANN 2007. Berlin/Heidelberg: Springer, volume 4669 of <italic>Lecture Notes in Computer Science</italic></comment>          </element-citation></ref>
<ref id="pcbi.1000495-Schwartz2"><label>59</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Schwartz</surname><given-names>O</given-names></name>
<name name-style="western"><surname>Pillow</surname><given-names>JW</given-names></name>
<name name-style="western"><surname>Rust</surname><given-names>NC</given-names></name>
<name name-style="western"><surname>Simoncelli</surname><given-names>EP</given-names></name>
</person-group>             <year>2006</year>             <article-title>Spike-triggered neural characterization.</article-title>             <source>Journal of Vision</source>             <volume>6</volume>             <fpage>484</fpage>             <lpage>507</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Touryan1"><label>60</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Touryan</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Felsen</surname><given-names>G</given-names></name>
<name name-style="western"><surname>Dan</surname><given-names>Y</given-names></name>
</person-group>             <year>2005</year>             <article-title>Spatial structure of complex cell receptive fields measured with natural images.</article-title>             <source>Neuron</source>             <volume>45</volume>             <fpage>781</fpage>             <lpage>791</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Chen1"><label>61</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Chen</surname><given-names>X</given-names></name>
<name name-style="western"><surname>Han</surname><given-names>F</given-names></name>
<name name-style="western"><surname>Poo</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Dan</surname><given-names>Y</given-names></name>
</person-group>             <year>2007</year>             <article-title>Excitatory and suppressive receptive field subunits in awake monkey primary visual cortex (V1).</article-title>             <source>Proceedings of the National Academy of Sciences</source>             <volume>104</volume>             <fpage>19120</fpage>             <lpage>19125</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Rust1"><label>62</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Rust</surname><given-names>NC</given-names></name>
<name name-style="western"><surname>Schwartz</surname><given-names>O</given-names></name>
<name name-style="western"><surname>Movshon</surname><given-names>JA</given-names></name>
<name name-style="western"><surname>Simoncelli</surname><given-names>EP</given-names></name>
</person-group>             <year>2005</year>             <article-title>Spatiotemporal elements of macaque V1 receptive fields.</article-title>             <source>Neuron</source>             <volume>46</volume>             <fpage>945</fpage>             <lpage>956</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Hyvrinen1"><label>63</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Hyvärinen</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Hoyer</surname><given-names>P</given-names></name>
</person-group>             <year>2000</year>             <article-title>Emergence of phase and shift invariant features by decomposition of natural images into independent feature subspaces.</article-title>             <source>Neural Computation</source>             <volume>12</volume>             <fpage>1705</fpage>             <lpage>1720</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Schwartz3"><label>64</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Schwartz</surname><given-names>O</given-names></name>
<name name-style="western"><surname>Sejnowski</surname><given-names>TJ</given-names></name>
<name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name>
</person-group>             <year>2006</year>             <article-title>Soft mixer assignment in a hierarchical generative model of natural scene statistics.</article-title>             <source>Neural Computation</source>             <volume>18</volume>             <fpage>2680</fpage>             <lpage>2718</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Humphrey1"><label>65</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Humphrey</surname><given-names>AL</given-names></name>
<name name-style="western"><surname>Saul</surname><given-names>AB</given-names></name>
</person-group>             <year>1998</year>             <article-title>Strobe rearing reduces direction selectivity in area 17 by altering spatiotemporal receptive-field structure.</article-title>             <source>Journal of Neurophysiology</source>             <volume>80</volume>             <fpage>2991</fpage>             <lpage>3004</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Cremieux1"><label>66</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Cremieux</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Orban</surname><given-names>GA</given-names></name>
<name name-style="western"><surname>Duysens</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Amblard</surname><given-names>B</given-names></name>
</person-group>             <year>1987</year>             <article-title>Response properties of area 17 neurons in cats reared in stroboscopic illumination.</article-title>             <source>Journal of Neurophysiology</source>             <volume>57</volume>             <fpage>1511</fpage>             <lpage>1535</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Mechler1"><label>67</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Mechler</surname><given-names>F</given-names></name>
<name name-style="western"><surname>Ringach</surname><given-names>DL</given-names></name>
</person-group>             <year>2002</year>             <article-title>On the classification of simple and complex cells.</article-title>             <source>Vision Research</source>             <volume>42</volume>             <fpage>1017</fpage>             <lpage>33</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Mel1"><label>68</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Mel</surname><given-names>BW</given-names></name>
<name name-style="western"><surname>Ruderman</surname><given-names>DL</given-names></name>
<name name-style="western"><surname>Archie</surname><given-names>KA</given-names></name>
</person-group>             <year>1998</year>             <article-title>Translation-invariant orientation tuning in visual “complex” cells could derive from intradendritic computations.</article-title>             <source>Journal of Neuroscience</source>             <volume>18</volume>             <fpage>4325</fpage>             <lpage>34</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Chance1"><label>69</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Chance</surname><given-names>FS</given-names></name>
<name name-style="western"><surname>Nelson</surname><given-names>SB</given-names></name>
<name name-style="western"><surname>Abbott</surname><given-names>LF</given-names></name>
</person-group>             <year>1999</year>             <article-title>Complex cells as cortically amplified simple cells.</article-title>             <source>Nature Neuroscience</source>             <volume>2</volume>             <fpage>277</fpage>             <lpage>82</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Lcke2"><label>70</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Lücke</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Sahani</surname><given-names>M</given-names></name>
</person-group>             <year>2008</year>             <article-title>Maximal causes for non-linear component extraction.</article-title>             <source>Journal of Machine Learning Research</source>             <volume>9</volume>             <fpage>1227</fpage>             <lpage>1267</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Ross1"><label>71</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Ross</surname><given-names>DA</given-names></name>
<name name-style="western"><surname>Zemel</surname><given-names>RS</given-names></name>
</person-group>             <year>2006</year>             <article-title>Learning parts-based representations of data.</article-title>             <source>Journal of Machine Learning Research</source>             <volume>7</volume>             <fpage>2369</fpage>             <lpage>2397</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-vanHateren2"><label>72</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>van Hateren</surname><given-names>JH</given-names></name>
<name name-style="western"><surname>Ruderman</surname><given-names>DL</given-names></name>
</person-group>             <year>1998</year>             <article-title>Independent component analysis of natural image sequences yields spatio-temporal filters similar to simple cells in primary visual cortex.</article-title>             <source>Proceedings of the Royal Society B</source>             <volume>265</volume>             <fpage>2315</fpage>             <lpage>2320</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Biederman1"><label>73</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Biederman</surname><given-names>I</given-names></name>
</person-group>             <year>1987</year>             <article-title>Recognition-by-components: A theory of human image understanding.</article-title>             <source>Psychological Review</source>             <volume>94</volume>             <fpage>115</fpage>             <lpage>147</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Zhu1"><label>74</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Zhu</surname><given-names>L</given-names></name>
<name name-style="western"><surname>Yuille</surname><given-names>A</given-names></name>
</person-group>             <year>2006</year>             <article-title>A hierarchical compositional system for rapid object detection.</article-title>             <source>Advances in Neural Information Processing Systems</source>             <volume>volume 18</volume>             <fpage>1633</fpage>             <lpage>1640</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Sudderth1"><label>75</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Sudderth</surname><given-names>E</given-names></name>
<name name-style="western"><surname>Torralba</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Freeman</surname><given-names>W</given-names></name>
<name name-style="western"><surname>Willsky</surname><given-names>A</given-names></name>
</person-group>             <year>2006</year>             <article-title>Describing visual scenes using transformed Dirichlet Processes.</article-title>             <person-group person-group-type="editor">
<name name-style="western"><surname>Weiss</surname><given-names>Y</given-names></name>
<name name-style="western"><surname>Schölkopf</surname><given-names>B</given-names></name>
<name name-style="western"><surname>Platt</surname><given-names>J</given-names></name>
</person-group>             <source>Advances in Neural Information Processing Systems</source>             <publisher-loc>Cambridge, MA</publisher-loc>             <publisher-name>MIT Press</publisher-name>             <fpage>1297</fpage>             <lpage>1304</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Zhu2"><label>76</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Zhu</surname><given-names>L</given-names></name>
<name name-style="western"><surname>Chen</surname><given-names>Y</given-names></name>
<name name-style="western"><surname>Yuille</surname><given-names>AL</given-names></name>
</person-group>             <year>2007</year>             <article-title>Unsupervised learning of a probabilistic grammar for object detection and parsing.</article-title>             <person-group person-group-type="editor">
<name name-style="western"><surname>Schölkopf</surname><given-names>B</given-names></name>
<name name-style="western"><surname>Platt</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Hoffman</surname><given-names>T</given-names></name>
</person-group>             <source>Advances in Neural Information Processing Systems</source>             <volume>volume 19</volume> <publisher-loc>Cambridge, MA</publisher-loc>             <publisher-name>MIT Press</publisher-name>             <fpage>1617</fpage>             <lpage>1624</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Sudderth2"><label>77</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Sudderth</surname><given-names>E</given-names></name>
<name name-style="western"><surname>Torralba</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Freeman</surname><given-names>W</given-names></name>
<name name-style="western"><surname>Willsky</surname><given-names>A</given-names></name>
</person-group>             <year>2008</year>             <article-title>Describing visual scenes using transformed objects and parts.</article-title>             <source>International Journal of Computer Vision</source>             <volume>77</volume>             <fpage>291</fpage>             <lpage>330</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Jojic1"><label>78</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Jojic</surname><given-names>N</given-names></name>
<name name-style="western"><surname>Frey</surname><given-names>BJ</given-names></name>
</person-group>             <year>2001</year>             <article-title>Learning flexible sprites in video layers.</article-title>             <source>Proc. of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition</source>             <volume>volume I</volume>             <publisher-loc>Kauai, Hawaii</publisher-loc>             <publisher-name>IEEE Computer Society Press</publisher-name>             <fpage>191</fpage>             <lpage>206</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Williams1"><label>79</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Williams</surname><given-names>CKI</given-names></name>
<name name-style="western"><surname>Titsias</surname><given-names>MK</given-names></name>
</person-group>             <year>2004</year>             <article-title>Greedy learning of multiple objects in images using robust statistics and factorial learning.</article-title>             <source>Neural Computation</source>             <volume>16</volume>             <fpage>1039</fpage>             <lpage>1062</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Einhuser1"><label>80</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Einhäuser</surname><given-names>W</given-names></name>
<name name-style="western"><surname>Hipp</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Eggert</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Körner</surname><given-names>E</given-names></name>
<name name-style="western"><surname>König</surname><given-names>P</given-names></name>
</person-group>             <year>2005</year>             <article-title>Learning viewpoint invariant object representations using a temporal coherence principle.</article-title>             <source>Biological Cybernetics</source>             <volume>93</volume>             <fpage>79</fpage>             <lpage>90</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Franzius1"><label>81</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Franzius</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Wilbert</surname><given-names>N</given-names></name>
<name name-style="western"><surname>Wiskott</surname><given-names>L</given-names></name>
</person-group>             <year>2008</year>             <article-title>Invariant object recognition with Slow Feature Analysis.</article-title>             <fpage>961</fpage>             <lpage>970</lpage>             <comment>In: Springer, editor, Proc. 18th Intl. Conf. on Artificial Neural Networks, ICANN'08, Prague. volume 5163 of <italic>Lecture Notes in Computer Science</italic></comment>          </element-citation></ref>
<ref id="pcbi.1000495-Stringer1"><label>82</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Stringer</surname><given-names>SM</given-names></name>
<name name-style="western"><surname>Rolls</surname><given-names>ET</given-names></name>
</person-group>             <year>2008</year>             <article-title>Learning transform invariant object recognition in the visual system with multiple stimuli present during training.</article-title>             <source>Neural Networks</source>             <volume>21</volume>             <fpage>888</fpage>             <lpage>903</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Neal1"><label>83</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Neal</surname><given-names>RM</given-names></name>
<name name-style="western"><surname>Hinton</surname><given-names>GE</given-names></name>
</person-group>             <year>1998</year>             <article-title>A view of the EM algorithm that justifies incremental, sparse, and other variants.</article-title>             <person-group person-group-type="editor">
<name name-style="western"><surname>Jordan</surname><given-names>MI</given-names></name>
</person-group>             <source>Learning in Graphical Models, Dordrecht</source>             <publisher-name>Kluwer Academic Publishers</publisher-name>             <fpage>355</fpage>             <lpage>368</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-Dempster1"><label>84</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Dempster</surname><given-names>AP</given-names></name>
<name name-style="western"><surname>Laird</surname><given-names>NM</given-names></name>
<name name-style="western"><surname>Rubin</surname><given-names>DB</given-names></name>
</person-group>             <year>1977</year>             <article-title>Maximum likelihood from incomplete data via the EM algorithm.</article-title>             <source>Journal of the Royal Statistical Society Series B (Methodological)</source>             <volume>39</volume>             <fpage>1</fpage>             <lpage>38</lpage>          </element-citation></ref>
<ref id="pcbi.1000495-deRuytervanSteveninck1"><label>85</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>de Ruyter van Steveninck</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Bialek</surname><given-names>W</given-names></name>
</person-group>             <year>1988</year>             <article-title>Real-time performance of a movement-sensitive neuron in the blowfly visual system: Coding and information transfer in short spike sequences.</article-title>             <source>Proceedings of the Royal Society of London B, Biological Sciences</source>             <volume>234</volume>             <fpage>379</fpage>             <lpage>414</lpage>          </element-citation></ref>
</ref-list>

</back>
</article>
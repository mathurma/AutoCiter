<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="other" dtd-version="3.0" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">plosbiol</journal-id>
<journal-title-group>
<journal-title>PLOS Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1544-9173</issn>
<issn pub-type="epub">1545-7885</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pbio.1002106</article-id>
<article-id pub-id-type="publisher-id">PBIOLOGY-D-14-03772</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Perspective</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>The Extent and Consequences of P-Hacking in Science</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<name name-style="western">
<surname>Head</surname>
<given-names>Megan L.</given-names>
</name>
<xref rid="aff001" ref-type="aff"><sup>1</sup></xref>
<xref rid="cor001" ref-type="corresp">*</xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Holman</surname>
<given-names>Luke</given-names>
</name>
<xref rid="aff001" ref-type="aff"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Lanfear</surname>
<given-names>Rob</given-names>
</name>
<xref rid="aff001" ref-type="aff"><sup>1</sup></xref>
<xref rid="aff002" ref-type="aff"><sup>2</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Kahn</surname>
<given-names>Andrew T.</given-names>
</name>
<xref rid="aff001" ref-type="aff"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Jennions</surname>
<given-names>Michael D.</given-names>
</name>
<xref rid="aff001" ref-type="aff"><sup>1</sup></xref>
</contrib>
</contrib-group>
<aff id="aff001"><label>1</label> <addr-line>Division of Evolution, Ecology and Genetics, Research School of Biology, Australian National University, Acton, Canberra, Australia</addr-line></aff>
<aff id="aff002"><label>2</label> <addr-line>Department of Biological Sciences, Faculty of Science, Macquarie University, North Ryde, New South Wales, Australia</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">megan.l.head@gmail.com</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>13</day>
<month>3</month>
<year>2015</year>
</pub-date>
<pub-date pub-type="collection">
<month>3</month>
<year>2015</year>
</pub-date>
<volume>13</volume>
<issue>3</issue>
<elocation-id>e1002106</elocation-id>
<permissions>
<copyright-year>2015</copyright-year>
<copyright-holder>Head et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pbio.1002106" xlink:type="simple"/>
<abstract>
<p>A focus on novel, confirmatory, and statistically significant results leads to substantial bias in the scientific literature. One type of bias, known as “p-hacking,” occurs when researchers collect or select data or statistical analyses until nonsignificant results become significant. Here, we use text-mining to demonstrate that p-hacking is widespread throughout science. We then illustrate how one can test for p-hacking when performing a meta-analysis and show that, while p-hacking is probably common, its effect seems to be weak relative to the real effect sizes being measured. This result suggests that p-hacking probably does not drastically alter scientific consensuses drawn from meta-analyses.</p>
</abstract>
<abstract abstract-type="toc">
<p>Publication bias resulting from so-called "p-hacking" is pervasive throughout the life sciences; however, its effects on general conclusions made from the literature appear to be weak.</p>
</abstract>
<funding-group>
<funding-statement>Funding for this research was provided by Australian Research Council Grants awarded to MDJ, RL and LH. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="4"/>
<table-count count="3"/>
<page-count count="15"/>
</counts>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>There is increasing concern that many published results are false positives [<xref rid="pbio.1002106.ref001" ref-type="bibr">1</xref>,<xref rid="pbio.1002106.ref002" ref-type="bibr">2</xref>] (but see [<xref rid="pbio.1002106.ref003" ref-type="bibr">3</xref>]). Many argue that current scientific practices create strong incentives to publish statistically significant (i.e., “positive”) results, and there is good evidence that journals, especially prestigious ones with higher impact factors, disproportionately publish statistically significant results [<xref rid="pbio.1002106.ref004" ref-type="bibr">4</xref>–<xref rid="pbio.1002106.ref010" ref-type="bibr">10</xref>]. Employers and funders often count papers and weigh them by the journal’s impact factor to assess a researcher’s performance [<xref rid="pbio.1002106.ref011" ref-type="bibr">11</xref>]. In combination, these factors create incentives for researchers to selectively pursue and selectively attempt to publish statistically significant research findings.</p>
<p>There are two widely recognized types of researcher-driven publication bias: selection (also known as the “file drawer effect”, where studies with nonsignificant results have lower publication rates [<xref rid="pbio.1002106.ref007" ref-type="bibr">7</xref>]) and inflation [<xref rid="pbio.1002106.ref012" ref-type="bibr">12</xref>]. Inflation bias, also known as “p-hacking” or “selective reporting,” is the misreporting of true effect sizes in published studies (<xref ref-type="boxed-text" rid="pbio.1002106.box001">Box 1</xref>). It occurs when researchers try out several statistical analyses and/or data eligibility specifications and then selectively report those that produce significant results [<xref rid="pbio.1002106.ref012" ref-type="bibr">12</xref>–<xref rid="pbio.1002106.ref015" ref-type="bibr">15</xref>]. Common practices that lead to p-hacking include: conducting analyses midway through experiments to decide whether to continue collecting data [<xref rid="pbio.1002106.ref015" ref-type="bibr">15</xref>,<xref rid="pbio.1002106.ref016" ref-type="bibr">16</xref>]; recording many response variables and deciding which to report postanalysis [<xref rid="pbio.1002106.ref016" ref-type="bibr">16</xref>,<xref rid="pbio.1002106.ref017" ref-type="bibr">17</xref>], deciding whether to include or drop outliers postanalyses [<xref rid="pbio.1002106.ref016" ref-type="bibr">16</xref>], excluding, combining, or splitting treatment groups postanalysis [<xref rid="pbio.1002106.ref002" ref-type="bibr">2</xref>], including or excluding covariates postanalysis [<xref rid="pbio.1002106.ref014" ref-type="bibr">14</xref>], and stopping data exploration if an analysis yields a significant <italic>p</italic>-value [<xref rid="pbio.1002106.ref018" ref-type="bibr">18</xref>,<xref rid="pbio.1002106.ref019" ref-type="bibr">19</xref>].</p>
<p>If published data are biased, data synthesis might lead to flawed conclusions. Meta-analysis is a set of statistical methods that combine studies on the same question to estimate the true effect size [<xref rid="pbio.1002106.ref033" ref-type="bibr">33</xref>]. Meta-analyses are now the “gold standard” for synthesizing the evidence for an effect of a treatment or the existence of a relationship, and combining effect size estimates across studies to give an overall estimate. Meta-analyses guide the application of medical treatments and policy decisions, and influence future research directions [<xref rid="pbio.1002106.ref034" ref-type="bibr">34</xref>]. However, meta-analyses are compromised if the studies being synthesized do not reflect the true distribution of effect sizes [<xref rid="pbio.1002106.ref005" ref-type="bibr">5</xref>,<xref rid="pbio.1002106.ref035" ref-type="bibr">35</xref>–<xref rid="pbio.1002106.ref037" ref-type="bibr">37</xref>].</p>
<p>Quantifying p-hacking is important because publication of false positives hinders scientific progress. When false positive results enter the literature they can be very persistent. In many fields, there is little incentive to replicate research [<xref rid="pbio.1002106.ref038" ref-type="bibr">38</xref>]. Even when research is replicated, early positive studies often receive more attention than later negative ones. In addition, false positives can inspire investment in fruitless research programs, and even discredit entire fields [<xref rid="pbio.1002106.ref014" ref-type="bibr">14</xref>,<xref rid="pbio.1002106.ref016" ref-type="bibr">16</xref>].</p>
<p>Despite the potential importance of p-hacking, the consequences for formal and informal data synthesis are unknown. Here, we address both issues using p-curves (see <xref ref-type="boxed-text" rid="pbio.1002106.box002">Box 2</xref>). First, we used text-mining to obtain reported p-values in papers drawn from a broad range of scientific disciplines. We then looked for evidence of p-hacking based on the shape of the p-curves. Second, we produced p-curves from primary data used in published meta-analyses. This allowed us to test the evidence for p-hacking when looking at specific hypotheses which researchers have clearly identified as being of general interest (i.e., that warrant a meta-analysis).</p>
<boxed-text id="pbio.1002106.box001" position="float">
<sec id="sec002">
<title>Box 1. The History of P</title>
<p>Fisher [<xref rid="pbio.1002106.ref020" ref-type="bibr">20</xref>] introduced null hypothesis significance testing (NHST) to objectively separate interesting findings from background noise [<xref rid="pbio.1002106.ref021" ref-type="bibr">21</xref>]. NHST is the most widely used data analysis method in most scientific disciplines [<xref rid="pbio.1002106.ref022" ref-type="bibr">22</xref>,<xref rid="pbio.1002106.ref023" ref-type="bibr">23</xref>]. The null hypothesis is typically a statement of no relationship between variables or no effect of an experimental manipulation. With NHST, one computes the probability (i.e., p) of finding an effect at least or more extreme than the observed finding if the null hypothesis is true [<xref rid="pbio.1002106.ref024" ref-type="bibr">24</xref>,<xref rid="pbio.1002106.ref025" ref-type="bibr">25</xref>].</p>
<p>The NHST approach uses an arbitrary cutoff value (usually 0.05). Findings with smaller <italic>p</italic>-values are described as “statistically significant” (“positive” findings), and the remainder as “nonsignificant” (“negative” findings). This arbitrary cutoff has led to the scientifically dubious practice of regarding “significant” findings as more valuable, reliable, and reproducible [<xref rid="pbio.1002106.ref024" ref-type="bibr">24</xref>], thereby incentivizing various kinds of research bias.</p>
<p>Before computers, test statistics (e.g., <italic>t</italic> and <italic>F</italic>) were routinely calculated by hand and the associated <italic>p</italic>-value was looked up in statistical tables. Here, <italic>p</italic>-values were given for a limited set of values (e.g., 0.001, 0.01, 0.02, and 0.05) [<xref rid="pbio.1002106.ref026" ref-type="bibr">26</xref>]. Researchers then reported <italic>p</italic>-values as the lowest threshold consistent with the test statistic (e.g., <italic>p</italic> &lt; 0.05 or <italic>p</italic> &lt; 0.01). With modern statistical software this practice is unnecessary, as precise <italic>p</italic>-values are now provided, but it is still commonplace. Previous research has shown that strict adherence to <italic>p</italic>-value thresholds can bias how research is reported, even within the region of significance [<xref rid="pbio.1002106.ref027" ref-type="bibr">27</xref>].</p>
<p>The <italic>p</italic>-value is easily misinterpreted. For example, it is often equated with the strength of a relationship, but a tiny effect size can have very low <italic>p</italic>-values with a large enough sample size. Similarly, a low <italic>p</italic>-value does not mean that a finding is of major clinical or biological interest [<xref rid="pbio.1002106.ref028" ref-type="bibr">28</xref>]. Many researchers have advocated abolishing NHST (e.g., [<xref rid="pbio.1002106.ref029" ref-type="bibr">29</xref>,<xref rid="pbio.1002106.ref030" ref-type="bibr">30</xref>]). However, others note that many of the problems with publication bias reoccur with other approaches, such as reporting effect sizes and their confidence intervals [<xref rid="pbio.1002106.ref031" ref-type="bibr">31</xref>] or Bayesian credible intervals [<xref rid="pbio.1002106.ref032" ref-type="bibr">32</xref>]. Publication biases are not a problem with <italic>p</italic>-values per se. They simply reflect the incentives to report strong (i.e., significant) effects.</p>
</sec>
</boxed-text>
<boxed-text id="pbio.1002106.box002" position="float">
<sec id="sec003">
<title>Box 2. The P-Curve: What Can It Tell Us?</title>
<p>A p-curve is the distribution of <italic>p</italic>-values for a set of studies. P-curves can be a helpful tool to assess the reliability of published research. Here, we outline how they have been used to assess the literature.</p>
<sec id="sec004">
<title>Evidential value</title>
<p>One can examine whether a set of findings contains evidential value by examining the distribution of <italic>p</italic>-values, particularly those between 0 and 0.05. “Evidential value” refers to whether or not the published evidence for a specific hypothesis suggests that the effect size is nonzero.</p>
<p>When the effect size for a studied phenomenon is zero, every <italic>p</italic>-value is equally likely to be observed. The expected distribution of <italic>p</italic>-values under the null hypothesis is uniform (Black line, <xref rid="pbio.1002106.g001" ref-type="fig">Fig. 1A</xref> and <xref rid="pbio.1002106.g002" ref-type="fig">Fig. 2A</xref>), such that <italic>p</italic>&lt;0.05 will occur 5% of the time, <italic>p</italic>&lt;0.04 will occur 4% of the time, and so on. On the other hand, when the true effect size is nonzero, the expected distribution of <italic>p</italic>-values is exponential with a right skew [<xref rid="pbio.1002106.ref039" ref-type="bibr">39</xref>–<xref rid="pbio.1002106.ref042" ref-type="bibr">42</xref>] (Black line, <xref rid="pbio.1002106.g001" ref-type="fig">Fig. 1B</xref> and <xref rid="pbio.1002106.g002" ref-type="fig">Fig. 2B</xref>). When the true effect is strong, researchers are more likely to obtain very low <italic>p</italic>-values (e.g., <italic>p</italic>&lt;0.001) than moderately low <italic>p</italic>-values (e.g., 0.01), and less likely still to obtain nonsignificant <italic>p</italic>-values (p &gt; 0.05) [<xref rid="pbio.1002106.ref041" ref-type="bibr">41</xref>]. So, as the true effect size increases the p-curve is more right skewed [<xref rid="pbio.1002106.ref041" ref-type="bibr">41</xref>].</p>
</sec>
<sec id="sec005">
<title>Publication bias</title>
<p>Several studies have plotted the distribution of <italic>p</italic>-values or related test statistics (i.e., <italic>Z</italic> or <italic>t</italic>) around the main significance threshold of <italic>p</italic> = 0.05 (often in the range of 0.01 to 0.1). A notable drop in <italic>p</italic>-values above 0.05 (or for Z values, 1.96) (Red line, <xref rid="pbio.1002106.g001" ref-type="fig">Fig. 1A</xref> and <xref rid="pbio.1002106.g001" ref-type="fig">Fig. 1B</xref>) is interpreted as evidence for publication bias (e.g., [<xref rid="pbio.1002106.ref040" ref-type="bibr">40</xref>,<xref rid="pbio.1002106.ref043" ref-type="bibr">43</xref>–<xref rid="pbio.1002106.ref045" ref-type="bibr">45</xref>]). While a discontinuity in the distribution of <italic>p</italic>-values around 0.05 is indicative of publication bias, it does not distinguish between selective publication bias and p-hacking (see <xref ref-type="boxed-text" rid="pbio.1002106.box001">Box 1</xref>).</p>
</sec>
<sec id="sec006">
<title>P-hacking</title>
<p>The p-curve can, however, be used to identify p-hacking, by only considering significant findings [<xref rid="pbio.1002106.ref014" ref-type="bibr">14</xref>]. If researchers p-hack and turn a truly nonsignificant result into a significant one, then the p-curve’s shape will be altered close to the perceived significance threshold (typically <italic>p</italic> = 0.05). Consequently, a p-hacked p-curve will have an overabundance of <italic>p</italic>-values just below 0.05 [<xref rid="pbio.1002106.ref012" ref-type="bibr">12</xref>,<xref rid="pbio.1002106.ref040" ref-type="bibr">40</xref>,<xref rid="pbio.1002106.ref041" ref-type="bibr">41</xref>]. If researchers p-hack when there is no true effect, the p-curve will shift from being flat to left skewed (<xref rid="pbio.1002106.g002" ref-type="fig">Fig. 2A</xref>). If, however, researchers p-hack when there is a true effect, the p-curve will be exponential with right skew but there will be an overrepresentation of <italic>p</italic>-values in the tail of the distribution just below 0.05 (<xref rid="pbio.1002106.g002" ref-type="fig">Fig. 2B</xref>). Both p-hacking and selective publication bias predict a discontinuity in the p-curve around 0.05, but only p-hacking predicts an overabundance of <italic>p</italic>-values just below 0.05 [<xref rid="pbio.1002106.ref012" ref-type="bibr">12</xref>]. The exact shape of the p-curve will, however, depend on both the true effect (i.e., the p-curve before p-hacking) and the intensity of p-hacking [<xref rid="pbio.1002106.ref041" ref-type="bibr">41</xref>].</p>
</sec>
<sec id="sec007">
<title>Assessing p-curves for p-hacking and evidential value</title>
<p>Similar to previous studies (e.g., [<xref rid="pbio.1002106.ref014" ref-type="bibr">14</xref>,<xref rid="pbio.1002106.ref043" ref-type="bibr">43</xref>]) we employ binomial tests to look for evidence of evidential value and p-hacking in both our text-mined and meta-analyses datasets. We tested for evidential value using a two-tailed sign test, in which we compared the number of <italic>p</italic>-values falling in the bin 0 ≤ <italic>p</italic> &lt; 0.025 to the number in the bin 0.025 ≤ <italic>p</italic> &lt; 0.05. Under the null hypothesis of no evidential value, the expected number of <italic>p</italic>-values in each of these bins is equal. Significantly more <italic>p</italic>-values in the lower bin is consistent with evidential value (i.e., right skewed p-curve), and significantly more <italic>p</italic>-values in the upper bin is consistent with severe p-hacking. This test is a slightly modified version of a test proposed by Simohnson et al. [<xref rid="pbio.1002106.ref041" ref-type="bibr">41</xref>], who suggest using two separate one-tailed sign tests for the same purpose.</p>
<p>The two-tailed sign test with a <italic>p</italic> = 0.025 threshold (above) and the tests proposed by Simonsohn et al. [<xref rid="pbio.1002106.ref041" ref-type="bibr">41</xref>] can detect severe p-hacking, but are insensitive to more modest (and arguably more realistic) levels of p-hacking. This is true especially if the average true effect size is strong, as the right skew introduced to the p-curve will mask the left skew caused by p-hacking. A more sensitive approach to detect p-hacking is to look for an increase in the relative frequency of <italic>p</italic>-values just below 0.05, where we expect the signal of p-hacking to be strongest. Under the null hypothesis of no p-hacking, we expect either that the distribution of <italic>p</italic>-values is uniform close to 0.05 (if the true effect sizes are zero), or right skewed (i.e., if at least some effect sizes are nonzero). However, p-hacking introduces additional <italic>p</italic>-values close to 0.05, producing a left skew. Thus, a simple, and conservative, test for p-hacking involves testing the null hypothesis that the <italic>p</italic>-values just below 0.05 are either uniformly distributed or right skewed. We used a one-tailed sign test to ask whether the number of <italic>p</italic>-values in the bin that abuts 0.05 is greater than that in the adjacent lower bin. This test becomes more likely to detect p-hacking if one uses smaller bins, since <italic>p</italic>-values are right skewed when the average effect size is positive (masking p-hacking), but in practice, using smaller bins will reduce the sample size (and thus power) of the test. We selected a bin width of 0.005, with the lower bin specified as 0.04 &lt; <italic>p</italic> &lt; 0.045 and the upper bin as 0.045 &lt; p &lt; 0.05. We chose <italic>p</italic> &lt; 0.05 as the cutoff for our upper bin (following [<xref rid="pbio.1002106.ref003" ref-type="bibr">3</xref>]), rather than <italic>p</italic> = 0.05 (see [<xref rid="pbio.1002106.ref046" ref-type="bibr">46</xref>]) because we suspect that many authors do not regard <italic>p</italic> = 0.05 as significant. As a measure of the strength of p-hacking, we present the proportion of <italic>p</italic>-values in the upper bin and the associated 95% confidence intervals (calculated following Clopper and Pearson [<xref rid="pbio.1002106.ref047" ref-type="bibr">47</xref>] using the <italic>binom.test</italic> function in R).</p>
<p>We ran the above analyses separately for each discipline and meta-analysis dataset. In addition, we tested for overall evidential value (two-tailed test) and signs of p-hacking (one-tailed test) in the two main datasets (Text-mining of <italic>p</italic>-values and the meta-analysis data sets respectively). To do this, we used the proportion of <italic>p</italic>-values occurring in the upper bin for each discipline or meta-analysis (depending on the dataset being analysed) and ran a binomial generalised linear model to test whether the observed intercept differed from 0.5 (i.e., equal number of cases in the two bins). This approach is equivalent to a meta-analysis testing for a significant trend when combining the individual disciplines or questions because each is weighted by its sample size. The R code we used is deposited in Dryad [<xref rid="pbio.1002106.ref048" ref-type="bibr">48</xref>].</p>
</sec>
</sec>
</boxed-text>
<fig id="pbio.1002106.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.1002106.g001</object-id>
<label>Fig 1</label>
<caption>
<title>The effect of publication bias on the distribution of <italic>p</italic>-values around the significance threshold of 0.05.</title>
<p>A) Black line shows distribution of p-values when there is no evidential value and the red line shows how publication bias influences this distribution. B) Black line shows distribution of <italic>p</italic>-values when there is evidential value and red line shows how publication bias influences this distribution. Tests for publication bias due to a file-drawer effect often compare the number of <italic>p</italic>-values in each of the bins either side of 0.05.</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1002106.g001" position="float" xlink:type="simple"/>
</fig>
<fig id="pbio.1002106.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.1002106.g002</object-id>
<label>Fig 2</label>
<caption>
<title>The effect of p-hacking on the distribution of p-values in the range of significance.</title>
<p>A) Black line shows distribution of <italic>p</italic>-values when there is no evidential value and the red line shows how p-hacking influences this distribution. B) Black line shows distribution of <italic>p</italic>-values when there is evidential value and the red line shows how p-hacking influences this distribution. Tests for p-hacking often compare the number of <italic>p</italic>-values in two adjacent bins just below 0.05.</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1002106.g002" position="float" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec008">
<title>Assessing the Extent of P-Hacking in the Scientific Literature Using Text-Mining</title>
<p>We used text-mining to search for <italic>p</italic>-values in all Open Access papers available in the PubMed database (see <xref rid="pbio.1002106.s001" ref-type="supplementary-material">S1 Text</xref>). To quantify “evidential value” (i.e., if there is evidence that the true effect size is nonzero) and p-hacking, we constructed p-curves from the <italic>p</italic>-values we obtained (see <xref ref-type="boxed-text" rid="pbio.1002106.box002">Box 2</xref>). We present separate tests of evidential value and p-hacking for <italic>p</italic>-values extracted from the Results section, and for <italic>p</italic>-values extracted from the Abstracts. Researchers have identified weaknesses in the use of text-mined data to look for publication bias (e.g., [<xref rid="pbio.1002106.ref046" ref-type="bibr">46</xref>]). Here, we adopted several measures to counter these weaknesses (see <xref rid="pbio.1002106.s001" ref-type="supplementary-material">S1 Text</xref>).</p>
<p>Pooling <italic>p</italic>-values across all disciplines, there was strong evidence for “evidential value”; that is, researchers appear to be predominantly studying phenomena with nonzero effect sizes, as shown by the strong right skew of the p-curve for <italic>p</italic>-values found in both the Results (binomial glm: estimated proportion of <italic>p</italic>-values in the upper bin (0.025 ≤ <italic>p</italic> &lt; 0.05) (lower CI, upper CI) = 0.257 (0.254, 0.259), <italic>p</italic> &lt; 0.001, n = 14 disciplines) and the Abstracts (binomial glm: estimated proportion of <italic>p</italic>-values in the upper bin (0.025 ≤ p &lt; 0.05) (lower CI, upper CI) = 0.262 (0.257, 0.267), <italic>p</italic> &lt; 0.001, n = 10 disciplines). We found significant evidential value in every discipline represented in our text-mining data, irrespective of whether we tested the <italic>p</italic>-values from the Results or Abstracts (<xref rid="pbio.1002106.t001" ref-type="table">Table 1</xref>; <xref rid="pbio.1002106.t002" ref-type="table">Table 2</xref>). Based on the net trend across all disciplines, however, there was also strong evidence for p-hacking in both the Results (binomial glm: estimated proportion of <italic>p</italic>-values in the upper bin (0.045 &lt; <italic>p</italic> &lt; 0.05) (lower CI) = 0.546 (0.536), <italic>p</italic> &lt; 0.001, n = 14 disciplines) and the Abstracts (binomial glm: estimated proportion of p-values in the upper bin (0.045 &lt; p &lt; 0.05) (lower CI) = 0.537 (0.518), <italic>p</italic> &lt; 0.001, n = 10 disciplines). In most disciplines, there were more <italic>p</italic>-values in the upper than the lower bin; and when we look at the <italic>p</italic>-values text-mined from Results sections in every discipline where we had good statistical power (i.e., Health and medical Sciences, Biological Sciences, and Multidisciplinary), this difference was statistically significant (<xref rid="pbio.1002106.t001" ref-type="table">Table 1</xref>, <xref rid="pbio.1002106.g003" ref-type="fig">Fig. 3A</xref>). When looking at <italic>p</italic>-values text-mined from Abstracts, despite the significant general trend, only the multidisciplinary and Information and Computer Science categories were significant (<xref rid="pbio.1002106.t002" ref-type="table">Table 2</xref>, <xref rid="pbio.1002106.g003" ref-type="fig">Fig. 3B</xref>).</p>
<fig id="pbio.1002106.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.1002106.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Evidence for p-hacking across scientific disciplines.</title>
<p>A) Evidence for p-hacking from <italic>p</italic>-values obtained from Results sections. B) Evidence for p-hacking from <italic>p</italic>-values obtained from Abstracts. The strength of p-hacking is presented as the proportion of p-values in the upper bin (0.045 &lt; p &lt; 0.05) with one-tailed 95% confidence intervals (calculated following Clopper and Pearson [<xref rid="pbio.1002106.ref047" ref-type="bibr">47</xref>] using the <italic>binom.test</italic> function in R). Only disciplines where text-mining of the Results sections returned more than 25 <italic>p</italic>-values between 0.04 and 0.05 are presented. Marker colour is shaded according to the sample size: with white indicating low samples sizes and red indicating larger sample sizes.</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1002106.g003" position="float" xlink:type="simple"/>
</fig>
<table-wrap id="pbio.1002106.t001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.1002106.t001</object-id>
<label>Table 1</label> <caption><title>Tests for evidential value and p-hacking across disciplines, using <italic>p</italic>-values obtained from the Results section.</title></caption>
<alternatives>
<graphic id="pbio.1002106.t001g" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1002106.t001" xlink:type="simple"/>
<table>
<colgroup span="1">
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
</colgroup>
<thead>
<tr>
<th align="left" rowspan="1" colspan="1">Discipline</th>
<th align="left" rowspan="1" colspan="1">Number of <italic>p</italic>-values between 0 and 0.025</th>
<th align="left" rowspan="1" colspan="1">Number of <italic>p</italic>-values between 0.025 and 0.05</th>
<th align="left" rowspan="1" colspan="1">Binomial test for evidential value</th>
<th align="left" rowspan="1" colspan="1">Number of <italic>p</italic>-values between 0.04 and 0.045</th>
<th align="left" rowspan="1" colspan="1">Number of <italic>p</italic>-values between 0.045 and 0.05</th>
<th align="left" rowspan="1" colspan="1">Binomial test forp-hacking</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">Agricultural and veterinary sciences</td>
<td align="left" rowspan="1" colspan="1">375</td>
<td align="left" rowspan="1" colspan="1">125</td>
<td align="left" rowspan="1" colspan="1">&lt;0.001</td>
<td align="left" rowspan="1" colspan="1">10</td>
<td align="left" rowspan="1" colspan="1">16</td>
<td align="left" rowspan="1" colspan="1">0.163</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Biological sciences</td>
<td align="left" rowspan="1" colspan="1">11,074</td>
<td align="left" rowspan="1" colspan="1">3,562</td>
<td align="left" rowspan="1" colspan="1">&lt;0.001</td>
<td align="left" rowspan="1" colspan="1">350</td>
<td align="left" rowspan="1" colspan="1">423</td>
<td align="left" rowspan="1" colspan="1">0.005</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Chemical sciences</td>
<td align="left" rowspan="1" colspan="1">380</td>
<td align="left" rowspan="1" colspan="1">110</td>
<td align="left" rowspan="1" colspan="1">&lt;0.001</td>
<td align="left" rowspan="1" colspan="1">14</td>
<td align="left" rowspan="1" colspan="1">17</td>
<td align="left" rowspan="1" colspan="1">0.360</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Earth sciences</td>
<td align="left" rowspan="1" colspan="1">76</td>
<td align="left" rowspan="1" colspan="1">25</td>
<td align="left" rowspan="1" colspan="1">&lt;0.001</td>
<td align="left" rowspan="1" colspan="1">0</td>
<td align="left" rowspan="1" colspan="1">4</td>
<td align="left" rowspan="1" colspan="1">0.063</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Education</td>
<td align="left" rowspan="1" colspan="1">280</td>
<td align="left" rowspan="1" colspan="1">101</td>
<td align="left" rowspan="1" colspan="1">&lt;0.001</td>
<td align="left" rowspan="1" colspan="1">9</td>
<td align="left" rowspan="1" colspan="1">8</td>
<td align="left" rowspan="1" colspan="1">0.685</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Engineering</td>
<td align="left" rowspan="1" colspan="1">471</td>
<td align="left" rowspan="1" colspan="1">183</td>
<td align="left" rowspan="1" colspan="1">&lt;0.001</td>
<td align="left" rowspan="1" colspan="1">16</td>
<td align="left" rowspan="1" colspan="1">12</td>
<td align="left" rowspan="1" colspan="1">0.828</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Environmental sciences</td>
<td align="left" rowspan="1" colspan="1">657</td>
<td align="left" rowspan="1" colspan="1">190</td>
<td align="left" rowspan="1" colspan="1">&lt;0.001</td>
<td align="left" rowspan="1" colspan="1">10</td>
<td align="left" rowspan="1" colspan="1">19</td>
<td align="left" rowspan="1" colspan="1">0.068</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Information and computing sciences</td>
<td align="left" rowspan="1" colspan="1">790</td>
<td align="left" rowspan="1" colspan="1">266</td>
<td align="left" rowspan="1" colspan="1">&lt;0.001</td>
<td align="left" rowspan="1" colspan="1">20</td>
<td align="left" rowspan="1" colspan="1">30</td>
<td align="left" rowspan="1" colspan="1">0.101</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Mathematical sciences</td>
<td align="left" rowspan="1" colspan="1">72</td>
<td align="left" rowspan="1" colspan="1">22</td>
<td align="left" rowspan="1" colspan="1">&lt;0.001</td>
<td align="left" rowspan="1" colspan="1">3</td>
<td align="left" rowspan="1" colspan="1">0</td>
<td align="left" rowspan="1" colspan="1">1.000</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Medical and health sciences</td>
<td align="left" rowspan="1" colspan="1">45,460</td>
<td align="left" rowspan="1" colspan="1">16,537</td>
<td align="left" rowspan="1" colspan="1">&lt;0.001</td>
<td align="left" rowspan="1" colspan="1">1,477</td>
<td align="left" rowspan="1" colspan="1">1,785</td>
<td align="left" rowspan="1" colspan="1">&lt;0.001</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Multidisciplinary</td>
<td align="left" rowspan="1" colspan="1">21,209</td>
<td align="left" rowspan="1" colspan="1">6,793</td>
<td align="left" rowspan="1" colspan="1">&lt;0.001</td>
<td align="left" rowspan="1" colspan="1">638</td>
<td align="left" rowspan="1" colspan="1">750</td>
<td align="left" rowspan="1" colspan="1">0.001</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Psychology and cognitive sciences</td>
<td align="left" rowspan="1" colspan="1">1,355</td>
<td align="left" rowspan="1" colspan="1">487</td>
<td align="left" rowspan="1" colspan="1">&lt;0.001</td>
<td align="left" rowspan="1" colspan="1">29</td>
<td align="left" rowspan="1" colspan="1">50</td>
<td align="left" rowspan="1" colspan="1">0.012</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Studies in human society</td>
<td align="left" rowspan="1" colspan="1">139</td>
<td align="left" rowspan="1" colspan="1">45</td>
<td align="left" rowspan="1" colspan="1">&lt;0.001</td>
<td align="left" rowspan="1" colspan="1">8</td>
<td align="left" rowspan="1" colspan="1">3</td>
<td align="left" rowspan="1" colspan="1">0.967</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Technology</td>
<td align="left" rowspan="1" colspan="1">94</td>
<td align="left" rowspan="1" colspan="1">37</td>
<td align="left" rowspan="1" colspan="1">&lt;0.001</td>
<td align="left" rowspan="1" colspan="1">3</td>
<td align="left" rowspan="1" colspan="1">3</td>
<td align="left" rowspan="1" colspan="1">0.656</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t001fn001"><p>Number of <italic>p</italic>-values in each bin is the mean number based on 1,000 bootstraps of one <italic>p</italic>-value per Results section, rounded to the nearest whole number. Disciplines (n = 8) for which we found fewer than 50 <italic>p</italic>-values below 0.05 in the Results section were excluded.</p></fn>
</table-wrap-foot>
</table-wrap>
<table-wrap id="pbio.1002106.t002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.1002106.t002</object-id>
<label>Table 2</label> <caption><title>Tests for evidential value and p-hacking across disciplines, using <italic>p</italic>-values obtained from the Abstract.</title></caption>
<alternatives>
<graphic id="pbio.1002106.t002g" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1002106.t002" xlink:type="simple"/>
<table>
<colgroup span="1">
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
</colgroup>
<thead>
<tr>
<th align="left" rowspan="1" colspan="1">Discipline</th>
<th align="left" rowspan="1" colspan="1">Number of <italic>p</italic>-values between 0 and 0.025</th>
<th align="left" rowspan="1" colspan="1">Number of <italic>p</italic>-values between 0.025 and 0.05</th>
<th align="left" rowspan="1" colspan="1">Binomial test for evidential value</th>
<th align="left" rowspan="1" colspan="1">Number of <italic>p</italic>-values between 0.04 and 0.045</th>
<th align="left" rowspan="1" colspan="1">Number of <italic>p</italic>-values between 0.045 and 0.05</th>
<th align="left" rowspan="1" colspan="1">Binomial test for p-hacking</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">Agricultural and veterinary sciences</td>
<td align="left" rowspan="1" colspan="1">96</td>
<td align="left" rowspan="1" colspan="1">35</td>
<td align="char" char="." rowspan="1" colspan="1">&lt;0.001</td>
<td align="left" rowspan="1" colspan="1">3</td>
<td align="left" rowspan="1" colspan="1">2</td>
<td align="left" rowspan="1" colspan="1">0.813</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Biological sciences</td>
<td align="left" rowspan="1" colspan="1">1,787</td>
<td align="left" rowspan="1" colspan="1">632</td>
<td align="char" char="." rowspan="1" colspan="1">&lt;0.001</td>
<td align="left" rowspan="1" colspan="1">54</td>
<td align="left" rowspan="1" colspan="1">66</td>
<td align="left" rowspan="1" colspan="1">0.158</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Chemical sciences</td>
<td align="left" rowspan="1" colspan="1">76</td>
<td align="left" rowspan="1" colspan="1">31</td>
<td align="char" char="." rowspan="1" colspan="1">&lt;0.001</td>
<td align="left" rowspan="1" colspan="1">3</td>
<td align="left" rowspan="1" colspan="1">4</td>
<td align="left" rowspan="1" colspan="1">0.500</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Education</td>
<td align="left" rowspan="1" colspan="1">88</td>
<td align="left" rowspan="1" colspan="1">22</td>
<td align="char" char="." rowspan="1" colspan="1">&lt;0.001</td>
<td align="left" rowspan="1" colspan="1">2</td>
<td align="left" rowspan="1" colspan="1">0</td>
<td align="left" rowspan="1" colspan="1">1.000</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Engineering</td>
<td align="left" rowspan="1" colspan="1">121</td>
<td align="left" rowspan="1" colspan="1">52</td>
<td align="char" char="." rowspan="1" colspan="1">&lt;0.001</td>
<td align="left" rowspan="1" colspan="1">2</td>
<td align="left" rowspan="1" colspan="1">1</td>
<td align="left" rowspan="1" colspan="1">0.875</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Environmental sciences</td>
<td align="left" rowspan="1" colspan="1">42</td>
<td align="left" rowspan="1" colspan="1">15</td>
<td align="char" char="." rowspan="1" colspan="1">&lt;0.001</td>
<td align="left" rowspan="1" colspan="1">2</td>
<td align="left" rowspan="1" colspan="1">2</td>
<td align="left" rowspan="1" colspan="1">0.688</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Information and computing sciences</td>
<td align="left" rowspan="1" colspan="1">251</td>
<td align="left" rowspan="1" colspan="1">105</td>
<td align="char" char="." rowspan="1" colspan="1">&lt;0.001</td>
<td align="left" rowspan="1" colspan="1">5</td>
<td align="left" rowspan="1" colspan="1">15</td>
<td align="left" rowspan="1" colspan="1">0.021</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Medical and health sciences</td>
<td align="left" rowspan="1" colspan="1">18,428</td>
<td align="left" rowspan="1" colspan="1">6,692</td>
<td align="char" char="." rowspan="1" colspan="1">&lt;0.001</td>
<td align="left" rowspan="1" colspan="1">633</td>
<td align="left" rowspan="1" colspan="1">692</td>
<td align="left" rowspan="1" colspan="1">0.056</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Multidisciplinary</td>
<td align="left" rowspan="1" colspan="1">5,056</td>
<td align="left" rowspan="1" colspan="1">1,621</td>
<td align="char" char="." rowspan="1" colspan="1">&lt;0.001</td>
<td align="left" rowspan="1" colspan="1">123</td>
<td align="left" rowspan="1" colspan="1">174</td>
<td align="left" rowspan="1" colspan="1">0.002</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Psychology and cognitive sciences</td>
<td align="left" rowspan="1" colspan="1">98</td>
<td align="left" rowspan="1" colspan="1">37</td>
<td align="char" char="." rowspan="1" colspan="1">&lt;0.001</td>
<td align="left" rowspan="1" colspan="1">1</td>
<td align="left" rowspan="1" colspan="1">5</td>
<td align="left" rowspan="1" colspan="1">0.109</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t002fn001"><p>Number of <italic>p</italic>-values in each bin is the mean number based on 1,000 bootstraps of one <italic>p</italic>-value per Abstract, rounded to the nearest whole number. Disciplines (n = 12) for which we found fewer than 50 <italic>p</italic>-values below 0.05 in the Abstract were excluded.</p></fn>
</table-wrap-foot>
</table-wrap>
<p>Our text-mining suggests that p-hacking is widespread. Other studies that have inspected p-curves for far smaller sets of journals have also found evidence of p-hacking [<xref rid="pbio.1002106.ref012" ref-type="bibr">12</xref>,<xref rid="pbio.1002106.ref040" ref-type="bibr">40</xref>,<xref rid="pbio.1002106.ref045" ref-type="bibr">45</xref>]. By contrast, Jager and Leek [<xref rid="pbio.1002106.ref003" ref-type="bibr">3</xref>] found no evidence of p-hacking in a text-mining study of five medical journals. However, they were criticized for using <italic>p</italic>-values from Abstracts [<xref rid="pbio.1002106.ref046" ref-type="bibr">46</xref>], because reporting <italic>p</italic>-values in Abstracts is optional, so they are more likely to contain only the strongest results (i.e., smallest <italic>p</italic>-values). Such a bias would exaggerate evidential value in our analysis, and make it harder to detect p-hacking (e.g., if researchers censor results with <italic>p</italic> = 0.049 from the Abstract, but not <italic>p</italic> = 0.041). Even though Abstracts are more likely to contain <italic>p</italic>-values that relate to primary hypotheses, which are expected to be more strongly p-hacked than <italic>p</italic>-values from less interesting, ancillary tests [<xref rid="pbio.1002106.ref041" ref-type="bibr">41</xref>], lower power and reporting bias may impede detection of p-hacking using <italic>p</italic>-values obtained from Abstracts. The fact that we find evidence for p-hacking when using <italic>p</italic>-values from either the Abstracts or the Results sections across all scientific disciplines for which data are available (our overall analysis) supports the conclusion that p-hacking is rife.</p>
<p>Although we present evidence that p-hacking is widespread, there was still a strong right skew in all the p-curves we examined. This is consistent with researchers investigating predictions that lead to refutation of the null hypothesis, implying that the average true effect size studied by life scientists is nonzero. Given recent concerns about the lack of reproducibility of findings (e.g., [<xref rid="pbio.1002106.ref049" ref-type="bibr">49</xref>] but see [<xref rid="pbio.1002106.ref050" ref-type="bibr">50</xref>]) and the possibility that many published results are false [<xref rid="pbio.1002106.ref002" ref-type="bibr">2</xref>], our results are reassuring. It is, of course, important to note that when using text-mining, we are combining many different types of questions to generate our p-curves. Consequently, it remains unclear whether there are some research fields or questions subsumed within the disciplines we considered for which the average effect size of published results is zero (i.e., the p-curve is flat). To examine this, it is important to also look at p-curves for well-defined research questions [<xref rid="pbio.1002106.ref041" ref-type="bibr">41</xref>].</p>
</sec>
<sec id="sec009">
<title>The Consequences of P-Hacking for Meta-analyses</title>
<p>Meta-analysis is an excellent method for systematically synthesizing the literature and quantifying an effect or relationship by averaging effect sizes from multiple studies after weighting each one by its reliability [<xref rid="pbio.1002106.ref033" ref-type="bibr">33</xref>,<xref rid="pbio.1002106.ref051" ref-type="bibr">51</xref>]. However, meta-analyses are only as good as the data they use, and a recent study estimated that up to 37% of meta-analyses of clinical trials reporting a significant mean effect size represent false positives [<xref rid="pbio.1002106.ref034" ref-type="bibr">34</xref>].</p>
<p>Tests for evidential value and p-hacking can readily be used to detect biases in datasets used in meta-analyses. We encourage researchers conducting meta-analyses to report <italic>p</italic>-values associated with each effect size (which is not currently standard practice) and then to test for evidential value and p-hacking. For a recent example of this practice, see [<xref rid="pbio.1002106.ref052" ref-type="bibr">52</xref>]. To demonstrate this procedure, we obtained <italic>p</italic>-values from studies subject to meta-analyses by evolutionary biologists studying sexual selection [<xref rid="pbio.1002106.ref053" ref-type="bibr">53</xref>–<xref rid="pbio.1002106.ref061" ref-type="bibr">61</xref>] (see <xref rid="pbio.1002106.s001" ref-type="supplementary-material">S1 Text</xref>).</p>
<p>When conducting our own meta-analysis of all the data used in these meta-analyses, there was clear evidence that researchers have strong evidential value for claims that effect sizes are nonzero (binomial glm: estimated proportion of <italic>p</italic>-values in the upper bin (0.025 ≤ p &lt; 0.05) (lower CI, upper CI) = 0.202 (0.179, 0.228), <italic>p</italic>&lt;0.001, n = 12 datasets). We then examined each dataset separately and found statistically significant evidential value for 9 of the 12 p-curves (<xref rid="pbio.1002106.t003" ref-type="table">Table 3</xref>). The three p-curves that did not show evidential value had the three lowest sample sizes, so low statistical power to detect evidential value may explain the lack of significance. Again, it is worth noting that evidential value for well-studied phenomena is not a given (see a real-world example in [<xref rid="pbio.1002106.ref062" ref-type="bibr">62</xref>]).</p>
<table-wrap id="pbio.1002106.t003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.1002106.t003</object-id>
<label>Table 3</label> <caption><title>Tests for evidential value and p-hacking for published meta-analyses.</title></caption>
<alternatives>
<graphic id="pbio.1002106.t003g" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1002106.t003" xlink:type="simple"/>
<table>
<colgroup span="1">
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
</colgroup>
<thead>
<tr>
<th align="left" rowspan="1" colspan="1">Meta-analysis</th>
<th align="left" rowspan="1" colspan="1">Number of <italic>p</italic>-values between 0 and 0.025</th>
<th align="left" rowspan="1" colspan="1">Number of <italic>p</italic>-values between 0.025 and 0.05</th>
<th align="left" rowspan="1" colspan="1">Binomial test for evidential value</th>
<th align="left" rowspan="1" colspan="1">Number of <italic>p</italic>-values between 0.04 and 0.045</th>
<th align="left" rowspan="1" colspan="1">Number of <italic>p</italic>-values between 0.045 and 0.05</th>
<th align="left" rowspan="1" colspan="1">Binomial test for p-hacking</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">Ackay &amp; Roughgraden 2007 (1)</td>
<td align="left" rowspan="1" colspan="1">26</td>
<td align="left" rowspan="1" colspan="1">9</td>
<td align="left" rowspan="1" colspan="1">0.006</td>
<td align="left" rowspan="1" colspan="1">0 (0)</td>
<td align="left" rowspan="1" colspan="1">1 (1)</td>
<td align="left" rowspan="1" colspan="1">0.500 (0.500)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Cleasby &amp; Nakagawa 2012</td>
<td align="left" rowspan="1" colspan="1">12</td>
<td align="left" rowspan="1" colspan="1">4</td>
<td align="left" rowspan="1" colspan="1">0.077</td>
<td align="left" rowspan="1" colspan="1">0 (0)</td>
<td align="left" rowspan="1" colspan="1">2 (1)</td>
<td align="left" rowspan="1" colspan="1">0.250 (0.500)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">de Jong et al. 2012</td>
<td align="left" rowspan="1" colspan="1">22</td>
<td align="left" rowspan="1" colspan="1">1</td>
<td align="left" rowspan="1" colspan="1">&lt;0.001</td>
<td align="left" rowspan="1" colspan="1">0 (0)</td>
<td align="left" rowspan="1" colspan="1">0 (0)</td>
<td align="left" rowspan="1" colspan="1">NA</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Jiang et a.l 2013</td>
<td align="left" rowspan="1" colspan="1">318</td>
<td align="left" rowspan="1" colspan="1">82</td>
<td align="left" rowspan="1" colspan="1">&lt;0.001</td>
<td align="left" rowspan="1" colspan="1">7 (7)</td>
<td align="left" rowspan="1" colspan="1">17 (11)</td>
<td align="left" rowspan="1" colspan="1">0.032 (0.240)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Kelly 2008 (1)</td>
<td align="left" rowspan="1" colspan="1">83</td>
<td align="left" rowspan="1" colspan="1">23</td>
<td align="left" rowspan="1" colspan="1">&lt;0.001</td>
<td align="left" rowspan="1" colspan="1">3 (3)</td>
<td align="left" rowspan="1" colspan="1">5 (3)</td>
<td align="left" rowspan="1" colspan="1">0.363 (0.656)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Kelly 2008 (2)</td>
<td align="left" rowspan="1" colspan="1">91</td>
<td align="left" rowspan="1" colspan="1">18</td>
<td align="left" rowspan="1" colspan="1">&lt;0.001</td>
<td align="left" rowspan="1" colspan="1">2 (2)</td>
<td align="left" rowspan="1" colspan="1">4 (2)</td>
<td align="left" rowspan="1" colspan="1">0.344 (0.688)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Kelly 2008 (3)</td>
<td align="left" rowspan="1" colspan="1">72</td>
<td align="left" rowspan="1" colspan="1">18</td>
<td align="left" rowspan="1" colspan="1">&lt;0.001</td>
<td align="left" rowspan="1" colspan="1">3 (3)</td>
<td align="left" rowspan="1" colspan="1">6 (1)</td>
<td align="left" rowspan="1" colspan="1">0.254 (0.938)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Kraaijeveld et al. 2011</td>
<td align="left" rowspan="1" colspan="1">10</td>
<td align="left" rowspan="1" colspan="1">4</td>
<td align="left" rowspan="1" colspan="1">0.180</td>
<td align="left" rowspan="1" colspan="1">0 (0)</td>
<td align="left" rowspan="1" colspan="1">1 (1)</td>
<td align="left" rowspan="1" colspan="1">0.500 (0.500)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Prokop et al. 2012</td>
<td align="left" rowspan="1" colspan="1">79</td>
<td align="left" rowspan="1" colspan="1">15</td>
<td align="left" rowspan="1" colspan="1">&lt;0.001</td>
<td align="left" rowspan="1" colspan="1">2 (2)</td>
<td align="left" rowspan="1" colspan="1">2 (2)</td>
<td align="left" rowspan="1" colspan="1">0.688 (0.688)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Santos et al. 2011</td>
<td align="left" rowspan="1" colspan="1">40</td>
<td align="left" rowspan="1" colspan="1">23</td>
<td align="left" rowspan="1" colspan="1">0.043</td>
<td align="left" rowspan="1" colspan="1">8 (8)</td>
<td align="left" rowspan="1" colspan="1">2 (2)</td>
<td align="left" rowspan="1" colspan="1">0.989 (0.989)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Weir et al. 2011 (1)</td>
<td align="left" rowspan="1" colspan="1">15</td>
<td align="left" rowspan="1" colspan="1">2</td>
<td align="left" rowspan="1" colspan="1">0.002</td>
<td align="left" rowspan="1" colspan="1">0 (0)</td>
<td align="left" rowspan="1" colspan="1">0 (0)</td>
<td align="left" rowspan="1" colspan="1">NA</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Weir et al. 2011 (4)</td>
<td align="left" rowspan="1" colspan="1">9</td>
<td align="left" rowspan="1" colspan="1">2</td>
<td align="left" rowspan="1" colspan="1">0.065</td>
<td align="left" rowspan="1" colspan="1">0 (0)</td>
<td align="left" rowspan="1" colspan="1">0 (0)</td>
<td align="left" rowspan="1" colspan="1">NA</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t003fn001"><p>Meta-analyses with ten or fewer significant <italic>p</italic>-values are not shown. Numbers in the lower and upper bins of the p-hacking test are those including misreported <italic>p</italic>-values followed by those excluding misreported <italic>p</italic>-values in brackets.</p></fn>
</table-wrap-foot>
</table-wrap>
<p>When considering evidence for p-hacking, we found that when we included misreported <italic>p</italic>-values (those given as <italic>p</italic> &lt; 0.05 which were actually larger; a total of 16 cases—see <xref rid="pbio.1002106.s001" ref-type="supplementary-material">S1 Text</xref>) there were more <italic>p</italic>-values in the upper than the lower bin for 7 of 12 p-curves (<xref rid="pbio.1002106.t003" ref-type="table">Table 3</xref>). This bias was significant in one dataset (<xref rid="pbio.1002106.g004" ref-type="fig">Fig. 4</xref>), which was also the one with the largest sample size. However, the evidence for p-hacking disappeared when we excluded misreported <italic>p</italic>-values from our analyses (<xref rid="pbio.1002106.t003" ref-type="table">Table 3</xref>). One could argue that including misreported <italic>p</italic>-values in the upper bin of our binomial test biases our results toward detecting p-hacking, but reporting nonsignificant results as “<italic>p</italic>&lt;0.05” is a component of p-hacking that should not be ignored. Indeed, Leggett et al. [<xref rid="pbio.1002106.ref045" ref-type="bibr">45</xref>] also found considerable misreporting of <italic>p</italic>-values around the 0.05 threshold. They noted that <italic>p</italic>-values were more likely to be misreported as significant when they were not, rather than the reverse, and that this “error” has become more common in recent years.</p>
<fig id="pbio.1002106.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.1002106.g004</object-id>
<label>Fig 4</label>
<caption>
<title>The distribution of <italic>p</italic>-values associated with the meta-analysis conducted by Jiang et al. (2013).</title>
<p>The p-curve shows evidence for evidential value (strong right skew) and p-hacking (rise in <italic>p</italic>-values just below 0.05).</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1002106.g004" position="float" xlink:type="simple"/>
</fig>
<p>More importantly, when misreported <italic>p</italic>-values were included in our analysis we found significant p-hacking from a meta-analysis of the p-curves of the 12 meta-analyses (binomial glm: estimated proportion of p-values in the upper bin (0.045 &lt; <italic>p</italic> &lt; 0.05) (lower CI) = 0.615 (0.513), p = 0.033; excluding misreported <italic>p</italic>-values: 0.489 (0.375), <italic>p</italic> = 0.443). Although questions subjected to meta-analysis might not be a representative sample of all research questions asked by scientists, our results indicate that studies on questions identified by researchers as important enough to warrant a meta-analysis tend to be p-hacked. Whether this influences the general conclusions of a meta-analysis depends on both the extent of p-hacking and the strength of the true effect. For instance, we found a statistically significant indication of p-hacking in only one of the 12 questions examined in published meta-analyses (<xref rid="pbio.1002106.g004" ref-type="fig">Fig. 4</xref>). However, this study [<xref rid="pbio.1002106.ref056" ref-type="bibr">56</xref>] also showed strong evidential value and <italic>p</italic>-values in the 0.045–0.05 bin were only a small proportion of published significant <italic>p</italic>-values. It is therefore unlikely that p-hacking would change the qualitative conclusions made in this meta-analysis, although p-hacking might have inflated the estimated mean effect size. In general, meta-analyses might be robust to inflated effects sizes that results from p-hacking, because: 1) all else being equal, studies that are most susceptible to p-hacking are those with small sample sizes (i.e., because low statistical power means less chance of a significant result), and these are given less weighting in a meta-analysis, 2) at least in some fields (e.g., ecology and evolution), meta-analyses often use data that is not directly related to the primary focus of the original paper. The <italic>p</italic>-values associated with secondary questions are less likely to be p-hacked. One way to check how sensitive estimates of effects sizes are to p-hacking would be to randomly remove the appropriate number of studies that contribute to a hump in the p-curve just below 0.05. Alternatively, meta-analysts could estimate effect sizes using p-curves (i.e., using only the significant <italic>p</italic>-values they find), a method which has been proposed to account for publication biases and to offer a conservative estimate of the true effect when there is p-hacking [<xref rid="pbio.1002106.ref062" ref-type="bibr">62</xref>,<xref rid="pbio.1002106.ref063" ref-type="bibr">63</xref>]. Development of p-curve methods is ongoing and we look forward to further tests of their ability to correct for the file-drawer effect, p-hacking, and other forms of publication bias given that real world data are likely to violate some of the assumptions in the available simulations of their effectiveness.</p>
</sec>
<sec id="sec010">
<title>Summary and Conclusions</title>
<p>Our study provides two lines of empirical evidence that p-hacking is widespread in the scientific literature. Our text-mining approach is based on a very large dataset that consists of <italic>p</italic>-values from different disciplines and questions, while our meta-analysis approach consists of <italic>p</italic>-values concerning a few specific hypotheses. Both approaches yielded similar results: evidential value for claims that the mean effect sizes for key study questions are nonzero—the conclusions researchers are making based on significant study findings—but that estimated mean effect size has probably been inflated by p-hacking.</p>
<p>Eliminating p-hacking entirely is unlikely when career advancement is assessed by publication output, and publication decisions are affected by the <italic>p</italic>-value or other measures of statistical support for relationships. Even so, there are a number of steps that the research community and scientific publishers can take to decrease the occurrence of p-hacking (see <xref ref-type="boxed-text" rid="pbio.1002106.box003">Box 3</xref>).</p>
<boxed-text id="pbio.1002106.box003" position="float">
<sec id="sec011">
<title>Box 3. Recommendations</title>
<p>The key to decreasing p-hacking is better education of researchers. Many practices that lead to p-hacking are still deemed acceptable. John et al. [<xref rid="pbio.1002106.ref016" ref-type="bibr">16</xref>] measured the prevalence of questionable research practices in psychology. They asked survey participants if they had ever engaged in a set of questionable research practices and, if so, whether they thought their actions were defensible on a scale of 0–2 (0 = no, 1 = possibly, 2 = yes). Over 50% of participants admitted to “failing to report all of a study’s dependent measures” and “deciding whether to collect more data after looking to see whether the results were significant,” and these practices received a mean defensibility rating greater than 1.5. This indicates that many researchers p-hack but do not appreciate the extent to which this is a form of scientific misconduct. Amazingly, some animal ethics boards even encourage or mandate the termination of research if a significant result is obtained during the study, which is a particularly egregious form of p-hacking (Anonymous reviewer, personal communication).</p>
<sec id="sec012">
<title>What can researchers do?</title>
<list list-type="bullet">
<list-item><p>Clearly label research as prespecified (i.e., designed to answer a specific question, where detail of methods and analyses can be fully reported prior to data collection) or exploratory (i.e., involves exploration of data that looks intriguing, where methods and analyses used are often post hoc [<xref rid="pbio.1002106.ref013" ref-type="bibr">13</xref>]), so that readers can treat results with appropriate caution. Results from prespecified studies offer far more convincing evidence than those from exploratory research [<xref rid="pbio.1002106.ref002" ref-type="bibr">2</xref>].</p></list-item>
<list-item><p>Adhere to common analysis standards [<xref rid="pbio.1002106.ref002" ref-type="bibr">2</xref>]; measuring only response variables that are known (or predicted) to be important; and using sufficient sample sizes.</p></list-item>
<list-item><p>Perform data analysis blind wherever possible. This approach makes it difficult to p-hack for specific results.</p></list-item>
<list-item><p>Place greater emphasis on the quality of research methods and data collection rather than the significance or novelty of the subsequent findings when reviewing or assessing research. Ideally, methods should be assessed independently of results [<xref rid="pbio.1002106.ref013" ref-type="bibr">13</xref>,<xref rid="pbio.1002106.ref044" ref-type="bibr">44</xref>].</p></list-item>
</list>
</sec>
<sec id="sec013">
<title>What can journals do?</title>
<list list-type="bullet">
<list-item><p>Provide clear and detailed guidelines for the full reporting of data analyses and results. For instance, stating that it is necessary to report effect sizes whether small or large, to report all <italic>p</italic>-values to three decimal places [<xref rid="pbio.1002106.ref027" ref-type="bibr">27</xref>,<xref rid="pbio.1002106.ref064" ref-type="bibr">64</xref>], to report samples sizes, and, most importantly, to be explicit about the entire analysis process (not just the final tests used to generate reported <italic>p</italic>-values). This will reduce p-hacking and aid the collection of data for meta-analyses and text-mining studies.</p></list-item>
<list-item><p>Encourage and/or provide platforms for method prespecification [<xref rid="pbio.1002106.ref013" ref-type="bibr">13</xref>,<xref rid="pbio.1002106.ref065" ref-type="bibr">65</xref>]. Although methods and results in publications do not always match their prespecified protocols [<xref rid="pbio.1002106.ref005" ref-type="bibr">5</xref>,<xref rid="pbio.1002106.ref066" ref-type="bibr">66</xref>], prespecification allows readers to assess the risk of p-hacking and adjust their confidence in the reported outcomes accordingly.</p></list-item>
<list-item><p>Encourage and/or provide platforms for open access to raw data. While access to raw data does not prevent p-hacking, it does make researchers more accountable for marginal results and allows readers to reanalyze data to check the robustness of results.</p></list-item>
</list>
</sec>
</sec>
</boxed-text>
</sec>
<sec id="sec014">
<title>Supporting Information</title>
<supplementary-material id="pbio.1002106.s001" xlink:href="info:doi/10.1371/journal.pbio.1002106.s001" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:type="simple">
<label>S1 Text</label>
<caption>
<title>Details of how text-mined data and data from meta-analyses were collected and analysed.</title>
<p>(DOCX)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>We are grateful to members of the Jennions lab for comments and discussion on various versions of the manuscript.</p>
</ack>
<glossary>
<title>Abbreviations:</title>
<def-list>
<def-item><term>NHST</term>
<def><p>Null hypothesis significance testing</p></def>
</def-item>
</def-list>
</glossary>
<ref-list>
<title>References</title>
<ref id="pbio.1002106.ref001"><label>1</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Barch</surname> <given-names>DM</given-names></name>, <name name-style="western"><surname>Yarkoni</surname> <given-names>T</given-names></name> (<year>2013</year>) <article-title>Introduction to the special issue on reliability and replication in cognitive and affective neuroscience research</article-title>. <source>Cogn Affect Behav Neurosci</source> <volume>13</volume>: <fpage>687</fpage>–<lpage>689</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3758/s13415-013-0201-7" xlink:type="simple">10.3758/s13415-013-0201-7</ext-link></comment> <object-id pub-id-type="pmid">23922199</object-id></mixed-citation></ref>
<ref id="pbio.1002106.ref002"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ioannidis</surname> <given-names>JPA</given-names></name> (<year>2005</year>) <article-title>Why most published research findings are false</article-title>. <source>PLoS Med</source> <volume>2</volume>: <fpage>e124</fpage>. <object-id pub-id-type="pmid">16060722</object-id></mixed-citation></ref>
<ref id="pbio.1002106.ref003"><label>3</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jager</surname> <given-names>LR</given-names></name>, <name name-style="western"><surname>Leek</surname> <given-names>JT</given-names></name> (<year>2014</year>) <article-title>An estimate of the science-wise false discovery rate and application to the top medical literature</article-title>. <source>Biostatistics</source> <volume>15</volume>: <fpage>1</fpage>–<lpage>12</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/biostatistics/kxt007" xlink:type="simple">10.1093/biostatistics/kxt007</ext-link></comment> <object-id pub-id-type="pmid">24068246</object-id></mixed-citation></ref>
<ref id="pbio.1002106.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Begg</surname> <given-names>CB</given-names></name>, <name name-style="western"><surname>Berlin</surname> <given-names>JA</given-names></name> (<year>1988</year>) <article-title>Publication bias—a problem in interpreting medical data</article-title>. <source>J R Stat Soc Ser A Stat Soc</source> <volume>151</volume>: <fpage>419</fpage>–<lpage>463</lpage>.</mixed-citation></ref>
<ref id="pbio.1002106.ref005"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dwan</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Altman</surname> <given-names>DG</given-names></name>, <name name-style="western"><surname>Arnaiz</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Bloom</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Chan</surname> <given-names>A-W</given-names></name>, <etal>et al</etal>. (<year>2008</year>) <article-title>Systematic review of the empirical evidence of study publication bias and outcome reporting bias</article-title>. <source>PLoS ONE</source> <volume>3</volume>: <fpage>e3081</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0003081" xlink:type="simple">10.1371/journal.pone.0003081</ext-link></comment> <object-id pub-id-type="pmid">18769481</object-id></mixed-citation></ref>
<ref id="pbio.1002106.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fanelli</surname> <given-names>D</given-names></name> (<year>2012</year>) <article-title>Negative results are disappearing from most disciplines and countries</article-title>. <source>Scientometrics</source> <volume>90</volume>: <fpage>891</fpage>–<lpage>904</lpage>.</mixed-citation></ref>
<ref id="pbio.1002106.ref007"><label>7</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rosenthal</surname> <given-names>R</given-names></name> (<year>1979</year>) <article-title>The file drawer problem and tolerance for null results</article-title>. <source>Psychol Bull</source> <volume>86</volume>: <fpage>638</fpage>–<lpage>641</lpage>.</mixed-citation></ref>
<ref id="pbio.1002106.ref008"><label>8</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Song</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Eastwood</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Gilbody</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Duley</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Sutton</surname> <given-names>AJ</given-names></name> (<year>2000</year>) <article-title>Publication and related biases</article-title>. <source>Health technology assessment (Winchester, England)</source> <volume>4</volume>: <fpage>1</fpage>–<lpage>115</lpage>.</mixed-citation></ref>
<ref id="pbio.1002106.ref009"><label>9</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sterling</surname> <given-names>TD</given-names></name> (<year>1959</year>) <article-title>Publication decisions and their possible effects on inferences drawn from tests of significance—or vice versa</article-title>. <source>J Am Stat Assoc</source> <volume>54</volume>: <fpage>30</fpage>–<lpage>34</lpage>.</mixed-citation></ref>
<ref id="pbio.1002106.ref010"><label>10</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Stern</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Simes</surname> <given-names>RJ</given-names></name> (<year>1997</year>) <article-title>Publication bias: Evidence of delayed publication in a cohort study of clinical research projects</article-title>. <source>Br Med J</source> <volume>315</volume>: <fpage>640</fpage>–<lpage>645</lpage>. <object-id pub-id-type="pmid">9310565</object-id></mixed-citation></ref>
<ref id="pbio.1002106.ref011"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Laurance</surname> <given-names>WF</given-names></name>, <name name-style="western"><surname>Useche</surname> <given-names>DC</given-names></name>, <name name-style="western"><surname>Laurance</surname> <given-names>SG</given-names></name>, <name name-style="western"><surname>Bradshaw</surname> <given-names>CJA</given-names></name> (<year>2013</year>) <article-title>Predicting publication success for biologists</article-title>. <source>Bioscience</source> <volume>63</volume>: <fpage>817</fpage>–<lpage>823</lpage>.</mixed-citation></ref>
<ref id="pbio.1002106.ref012"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Brodeur A, Le M, Sangnier M, Zylberberg Y (2012) Star Wars: The empirics strike back. Paris School of Economics Working Paper 2012. <ext-link ext-link-type="uri" xlink:href="http://ssrn.com/abstract=2089580" xlink:type="simple">http://ssrn.com/abstract=2089580</ext-link>.</mixed-citation></ref>
<ref id="pbio.1002106.ref013"><label>13</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cumming</surname> <given-names>G</given-names></name> (<year>2014</year>) <article-title>The new statistics: Why and how</article-title>. <source>Psychol Sci</source> <volume>25</volume>: <fpage>7</fpage>–<lpage>29</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1177/0956797613504966" xlink:type="simple">10.1177/0956797613504966</ext-link></comment> <object-id pub-id-type="pmid">24220629</object-id></mixed-citation></ref>
<ref id="pbio.1002106.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Simmons</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Nelson</surname> <given-names>LD</given-names></name>, <name name-style="western"><surname>Simonsohn</surname> <given-names>U</given-names></name> (<year>2011</year>) <article-title>False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant</article-title>. <source>Psychol Sci</source> <volume>22</volume>: <fpage>1359</fpage>–<lpage>1366</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1177/0956797611417632" xlink:type="simple">10.1177/0956797611417632</ext-link></comment> <object-id pub-id-type="pmid">22006061</object-id></mixed-citation></ref>
<ref id="pbio.1002106.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gadbury</surname> <given-names>GL</given-names></name>, <name name-style="western"><surname>Allison</surname> <given-names>DB</given-names></name> (<year>2014</year>) <article-title>Inappropriate fiddling with statistical analyses to obtain a desirable p-value: Tests to detect its presence in published literature</article-title>. <source>PLoS ONE</source> <volume>7</volume>: <fpage>e46363</fpage>.</mixed-citation></ref>
<ref id="pbio.1002106.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>John</surname> <given-names>LK</given-names></name>, <name name-style="western"><surname>Loewenstein</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Prelec</surname> <given-names>D</given-names></name> (<year>2012</year>) <article-title>Measuring the prevalence of questionable research practices with incentives for truth telling</article-title>. <source>Psychol Sci</source> <volume>23</volume>: <fpage>524</fpage>–<lpage>532</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1177/0956797611430953" xlink:type="simple">10.1177/0956797611430953</ext-link></comment> <object-id pub-id-type="pmid">22508865</object-id></mixed-citation></ref>
<ref id="pbio.1002106.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hutton</surname> <given-names>JL</given-names></name>, <name name-style="western"><surname>Williamson</surname> <given-names>PR</given-names></name> (<year>2000</year>) <article-title>Bias in meta-analysis due to outcome variable selection within studies</article-title>. <source>J R Stat Soc Ser C Appl Stat</source> <volume>49</volume>: <fpage>359</fpage>–<lpage>370</lpage>.</mixed-citation></ref>
<ref id="pbio.1002106.ref018"><label>18</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bastardi</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Uhlmann</surname> <given-names>EL</given-names></name>, <name name-style="western"><surname>Ross</surname> <given-names>L</given-names></name> (<year>2011</year>) <article-title>Wishful thinking: Belief, desire, and the motivated evaluation of scientific evidence</article-title>. <source>Psychol Sci</source> <volume>22</volume>: <fpage>731</fpage>–<lpage>732</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1177/0956797611406447" xlink:type="simple">10.1177/0956797611406447</ext-link></comment> <object-id pub-id-type="pmid">21515736</object-id></mixed-citation></ref>
<ref id="pbio.1002106.ref019"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nosek</surname> <given-names>BA</given-names></name>, <name name-style="western"><surname>Spies</surname> <given-names>JR</given-names></name>, <name name-style="western"><surname>Motyl</surname> <given-names>M</given-names></name> (<year>2012</year>) <article-title>Scientific utopia: II. Restructuring incentives and practices to promote truth over publishability</article-title>. <source>Perspect Psychol Sci</source> <volume>7</volume>: <fpage>615</fpage>–<lpage>631</lpage>.</mixed-citation></ref>
<ref id="pbio.1002106.ref020"><label>20</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Fisher</surname> <given-names>RA</given-names></name> (<year>1925</year>) <chapter-title>Statistical methods for research workers</chapter-title>. <publisher-loc>London</publisher-loc>: <publisher-name>Oliver &amp; Boyd</publisher-name>.</mixed-citation></ref>
<ref id="pbio.1002106.ref021"><label>21</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Benjamini</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Hechtlinger</surname> <given-names>Y</given-names></name> (<year>2014</year>) <article-title>Discussion: An estimate of the science-wise false discovery rate and applications to top medical journals by Jager and Leek</article-title>. <source>Biostatistics</source> <volume>15</volume>: <fpage>13</fpage>–<lpage>16</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/biostatistics/kxt032" xlink:type="simple">10.1093/biostatistics/kxt032</ext-link></comment> <object-id pub-id-type="pmid">24068247</object-id></mixed-citation></ref>
<ref id="pbio.1002106.ref022"><label>22</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Goodman</surname> <given-names>SN</given-names></name> (<year>1999</year>) <article-title>Toward evidence-based medical statistics. 1: The P value fallacy</article-title>. <source>Ann Intern Med</source> <volume>130</volume>: <fpage>995</fpage>–<lpage>1004</lpage>. <object-id pub-id-type="pmid">10383371</object-id></mixed-citation></ref>
<ref id="pbio.1002106.ref023"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sterne</surname> <given-names>JAC</given-names></name>, <name name-style="western"><surname>Smith</surname> <given-names>GD</given-names></name> (<year>2001</year>) <article-title>Sifting the evidence—what's wrong with significance tests?</article-title> <source>Br Med J</source> <volume>322</volume>: <fpage>226</fpage>–<lpage>231</lpage>.</mixed-citation></ref>
<ref id="pbio.1002106.ref024"><label>24</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nickerson</surname> <given-names>RS</given-names></name> (<year>2000</year>) <article-title>Null hypothesis significance testing: A review of an old and continuing controversy</article-title>. <source>Psychol Methods</source> <volume>5</volume>: <fpage>241</fpage>–<lpage>301</lpage>. <object-id pub-id-type="pmid">10937333</object-id></mixed-citation></ref>
<ref id="pbio.1002106.ref025"><label>25</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Trafimow</surname> <given-names>D</given-names></name> (<year>2003</year>) <article-title>Hypothesis testing and theory evaluation at the boundaries: Surprising insights from Bayes's theorem</article-title>. <source>Psychol Rev</source> <volume>110</volume>: <fpage>526</fpage>–<lpage>535</lpage>. <object-id pub-id-type="pmid">12885113</object-id></mixed-citation></ref>
<ref id="pbio.1002106.ref026"><label>26</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Rohlf</surname> <given-names>FJ</given-names></name>, <name name-style="western"><surname>Sokal</surname> <given-names>RR</given-names></name> (<year>1995</year>) <chapter-title>Statistical tables</chapter-title>. <publisher-loc>New York</publisher-loc>: <publisher-name>W.H. Freeman</publisher-name>.</mixed-citation></ref>
<ref id="pbio.1002106.ref027"><label>27</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ridley</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Kolm</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Freckleton</surname> <given-names>RP</given-names></name>, <name name-style="western"><surname>Gage</surname> <given-names>MJG</given-names></name> (<year>2007</year>) <article-title>An unexpected influence of widely used significance thresholds on the distribution of reported P-values</article-title>. <source>J Evol Biol</source> <volume>20</volume>: <fpage>1082</fpage>–<lpage>1089</lpage>. <object-id pub-id-type="pmid">17465918</object-id></mixed-citation></ref>
<ref id="pbio.1002106.ref028"><label>28</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nakagawa</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Cuthill</surname> <given-names>IC</given-names></name> (<year>2007</year>) <article-title>Effect size, confidence interval and statistical significance: A practical guide for biologists</article-title>. <source>Biol Rev Camb Philos Soc</source> <volume>82</volume>: <fpage>591</fpage>–<lpage>605</lpage>. <object-id pub-id-type="pmid">17944619</object-id></mixed-citation></ref>
<ref id="pbio.1002106.ref029"><label>29</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Anderson</surname> <given-names>DR</given-names></name>, <name name-style="western"><surname>Burnham</surname> <given-names>KP</given-names></name>, <name name-style="western"><surname>Thompson</surname> <given-names>WL</given-names></name> (<year>2000</year>) <article-title>Null hypothesis testing: Problems, prevalence, and an alternative</article-title>. <source>J Wildl Manage</source> <volume>64</volume>: <fpage>912</fpage>–<lpage>923</lpage>.</mixed-citation></ref>
<ref id="pbio.1002106.ref030"><label>30</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Loftus</surname> <given-names>GR</given-names></name> (<year>1996</year>) <article-title>Psychology will be a much better science when we change the way we analyze data</article-title>. <source>Curr Dir Psychol Sci</source> <volume>5</volume>: <fpage>161</fpage>–<lpage>171</lpage>.</mixed-citation></ref>
<ref id="pbio.1002106.ref031"><label>31</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Benjamini</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Yekutieli</surname> <given-names>D</given-names></name> (<year>2005</year>) <article-title>False discovery rate-adjusted multiple confidence intervals for selected parameters</article-title> <source>J Am Stat Assoc</source> <volume>100</volume>: <fpage>71</fpage>–<lpage>81</lpage>.</mixed-citation></ref>
<ref id="pbio.1002106.ref032"><label>32</label><mixed-citation publication-type="other" xlink:type="simple">Simonsohn U (2014c) Posterior-hacking: Selective reporting invalidates Bayesian results also. <ext-link ext-link-type="uri" xlink:href="http://ssrncom/abstract=2374040" xlink:type="simple">http://ssrncom/abstract=2374040</ext-link>.</mixed-citation></ref>
<ref id="pbio.1002106.ref033"><label>33</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Koricheva</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Gurevitch</surname> <given-names>J</given-names></name> (<year>2013</year>) <chapter-title>Place of meta-analysis among other methods of research synthesis</chapter-title>. In: <name name-style="western"><surname>Koricheva</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Gurevitch</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Mengersen</surname> <given-names>K</given-names></name>, editors. <source>Handbook of met-analysis in ecology and evolution</source>. <publisher-loc>Princeton, New Jersey</publisher-loc>: <publisher-name>Princeton University Press</publisher-name>.</mixed-citation></ref>
<ref id="pbio.1002106.ref034"><label>34</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pereira</surname> <given-names>TV</given-names></name>, <name name-style="western"><surname>Ioannidis</surname> <given-names>JPA</given-names></name> (<year>2011</year>) <article-title>Statistically significant meta-analyses of clinical trials have modest credibility and inflated effects</article-title>. <source>J Clin Epidemiol</source> <volume>64</volume>: <fpage>1060</fpage>–<lpage>1069</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.jclinepi.2010.12.012" xlink:type="simple">10.1016/j.jclinepi.2010.12.012</ext-link></comment> <object-id pub-id-type="pmid">21454050</object-id></mixed-citation></ref>
<ref id="pbio.1002106.ref035"><label>35</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jennions</surname> <given-names>MD</given-names></name>, <name name-style="western"><surname>Moller</surname> <given-names>AP</given-names></name>, <name name-style="western"><surname>Hunt</surname> <given-names>J</given-names></name> (<year>2004</year>) <article-title>Meta-analysis can "fail": Reply to Kotiaho and Tomkins</article-title>. <source>Oikos</source> <volume>104</volume>: <fpage>191</fpage>–<lpage>193</lpage>.</mixed-citation></ref>
<ref id="pbio.1002106.ref036"><label>36</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kotiaho</surname> <given-names>JS</given-names></name>, <name name-style="western"><surname>Tomkins</surname> <given-names>JL</given-names></name> (<year>2002</year>) <article-title>Meta-analysis, can it ever fail?</article-title> <source>Oikos</source> <volume>96</volume>: <fpage>551</fpage>–<lpage>553</lpage>.</mixed-citation></ref>
<ref id="pbio.1002106.ref037"><label>37</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Palmer</surname> <given-names>AR</given-names></name> (<year>2000</year>) <article-title>Quasireplication and the contract of error: Lessons from sex ratios, heritabilities and fluctuating asymmetry</article-title>. <source>Annu Rev Ecol Sys</source> <volume>31</volume>: <fpage>441</fpage>–<lpage>480</lpage>.</mixed-citation></ref>
<ref id="pbio.1002106.ref038"><label>38</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kelly</surname> <given-names>CD</given-names></name> (<year>2006</year>) <article-title>Replicating empirical research in behavioural ecology: How and why it should be done but rarely ever is</article-title>. <source>The Quarterly Review of Biology</source> <volume>81</volume>: <fpage>221</fpage>–<lpage>236</lpage>. <object-id pub-id-type="pmid">17051829</object-id></mixed-citation></ref>
<ref id="pbio.1002106.ref039"><label>39</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cumming</surname> <given-names>G</given-names></name> (<year>2008</year>) <article-title>Replication and p intervals p values predict the future only vaguely, but confidence Intervals do much better</article-title>. <source>Perspectives on Psychological Science</source> <volume>3</volume>: <fpage>286</fpage>–<lpage>300</lpage>.</mixed-citation></ref>
<ref id="pbio.1002106.ref040"><label>40</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mariscampo</surname> <given-names>EJ</given-names></name>, <name name-style="western"><surname>Lalande</surname> <given-names>DR</given-names></name> (<year>2012</year>) <article-title>A peculiar prevalence of p values just below .05</article-title>. <source>Q Rev Biol</source> <volume>65</volume>: <fpage>2271</fpage>–<lpage>2279</lpage>.</mixed-citation></ref>
<ref id="pbio.1002106.ref041"><label>41</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Simonsohn</surname> <given-names>U</given-names></name>, <name name-style="western"><surname>Nelson</surname> <given-names>LD</given-names></name>, <name name-style="western"><surname>Simmons</surname> <given-names>JP</given-names></name> (<year>2014</year>a) <article-title>P-curve: A key to the file drawer</article-title>. <source>J Exp Psychol Gen</source> <volume>143</volume>: <fpage>534</fpage>–<lpage>547</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/a0033242" xlink:type="simple">10.1037/a0033242</ext-link></comment> <object-id pub-id-type="pmid">23855496</object-id></mixed-citation></ref>
<ref id="pbio.1002106.ref042"><label>42</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wallis</surname> <given-names>WA</given-names></name> (<year>1942</year>) <article-title>Compounding probabilities from independent significance tests</article-title>. <source>Econometrica</source> <volume>10</volume>: <fpage>229</fpage>–<lpage>248</lpage>.</mixed-citation></ref>
<ref id="pbio.1002106.ref043"><label>43</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gerber</surname> <given-names>AS</given-names></name>, <name name-style="western"><surname>Malhotra</surname> <given-names>N</given-names></name> (<year>2008</year>) <article-title>Publication bias in empirical sociological research—Do arbitrary significance levels distort published results?</article-title> <source>Sociol Methods Res</source> <volume>37</volume>: <fpage>3</fpage>–<lpage>30</lpage>.</mixed-citation></ref>
<ref id="pbio.1002106.ref044"><label>44</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ho</surname> <given-names>DE</given-names></name> (<year>2013</year>) <article-title>Foreword: Conference bias</article-title>. <source>J Empir Leg Stud</source> <volume>10</volume>: <fpage>603</fpage>–<lpage>611</lpage>.</mixed-citation></ref>
<ref id="pbio.1002106.ref045"><label>45</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Leggett</surname> <given-names>NC</given-names></name>, <name name-style="western"><surname>Thomas</surname> <given-names>NA</given-names></name>, <name name-style="western"><surname>Loetscher</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Nicholls</surname> <given-names>MER</given-names></name> (<year>2013</year>) <article-title>The life of p: "Just significant" results are on the rise</article-title>. <source>Q J Exp Psychol</source> <volume>66</volume>: <fpage>2303</fpage>–<lpage>2309</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1080/17470218.2013.863371" xlink:type="simple">10.1080/17470218.2013.863371</ext-link></comment> <object-id pub-id-type="pmid">24205936</object-id></mixed-citation></ref>
<ref id="pbio.1002106.ref046"><label>46</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ioannidis</surname> <given-names>JPA</given-names></name> (<year>2014</year>) <article-title>Discussion: Why "An estimate of the science-wise false discovery rate and application to the top medical literature" is false</article-title>. <source>Biostatistics</source> <volume>15</volume>: <fpage>28</fpage>–<lpage>36</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/biostatistics/kxt036" xlink:type="simple">10.1093/biostatistics/kxt036</ext-link></comment> <object-id pub-id-type="pmid">24068251</object-id></mixed-citation></ref>
<ref id="pbio.1002106.ref047"><label>47</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Clopper</surname> <given-names>CJ</given-names></name>, <name name-style="western"><surname>Pearson</surname> <given-names>ES</given-names></name> (<year>1934</year>) <article-title>The use of confidence or fiducial limits illustrated in the case of the binomial</article-title>. <source>Biometrika</source> <volume>26</volume>: <fpage>404</fpage>–<lpage>413</lpage>.</mixed-citation></ref>
<ref id="pbio.1002106.ref048"><label>48</label><mixed-citation publication-type="other" xlink:type="simple">Head ML, Holman L, Lanfear R, Kahn AT, Jennions MD (2015) Data from: The extent and consequences of p-hacking in science. Dryad Digital Repository. <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.5061/dryad.79d43" xlink:type="simple">http://dx.doi.org/10.5061/dryad.79d43</ext-link>.</mixed-citation></ref>
<ref id="pbio.1002106.ref049"><label>49</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nuzzo</surname> <given-names>R</given-names></name> (<year>2014</year>) <article-title>Scientific method: Statistical errors</article-title>. <source>Nature</source> <volume>506</volume>: <fpage>150</fpage>–<lpage>152</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/506150a" xlink:type="simple">10.1038/506150a</ext-link></comment> <object-id pub-id-type="pmid">24522584</object-id></mixed-citation></ref>
<ref id="pbio.1002106.ref050"><label>50</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Klein</surname> <given-names>RA</given-names></name>, <name name-style="western"><surname>Ratliff</surname> <given-names>KA</given-names></name>, <name name-style="western"><surname>Vianello</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>R.B. A</surname></name>, <name name-style="western"><surname>Bahník</surname> <given-names>S</given-names></name>, <etal>et al</etal>. (<year>2014</year>) <article-title>Data from investigating variation in replicability: A "many labs" replication project</article-title>. <source>J Open Psychol Data</source> <volume>2</volume>: <fpage>e4</fpage>.</mixed-citation></ref>
<ref id="pbio.1002106.ref051"><label>51</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Sutton</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Abrams</surname> <given-names>KR</given-names></name>, <name name-style="western"><surname>Jones</surname> <given-names>DR</given-names></name>, <name name-style="western"><surname>Sheldon</surname> <given-names>TA</given-names></name>, <name name-style="western"><surname>Song</surname> <given-names>F</given-names></name> (<year>2000</year>) <chapter-title>Methods for meta-analysis in medical research</chapter-title>. <publisher-loc>New york</publisher-loc>: <publisher-name>John Wiley &amp; Sons</publisher-name>.</mixed-citation></ref>
<ref id="pbio.1002106.ref052"><label>52</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gildersleeve</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Haselton</surname> <given-names>MG</given-names></name>, <name name-style="western"><surname>Fales</surname> <given-names>MR</given-names></name> (<year>2014</year>) <article-title>Meta-Analyses and p-curves support robust cycle shifts in women's mate preferencs: Reply to Wood &amp; Carden (2014) and Harris, Pashler, and Mickes (2014)</article-title>. <source>Psychol Bull</source> <volume>140</volume>: <fpage>1272</fpage>–<lpage>1280</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/a0037714" xlink:type="simple">10.1037/a0037714</ext-link></comment> <object-id pub-id-type="pmid">25180805</object-id></mixed-citation></ref>
<ref id="pbio.1002106.ref053"><label>53</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Akcay</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Roughgarden</surname> <given-names>J</given-names></name> (<year>2007</year>) <article-title>Extra-pair paternity in birds: Review of the genetic benefits</article-title>. <source>Evol Ecol Res</source> <volume>9</volume>: <fpage>855</fpage>–<lpage>868</lpage>.</mixed-citation></ref>
<ref id="pbio.1002106.ref054"><label>54</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cleasby</surname> <given-names>IR</given-names></name>, <name name-style="western"><surname>Nakagawa</surname> <given-names>S</given-names></name> (<year>2012</year>) <article-title>The influence of male age on within-pair and extra-pair paternity in passerines</article-title>. <source>Ibis</source> <volume>154</volume>: <fpage>318</fpage>–<lpage>324</lpage>.</mixed-citation></ref>
<ref id="pbio.1002106.ref055"><label>55</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>de Jong</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Forsgren</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Sandvik</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Amundsen</surname> <given-names>T</given-names></name> (<year>2012</year>) <article-title>Measuring mating competition correctly: available evidence supports operational sex ratio theory</article-title>. <source>Behav Ecol</source> <volume>23</volume>: <fpage>1170</fpage>–<lpage>1177</lpage>.</mixed-citation></ref>
<ref id="pbio.1002106.ref056"><label>56</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jiang</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Bolnick</surname> <given-names>DI</given-names></name>, <name name-style="western"><surname>Kirkpatrick</surname> <given-names>M</given-names></name> (<year>2013</year>) <article-title>Assortative mating in animals</article-title>. <source>Am Nat</source> <volume>181</volume>: <fpage>E125</fpage>–<lpage>E138</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1086/670160" xlink:type="simple">10.1086/670160</ext-link></comment> <object-id pub-id-type="pmid">23669548</object-id></mixed-citation></ref>
<ref id="pbio.1002106.ref057"><label>57</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kelly</surname> <given-names>CD</given-names></name> (<year>2008</year>) <article-title>The interrelationships between resource-holding potential, resource-value and reproductive success in territorial males: How much variation can we explain?</article-title> <source>Behav Ecol Sociobiol</source> <volume>62</volume>: <fpage>855</fpage>–<lpage>871</lpage>.</mixed-citation></ref>
<ref id="pbio.1002106.ref058"><label>58</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kraaijeveld</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Kraaijeveld-Smit</surname> <given-names>FJL</given-names></name>, <name name-style="western"><surname>Maan</surname> <given-names>ME</given-names></name> (<year>2011</year>) <article-title>Sexual selection and speciation: The comparative evidence revisited</article-title>. <source>Biol Rev Camb Philos Soc</source> <volume>86</volume>: <fpage>367</fpage>–<lpage>377</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1111/j.1469-185X.2010.00150.x" xlink:type="simple">10.1111/j.1469-185X.2010.00150.x</ext-link></comment> <object-id pub-id-type="pmid">20659104</object-id></mixed-citation></ref>
<ref id="pbio.1002106.ref059"><label>59</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Prokop</surname> <given-names>ZM</given-names></name>, <name name-style="western"><surname>Michalczyk</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Drobniak</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Herdegen</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Radwan</surname> <given-names>J</given-names></name> (<year>2012</year>) <article-title>Meta-analysis suggests choosy females get sexy sons more than "good genes"</article-title>. <source>Evolution</source> <volume>66</volume>: <fpage>2665</fpage>–<lpage>2673</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1111/j.1558-5646.2012.01654.x" xlink:type="simple">10.1111/j.1558-5646.2012.01654.x</ext-link></comment> <object-id pub-id-type="pmid">22946794</object-id></mixed-citation></ref>
<ref id="pbio.1002106.ref060"><label>60</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Santos</surname> <given-names>ESA</given-names></name>, <name name-style="western"><surname>Scheck</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Nakagawa</surname> <given-names>S</given-names></name> (<year>2011</year>) <article-title>Dominance and plumage traits: Meta-analysis and metaregression analysis</article-title>. <source>Anim Behav</source> <volume>82</volume>: <fpage>3</fpage>–<lpage>19</lpage>.</mixed-citation></ref>
<ref id="pbio.1002106.ref061"><label>61</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Weir</surname> <given-names>LK</given-names></name>, <name name-style="western"><surname>Grant</surname> <given-names>JWA</given-names></name>, <name name-style="western"><surname>Hutchings</surname> <given-names>JA</given-names></name> (<year>2011</year>) <article-title>The influence of operational sex ratio on the intensity of competition for mates</article-title>. <source>Am Nat</source> <volume>177</volume>: <fpage>167</fpage>–<lpage>176</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1086/657918" xlink:type="simple">10.1086/657918</ext-link></comment> <object-id pub-id-type="pmid">21460553</object-id></mixed-citation></ref>
<ref id="pbio.1002106.ref062"><label>62</label><mixed-citation publication-type="other" xlink:type="simple">Simonsohn U, Nelson LD, Simmons JP (2014b) P-Curve and effect size: Correcting for publication bias using only significant results. <ext-link ext-link-type="uri" xlink:href="http://ssrncom/abstract=2377290" xlink:type="simple">http://ssrncom/abstract=2377290</ext-link></mixed-citation></ref>
<ref id="pbio.1002106.ref063"><label>63</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>van Assen</surname> <given-names>MALM</given-names></name>, <name name-style="western"><surname>van Aert</surname> <given-names>RCM</given-names></name>, <name name-style="western"><surname>Wicherts</surname> <given-names>JM</given-names></name> (<year>2014</year>) <chapter-title>Meta-analysis using effect size distributions of only statistically significant studies</chapter-title>. <publisher-name>Psychol Methods Advance Online Publication</publisher-name>.</mixed-citation></ref>
<ref id="pbio.1002106.ref064"><label>64</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Altman</surname> <given-names>DG</given-names></name>, <name name-style="western"><surname>Gore</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Gardner</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Pocock</surname> <given-names>SJ</given-names></name> (<year>1983</year>) <article-title>Statistical guidelines for contributors to medical journals</article-title>. <source>Br Med J</source> <volume>286</volume>: <fpage>1489</fpage>–<lpage>1493</lpage>. <object-id pub-id-type="pmid">6405856</object-id></mixed-citation></ref>
<ref id="pbio.1002106.ref065"><label>65</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wagenmakers</surname> <given-names>E-J</given-names></name> (<year>2007</year>) <article-title>A practical solution to the pervasive problems of p values</article-title>. <source>Psychon Bull Rev</source> <volume>14</volume>: <fpage>779</fpage>–<lpage>804</lpage>. <object-id pub-id-type="pmid">18087943</object-id></mixed-citation></ref>
<ref id="pbio.1002106.ref066"><label>66</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hahn</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Williamson</surname> <given-names>PR</given-names></name>, <name name-style="western"><surname>Hutton</surname> <given-names>JL</given-names></name> (<year>2002</year>) <article-title>Investigation of within-study selective reporting in clinical research: follow-up of applications submitted to a local research ethics committee</article-title>. <source>J Eval Clin Pract</source> <volume>8</volume>: <fpage>353</fpage>–<lpage>359</lpage>. <object-id pub-id-type="pmid">12164983</object-id></mixed-citation></ref>
</ref-list>
</back>
</article>
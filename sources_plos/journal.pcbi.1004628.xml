<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article article-type="research-article" dtd-version="3.0" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-15-00780</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1004628</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>The Essential Complexity of Auditory Receptive Fields</article-title>
<alt-title alt-title-type="running-head">Essential Complexity of Auditory Receptive Fields</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Thorson</surname> <given-names>Ivar L.</given-names></name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Liénard</surname> <given-names>Jean</given-names></name>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
</contrib>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<name name-style="western">
<surname>David</surname> <given-names>Stephen V.</given-names></name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
</contrib-group>
<aff id="aff001">
<label>1</label>
<addr-line>Oregon Hearing Research Center, Oregon Health &amp; Science University, Portland, Oregon, United States of America</addr-line>
</aff>
<aff id="aff002">
<label>2</label>
<addr-line>Department of Mathematics, Washington State University, Vancouver, Washington, United States of America</addr-line>
</aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Theunissen</surname> <given-names>Frédéric E.</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>University of California at Berkeley, UNITED STATES</addr-line>
</aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<fn fn-type="con" id="contrib001">
<p>Conceived and designed the experiments: ILT SVD. Performed the experiments: SVD. Analyzed the data: ILT JL SVD. Contributed reagents/materials/analysis tools: ILT JL SVD. Wrote the paper: ILT JL SVD.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">davids@ohsu.edu</email></corresp>
</author-notes>
<pub-date pub-type="collection">
<month>12</month>
<year>2015</year>
</pub-date>
<pub-date pub-type="epub">
<day>18</day>
<month>12</month>
<year>2015</year>
</pub-date>
<volume>11</volume>
<issue>12</issue>
<elocation-id>e1004628</elocation-id>
<history>
<date date-type="received">
<day>12</day>
<month>5</month>
<year>2015</year>
</date>
<date date-type="accepted">
<day>26</day>
<month>10</month>
<year>2015</year>
</date>
</history>
<permissions>
<copyright-year>2015</copyright-year>
<copyright-holder>Thorson et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1004628"/>
<abstract>
<p>Encoding properties of sensory neurons are commonly modeled using linear finite impulse response (FIR) filters. For the auditory system, the FIR filter is instantiated in the spectro-temporal receptive field (STRF), often in the framework of the generalized linear model. Despite widespread use of the FIR STRF, numerous formulations for linear filters are possible that require many fewer parameters, potentially permitting more efficient and accurate model estimates. To explore these alternative STRF architectures, we recorded single-unit neural activity from auditory cortex of awake ferrets during presentation of natural sound stimuli. We compared performance of &gt; 1000 linear STRF architectures, evaluating their ability to predict neural responses to a novel natural stimulus. Many were able to outperform the FIR filter. Two basic constraints on the architecture lead to the improved performance: (1) factorization of the STRF matrix into a small number of spectral and temporal filters and (2) low-dimensional parameterization of the factorized filters. The best parameterized model was able to outperform the full FIR filter in both primary and secondary auditory cortex, despite requiring fewer than 30 parameters, about 10% of the number required by the FIR filter. After accounting for noise from finite data sampling, these STRFs were able to explain an average of 40% of A1 response variance. The simpler models permitted more straightforward interpretation of sensory tuning properties. They also showed greater benefit from incorporating nonlinear terms, such as short term plasticity, that provide theoretical advances over the linear model. Architectures that minimize parameter count while maintaining maximum predictive power provide insight into the essential degrees of freedom governing auditory cortical function. They also maximize statistical power available for characterizing additional nonlinear properties that limit current auditory models.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author Summary</title>
<p>Understanding how the brain solves sensory problems can provide useful insight for the development of automated systems such as speech recognizers and image classifiers. Recent developments in nonlinear regression and machine learning have produced powerful algorithms for characterizing the input-output relationship of complex systems. However, the complexity of sensory neural systems, combined with practical limitations on experimental data, make it difficult to apply arbitrarily complex analyses to neural data. In this study we pushed analysis in the opposite direction, toward simpler models. We asked how simple a model can be while still capturing the essential sensory properties of neurons in auditory cortex. We found that substantially simpler formulations of the widely-used spectro-temporal receptive field are able to perform as well as the best current models. These simpler formulations define new basis sets that can be incorporated into state-of-the-art machine learning algorithms for a more exhaustive exploration of sensory processing.</p>
</abstract>
<funding-group>
<funding-statement>Funding for this work was provided by the National Institute on Deafness and Other Communication Disorders (<ext-link ext-link-type="uri" xlink:href="http://www.nidcd.nih.gov/" xlink:type="simple">http://www.nidcd.nih.gov/</ext-link>), grant R00 DC010439. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="14"/>
<table-count count="0"/>
<page-count count="33"/>
</counts>
<custom-meta-group>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>Data from this study are publicly available via the Neural Prediction Challenge (<ext-link ext-link-type="uri" xlink:href="http://neuralprediction.berkeley.edu/" xlink:type="simple">http://neuralprediction.berkeley.edu/</ext-link>).</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Encoding models provide a powerful, objective means to evaluate our understanding of how sensory neural systems represent complex natural stimuli [<xref ref-type="bibr" rid="pcbi.1004628.ref001">1</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref002">2</xref>]. An encoding model describes any time-varying neural signal (single- or multiunit activity [<xref ref-type="bibr" rid="pcbi.1004628.ref003">3</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref004">4</xref>], local field potential [<xref ref-type="bibr" rid="pcbi.1004628.ref005">5</xref>], hemodynamic activity [<xref ref-type="bibr" rid="pcbi.1004628.ref006">6</xref>], or behavior [<xref ref-type="bibr" rid="pcbi.1004628.ref007">7</xref>]) as a function of the input stimulus, and it can predict the neural response to an arbitrary novel stimulus, including complex natural sounds. Prediction accuracy provides a quantitative measure of how well a model describes sensory-evoked activity; a completely accurate model should predict neural responses to any stimulus without error. More accurate models of sensory neural activity provide insight into algorithms that can be integrated into automated systems, such as speech recognizers and image classifiers.</p>
<p>In the auditory system, the linear spectro-temporal receptive field (STRF), implemented as a finite impulse response (FIR) filter, is the established “standard model” for neural representation [<xref ref-type="bibr" rid="pcbi.1004628.ref002">2</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref004">4</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref008">8</xref>–<xref ref-type="bibr" rid="pcbi.1004628.ref013">13</xref>]. This filter forms the core of generalized linear models (GLMs) applied to the auditory system [<xref ref-type="bibr" rid="pcbi.1004628.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref015">15</xref>], and models sharing the same analytical form as the FIR STRF have been developed for studying visual [<xref ref-type="bibr" rid="pcbi.1004628.ref016">16</xref>–<xref ref-type="bibr" rid="pcbi.1004628.ref018">18</xref>], somatosensory [<xref ref-type="bibr" rid="pcbi.1004628.ref019">19</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref020">20</xref>], and olfactory systems [<xref ref-type="bibr" rid="pcbi.1004628.ref021">21</xref>]. Despite its widespread use, careful assessments of how well the linear STRF actually describes auditory neural activity are limited [<xref ref-type="bibr" rid="pcbi.1004628.ref022">22</xref>]. A few studies have shown that the linear STRF can explain only a limited portion of sound-evoked activity in cortex, especially for complex natural stimuli [<xref ref-type="bibr" rid="pcbi.1004628.ref009">9</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref023">23</xref>]. Others have argued that nonlinear variants of the classical linear STRF can improve predictive power [<xref ref-type="bibr" rid="pcbi.1004628.ref003">3</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref024">24</xref>–<xref ref-type="bibr" rid="pcbi.1004628.ref033">33</xref>]. These nonlinear variants of the STRF show improved predictive power under specific experimental conditions. However, the more complex models are difficult to estimate reliably when experimental data are limited [<xref ref-type="bibr" rid="pcbi.1004628.ref001">1</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref018">18</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref022">22</xref>], especially for natural stimuli [<xref ref-type="bibr" rid="pcbi.1004628.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref023">23</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref034">34</xref>]. Difficulties associated with fitting and testing have prevented any single alternative from replacing the linear STRF as a new standard.</p>
<p>The challenges encountered when evaluating alternatives to the FIR STRF highlight the trade-off between model <italic>performance</italic>, how accurately it predicts neural activity, and <italic>complexity</italic>, the degrees of freedom governing the stimulus-response relationship [<xref ref-type="bibr" rid="pcbi.1004628.ref035">35</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref036">36</xref>]. In order to completely describe a system’s function, an encoding model must account for all the degrees of freedom of the actual system. If the system is not well understood, some degrees of freedom in a model are likely to be mismatched to the system’s function. Any mismatched complexity does not provide additional explanatory power, but it does introduce noise into model parameter estimates. Because this complexity does not improve performance, there should exist a model with fewer degrees of freedom that can perform as well as the more complex model.</p>
<p>In this study we focus on the problem of complexity. Rather than simply seeking the model that performs best, we identify the simplest possible model that attains a minimum level of performance. Specifically, we ask, can we produce a low-dimensional approximation of the linear STRF that performs as well as the full FIR STRF? The idea of improving STRF performance by dimensionality reduction has been proposed previously. Isolated studies have shown benefits of low-rank approximations of the STRF [<xref ref-type="bibr" rid="pcbi.1004628.ref028">28</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref031">31</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref037">37</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref038">38</xref>]. In the visual system, several studies have also proposed low-dimensional, system-specific parameterizations [<xref ref-type="bibr" rid="pcbi.1004628.ref018">18</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref029">29</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref039">39</xref>–<xref ref-type="bibr" rid="pcbi.1004628.ref043">43</xref>]. Despite the many parameterizations that have been proposed, however, direct comparisons between them have been limited, especially for natural stimuli. Thus it remains difficult to identify the important features of these different models.</p>
<p>We approached the complexity problem directly by systematic comparison of a large set of alternative parameterizations. We generated a collection of models that instantiate a variety of low-dimensional approximations to the FIR STRF. We then compared their performance on single-unit data collected from primary auditory cortex during presentation of natural vocalizations. By exploring the performance of this family of models, we were able to identify the minimal essential components required by linear STRFs that best described the data and to study the relationship between the amount of data available and optimal model complexity.</p>
<p>We found that the standard FIR STRF is suboptimal according to the complexity criterion. Instead, a much simpler model, which defines the STRF as a product of three Gaussian-tuned spectral filters and biphasic temporal filters, outperformed the FIR STRF, while requiring only about 10% of the parameters (29 vs. 276 free parameters). These results indicate that, for the average A1 neuron, a model with about 30 free parameters is able to capture its linear filter properties. The total degrees of freedom of a comprehensive nonlinear model is likely to be higher, but our minimally complex linear STRF provides a starting point for developing better-performing nonlinear models.</p>
</sec>
<sec id="sec002" sec-type="results">
<title>Results</title>
<sec id="sec003">
<title>Predictive model framework</title>
<p>We recorded single-unit neural activity from the auditory cortex (A1) of awake, passively listening ferrets during presentation of natural ferret vocalizations. The same set of 42 3-second vocalizations was presented during recordings from all neurons (<italic>N</italic> = 176). We then fit a large number of encoding models with different architectures to data from each neuron and compared their performance. Data for each neuron were grouped into an estimation data set (40 vocalizations), which was used for fitting, and a validation data set (2 vocalizations), which was used only to test how well each fit predicted responses to a novel stimulus (<xref ref-type="fig" rid="pcbi.1004628.g001">Fig 1A</xref>). Our primary performance metric was prediction correlation, <italic>i.e.</italic>, the correlation coefficient (Pearson’s <italic>R</italic>) between the actual peri-stimulus time histogram (PSTH), <italic>r</italic>(<italic>t</italic>), and the PSTH predicted by the model, <italic>p</italic>(<italic>t</italic>) (<xref ref-type="fig" rid="pcbi.1004628.g001">Fig 1C</xref>). Other commonly used performance metrics showed the same pattern of results (<italic>e.g.</italic>, log-likelihood and mutual information, see below).</p>
<fig id="pcbi.1004628.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004628.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Model estimation and validation procedures.</title>
<p><bold>A.</bold> Data for each neuron were split into an estimation data set, used to fit model parameters, and a validation data set, used only for testing prediction accuracy. <bold>B.</bold> Models were defined by a sequence of functions mapping stimulus to predicted response. This study focused on alternative parameterizations of the spectro-temporal filter module, and other modules were kept fixed for most comparisons. <bold>C.</bold> Spectrogram of example 3-second ferret vocalization used for testing prediction accuracy (top). Raster response of one neuron to 20 repetitions (middle) and PSTH binned at 100 Hz (bottom, blue). Predicted PSTH response is overlaid in red. <bold>D.</bold> The STRF is typically implemented as a multichannel finite impulse response (FIR) filter, requiring one parameter for each frequency and time lag. In this heat map, red areas indicate stimulus frequencies and time lags associated with increased neuronal spike rate and blue areas with decreased rate. <bold>E.</bold> Factorized STRF approximation is generated by the outer product of spectral- and temporal filter matrices, reducing the total parameter count. <bold>F.</bold> Parameterized models generate factorized matrices from parametric tuning curves, further reducing parameter count. Example Gaussian spectral and P3Z1 temporal parameterizations are shown. Factorized and parameterized models also permit the insertion of nonlinear modules, such as a filter mimicking short-term plasticity (STP), after projection onto the spectral channels.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004628.g001" xlink:type="simple"/>
</fig>
<p>Models were structured as a sequence of signal transformations, or functional <italic>modules</italic>, corresponding to the block diagram in <xref ref-type="fig" rid="pcbi.1004628.g001">Fig 1B</xref>,
<disp-formula id="pcbi.1004628.e001"><alternatives><graphic id="pcbi.1004628.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004628.e001" xlink:type="simple"/><mml:math display="block" id="M1"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>x</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mover><mml:mo>→</mml:mo> <mml:mrow><mml:msub><mml:mi>f</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mo>·</mml:mo> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mover> <mml:msub><mml:mi>x</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mover><mml:mo>→</mml:mo> <mml:mrow><mml:msub><mml:mi>f</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mo>·</mml:mo> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mover> <mml:mo>⋯</mml:mo> <mml:mover><mml:mo>→</mml:mo> <mml:mrow><mml:msub><mml:mi>f</mml:mi> <mml:mi>n</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mo>·</mml:mo> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mover> <mml:mi>y</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(1)</label></disp-formula>
where the output, <italic>x</italic><sub><italic>i</italic></sub>(<italic>t</italic>), of each module, <italic>f</italic><sub><italic>i</italic></sub>(⋅), provides the input into the subsequent module. The final module produced the predicted time-varying spike rate, <italic>y</italic>(<italic>t</italic>). In most models tested, this sequence consisted of three modules, a cochlear filterbank [<xref ref-type="bibr" rid="pcbi.1004628.ref026">26</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref044">44</xref>], followed by a linear spectro-temporal filter [<xref ref-type="bibr" rid="pcbi.1004628.ref008">8</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref009">9</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref011">11</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref012">12</xref>], and finally an output nonlinearity to account for spike generation thresholds [<xref ref-type="bibr" rid="pcbi.1004628.ref013">13</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref017">17</xref>].</p>
<p>Alternative model architectures were compared by replacing one or more modules in <xref ref-type="disp-formula" rid="pcbi.1004628.e001">Eq 1</xref>, while keeping the others the same. Thus the impact of the choice for each module on model performance could be tested individually (see <xref ref-type="fig" rid="pcbi.1004628.g002">Fig 2C</xref>). Using this empirical approach, we selected optimal modules for the cochlear filterbank (Eqs <xref ref-type="disp-formula" rid="pcbi.1004628.e013">11</xref>–<xref ref-type="disp-formula" rid="pcbi.1004628.e015">13</xref>) and output nonlinearity (<xref ref-type="disp-formula" rid="pcbi.1004628.e016">Eq 14</xref>) for the same linear filter module (FIR filter, see below, <xref ref-type="disp-formula" rid="pcbi.1004628.e004">Eq 3</xref>). These modules were then held constant while we compared performance for the different formulations of the linear filter module that follow.</p>
<fig id="pcbi.1004628.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004628.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Model complexity vs. performance.</title>
<p>Pareto plots compare model parameter count (horizontal axis) versus prediction correlation (vertical axis) for each linear STRF architecture, averaged over <italic>N</italic> = 176 A1 neurons. The Pareto front (red line) indicates the best prediction correlation for models with parameter count at or below the current abscissa. Dark gray points indicate models at the focus of this study, varying in only in the linear filter module and sharing the same input compression, spike nonlinearity, and fit algorithm. Black, purple, and orange points/arrows indicate the FIR, factorized, and parameterized models, respectively, explored in detail in later sections. <bold>A.</bold> For estimation data, prediction correlation tends to increase for more complex models. <bold>B.</bold> For validation data, performance reaches its maximum at just 29 parameters, suggesting that the increase in the estimation data for higher parameter counts reflects overfitting to noise by the more complex models. <bold>C.</bold> Summary of model architecture variants. Each bar shows the number of architectures evaluated using modules and fitting algorithms that differed from the core set of modules and procedures detailed in subsequent figures. For example, “Filterbank+output NL” indicates the number of models tested with a filterbank other than the second-order gammatone (<xref ref-type="disp-formula" rid="pcbi.1004628.e013">Eq 11</xref>) and output nonlinearity other than the double exponential sigmoid (<xref ref-type="disp-formula" rid="pcbi.1004628.e016">Eq 14</xref>).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004628.g002" xlink:type="simple"/>
</fig>
<p>Models were fit using an iterated coordinate descent (a.k.a. boosting) algorithm [<xref ref-type="bibr" rid="pcbi.1004628.ref034">34</xref>]. On each iteration, the algorithm cycled through each module sequentially and performed a few steps of coordinate descent within that module before moving on to the next one (see <xref ref-type="sec" rid="sec028">Methods</xref>). We have previously demonstrated that this coordinate descent algorithm is able to accurately recover linear STRFs in simulation [<xref ref-type="bibr" rid="pcbi.1004628.ref030">30</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref034">34</xref>].</p>
<p>Because datasets are finite, the performance of any model will be limited by sampling noise. This noise impacts the analysis at two stages: producing error in the estimation of model parameters and in validation of prediction accuracy [<xref ref-type="bibr" rid="pcbi.1004628.ref018">18</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref022">22</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref045">45</xref>]. Accounting for the first problem is a nuanced issue: more complex models that require a large number of parameters are more susceptible to noise than simpler models. We address the issue of finite estimation data in a later section (see Parameterized models perform similarly to FIR models in the limit of infinite data, below). To account for the latter problem, measures of prediction correlation were normalized by a factor reflecting response reliability in the validation stimulus (<xref ref-type="disp-formula" rid="pcbi.1004628.e026">Eq 23</xref>, [<xref ref-type="bibr" rid="pcbi.1004628.ref045">45</xref>]). This factor was fixed for an individual neuron’s validation data. Thus it does not affect the performance of one model relative to another. Numerically, this correction increased prediction correlations in A1 by a mean of 20% (ranging from 3% to 39% for individual neurons).</p>
</sec>
<sec id="sec004">
<title>Pareto front describes a trade-off between model performance and complexity</title>
<p>Model complexity is often factored into cost functions for model fitting, in order to positively weigh simpler models [<xref ref-type="bibr" rid="pcbi.1004628.ref035">35</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref046">46</xref>]. Our goal was to study in depth the relationship between model complexity and performance. Thus, rather than combining them into a single cost function, we studied the trade-off between these criteria in detail, exploring the family of solutions that are optimal with respect to both. This optimal set of solutions is known as the Pareto front [<xref ref-type="bibr" rid="pcbi.1004628.ref036">36</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref047">47</xref>]. Formally, all items belonging to this front are non-dominated in the Pareto sense [<xref ref-type="bibr" rid="pcbi.1004628.ref047">47</xref>] which means that for all pairs of models on the front, one is less complex while the other fits more closely to the data. All models below the Pareto front are non-optimal: there is at least one model on the front that is both less complex and more accurate.</p>
<p>We generated Pareto plots for the 1061 different linear STRF architectures tested, comparing model parameter count against average prediction correlation for estimation data (<xref ref-type="fig" rid="pcbi.1004628.g002">Fig 2A</xref>) and validation data (<xref ref-type="fig" rid="pcbi.1004628.g002">Fig 2B</xref>). Most models lie under the Pareto front (red line) and are suboptimal relative to models that are less complex, better performing, or both. More complex models tend to perform better for estimation data, but they do not necessarily predict novel validation data more accurately. The differences between estimation and validation plots illustrate the problem of overfitting when available estimation data are finite. Among the more complex models, the FIR STRF falls below the Pareto front for the validation data (black point, <xref ref-type="fig" rid="pcbi.1004628.g002">Fig 2B</xref>). Instead, best performance in the current dataset is achieved by a model requiring just 29 parameters (orange point).</p>
<p>In the following sections, we discuss in detail the subset of 260 architectures in which only the linear filtering module was varied, while all other modules (cochlear filterbank, input nonlinearity, output nonlinearity) and the fitting algorithm were held constant (dark gray points, <xref ref-type="fig" rid="pcbi.1004628.g002">Fig 2A and 2B</xref>). Our focus is on identifying model architectures that fall on or near the Pareto front, making them optimal for a given level of complexity. The remaining models were generated by manipulating one or more modules other than the linear filter (<xref ref-type="fig" rid="pcbi.1004628.g002">Fig 2C</xref>). Varying the other modules had less dramatic effects on model complexity and performance, but they provide a dense sampling of the complexity-performance space. A complete list of architectures evaluated is included in the supplementary materials (<xref ref-type="supplementary-material" rid="pcbi.1004628.s001">S1 Table</xref>).</p>
</sec>
<sec id="sec005">
<title>STRF parameterization improves model predictive power</title>
<sec id="sec006">
<title>Finite impulse response (FIR) STRF</title>
<p>Classically, the STRF has been implemented as a multi-channel FIR filter (<xref ref-type="fig" rid="pcbi.1004628.g001">Fig 1D</xref>, [<xref ref-type="bibr" rid="pcbi.1004628.ref008">8</xref>]). At its core, the FIR STRF is simply a matrix of weights associated with different sound frequencies and time lags that predicts the time-varying neural firing rate by convolution with the stimulus spectrogram. The STRF has proven to be a useful tool for characterizing the feature selectivity of auditory neurons [<xref ref-type="bibr" rid="pcbi.1004628.ref004">4</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref008">8</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref010">10</xref>] and how that selectivity changes across the auditory hierarchy [<xref ref-type="bibr" rid="pcbi.1004628.ref048">48</xref>]. In addition, the FIR STRF has been used as a tool to study changes in sensory representation reflecting the modulatory effects of learning and attention [<xref ref-type="bibr" rid="pcbi.1004628.ref049">49</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref050">50</xref>]. For a stimulus spectrogram, <bold>x</bold>(<italic>t</italic>) = [<italic>x</italic><sub>1</sub>(<italic>t</italic>) <italic>x</italic><sub>2</sub>(<italic>t</italic>) ⋯ <italic>x</italic><sub><italic>c</italic></sub>(<italic>t</italic>)], with <italic>C</italic> channels binned each <italic>τ</italic> ms, the FIR filter, <bold>H</bold>, with a maximum memory of <italic>U</italic> time bins is a <italic>C</italic> × <italic>U</italic> matrix
<disp-formula id="pcbi.1004628.e003"><alternatives><graphic id="pcbi.1004628.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004628.e003" xlink:type="simple"/><mml:math display="block" id="M3"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="bold">H</mml:mi> <mml:mo>=</mml:mo> <mml:mfenced close="]" open="[" separators=""><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mi>h</mml:mi> <mml:mn>11</mml:mn></mml:msub></mml:mtd> <mml:mtd><mml:msub><mml:mi>h</mml:mi> <mml:mn>12</mml:mn></mml:msub></mml:mtd> <mml:mtd><mml:mo>⋯</mml:mo></mml:mtd> <mml:mtd><mml:msub><mml:mi>h</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mi>U</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:msub><mml:mi>h</mml:mi> <mml:mn>21</mml:mn></mml:msub></mml:mtd> <mml:mtd><mml:msub><mml:mi>h</mml:mi> <mml:mn>22</mml:mn></mml:msub></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd> <mml:mtd/><mml:mtd><mml:mo>⋱</mml:mo></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:msub><mml:mi>h</mml:mi> <mml:mrow><mml:mi>C</mml:mi> <mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd> <mml:mtd/><mml:mtd/><mml:mtd><mml:msub><mml:mi>h</mml:mi> <mml:mrow><mml:mi>C</mml:mi> <mml:mi>U</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable></mml:mfenced></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(2)</label></disp-formula>
The time-varying output <italic>y</italic><sub>FIR</sub> of the filter is then the convolution with the stimulus in time and sum across frequencies,
<disp-formula id="pcbi.1004628.e004"><alternatives><graphic id="pcbi.1004628.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004628.e004" xlink:type="simple"/><mml:math display="block" id="M4"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>y</mml:mi> <mml:mtext>FIR</mml:mtext></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mi>b</mml:mi> <mml:mo>+</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>U</mml:mi></mml:munderover> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>f</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>C</mml:mi></mml:munderover> <mml:msub><mml:mi>h</mml:mi> <mml:mrow><mml:mi>f</mml:mi> <mml:mi>i</mml:mi></mml:mrow></mml:msub> <mml:msub><mml:mi>x</mml:mi> <mml:mi>f</mml:mi></mml:msub> <mml:mfenced close=")" open="(" separators=""><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mfenced close=")" open="(" separators=""><mml:mi>i</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mfenced> <mml:mi>τ</mml:mi></mml:mfenced></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(3)</label></disp-formula>
Positive values of coefficients <italic>h</italic><sub><italic>fi</italic></sub> indicate components of the stimulus that correlate with increased output, and negative values with decreased output. The constant term, <italic>b</italic>, accounts for the possibility of nonzero output even when the input is zero. Unless otherwise specified, in the following results, <bold>x</bold> is produced by passing the raw sound waveform through a cochlear filterbank with <italic>C</italic> = 18 channels, logarithmically spaced over 200–20,000 Hz [<xref ref-type="bibr" rid="pcbi.1004628.ref044">44</xref>]. The filterbank output is log-compressed (<xref ref-type="disp-formula" rid="pcbi.1004628.e015">Eq 13</xref>) before input to the linear spectro-temporal filter. The duration of the filter is 150 ms (<italic>i.e.,</italic> <italic>U</italic> = 15 for <italic>τ</italic> = 10 ms temporal bins), requiring <italic>C</italic> × <italic>U</italic> = 270 parameters. From the linear filter, the signal finally passes through a static output nonlinearity that accounts for spike threshold and saturation (<xref ref-type="disp-formula" rid="pcbi.1004628.e016">Eq 14</xref>). An additional 6 parameters for the baseline response, input compression and output nonlinearity make a total of 276 for the entire FIR STRF. We explored the impact of varying <italic>C</italic> (see below) and <italic>U</italic> (<xref ref-type="supplementary-material" rid="pcbi.1004628.s001">S1 Table</xref>), and found no improvement for smaller or larger values of either parameter. Moreover, changing spectral or temporal resolution had no impact on the relative performance of the different model architectures compared below.</p>
<p>Fits using the full FIR implementation of the STRF typically show localized spectro-temporal regions of large excitatory and/or inhibitory filter weights, indicating a best frequency (BF) and response latency for each neuron (<xref ref-type="fig" rid="pcbi.1004628.g003">Fig 3</xref>, left panels). Although we did not explicitly compare tuning for different stimuli in the current study, the BF measured from the STRF is typically similar to the BF measured from other stimuli, such as pure tones [<xref ref-type="bibr" rid="pcbi.1004628.ref005">5</xref>] or broadband noise [<xref ref-type="bibr" rid="pcbi.1004628.ref009">9</xref>]. Additional features of the STRF, away from BF and peak latency, often do depend on the stimulus used for STRF estimation, and thus it is more challenging to determine if these features reflect off-peak tuning or estimation noise.</p>
<fig id="pcbi.1004628.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004628.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Example STRF fits for different model architectures.</title>
<p><bold>A.</bold> STRF weight matrices (<italic>H</italic>) for the FIR, factorized, and parameterized models fit to the same neuron. Prediction correlation (Pearson’s <italic>R</italic>) is indicated in the corner of each STRF. For factorized and parameterized models, the STRF is computed from the outer product of the spectral and temporal filters that specify those models, <bold>H</bold> = <bold>H</bold><sub><italic>s</italic></sub> <bold>H</bold><sub><italic>t</italic></sub>. Dimensionality (<italic>D</italic>) of the spectral and temporal filters constrains frequency-time separability of the STRF, but it does not restrict tuning bandwidth (<italic>i.e.</italic>, spectral tuning can span more than <italic>D</italic> channels, as in this example). The factorized and parameterized models exhibit less spurious noise, are easier to interpret, and show improved prediction accuracy over the full FIR. <bold>B.</bold> Example STRFs for a second neuron exhibit more complex tuning and basis functions in the parameterized model can account for tuning to distinct spectro-temporal features.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004628.g003" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec007">
<title>Factorization of the FIR matrix</title>
<p>The first strategy we explored for reducing the number of parameters required for the linear STRF was a factorized model (<xref ref-type="fig" rid="pcbi.1004628.g001">Fig 1E</xref>, [<xref ref-type="bibr" rid="pcbi.1004628.ref037">37</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref038">38</xref>]). This model follows the same sequence of modules as the FIR STRF, but the linear filter, <bold>H</bold>, is approximated as the product of a <italic>C</italic> × <italic>D</italic> spectral weighting matrix, <bold>H</bold><sub><italic>s</italic></sub>, and a <italic>D</italic> × <italic>U</italic> temporal filtering matrix, <bold>H</bold><sub><italic>t</italic></sub>,
<disp-formula id="pcbi.1004628.e005"><alternatives><graphic id="pcbi.1004628.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004628.e005" xlink:type="simple"/><mml:math display="block" id="M5"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="bold">H</mml:mi> <mml:mo>=</mml:mo> <mml:msub><mml:mi mathvariant="bold">H</mml:mi> <mml:mi>s</mml:mi></mml:msub> <mml:msub><mml:mi mathvariant="bold">H</mml:mi> <mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(4)</label></disp-formula>
A model with dimensionality <italic>D</italic> = 1 is often referred to as a space-time separable model, a common strategy for dimensionality reduction [<xref ref-type="bibr" rid="pcbi.1004628.ref020">20</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref028">28</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref051">51</xref>]. Varying <italic>D</italic> impacts the complexity of the spectro-temporal filter [<xref ref-type="bibr" rid="pcbi.1004628.ref037">37</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref038">38</xref>], and we explored the effect of different values of <italic>D</italic> on model performance. Factorization is closely related to reduced-rank approximations of the STRF, except that the factorized dimensions are not required to be orthogonal. For the linear model, this distinction is trivial and has no effect on theoretical performance. However, when nonlinear terms are introduced between the spectral and temporal filtering stages, non-orthogonal spectral dimensions allow for additional model functionality (see STP STRF, below).</p>
<p>The factorized <bold>H</bold> can be interpreted as breaking down the linear filter module into a sequence of two modules (<xref ref-type="disp-formula" rid="pcbi.1004628.e001">Eq 1</xref>, <xref ref-type="fig" rid="pcbi.1004628.g001">Fig 1E</xref>). First, a set of spectral filters, <bold>h</bold><sub><italic>s</italic><sub><italic>j</italic></sub></sub> (rows of <bold>H</bold><sub><italic>s</italic></sub>), maps the <italic>C</italic>-dimensional input spectrogram into a <italic>D</italic>-dimensional subspace, <bold>s</bold>(<italic>t</italic>) = [<italic>s</italic><sub>1</sub>(<italic>t</italic>) <italic>s</italic><sub>2</sub>(<italic>t</italic>) ⋯ <italic>s</italic><sub>D</sub>(<italic>t</italic>)],
<disp-formula id="pcbi.1004628.e007"><alternatives><graphic id="pcbi.1004628.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004628.e007" xlink:type="simple"/><mml:math display="block" id="M7"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>s</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>f</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>C</mml:mi></mml:munderover> <mml:msub><mml:mi>h</mml:mi> <mml:msub><mml:mi>s</mml:mi> <mml:mi>j</mml:mi></mml:msub></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>f</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msub><mml:mi>x</mml:mi> <mml:mi>f</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(5)</label></disp-formula>
Second, the signal in each dimension of this new spectral subspace is convolved with a temporal filter, <bold><bold>h</bold><sub><italic>t</italic><sub><italic>j</italic></sub></sub></bold> (columns of <bold>H</bold><sub><italic>t</italic></sub>), before summing across spectral channels,
<disp-formula id="pcbi.1004628.e008"><alternatives><graphic id="pcbi.1004628.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004628.e008" xlink:type="simple"/><mml:math display="block" id="M8"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>y</mml:mi> <mml:mtext>FAC</mml:mtext></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mi>b</mml:mi> <mml:mo>+</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>U</mml:mi></mml:munderover> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>D</mml:mi></mml:munderover> <mml:msub><mml:mi>h</mml:mi> <mml:msub><mml:mi>t</mml:mi> <mml:mi>j</mml:mi></mml:msub></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>i</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msub><mml:mi>s</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mfenced close=")" open="(" separators=""><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mfenced close=")" open="(" separators=""><mml:mi>i</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mfenced> <mml:mi>τ</mml:mi></mml:mfenced></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(6)</label></disp-formula>
Factorization reduces the number of parameters required to define <bold>H</bold> to <italic>D</italic> × (<italic>C</italic> + <italic>U</italic>), which is usually much less than <italic>C</italic> × <italic>U</italic>. Although small values of <italic>D</italic> constrain the spectro-temporal complexity of the STRF, they do not limit spectral tuning bandwidth, as a single spectral channel can have arbitrarily broad tuning bandwidth. Similarly, the factorized temporal filter can integrate across many time lags.</p>
<p>We compared performance of the factorized model for different values of <italic>D</italic>. The same fitting algorithm was used as for the FIR STRF, but iterating separately on the spectral- and temporal filter modules (see <xref ref-type="sec" rid="sec028">Methods</xref>). Across the entire vocalization dataset, factorization with <italic>D</italic> = 2 spectral channels produced the highest mean prediction correlation and performed significantly better than the FIR STRF (<xref ref-type="fig" rid="pcbi.1004628.g004">Fig 4A and 4B</xref>, mean <italic>R</italic> = 0.464 vs. 0.406, <italic>p</italic> &lt; 0.0001, sign test). Depending on the convergence of synaptic inputs, there is a theoretically optimal number of dimensions <italic>D</italic> that describe spectro-temporal selectivity [<xref ref-type="bibr" rid="pcbi.1004628.ref037">37</xref>]. Beyond that number, STRF performance should asymptote to the performance of the full FIR STRF. In practice, however, factorized models for all values of <italic>D</italic> tested surpassed the FIR STRF performance, indicating that the reduced number of parameters also improves model performance by reducing estimation noise (<xref ref-type="fig" rid="pcbi.1004628.g004">Fig 4C</xref>).</p>
<fig id="pcbi.1004628.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004628.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Factorized model performance.</title>
<p><bold>A.</bold> Scatter plot of <italic>D</italic> = 2 factorized- versus FIR model prediction correlation per neuron shows that the factorized model predicts more accurately for most neurons. <bold>B.</bold> Histogram of difference in prediction correlation <italic>D</italic> = 2 factorized and FIR models for each neuron. Error bar at top shows 1 SEM on the difference between model predictions, illustrating the procedure for measuring error bars in the comparisons of average model performance that follow (see <xref ref-type="sec" rid="sec028">Methods</xref>). <bold>C.</bold> Pareto plot compares model complexity (parameter count) versus mean prediction correlation for the FIR model and factorized models, plotted as in <xref ref-type="fig" rid="pcbi.1004628.g002">Fig 2</xref> (channel count, <italic>D</italic> = 1…4). Error bars calculated as in B, relative to the FIR STRF. Despite having fewer parameters, the factorized models perform consistently better than the FIR (<italic>p</italic> &lt; 0.001, sign test, <italic>N</italic> = 176). The <italic>D</italic> = 2 factorized model performs best, with about a 15% average increase in correlation over the FIR STRF, despite requiring about one-quarter of the parameters.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004628.g004" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec008">
<title>Factorized models motivate parameterization for further dimensionality reduction</title>
<p>To explore models with further reduced complexity, we considered ways to approximate spectral and temporal tuning with even fewer parameters than the factorized model. In the factorized model, the columns of <bold>H</bold><sub><italic>s</italic></sub> and the rows of <bold>H</bold><sub><italic>t</italic></sub> describe selectivity in the spectral and temporal domains, respectively. These spectral and temporal tuning functions are nonparametric, in the sense that they are not constrained to have a specific functional form. We identified candidate parameterizations of these curves by measuring their average shape across the neural population for the <italic>D</italic> = 2 factorized model.</p>
<p>When spectral filters were aligned at best frequency (BF, <xref ref-type="fig" rid="pcbi.1004628.g005">Fig 5A</xref>), sensitivity in neighboring frequency bands covaried with the response at BF, producing approximately Gaussian tuning. Weights for off-BF bins were often negative, suggesting that sideband inhibition could be useful to include in a parameterized model. After subtracting the mean, we also performed principal components analysis to identify any additional patterns in the distribution of <bold>H</bold><sub><italic>s</italic></sub> fits, but the resulting principal components were quite small (29%, 13% of the variance) and did not have any clear structure. Based on the average tuning curve, we hypothesized that <bold>H</bold><sub><italic>s</italic></sub> might be well parameterized by one of two functions (<xref ref-type="fig" rid="pcbi.1004628.g005">Fig 5B</xref>): a Gaussian function, parameterized by a mean frequency and tuning bandwidth, or a Morlet wavelet, which also permits inhibitory sidebands.</p>
<fig id="pcbi.1004628.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004628.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Parameterization of spectral and temporal tuning.</title>
<p><bold>A.</bold> Values of factorized spectral weighting matrix <bold>H</bold><sub><italic>s</italic></sub>, centered about their peak and normalized by variance across all weights. <bold>B.</bold> Based on the Gaussian-like mean weights and presence of negative values in the sidebands, we parameterized spectral filters using either a Gaussian function or Morlet wavelet. <bold>C.</bold> Values of the temporal weighting matrix <bold>H</bold><sub><italic>t</italic></sub> binned at 100 Hz and aligned at peak latency. The -40 ms bin was cropped because very few neurons had peak latency longer than 40 ms. The asymmetric rapid onset and slower fall-off are not well-described by a Gaussian. <bold>D.</bold> Temporal filters were parameterized using either a difference of exponentials or a pole-zero filter.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004628.g005" xlink:type="simple"/>
</fig>
<p>Temporal filters were aligned at their peak latency before averaging (<xref ref-type="fig" rid="pcbi.1004628.g005">Fig 5C</xref>). They tended to have a longer tail following the peak latency, compared to a relatively rapid rise before the peak. Thus they were not well characterized by a Gaussian. The first two principal components of <bold>H</bold><sub><italic>t</italic></sub> were again small (31%, 14% of variance) but resembled high-pass filters (<italic>i.e.</italic>, temporal differentiators), consistent with sensitivity to changes in stimulus intensity within a spectral frequency band. We therefore hypothesized that <bold>H</bold><sub><italic>t</italic></sub> might be well-parameterized by either a difference of exponentials, describing a fast rise followed by a slow decay [<xref ref-type="bibr" rid="pcbi.1004628.ref029">29</xref>], or a more general linear filter that could generate peaked impulse responses yet could also be weakly high pass (<xref ref-type="fig" rid="pcbi.1004628.g005">Fig 5D</xref>).</p>
</sec>
<sec id="sec009">
<title>Gaussian spectral parameterization</title>
<p>We parameterized the spectral channel matrix <bold>H</bold><sub><italic>s</italic></sub> using a single Gaussian function per channel (<xref ref-type="fig" rid="pcbi.1004628.g005">Fig 5B</xref>). Thus the weights for column, <italic>j</italic>, and frequency bin, <italic>i</italic>, are specified by two parameters, center frequency <italic>f</italic><sub>0</sub> and bandwidth <italic>σ</italic>,
<disp-formula id="pcbi.1004628.e009"><alternatives><graphic id="pcbi.1004628.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004628.e009" xlink:type="simple"/><mml:math display="block" id="M9"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>h</mml:mi> <mml:msub><mml:mi>s</mml:mi> <mml:mi>j</mml:mi></mml:msub></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>i</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mi>σ</mml:mi> <mml:msqrt><mml:mrow><mml:mn>2</mml:mn> <mml:mi>π</mml:mi></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac> <mml:mo form="prefix">exp</mml:mo> <mml:mfenced close=")" open="(" separators=""><mml:mo>-</mml:mo> <mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>f</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>f</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mrow><mml:mn>2</mml:mn> <mml:msup><mml:mi>σ</mml:mi> <mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mfenced></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(7)</label></disp-formula>
For <italic>D</italic> spectral channels, the Gaussian spectral filter requires only 2<italic>D</italic> parameters, compared to <italic>C</italic> × <italic>D</italic> parameters for the factorized model. When we replaced the factorized spectral filter with the Gaussian parameterization (while preserving the factorized temporal filter), model performance again improved, despite the further decrease in parameter count (<xref ref-type="fig" rid="pcbi.1004628.g006">Fig 6A</xref>). The <italic>D</italic> = 3 Gaussian spectral model showed the highest average correlation (mean <italic>R</italic> = 0.476), significantly surpassing the performance of the FIR STRF by about 10% (<italic>p</italic> &lt; 0.0001) and the best factorized model by about 3% (<italic>p</italic> &lt; 0.01, sign test).</p>
<fig id="pcbi.1004628.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004628.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Parameterized model performance.</title>
<p><bold>A.</bold> Average performance of spectrally parameterized (Gaussian and Morlet) models (<italic>W</italic><sub><italic>s</italic></sub>), using a factorized temporal filter (<italic>W</italic><sub><italic>t</italic></sub>) and plotted as in <xref ref-type="fig" rid="pcbi.1004628.g004">Fig 4C</xref>. For a given spectral channel count, <italic>D</italic>, the improvement over the factorized model is significant for both parameterizations (<italic>p</italic> &lt; 0.01, sign test), despite requiring fewer parameters. <bold>B.</bold> Average performance of temporally parameterized models, using Gaussian spectral parameterization and plotted as in A. The P3Z1 pole-zero parameterization performed significantly better than the difference of exponentials (<italic>p</italic> &lt; 0.01, sign test), although neither showed a significant difference from the factorized temporal filter. <bold>C.</bold> Summary of performance for the factorized model and the best parameterized model (Gaussian <italic>W</italic><sub><italic>s</italic></sub>, P3Z1 <italic>W</italic><sub><italic>t</italic></sub>) for each channel count. Performance of the parameterized model is significantly better than the factorized (<italic>p</italic> &lt; 0.01, sign test) and the FIR model (<italic>p</italic> &lt; 0.001).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004628.g006" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec010">
<title>Morlet spectral parameterization</title>
<p>The Morlet wavelet provided an alternative spectral parameterization similar to the Gaussian (<xref ref-type="fig" rid="pcbi.1004628.g005">Fig 5B</xref>), which could also account for sideband inhibition. The Morlet wavelet determines coefficients according to three parameters, center frequency, <italic>f</italic><sub>0</sub>, bandwidth, <italic>σ</italic>, and sideband amplitude, <italic>z</italic>,
<disp-formula id="pcbi.1004628.e010"><alternatives><graphic id="pcbi.1004628.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004628.e010" xlink:type="simple"/><mml:math display="block" id="M10"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>h</mml:mi> <mml:msub><mml:mi>s</mml:mi> <mml:mi>j</mml:mi></mml:msub></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>i</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mi>ℜ</mml:mi> <mml:mfenced close=")" open="(" separators=""><mml:mo form="prefix">exp</mml:mo> <mml:mfenced close=")" open="(" separators=""><mml:mfrac><mml:mrow><mml:mo>-</mml:mo> <mml:msup><mml:mrow><mml:mfenced close=")" open="(" separators=""><mml:msub><mml:mi>f</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>f</mml:mi> <mml:mn>0</mml:mn></mml:msub></mml:mfenced></mml:mrow> <mml:mn>2</mml:mn></mml:msup></mml:mrow> <mml:msup><mml:mi>σ</mml:mi> <mml:mn>2</mml:mn></mml:msup></mml:mfrac> <mml:mo>-</mml:mo> <mml:mi>i</mml:mi> <mml:mi>z</mml:mi> <mml:mfenced close=")" open="(" separators=""><mml:msub><mml:mi>f</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>f</mml:mi> <mml:mn>0</mml:mn></mml:msub></mml:mfenced></mml:mfenced></mml:mfenced></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(8)</label></disp-formula>
where ℜ(⋅) indicates taking the real component. Thus 3<italic>D</italic> parameters are required for the <italic>D</italic> spectral filters. The best Morlet parameterization (<italic>D</italic> = 3) performed significantly better than the factorized model (<xref ref-type="fig" rid="pcbi.1004628.g006">Fig 6A</xref>, mean <italic>R</italic> = 0.479, <italic>p</italic> &lt; 0.001, sign test). However, its performance was not significantly different from the Gaussian parameterization. Because increasing the parameter count to account for spectral sidebands did not improve predictive power, we subsequently focused on the Gaussian spectral parameterization.</p>
</sec>
<sec id="sec011">
<title>Difference of exponentials temporal parameterization</title>
<p>The difference of exponentials temporal filter produces a family of curves that resemble the mean of <bold>H</bold><sub><italic>t</italic></sub> (<xref ref-type="fig" rid="pcbi.1004628.g005">Fig 5D</xref>),
<disp-formula id="pcbi.1004628.e011"><alternatives><graphic id="pcbi.1004628.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004628.e011" xlink:type="simple"/><mml:math display="block" id="M11"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>h</mml:mi> <mml:msub><mml:mi>t</mml:mi> <mml:mi>j</mml:mi></mml:msub></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>i</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo form="prefix">exp</mml:mo> <mml:mfenced close=")" open="(" separators=""><mml:mo>-</mml:mo> <mml:mfrac><mml:mrow><mml:mi>i</mml:mi> <mml:mo>-</mml:mo> <mml:msub><mml:mi>θ</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:mrow> <mml:msub><mml:mi>τ</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:mfrac></mml:mfenced> <mml:mo>-</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo form="prefix">exp</mml:mo> <mml:mfenced close=")" open="(" separators=""><mml:mo>-</mml:mo> <mml:mfrac><mml:mrow><mml:mi>i</mml:mi> <mml:mo>-</mml:mo> <mml:msub><mml:mi>θ</mml:mi> <mml:mn>2</mml:mn></mml:msub></mml:mrow> <mml:msub><mml:mi>τ</mml:mi> <mml:mn>2</mml:mn></mml:msub></mml:mfrac></mml:mfenced></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(9)</label></disp-formula>
where the output exp() is set to zero for <italic>i</italic> &lt; <italic>θ</italic><sub><italic>n</italic></sub>. This filter requires six parameters (<italic>A</italic><sub>1</sub>, <italic>τ</italic><sub>1</sub>, <italic>θ</italic><sub>1</sub>, <italic>A</italic><sub>2</sub>, <italic>τ</italic><sub>2</sub>, <italic>θ</italic><sub>2</sub>) per spectral channel and thus a total of 6<italic>D</italic> parameters, compared to <italic>D</italic> × <italic>U</italic> for the factorized temporal filter. The <italic>D</italic> = 3 difference of exponentials parameterization performed nearly as well as the Gaussian spectral model (mean <italic>R</italic> = 0.467, <italic>p</italic> &gt; 0.05, sign test), indicating that this filter captures many of the features of the factorized temporal filter (<xref ref-type="fig" rid="pcbi.1004628.g006">Fig 6B</xref>).</p>
</sec>
<sec id="sec012">
<title>Pole-zero temporal parameterization</title>
<p>Many physical systems are well-described by linear ordinary differential equations, or infinite impulse response (IIR) filters. This parameterization can be defined in the frequency domain using <italic>pole-zero</italic> (PZ) notation. We compared performance of parameterizations with variable numbers of poles and zeros (<xref ref-type="fig" rid="pcbi.1004628.g007">Fig 7A</xref>). The number of poles determines the shape of the filter, and the number of zeros determines the number of zero crossings. We also included parameters for filter gain and latency. Thus, a 3-pole, 1-zero filter (P3Z1) is defined in the frequency domain (<italic>s</italic>),
<disp-formula id="pcbi.1004628.e012"><alternatives><graphic id="pcbi.1004628.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004628.e012" xlink:type="simple"/><mml:math display="block" id="M12"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>G</mml:mi> <mml:mrow><mml:mi>P</mml:mi> <mml:mn>3</mml:mn> <mml:mi>Z</mml:mi> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mi>A</mml:mi> <mml:mo form="prefix">exp</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mo>-</mml:mo> <mml:mi>l</mml:mi> <mml:mo>·</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mfrac><mml:mrow><mml:mi>s</mml:mi> <mml:mo>-</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:mrow> <mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>+</mml:mo> <mml:msub><mml:mi>p</mml:mi> <mml:mn>3</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>+</mml:mo> <mml:msub><mml:mi>p</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>+</mml:mo> <mml:msub><mml:mi>p</mml:mi> <mml:mn>3</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(10)</label></disp-formula>
where <italic>A</italic> is magnitude, <italic>l</italic> is delay, <italic>p</italic><sub>1</sub>, <italic>p</italic><sub>2</sub>, <italic>p</italic><sub>3</sub> are the poles, and <italic>z</italic><sub>1</sub> is the zero (6 parameters per spectral channel). PZ filters provide a more general formulation of temporal dynamics than the difference of exponentials. In fact, it is possible to construct a <italic>D</italic> = 2, P1Z0 model that is exactly equivalent to a <italic>D</italic> = 1 difference of exponentials model. Here we constrained poles and zeros to be real, which restricted the impulse response to being a sum of decaying exponentials. Including complex poles and zeros doubles the number of parameters, and the neural data did not show the oscillatory responses that this would characterize.</p>
<fig id="pcbi.1004628.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004628.g007</object-id>
<label>Fig 7</label>
<caption>
<title>Pole-zero IIR filters.</title>
<p><bold>A.</bold> Examples of parameterized temporal filters with varying numbers of poles (<italic>P</italic>) and zeros (<italic>Z</italic>). Curve at top shows a very simple kernel with only one pole and no zeros (P1Z0). The curves below show more complex kernels requiring more parameters. <bold>B.</bold> Pareto plot comparing performance of the different pole-zero parameterizations, each for <italic>D</italic> = 1…5 spectral channels (Gaussian parameterization), plotted as in <xref ref-type="fig" rid="pcbi.1004628.g004">Fig 4C</xref>. The simplest temporal kernel requires more spectral channels to approach the performance of more complex kernels. The <italic>D</italic> = 3, P3Z1 kernel showed the trend for best performance overall.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004628.g007" xlink:type="simple"/>
</fig>
<p>We tested all possible combinations of 1 to 5 poles and zeros over <italic>D</italic> = 1 − 5 spectral channels to determine possible candidate kernels (<xref ref-type="fig" rid="pcbi.1004628.g007">Fig 7B</xref>). The best model used P3Z1 parameterization (<italic>D</italic> = 3, mean <italic>R</italic> = 0.485, <xref ref-type="fig" rid="pcbi.1004628.g006">Fig 6B</xref>). This model performed as well as the <italic>D</italic> = 3 Gaussian model (<italic>p</italic> &gt; 0.05, sign test) and significantly better than the difference of exponentials parameterization (<italic>p</italic> &lt; 0.01, sign test). The simplest one- or two-pole filters could not fully describe temporal encoding properties. Instead, a more complex temporal filter was required, and a combination of Gaussian spectral and P3Z1 temporal filter for <italic>D</italic> = 3 spectral channels gave the best performance among parameterizations of the linear STRF (<xref ref-type="fig" rid="pcbi.1004628.g006">Fig 6C</xref>).</p>
</sec>
</sec>
<sec id="sec013">
<title>Parameterized models perform similarly to FIR models in the limit of infinite data</title>
<p>Parameterized STRFs are approximations of the FIR STRF. Thus, in theory, the FIR STRF should perform as well as or better than any parameterized STRF. In practice, however, data available for estimation are finite, and simpler models can be estimated more accurately than the full FIR STRF. Thus simpler models are able to perform better than the FIR STRF in our analysis (<xref ref-type="fig" rid="pcbi.1004628.g006">Fig 6</xref>). The results so far demonstrate a clear practical advantage of the factorized and parameterized models, but they do not answer the question of whether any simpler model fully accounts for the linear STRF. Such a question can only be answered by comparing the relative performance of these models in the limit of infinite estimation data [<xref ref-type="bibr" rid="pcbi.1004628.ref018">18</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref022">22</xref>].</p>
<p>Extrapolating performance to infinite estimation data is challenging because there is no widely agreed upon model of variability in sensory-evoked neural activity. We made a simplifying assumption that prediction error from estimation noise is additive and inversely proportional to the square root of the number of samples used to estimate the STRF, <italic>T</italic> (see <xref ref-type="sec" rid="sec028">Methods</xref>, <xref ref-type="disp-formula" rid="pcbi.1004628.e034">Eq 31</xref>, [<xref ref-type="bibr" rid="pcbi.1004628.ref018">18</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref045">45</xref>]). When these assumptions hold, then the effect of noise on model variance explained (square of prediction correlation, <italic>R</italic><sup>2</sup>) also decreases proportionally to <italic>T</italic>. We varied <italic>T</italic> by subsampling the available estimation data (10%–75%) and measured the average <italic>R</italic><sub><italic>T</italic></sub> across neurons for models fit with the different data subsets. We then fit the free parameters in <xref ref-type="disp-formula" rid="pcbi.1004628.e034">Eq 31</xref> to determine the theoretical limit on performance for each model, <italic>R</italic><sub>inf</sub>.</p>
<p>We measured the asymptotic performance limit of four model architectures, ranging from high to low complexity: the full FIR model (FIR, 276 parameters), <italic>D</italic> = 3 factorized model (Factorized x3, 109 parameters), <italic>D</italic> = 3 Gaussian spectral/P3Z1 temporal parameterization (P3Z1x3, 29 parameters), and <italic>D</italic> = 1 Gaussian spectral/P3Z1 temporal parameterization (P3Z1x1, 13 parameters). We removed very noisy data and focused on the subset of 124 neurons that produced reliable auditory-evoked responses (SNR &gt; 0.005, see <xref ref-type="sec" rid="sec028">Methods</xref>, <xref ref-type="disp-formula" rid="pcbi.1004628.e024">Eq 21</xref>).</p>
<p>For all models, performance improved as more estimation data became available (<xref ref-type="fig" rid="pcbi.1004628.g008">Fig 8A</xref>). As expected, the lower-dimensional models performed better for small data sets and neared asymptotic performance sooner than higher-dimensional models. Consistent with this observation, performance of the FIR STRF showed the greatest improvement in the asymptote (<italic>R</italic><sub>inf</sub> = 0.63, <xref ref-type="fig" rid="pcbi.1004628.g008">Fig 8B</xref>). However, performance of the Factorized x3 (<italic>R</italic><sub>inf</sub> = 0.63) and P3Z1x3 models (<italic>R</italic><sub>inf</sub> = 0.62) was not significantly different from the FIR STRF (jackknifed <italic>t</italic>-test). Thus within the precision we could achieve with this analysis, both models captured the essential features of the FIR STRF. Error bars on asymptotic performance are relatively large, especially for the FIR STRF, so a strong conclusion about relative performance of these models is difficult. However, asymptotic performance of the P3Z1x1 model was significantly worse than the other models (<italic>R</italic><sub>inf</sub> = 0.56, <italic>p</italic> &lt; 0.001), indicating a failure of this very simple model to capture the full linear model.</p>
<fig id="pcbi.1004628.g008" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004628.g008</object-id>
<label>Fig 8</label>
<caption>
<title>Theoretical performance in the limit of infinite estimation data.</title>
<p><bold>A.</bold> Curves compare average performance of models of varying complexity as a function of the fraction of estimation data used for fitting (<italic>N</italic> = 124 neurons with response SNR &gt; 0.005). Error bars indicate the standard error on the mean difference between each model’s performance and average performance of all models estimated using 100% of available data. If only 10% of estimation data are used (12 sec of stimulation), the best-predicting model is the <italic>D</italic> = 1 P2Z1 model (peach), requiring only 13 parameters. For this estimation set, the FIR STRF (black, 276 parameters) performs substantially worse. As the quantity of available data increases, more complex models perform better, although the FIR model still lags behind the factorized (purple) and P3Z1 parameterized (orange) models of intermediate complexity. Fits to theses curves are plotted with dashed lines (<xref ref-type="disp-formula" rid="pcbi.1004628.e034">Eq 31</xref>), and asymptotic performance is indicated at far right. Note that prediction correlation plotted for 100% of estimation data is higher than in <xref ref-type="fig" rid="pcbi.1004628.g006">Fig 6</xref> because only high-SNR neurons are included here. <bold>B.</bold> Average asymptotic performance of each model in the limit of infinite estimation data. Actual performance for each model with 100% of estimation data is plotted with the thinner bars. The FIR STRF with no spike nonlinearity is also included (gray) for comparison with previous asymptotic analysis [<xref ref-type="bibr" rid="pcbi.1004628.ref022">22</xref>].</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004628.g008" xlink:type="simple"/>
</fig>
<p>For comparison with a previous analysis [<xref ref-type="bibr" rid="pcbi.1004628.ref022">22</xref>], we also measured asymptotic performance for the FIR STRF with no output nonlinearity. This model performed better than the standard FIR STRF for smaller estimation sets, presumably due to its reduced complexity, but its advantage diminished for larger datasets. Asymptotic performance was slightly lower than the standard FIR STRF that included an output nonlinearity (<italic>R</italic><sub>inf</sub> = 0.61, <italic>p</italic> &lt; 0.05, <xref ref-type="fig" rid="pcbi.1004628.g008">Fig 8B</xref>).</p>
</sec>
<sec id="sec014">
<title>Additional benefits of STRF parameterization</title>
<p>In addition to outperforming the FIR model in finite data conditions, reduced-dimensionality factorized and parameterized STRFs demonstrated several other benefits over the FIR STRF, which we detail below. For brevity in this section, <italic>factorized model</italic> refers specifically to the <italic>D</italic> = 2 factorized model, and <italic>parameterized model</italic> refers to the <italic>D</italic> = 3 Gaussian spectral parameterization with P3Z1 temporal parameterization. These models were chosen because they represent the best-performing models, respectively, among the factorized and parameterized models tested (<xref ref-type="fig" rid="pcbi.1004628.g006">Fig 6C</xref>).</p>
<sec id="sec015">
<title>Parameterization permits higher spectral and temporal resolution STRFs</title>
<p>The dimensionality of the smooth, continuous parameterized basis functions is independent of spectral and temporal sampling resolution, similar to spline basis functions used in other encoding models [<xref ref-type="bibr" rid="pcbi.1004628.ref029">29</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref033">33</xref>]. Thus, unlike the FIR models, these models do not require more parameters as spectral or temporal granularity is increased. To test the impact of increasing resolution, we compared performance of the FIR, factorized and parameterized models for increasing spectral (24 or 36 channels instead of 18) and temporal resolution (200- or 400 Hz sampling instead of 100 Hz). At higher spectral resolution, performance of the FIR models decreased, reflecting greater estimation noise from the larger number of parameters (<italic>p</italic> &lt; 0.001, sign test, <xref ref-type="fig" rid="pcbi.1004628.g009">Fig 9A</xref>). At the same time, performance of the parameterized models remained stable with higher spectral resolution.</p>
<fig id="pcbi.1004628.g009" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004628.g009</object-id>
<label>Fig 9</label>
<caption>
<title>Effects of spectral and temporal resolution on model performance.</title>
<p><bold>A.</bold> As the number of cochlear filterbank channels increases from <italic>C</italic> = 18 to 24 or 36, there is no significant change in performance of the parameterized model. However, performance of the factorized and FIR models is significantly decreased (sign test). <bold>B.</bold> As temporal resolution is increased from 100 to 200 or 400 Hz, the average prediction correlation of all models decreases. However, FIR model performance degrades more than the factorized and parameterized models. Numbers in parentheses denote the number of temporal bins <italic>U</italic> used. <bold>C.</bold> Average performance of models with and without nonlinear short-term plasticity (STP) incorporated into the STRF. STP does not significantly improve performance of the FIR STRF, but it does improve performance of the factorized and parameterized models.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004628.g009" xlink:type="simple"/>
</fig>
<p>Increasing temporal resolution decreased performance of all models, as expected for the greater temporal bandwidth of the predicted PSTH [<xref ref-type="bibr" rid="pcbi.1004628.ref045">45</xref>] and the tuning of some A1 neurons for fast temporal modulations [<xref ref-type="bibr" rid="pcbi.1004628.ref027">27</xref>]. The general decrease in performance may also reflect fast temporal nonlinearities such as the spike refractory period that are incorporated into some implementations of the GLM [<xref ref-type="bibr" rid="pcbi.1004628.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref031">31</xref>]. Although performance decreased for all models, the relative decrease for the FIR model was greater than for the others (<xref ref-type="fig" rid="pcbi.1004628.g009">Fig 9B</xref>). Thus the parameterized models are consistently less sensitive to effects of increased temporal resolution.</p>
</sec>
<sec id="sec016">
<title>Parameterization improves performance of models with additional nonlinear terms</title>
<p>Parameterization need not be limited to the <italic>linear</italic> STRF. By minimizing the number of parameters required to account for linear response properties, this strategy preserves statistical power for incorporating additional <italic>nonlinear</italic> terms. To test the feasibility of adding nonlinear terms to the parameterized model, we incorporated a module that mimicked the effects of short-term synaptic plasticity on each spectral channel prior to temporal filtering (STP, <xref ref-type="fig" rid="pcbi.1004628.g001">Fig 1F</xref>, [<xref ref-type="bibr" rid="pcbi.1004628.ref052">52</xref>]). This architecture permits distinct, nonlinear adaptation for each spectral channel and may explain some properties of stimulus-specific adaptation [<xref ref-type="bibr" rid="pcbi.1004628.ref053">53</xref>]. Incorporating nonlinear STP into encoding models improves prediction accuracy for responses to narrowband noise stimuli [<xref ref-type="bibr" rid="pcbi.1004628.ref030">30</xref>], and we expected that it would also improve model performance for the more spectrally complex vocalizations.</p>
<p>In our general model framework, STP is incorporated by inserting an extra module into the sequence of transformations that maps input stimulus to output spike rate (<xref ref-type="disp-formula" rid="pcbi.1004628.e001">Eq 1</xref>). The STP module mimicked the effects of short-term depression and/or facilitation prior to the linear temporal filter (<xref ref-type="fig" rid="pcbi.1004628.g001">Fig 1F</xref>). Each STP synapse was specified by three free parameters: baseline presynaptic activity level (in the absence of an auditory stimulus), probability of vesicle release and rate of vesicle recovery (<xref ref-type="disp-formula" rid="pcbi.1004628.e019">Eq 17</xref>). We first tested the effect of incorporating STP into the FIR STRF. For the <italic>C</italic> = 18 channel FIR, STP required 54 additional parameters, but it did not significantly improve performance (<xref ref-type="fig" rid="pcbi.1004628.g009">Fig 9C</xref>), presumably because the many additional parameters lead to overfitting. However, adding STP to the factorized and parameterized models did significantly improve predictions (<xref ref-type="fig" rid="pcbi.1004628.g009">Fig 9C</xref>, parameterized model: <italic>R</italic> = 0.510 vs. 0.485, <italic>p</italic> &lt; 0.001, sign test). These results suggest that the STP module introduced useful new degrees of freedom, reflecting properties of A1 neurons that are not captured by the linear model.</p>
</sec>
<sec id="sec017">
<title>Parameterization tolerates unreliable sensory responses</title>
<p>In auditory cortex, the reliability of auditory-evoked responses varies from neuron to neuron [<xref ref-type="bibr" rid="pcbi.1004628.ref022">22</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref045">45</xref>]. Thus for a fixed data set size, such as the vocalization data in the current study, the amount of information available for measuring sensory coding properties is also variable across neurons. To account for differences in response reliability, we computed a signal-to-noise ratio for each neuron, based on the variability of single-trial responses to repetitions of the same vocalization (SNR, <xref ref-type="disp-formula" rid="pcbi.1004628.e024">Eq 21</xref>). The SNR provided a simple measure of the fraction of single-trial neural activity that could be accounted for by the stimulus.</p>
<p>Neurons with low SNR were more susceptible to fitting error and produced STRFs with lower predictive power (<xref ref-type="fig" rid="pcbi.1004628.g010">Fig 10A</xref>). We measured prediction correlation (validation data) as a function of SNR (estimation data) and found a positive correlation (<xref ref-type="fig" rid="pcbi.1004628.g010">Fig 10B</xref>). We expected noise from overfitting to be particularly severe for models such as the FIR STRF that require a large number of parameters. To test this prediction, we sorted neural data according to SNR and compared performance of the FIR, factorized and parameterized models in the top and bottom quintiles (<xref ref-type="fig" rid="pcbi.1004628.g010">Fig 10C</xref>). In the top quintile, performance of all three models was nearly the same, and the FIR model performed only slightly worse than the others (<italic>p</italic> &lt; 0.05, sign test). In the bottom quintile, all models performed worse, but the average prediction correlation for the parameterized model was about 50% greater than the FIR model (<italic>p</italic> &lt; 0.0001, sign test). Thus when SNR is low, the FIR model is particularly susceptible to overfitting compared to parameterized models.</p>
<fig id="pcbi.1004628.g010" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004628.g010</object-id>
<label>Fig 10</label>
<caption>
<title>Model performance versus neuronal signal-to-noise.</title>
<p><bold>A.</bold> Example data for two neurons with high (left) or low (right) response SNR. A validation stimulus (spectrogram, top) was presented over 20 repetitions (raster response, middle). Both the FIR and parameterized STRFs were able to predict activity of the high-SNR neuron more accurately than the low-SNR (predicted versus actual PSTHs, bottom). However, the relative improvement for the parameterized STRF was greater for the low-SNR neuron (prediction correlations shown, <italic>R</italic>). <bold>B.</bold> Scatter plot compares signal-to-noise ratio (SNR, estimation data) against prediction correlation (validation data) by the parameterized model for each A1 neuron. Orange line plots the average for data grouped in quintiles according to SNR, showing a correlation (<italic>R</italic> = 0.45). <bold>C.</bold> Average prediction correlation for the FIR, factorized, and parameterized models separately for top and bottom quintile of neurons, ranked by response SNR. The factorized and parameterized models show greater improvement over the FIR model for the low-SNR neurons than the high-SNR neurons.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004628.g010" xlink:type="simple"/>
</fig>
</sec>
</sec>
<sec id="sec018">
<title>Broader applicability</title>
<sec id="sec019">
<title>Results are not specific only to a brain region or stimulus</title>
<p>Because of the large number of model comparisons in the current study, our best parameterization could be overly specific to the A1 vocalization dataset (<xref ref-type="fig" rid="pcbi.1004628.g011">Fig 11A</xref>). The question remains whether the performance of the factorized and/or parameterized models generalizes to different brain areas and different stimuli. To test for generalization across brain areas, we compared model performance on data collected with the same vocalization stimuli from a secondary (belt) auditory cortical area (dorsal posterior ectosylvian gyrus, dPEG [<xref ref-type="bibr" rid="pcbi.1004628.ref054">54</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref055">55</xref>]). Overall, prediction correlation was lower than for A1, as expected for a more central brain area (<xref ref-type="fig" rid="pcbi.1004628.g011">Fig 11B</xref>). The dimensionality of the best-performing models also differed slightly. However, the factorized and parameterized models again showed the same pattern of improved performance over the FIR STRF.</p>
<fig id="pcbi.1004628.g011" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004628.g011</object-id>
<label>Fig 11</label>
<caption>
<title>Comparison of model architectures across brain areas and stimulus domains.</title>
<p><bold>A.</bold> Pareto plot summarizes performance of the FIR, factorized, parameterized and parameterized-STP models for A1 vocalization data. Error bars indicate SEM for the difference from performance by the FIR STRF, as in <xref ref-type="fig" rid="pcbi.1004628.g004">Fig 4C</xref>. <bold>B.</bold> Comparison of model performance for vocalization data recorded in ferret belt auditory cortex (dPEG), plotted as in A. Overall performance is lower than in A1, but performance rankings are the same: <italic>D</italic> = 2 factorized &gt; FIR model (<italic>p</italic> &lt; 0.001, sign test), <italic>D</italic> = 3 parameterized &gt; <italic>D</italic> = 2 factorized model (<italic>p</italic> &lt; 0.01), <italic>D</italic> = 3 parameterized-STP &gt; <italic>D</italic> = 3 parameterized model (<italic>p</italic> &lt; 0.001). Thus results of the model comparison generalize across areas in the auditory processing hierarchy. <bold>C.</bold> Comparison of model performance for human speech data recorded in A1. The parameterized-STP models again show the strongest performance with successive significant improvements for each model architecture (<italic>p</italic> &lt; 0.001, sign test, for all comparisons), indicating that the results generalize across different natural stimuli. <bold>D.</bold> Comparison of model performance for 1/<italic>f</italic> noise data recorded in A1. The models again show the same pattern of relative performance, indicating that the results also generalize to synthetic noise stimuli.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004628.g011" xlink:type="simple"/>
</fig>
<p>To test for generalization across stimuli, we compared model performance for a dataset collected from a different population of A1 neurons during presentation of continuous human speech (data reanalyzed from [<xref ref-type="bibr" rid="pcbi.1004628.ref009">9</xref>]) and during presentation 1/<italic>f</italic> spectro-temporal noise [<xref ref-type="bibr" rid="pcbi.1004628.ref056">56</xref>]. For the noise stimulus, first order spectral and temporal modulation power spectra were matched to natural stimuli, but higher order correlations were not. As in the case of vocalizations, we observed a pattern of greater prediction accuracy by the parameterized and factorized STRFs in both datasets (<xref ref-type="fig" rid="pcbi.1004628.g011">Fig 11C and 11D</xref>). In the case of 1/<italic>f</italic> noise, relative differences in model performance were not as large as for the natural stimuli, possibly because the noise did not contain as many sharp onsets as vocalizations. Despite the quantitative differences, these results confirm that the improved performance of the low-dimensional models is a general property across auditory cortical areas and across stimulus conditions.</p>
</sec>
<sec id="sec020">
<title>Parameterized models provide more direct measures of neural circuit properties</title>
<p>Any encoding model captures information about function of the underlying biological circuit, but extracting this information is more straightforward for parameterized models. Parameterized model fits provide direct measures of sensory tuning such as response latency (<italic>l</italic> in <xref ref-type="disp-formula" rid="pcbi.1004628.e012">Eq 10</xref>) and spectral tuning bandwidth (<italic>σ</italic> in <xref ref-type="disp-formula" rid="pcbi.1004628.e009">Eq 7</xref>). We compared response latencies between A1 and dPEG for the parameterized model and found longer average response latency in dPEG (<italic>p</italic> &lt; 0.001, Wilcoxon rank-sum test, <xref ref-type="fig" rid="pcbi.1004628.g012">Fig 12A</xref>). The tendency toward longer response latency in belt versus core fields is consistent with previous reports [<xref ref-type="bibr" rid="pcbi.1004628.ref054">54</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref055">55</xref>]. This difference is typically attributed to the greater number of synapses (and associated delays) required for auditory signals to reach belt than core areas. However, nonlinearities in the temporal response can also shift response latency in the linear STRF, which may explain why some latencies in the current results are shorter than the minimum of 10–15 ms typically reported for cortex [<xref ref-type="bibr" rid="pcbi.1004628.ref030">30</xref>]. Thus differences between A1 and dPEG could reflect nonlinear response properties in addition to differences in accumulated synaptic delays.</p>
<fig id="pcbi.1004628.g012" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004628.g012</object-id>
<label>Fig 12</label>
<caption>
<title>Direct interpretation of parameterized models.</title>
<p><bold>A.</bold> Histogram compares latency measured directly from the P3Z1 temporal filter for neurons in A1 and dPEG. Mean response latency is shorter in A1 (12.6 ms) than in PEG (17.9 ms, <italic>p</italic> &lt; 0.001, Wilcoxon rank-sum test, <italic>N</italic> = 124 neurons with SNR &gt; 0.005). <bold>B.</bold> Histogram of optimal spectral channel count for neurons in A1 and dPEG. Neurons were classified according to the spectral channel count (<italic>D</italic> = 1…5) of the P3Z1 parameterized model that produced the best prediction in the validation data. Mean optimal channel count in A1 (3.04) was lower than in dPEG (3.41, <italic>p</italic> &lt; 0.05, rank-sum test)</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004628.g012" xlink:type="simple"/>
</fig>
<p>The structure of parameterized models can also be studied at a higher level to assess the general complexity of STRFs. To illustrate this idea, we determined the number of spectral channels, <italic>D</italic> = 1 to <italic>D</italic> = 5, that produced the best-performing parameterized model for each neuron in A1 and PEG. The average best number of spectral channels is <italic>D</italic> = 3.04 for A1 and <italic>D</italic> = 3.41 for dPEG (<xref ref-type="fig" rid="pcbi.1004628.g012">Fig 12B</xref>, <italic>p</italic> &lt; 0.05, rank-sum test). Optimal channel counts were determined from performance on validation data only. Thus this effect is not biased by the lower SNR typically observed in dPEG relative to A1 [<xref ref-type="bibr" rid="pcbi.1004628.ref055">55</xref>]). Instead, the larger average channel count indicates greater complexity in dPEG STRFs and that encoding models require greater degrees of freedom in dPEG than in A1. Identifying optimal channel counts also provides a form of relevancy determination that groups model parameters logically (<italic>i.e.</italic>, entire spectro-temporal dimensions) for inclusion or exclusion, rather than individual parameters of a much larger model [<xref ref-type="bibr" rid="pcbi.1004628.ref038">38</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref046">46</xref>].</p>
<p>In practice, properties such as response latency and optimal spectral channel count can also be measured from FIR STRF coefficients [<xref ref-type="bibr" rid="pcbi.1004628.ref009">9</xref>]. However, this procedure requires a second stage of analysis in which tuning properties must be fit to the FIR parameters, an approach that requires more involved analysis and is susceptible to the effects of noise in the FIR parameter estimates. For a parameterized model, these properties are fit in a single procedure that maximizes predictive power. Either approach makes assumptions about tuning properties that may introduce bias their measurement, but that bias is made explicit in a single operation for a parameterized model rather than in the multiple stages of fitting and feature extraction required for more complex models.</p>
</sec>
<sec id="sec021">
<title>Parameterized model performance holds under alternative prediction accuracy metrics</title>
<p>Finally, a number of alternative metrics have been proposed for evaluating the performance of receptive field models, including mutual information (MI) [<xref ref-type="bibr" rid="pcbi.1004628.ref057">57</xref>], mean coherence (closely related to mutual information) [<xref ref-type="bibr" rid="pcbi.1004628.ref045">45</xref>], and negative log likelihood (NLOGL, maximum likelihood for a Poisson-spiking noise model) [<xref ref-type="bibr" rid="pcbi.1004628.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref015">15</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref029">29</xref>]. We compared the performance of the FIR, factorized and parameterized models according to these different metrics (<xref ref-type="fig" rid="pcbi.1004628.g013">Fig 13</xref>). There was some variability in scores across individual neurons, but the relative performance of the different models was largely consistent for all the metrics, particularly the improved performance of the parameterized model over the FIR.</p>
<fig id="pcbi.1004628.g013" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004628.g013</object-id>
<label>Fig 13</label>
<caption>
<title>Different performance metrics yield the same model ranking.</title>
<p>Average performance of the FIR, factorized and parameterized models evaluated using four different metrics of prediction accuracy. All four metrics produce the same rankings of relative model performance. Data are shown for <italic>N</italic> = 117 neurons with SNR &gt; 0.01 because some performance metrics were susceptible to noise for low-SNR neurons.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004628.g013" xlink:type="simple"/>
</fig>
</sec>
</sec>
</sec>
<sec id="sec022" sec-type="conclusions">
<title>Discussion</title>
<sec id="sec023">
<title>Reduced complexity of auditory encoding models without reduced performance</title>
<p>The finite impulse response (FIR) STRF represents the current standard model for stimulus-response filtering in the auditory system [<xref ref-type="bibr" rid="pcbi.1004628.ref002">2</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref004">4</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref008">8</xref>–<xref ref-type="bibr" rid="pcbi.1004628.ref013">13</xref>]. Our results agree with previous findings that, as a general architecture, the linear STRF accounts only partially for the neural response to natural sounds in A1 [<xref ref-type="bibr" rid="pcbi.1004628.ref009">9</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref023">23</xref>]. However, we find that the same level of performance can be achieved by much simpler models. A model requiring fewer than 30 parameters not only matches performance of the FIR STRF (&gt; 250 parameters) but actually outperforms it for large but finite datasets. The simplest parameterization that works optimally for a neural population provides insight into the neural circuitry underlying system function [<xref ref-type="bibr" rid="pcbi.1004628.ref036">36</xref>]. According to this logic, the average linear STRF of an A1 neuron can be captured by the sum of three channels with Gaussian spectral tuning and an IIR temporal filter.</p>
<p>When data are finite, a critical issue is that a simpler model with fewer free parameters will be less susceptible to estimation noise than a more complex model. Thus the simpler model may perform better, even if it fails to account for important degrees of freedom in the more complex one. Accounting for the impact of estimation noise on model performance is difficult, as it requires extrapolation to the condition where data are infinite [<xref ref-type="bibr" rid="pcbi.1004628.ref018">18</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref022">22</xref>]. By assuming that estimation noise is additive, we found that a simple inverse relationship between estimation set size and prediction error accurately described performance for several different architectures (<xref ref-type="fig" rid="pcbi.1004628.g008">Fig 8A</xref>). In the limit of infinite data and under these assumptions, the FIR STRF did not perform significantly better than the simple parameterized model. These results should be confirmed with a larger dataset, but the current analysis suggests that the essential degrees of freedom for the linear STRF are much closer to 29 than to the 276 specified by the FIR STRF.</p>
<p>The average linear STRF in A1 may be described by about 30 parameters, but STRFs for individual neurons do vary substantially in their complexity. Some neurons require only one spectral channel for optimal performance while others require four or more channels (<xref ref-type="fig" rid="pcbi.1004628.g012">Fig 12B</xref>). The fact that only a minority of neurons were best described by a single dimension argues that most linear STRFs are not frequency-time separable [<xref ref-type="bibr" rid="pcbi.1004628.ref037">37</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref051">51</xref>]. At the other extreme, even STRFs with four or five spectral channels required substantially fewer parameters than the standard FIR STRF.</p>
<p>This low dimensionality generalizes across other natural and synthentic stimuli in A1, but our analysis of data from the belt area dPEG indicates that more complex models are required for non-primary cortex (<xref ref-type="fig" rid="pcbi.1004628.g011">Fig 11</xref>). Moreover, even in A1, the full dimensionality of encoding models is likely to be greater than what is required to specify the linear STRF. As demonstrated by the enhanced performance of the nonlinear STP STRFs (<xref ref-type="fig" rid="pcbi.1004628.g011">Fig 11</xref>), introducing additional dimensionality that extends outside of the linear STRF architecture can improve model performance.</p>
</sec>
<sec id="sec024">
<title>Upper bounds on linear STRF performance</title>
<p>How well can the linear STRF actually describe sensory responses in A1? Issues surrounding finite sampling of experimental data again make it difficult to answer this question definitively [<xref ref-type="bibr" rid="pcbi.1004628.ref018">18</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref045">45</xref>]. After implementing our estimation noise model, we found that the FIR STRF is able to account for 40% of A1 response variance on average (<italic>i.e.</italic>, variance explained is 100<italic>R</italic><sup>2</sup> for <italic>R</italic> = 0.63, <xref ref-type="fig" rid="pcbi.1004628.g008">Fig 8</xref>). Factorized and parameterized STRFs very nearly matched performance of the FIR model (39% of response variance), indicating that these approximations capture the essential features of the more complex model, despite requiring only about 50% and 10% of the parameters, respectively. These measurements establish baseline performance by the linear STRF that must be surpassed by any more accurate model. At the Pareto frontier, a better model must either produce more accurate predictions or require fewer parameters and perform as well.</p>
<p>Only one previous study has attempted to answer this question rigorously, using activity driven by random chord stimuli in anesthetized mice [<xref ref-type="bibr" rid="pcbi.1004628.ref022">22</xref>]. Although we focused primarily on models that included an output nonlinearity [<xref ref-type="bibr" rid="pcbi.1004628.ref013">13</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref014">14</xref>], we also computed asymptotic performance of STRFs without this nonlinear term in order to make a more direct comparison to the previous analysis of asymptotic performance. Without a spiking nonlinearity, the average FIR STRF was able to account for about 37% of response variance. This result falls in the range of 18–40% reported previously [<xref ref-type="bibr" rid="pcbi.1004628.ref022">22</xref>], although several factors make a direct comparison difficult. In the current study, recordings were performed in awake ferrets and used natural vocalizations rather than anesthetized mice and noise stimuli. Anesthesia can impact auditory neural activity [<xref ref-type="bibr" rid="pcbi.1004628.ref058">58</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref059">59</xref>], and natural sounds evoke nonlinear response properties in a different functional domain than noise stimuli [<xref ref-type="bibr" rid="pcbi.1004628.ref009">9</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref060">60</xref>].</p>
<p>The number of models tested here was relatively large, but they are still likely to be suboptimal compared to as-yet-untested parameterizations. The current study explored only two spectral parameterizations (Gaussian and Morlet functions) and the pole-zero family of IIR temporal filters. Numerous other basis functions could be considered, including Gabor wavelets [<xref ref-type="bibr" rid="pcbi.1004628.ref042">42</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref061">61</xref>] or empirically-derived basis functions [<xref ref-type="bibr" rid="pcbi.1004628.ref029">29</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref031">31</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref033">33</xref>]. There is a clear trade-off between basis function complexity and the number of spectral dimensions needed. Better-performing temporal kernels like the P3Z1 filter reach their peak performance when <italic>D</italic> = 3, while simpler kernels like P1Z0 need <italic>D</italic> ≥ 4 to reach the same performance. Thus the interaction between channel count and basis function complexity will be relevant to identifying optimal parameterizations.</p>
</sec>
<sec id="sec025">
<title>Parameterization supports exploration of nonlinear and state-dependent models</title>
<p>The efficiency of estimating parameterized STRFs allows the introduction of new, nonlinear terms that can account for encoding properties that are not captured by the linear model [<xref ref-type="bibr" rid="pcbi.1004628.ref030">30</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref031">31</xref>]. When nonlinear short-term plasticity was introduced to the FIR STRF, it did not change model performance, but when it was introduced to the parameterized model, it improved predictive power. Thus the benefits of nonlinear terms may only become apparent when sufficient statistical power is available in the current dataset.</p>
<p>The family of models used in this study incorporate static nonlinearities that are commonly part of STRFs. This include log-compression of the input spectrogram to account for basilar membrane mechanics [<xref ref-type="bibr" rid="pcbi.1004628.ref025">25</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref026">26</xref>] and an output nonlinearity to account for spike threshold and saturation [<xref ref-type="bibr" rid="pcbi.1004628.ref013">13</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref014">14</xref>]. Other studies have incorporated nonlinear terms into the core computation of the filter. Some use general Volterra series expansions to account for second- and higher-order nonlinearities [<xref ref-type="bibr" rid="pcbi.1004628.ref003">3</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref027">27</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref057">57</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref062">62</xref>]. Others incorporate more specific terms aimed at capturing contextual influences [<xref ref-type="bibr" rid="pcbi.1004628.ref028">28</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref029">29</xref>] or mimicking biological circuit elements [<xref ref-type="bibr" rid="pcbi.1004628.ref026">26</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref031">31</xref>]. These additional nonlinear terms can be incorporated into the parameterized framework, potentially providing substantial improvements in predictive power.</p>
<p>Neurons also undergo plasticity at multiple timescales due to stimulus context [<xref ref-type="bibr" rid="pcbi.1004628.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref030">30</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref063">63</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref064">64</xref>], changes in behavioral state [<xref ref-type="bibr" rid="pcbi.1004628.ref050">50</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref065">65</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref066">66</xref>], and learning [<xref ref-type="bibr" rid="pcbi.1004628.ref049">49</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref067">67</xref>]. In many experimental settings, the quantity of data available in a single behavioral state may provide a critical limitation on statistical power. Low-dimensional parameterized models may be particularly beneficial for exploring changes in spectro-temporal response properties in these experimental settings.</p>
</sec>
<sec id="sec026">
<title>Parameterization as regularization</title>
<p>From a general analytical perspective, parameterization is similar to regularization during model estimation [<xref ref-type="bibr" rid="pcbi.1004628.ref001">1</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref046">46</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref068">68</xref>]. In both cases, pre-existing knowledge or a hypothesis about the system’s function is used to constrain model fits. The idea that sensory receptive fields should vary smoothly in space and time has motivated the use of priors for smoothly varying STRFs [<xref ref-type="bibr" rid="pcbi.1004628.ref046">46</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref068">68</xref>]. Similarly, the idea that receptive fields should have a relatively small number of non-zero parameters has motivated a sparse prior on model fits [<xref ref-type="bibr" rid="pcbi.1004628.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref046">46</xref>]. Constraining the STRF to have analytical form of the factorized or parameterized models serves the same purpose of imposing a prior on the fit [<xref ref-type="bibr" rid="pcbi.1004628.ref038">38</xref>]. In the current study, the spectral and temporal parameterizations constrain both sparseness (limiting the model’s degrees of freedom) and smoothness (Gaussian spectral tuning and exponential temporal tuning).</p>
<p>To simplify model comparisons in this study, we used a single fit algorithm across all models. Thus it was not optimized specifically for the FIR STRF. Incorporating stricter stop criteria and sparseness constraints improve FIR STRF performance, but even after tuning the cost function, it did not match the performance of the parameterized model. The factorized and parameterized models were less sensitive to details of the fit algorithm such as the stop criterion, emphasizing the benefits of regularization effectively built into parameterization.</p>
</sec>
<sec id="sec027">
<title>Pareto fronts describe optimal trade-offs in model performance</title>
<p>Most real world optimization problems involve the simultaneous minimization of several objectives [<xref ref-type="bibr" rid="pcbi.1004628.ref069">69</xref>]. Thus when comparing different model architectures, it may be helpful to consider trade-offs separately along different dimensions [<xref ref-type="bibr" rid="pcbi.1004628.ref036">36</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref070">70</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref071">71</xref>]. The current study focused in particular on the trade-off between model prediction accuracy and parameter count. In general, however, such an approach can be used to define an <italic>N</italic>-dimensional Pareto front containing the best models according to numerous other measures, including alternative performance metrics (<xref ref-type="fig" rid="pcbi.1004628.g013">Fig 13</xref>, see also [<xref ref-type="bibr" rid="pcbi.1004628.ref072">72</xref>]), alternative model complexity metrics [<xref ref-type="bibr" rid="pcbi.1004628.ref073">73</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref074">74</xref>], data required to fit (<xref ref-type="fig" rid="pcbi.1004628.g008">Fig 8</xref>), computational cost [<xref ref-type="bibr" rid="pcbi.1004628.ref075">75</xref>], or model plausibility [<xref ref-type="bibr" rid="pcbi.1004628.ref076">76</xref>].</p>
<p>Pareto fronts are extensively used in the context of multiobjective optimization for the formulation of heuristics [<xref ref-type="bibr" rid="pcbi.1004628.ref069">69</xref>]. Given the complexity of performing a search on the space of model architectures, we relied here on inspection of the Pareto front to guide model design. While developing new analytic models to test, we found it most helpful to generate new models by adding to or discarding from a model on the current Pareto front. Variants of non-Pareto-optimal models rarely improved performance or provided insight into the relevancy of new parameters. Of particular note, the FIR implementation falls far from the Pareto front (<xref ref-type="fig" rid="pcbi.1004628.g002">Fig 2B</xref>), making it difficult to test variants based on the FIR STRF.</p>
</sec>
</sec>
<sec id="sec028" sec-type="materials|methods">
<title>Methods</title>
<sec id="sec029">
<title>Experimental procedures</title>
<p>Single-unit neural activity was recorded from five awake, passively listening ferrets. For the main analysis of responses to vocalizations, a total of 176 single units were recorded in primary auditory cortex (A1) and 130 units in belt auditory cortex (dPEG). For one analysis (<xref ref-type="fig" rid="pcbi.1004628.g011">Fig 11C and 11D</xref>), responses were analyzed for 808 A1 units recorded during the presentation of continuous speech (reanalyzed from a previous publication [<xref ref-type="bibr" rid="pcbi.1004628.ref009">9</xref>]) and for 139 A1 units recorded during the presentation of 1/<italic>f</italic> noise [<xref ref-type="bibr" rid="pcbi.1004628.ref056">56</xref>].</p>
<p>Data used in this study will be made publicly available online via the Neural Prediction Challenge (<ext-link ext-link-type="uri" xlink:href="http://neuralprediction.berkeley.edu/" xlink:type="simple">http://neuralprediction.berkeley.edu/</ext-link>).</p>
<sec id="sec030">
<title>Neurophysiological recordings</title>
<p>Prior to experiments, animals were implanted with a custom steel head post to allow for stable recording. While under anesthesia (ketamine followed by isoflurane) and under sterile conditions, the skin and muscles on the top of the head were retracted from the central 4 cm diameter of skull. Several stainless steel bone screws (Synthes, 6 mm) were attached to the skull, the head post was glued on the mid-line (3M Durelon), and the site was covered with bone cement (Zimmer Palacos). After surgery, the skin around the implant was allowed to heal. Analgesics and antibiotics were administered under veterinary supervision until recovery.</p>
<p>After animals fully recovered from surgery and were habituated to a head-fixed posture, a small craniotomy (1–2 mm diameter) was opened over A1. Neurophysiological activity was recorded using tungsten microelectrodes (1–5 M<italic>Ω</italic>, A.M. Systems). One to four electrodes positioned by independent microdrives (Alpha-Omega Engineering EPS) were inserted into the cortex. Electrophysiological activity was amplified (A.M. Systems 3600), digitized (National Instruments PCI-6259), and recorded using the MANTA open-source data acquisition software [<xref ref-type="bibr" rid="pcbi.1004628.ref077">77</xref>]. Recording site locations were confirmed as being in A1 based on tonotopy, relatively well-defined frequency tuning and short response latency [<xref ref-type="bibr" rid="pcbi.1004628.ref011">11</xref>].</p>
<p>Spiking events were extracted from the continuous raw electrophysiological trace by principal components analysis and <italic>k</italic>-means clustering [<xref ref-type="bibr" rid="pcbi.1004628.ref009">9</xref>]. Single unit isolation was quantified from cluster variance and overlap as the fraction of spikes that were likely to be from a single cell rather than from another cell. Only units with &gt; 80% isolation were used for analysis.</p>
<p>Stimulus presentation was controlled by custom software written in Matlab (version 2012A, Mathworks). Digital acoustic signals were transformed to analog (National Instruments PCI-6259) and amplified (Crown D-75a) to the desired sound level. Stimuli were presented through a flat-gain, free-field speaker (Manger) 80 cm distant, 0-deg elevation and 30-deg azimuth contralateral to the neurophysiological recording site. Prior to experiments, sound level was calibrated using to a standard reference (Brüel &amp; Kjær). Stimuli were presented at 60–65 dB SPL.</p>
</sec>
<sec id="sec031">
<title>Auditory stimuli</title>
<p>For most experiments, stimuli used for estimation were ferret vocalizations, which were recorded in a sound-attenuating chamber using a commercial digital recorder (44-KHz sampling, Tascam DR-400). Recordings included infant calls (1 week to 1 month of age), adult aggression calls, and adult play calls. No animals that produced the vocalizations in the stimulus library were used in the current study. Neural activity was recorded during 4–6 repetitions of 40 randomly ordered 3-second stimuli, used for model estimation, and during 20 repetitions of two additional 3-second stimuli, used for model validation.</p>
<p>Because validation data always used the same two vocalization sequences, one possible concern is that the vocalization results might not generalize to other stimuli. To test whether the improved performance of reduced-parameter models generalized across stimulus conditions, model performance was also compared for A1 neural activity recorded during presentation of continuous human speech. The stimulus consisted of 4–5 repetitions of 30 3-second sentences from the TIMIT library [<xref ref-type="bibr" rid="pcbi.1004628.ref078">78</xref>], each uttered by a different speaker. Data for 28 sentences were used for model estimation, and data from the remaining two were used for validation. Activity was recorded from a different set of A1 neurons during presentation of continuous 1/<italic>f</italic> noise. The noise was generated by computing the spectrogram of a white noise signal, low-pass filtering the spectrogram to impose temporal and spectral modulations matched to natural stimuli, and then inverting the spectrogram into a time-varying acoustic signal [<xref ref-type="bibr" rid="pcbi.1004628.ref056">56</xref>]. Neurophysiological recording techniques and the experimental protocol were identical to those used for vocalizations, except the speech stimuli were presented through a calibrated, closed-field earphone (Etymotic ER2) contralateral to the recording site. Data collected using the speech stimulus have been published previously [<xref ref-type="bibr" rid="pcbi.1004628.ref009">9</xref>].</p>
</sec>
</sec>
<sec id="sec032">
<title>Receptive field model framework</title>
<p>The relationship between the time-varying input auditory stimulus, <italic>x</italic>(<italic>t</italic>), and simultaneously recorded single-unit firing rate response, <italic>y</italic>(<italic>t</italic>), is described by the spectro-temporal receptive field (STRF [<xref ref-type="bibr" rid="pcbi.1004628.ref008">8</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref009">9</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref011">11</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref012">12</xref>]) or, more generally, any function that maps <italic>x</italic> to <italic>y</italic>. In the current study, this mapping was cast as a sequence of functional modules, in which each function was applied to the output of the previous one (<xref ref-type="disp-formula" rid="pcbi.1004628.e001">Eq 1</xref>, <xref ref-type="fig" rid="pcbi.1004628.g001">Fig 1C</xref>). The series of functions maps roughly to the physical elements that transmit auditory information to cortex. A detailed list of all models tested in this framework is included in <xref ref-type="supplementary-material" rid="pcbi.1004628.s001">S1 Table</xref>.</p>
<sec id="sec033">
<title>Cochlear filterbank</title>
<p>The first stage of each STRF consisted of a second-order gammatone filterbank that modeled spectral processing in the a cochlea [<xref ref-type="bibr" rid="pcbi.1004628.ref044">44</xref>]. The frequency domain transfer function, <italic>G</italic><sub><italic>i</italic></sub>, for the <italic>i</italic>th filter (<italic>i</italic> = 1…<italic>C</italic>) was parameterized in terms of quality factor <italic>Q</italic> and center frequency <italic>f</italic><sub><italic>i</italic></sub>:
<disp-formula id="pcbi.1004628.e013"><alternatives><graphic id="pcbi.1004628.e013g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004628.e013" xlink:type="simple"/><mml:math display="block" id="M13"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>G</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mfrac><mml:mi>K</mml:mi> <mml:msup><mml:mrow><mml:mfenced close="]" open="[" separators=""><mml:msup><mml:mi>s</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mo>+</mml:mo> <mml:mfenced close=")" open="(" separators=""><mml:mfrac><mml:msub><mml:mi>ω</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mi>Q</mml:mi></mml:mfrac></mml:mfenced> <mml:mi>s</mml:mi> <mml:mo>+</mml:mo> <mml:mn>2</mml:mn> <mml:mi>π</mml:mi> <mml:msub><mml:mi>f</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow> <mml:mn>4</mml:mn></mml:msup></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(11)</label></disp-formula>
All filters had fixed <italic>Q</italic>:
<disp-formula id="pcbi.1004628.e014"><alternatives><graphic id="pcbi.1004628.e014g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004628.e014" xlink:type="simple"/><mml:math display="block" id="M14"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>Q</mml:mi> <mml:mo>=</mml:mo> <mml:msup><mml:mrow><mml:mfenced close=")" open="(" separators=""><mml:msup><mml:mrow><mml:mfenced close=")" open="(" separators=""><mml:mfrac><mml:msub><mml:mi>f</mml:mi> <mml:mtext>high</mml:mtext></mml:msub> <mml:msub><mml:mi>f</mml:mi> <mml:mtext>low</mml:mtext></mml:msub></mml:mfrac></mml:mfenced></mml:mrow> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mi>C</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:mfrac></mml:msup> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mfenced></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(12)</label></disp-formula>
For most analyses, the filterbank included <italic>C</italic> = 18 filters with <italic>f</italic><sub><italic>i</italic></sub> spaced logarithmically from <italic>f</italic><sub>low</sub> = 200 to <italic>f</italic><sub>high</sub> = 20,000Hz.</p>
<p>The complex output of each gammatone filter was transformed into a positive, real signal by taking the absolute value of its Hilbert transform. The signal was then smoothed and downsampled to match the temporal bin size of the PSTH, usually 100 Hz, but sometimes 200 or 400 Hz. We found that the second-order filters used here produce models with better prediction accuracy than the classical gammatone (<xref ref-type="supplementary-material" rid="pcbi.1004628.s001">S1 Table</xref>, [<xref ref-type="bibr" rid="pcbi.1004628.ref044">44</xref>]). However, it is likely that more detailed cochlear models would further improve performance [<xref ref-type="bibr" rid="pcbi.1004628.ref026">26</xref>].</p>
<p>To account for nonlinear level sensitivity in the auditory periphery, each spectrogram channel was then passed through a logarithmic compressor (LOG<italic>n</italic>), which required a single free parameter, <italic>ϕ</italic><sub>1</sub>, that determined the amount of compression,
<disp-formula id="pcbi.1004628.e015"><alternatives><graphic id="pcbi.1004628.e015g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004628.e015" xlink:type="simple"/><mml:math display="block" id="M15"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi mathvariant="bold">y</mml:mi> <mml:mrow><mml:mtext>LOG</mml:mtext> <mml:mi>n</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo form="prefix">log</mml:mo> <mml:mfenced close=")" open="(" separators=""><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msub><mml:mi>ϕ</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:mfenced></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(13)</label></disp-formula>
The gammatone filterbank itself did not require any additional free parameters for model estimation.</p>
</sec>
<sec id="sec034">
<title>Linear filter</title>
<p>The core of STRF models is the linear filter that performs a weighted sum of the spectrogram over frequency and time (<xref ref-type="fig" rid="pcbi.1004628.g003">Fig 3</xref>, [<xref ref-type="bibr" rid="pcbi.1004628.ref008">8</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref009">9</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref011">11</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref012">12</xref>]). The details of the different formulations used in the current study are provided in the Results.</p>
</sec>
<sec id="sec035">
<title>Output nonlinearity</title>
<p>After linear filtering, a static sigmoid nonlinearity produced a prediction of instantaneous spike rate that accounted for spike threshold and saturation. The spike nonlinearity was modeled as a double-exponential (DEXP) and required four parameters, <italic>ϕ</italic><sub>1 − 4</sub>,
<disp-formula id="pcbi.1004628.e016"><alternatives><graphic id="pcbi.1004628.e016g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004628.e016" xlink:type="simple"/><mml:math display="block" id="M16"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi mathvariant="bold">y</mml:mi> <mml:mtext>DEXP</mml:mtext></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msub><mml:mi>ϕ</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>ϕ</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:msub><mml:mi>ϕ</mml:mi> <mml:mn>3</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:msub><mml:mi>ϕ</mml:mi> <mml:mn>4</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(14)</label></disp-formula>
As in the case of the cochlear model, a large number of alternative spike nonlinearities are possible [<xref ref-type="bibr" rid="pcbi.1004628.ref013">13</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref017">17</xref>]. Our priority for the current study was to keep the output nonlinearity constant across all variants tested for the linear filter. The double-exponential performed as well as other sigmoid functions and proved consistently stable in the fitting algorithm used here. A complete list of output nonlinearities tested is included in <xref ref-type="supplementary-material" rid="pcbi.1004628.s001">S1 Table</xref>.</p>
</sec>
<sec id="sec036">
<title>Nonlinear short-term plasticity (STP)</title>
<p>To test performance of a nonlinear architecture with theoretically broader explanatory power than the linear STRF, we incorporated a new module prior to the temporal filtering module (<xref ref-type="fig" rid="pcbi.1004628.g001">Fig 1F</xref>). Each spectral channel (either output from the cochlear filterbank or from a spectral filterbank), provided input into a simulated synapse that could undergo either depression or facilitation [<xref ref-type="bibr" rid="pcbi.1004628.ref030">30</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref052">52</xref>]. In this simple model, the number of presynaptic vesicles available for release is dictated by the fraction of vesicles released by previous stimulation, <italic>ν</italic>, and a recovery time constant, <italic>τ</italic>. For depression, <italic>ν</italic> &gt; 0, and the fraction of available vesicles, <italic>d</italic>(<italic>t</italic>), is updated,
<disp-formula id="pcbi.1004628.e017"><alternatives><graphic id="pcbi.1004628.e017g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004628.e017" xlink:type="simple"/><mml:math display="block" id="M17"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>d</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msub><mml:mi>d</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:mi>ν</mml:mi> <mml:msub><mml:mi>s</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:msub><mml:mi>d</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mfrac><mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>d</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mi>τ</mml:mi></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(15)</label></disp-formula>
For facilitation, <italic>ν</italic> &lt; 0, and <italic>d</italic>(<italic>t</italic>) is updated,
<disp-formula id="pcbi.1004628.e018"><alternatives><graphic id="pcbi.1004628.e018g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004628.e018" xlink:type="simple"/><mml:math display="block" id="M18"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>d</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msub><mml:mi>d</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:mi>ν</mml:mi> <mml:msub><mml:mi>s</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>[</mml:mo> <mml:mn>2</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>d</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mfrac><mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>d</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mi>τ</mml:mi></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(16)</label></disp-formula>
The input to the synapse is scaled by the fraction of available vesicles and output to the next module,
<disp-formula id="pcbi.1004628.e019"><alternatives><graphic id="pcbi.1004628.e019g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004628.e019" xlink:type="simple"/><mml:math display="block" id="M19"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>s</mml:mi> <mml:mrow><mml:mi>d</mml:mi> <mml:mi>i</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msub><mml:mi>d</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msub><mml:mi>s</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(17)</label></disp-formula></p>
</sec>
</sec>
<sec id="sec037">
<title>Model estimation and validation</title>
<p>For most models, stimulus and response data were binned at 10 ms (100 Hz) and averaged across repetitions. Stimulus binning was applied after transformation to the spectrogram.</p>
<p>Data recorded from each neuron were divided into two subsets, one used only for model estimation (4–6 repetitions of 40 3-sec vocalization sequences) and the other for validation (20 repetitions of 2 3-sec sequences). Model parameters were fit using an iterated, greedy version of boosting that minimized mean-squared error prediction of the neural PSTH in the estimation dataset (details below). Each model was then evaluated based on its ability to predict the time-varying PSTH response in the reserved validation data set. Prediction accuracy was measured as the correlation coefficient (Pearson’s <italic>R</italic>) between the predicted and observed PSTH [<xref ref-type="bibr" rid="pcbi.1004628.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref034">34</xref>]. The correlation coefficient provides a useful metric because it scales performance between 0 (completely random) and 1 (perfect correlation). Model performance can be variable across single neurons. Thus to compare models we focused on average performance across the entire set of neurons studied, using the nonparametric Wilcoxon signed rank test (sign test) to assess significant differences in performance. Error bars for average prediction correlation plots were computed on the difference between prediction correlation for each model and the FIR STRF fit to the same neuron. Computing error bars based on the difference per neuron removed variability in overall neural response SNR (<italic>e.g.</italic>, Figs <xref ref-type="fig" rid="pcbi.1004628.g004">4A</xref> and <xref ref-type="fig" rid="pcbi.1004628.g010">10B</xref>) and revealed model differences commensurate with the sign test.</p>
<sec id="sec038">
<title>Signal-to-noise ratio (SNR) of neural sensory responses</title>
<p>Because neural responses vary across repeated stimulus presentations, some fit error resulted from uncertainty in the response in the estimation data set [<xref ref-type="bibr" rid="pcbi.1004628.ref022">22</xref>]. Therefore, we evaluated the repeatability of each neuron’s response by computing a signal-to-noise ratio. We assume that the neural noise is additive so that the response for trial <italic>i</italic>, is
<disp-formula id="pcbi.1004628.e020"><alternatives><graphic id="pcbi.1004628.e020g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004628.e020" xlink:type="simple"/><mml:math display="block" id="M20"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>r</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mtext>actual</mml:mtext></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msub><mml:mi>ϵ</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(18)</label></disp-formula>
and the total response variance is the sum of the actual response and noise variance, <inline-formula id="pcbi.1004628.e021"><alternatives><graphic id="pcbi.1004628.e021g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004628.e021" xlink:type="simple"/><mml:math display="inline" id="M21"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>r</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>=</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mtext>actual</mml:mtext> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>ϵ</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>. Total variance is measured as the autocovariance of the single trial response averaged across trials,
<disp-formula id="pcbi.1004628.e022"><alternatives><graphic id="pcbi.1004628.e022g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004628.e022" xlink:type="simple"/><mml:math display="block" id="M22"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>r</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>=</mml:mo> <mml:msub><mml:mrow><mml:mo>〈</mml:mo> <mml:mtext>cov</mml:mtext> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>〉</mml:mo></mml:mrow> <mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(19)</label></disp-formula>
Because <italic>ϵ</italic><sub><italic>i</italic></sub> is uncorrelated between trials, the actual response variance is the covariance between trials,
<disp-formula id="pcbi.1004628.e023"><alternatives><graphic id="pcbi.1004628.e023g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004628.e023" xlink:type="simple"/><mml:math display="block" id="M23"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mtext>actual</mml:mtext> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>=</mml:mo> <mml:msub><mml:mrow><mml:mo>〈</mml:mo> <mml:mtext>cov</mml:mtext> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>〉</mml:mo></mml:mrow> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>≠</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(20)</label></disp-formula>
and SNR is the ratio of actual response variance to noise variance,
<disp-formula id="pcbi.1004628.e024"><alternatives><graphic id="pcbi.1004628.e024g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004628.e024" xlink:type="simple"/><mml:math display="block" id="M24"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtext>SNR</mml:mtext> <mml:mo>=</mml:mo> <mml:mfrac><mml:msubsup><mml:mi>σ</mml:mi> <mml:mtext>actual</mml:mtext> <mml:mn>2</mml:mn></mml:msubsup> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>ϵ</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mfrac> <mml:mo>=</mml:mo> <mml:mfrac><mml:msubsup><mml:mi>σ</mml:mi> <mml:mtext>actual</mml:mtext> <mml:mn>2</mml:mn></mml:msubsup> <mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>r</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mtext>actual</mml:mtext> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(21)</label></disp-formula>
This simple statistic correlates strongly with how well the estimation set data can be described by linear models, and provides a means for ranking neurons according to how well they can be modeled (<xref ref-type="fig" rid="pcbi.1004628.g010">Fig 10</xref>).</p>
<p>Although we included the entire set of 176 neurons in most comparisons of prediction accuracy, we excluded a subset with SNR &lt; 0.005 (leaving 124 high-SNR neurons) for the analysis of asymptotic behavior (<xref ref-type="fig" rid="pcbi.1004628.g008">Fig 8</xref>) and tuning properties (<xref ref-type="fig" rid="pcbi.1004628.g012">Fig 12</xref>).</p>
</sec>
<sec id="sec039">
<title>Prediction correlation adjusted for finite sampling of validation data</title>
<p>The validation PSTH is also susceptible to noise from finite sampling, and the practical limit on the correlation coefficient is less than the ideal value of 1.0. The effect of this non-predictable variability can be compensated for by normalizing the measured correlation coefficient by the trial-to-trial response correlation (TTRC) [<xref ref-type="bibr" rid="pcbi.1004628.ref045">45</xref>]. If we define TTRC as the mean correlation coefficient (Pearson’s <italic>R</italic>) between all unique trial pairs, <italic>i</italic> ≠ <italic>j</italic>,
<disp-formula id="pcbi.1004628.e025"><alternatives><graphic id="pcbi.1004628.e025g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004628.e025" xlink:type="simple"/><mml:math display="block" id="M25"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtext>TTRC</mml:mtext> <mml:mo>=</mml:mo> <mml:msub><mml:mrow><mml:mo>〈</mml:mo> <mml:mtext>corr</mml:mtext> <mml:mfenced close=")" open="(" separators=""><mml:msub><mml:mi>r</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mfenced> <mml:mo>〉</mml:mo></mml:mrow> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>,</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(22)</label></disp-formula>
then the corrected prediction correlation is the mean correlation between the predicted and the single-trial actual response, normalized by the TTRC,
<disp-formula id="pcbi.1004628.e026"><alternatives><graphic id="pcbi.1004628.e026g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004628.e026" xlink:type="simple"/><mml:math display="block" id="M26"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>ρ</mml:mi> <mml:mtext>norm</mml:mtext></mml:msub> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:msqrt><mml:mrow><mml:mi>T</mml:mi> <mml:mi>T</mml:mi> <mml:mi>R</mml:mi> <mml:mi>C</mml:mi></mml:mrow></mml:msqrt></mml:mfrac> <mml:msub><mml:mrow><mml:mo>〈</mml:mo> <mml:mtext>corr</mml:mtext> <mml:mfenced close=")" open="(" separators=""><mml:msub><mml:mi>r</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mi>p</mml:mi></mml:mfenced> <mml:mo>〉</mml:mo></mml:mrow> <mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(23)</label></disp-formula>
For very small TTRC or for small number of repetitions, this approximation can be unstable, but for the 20-repetition validation datasets in the current study, this approximation was stable, adjusting prediction scores by 3–39% (mean 20%). Importantly, applying this correction allowed for accurate measures of prediction accuracy, but it had no impact on relative model performance, as it was computed independent of the model fit.</p>
</sec>
<sec id="sec040">
<title>Prediction correlation adjusted for finite sampling of estimation data</title>
<p>To account for prediction error resulting from finite sampling of estimation data, we adapted a technique applied to the visual system for linear FIR STRFs [<xref ref-type="bibr" rid="pcbi.1004628.ref018">18</xref>]. We treated the observed neural activity as the sum of three components,
<disp-formula id="pcbi.1004628.e027"><alternatives><graphic id="pcbi.1004628.e027g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004628.e027" xlink:type="simple"/><mml:math display="block" id="M27"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>r</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mtext>lin</mml:mtext></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mtext>res</mml:mtext></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msub><mml:mi>ϵ</mml:mi> <mml:mi>r</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(24)</label></disp-formula>
where <italic>r</italic><sub>lin</sub> is the portion of stimulus-dependent activity that can be explained by the current model architecture, with optimal STRF estimate <bold>H</bold><sub>lin</sub>, <italic>r</italic><sub>res</sub> is the residual stimulus-dependent portion that cannot be explained by the model, and <italic>ϵ</italic><sub><italic>r</italic></sub> is stimulus-independent activity that produces trial-to-trial variability. The components <italic>r</italic><sub>res</sub> and <italic>ϵ</italic><sub><italic>r</italic></sub> cannot be predicted by the current model architecture, <bold>H</bold><sub>lin</sub>. Thus they should have no impact on optimal model estimates and should not be correlated with <italic>r</italic><sub>lin</sub> in the limit of infinite data. However, for finite data, they can be correlated with stimuli by chance, introducing error in the STRF estimate, <bold>H</bold><sub>est</sub> = <bold>H</bold><sub>lin</sub> + <bold>H</bold><sub>err</sub>, and subsequent error in STRF predictions,
<disp-formula id="pcbi.1004628.e028"><alternatives><graphic id="pcbi.1004628.e028g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004628.e028" xlink:type="simple"/><mml:math display="block" id="M28"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mtext>lin</mml:mtext></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msub><mml:mi>ϵ</mml:mi> <mml:mi>p</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(25)</label></disp-formula></p>
<p>Given this formulation of the observed and predicted response, the squared prediction correlation is
<disp-formula id="pcbi.1004628.e029"><alternatives><graphic id="pcbi.1004628.e029g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004628.e029" xlink:type="simple"/><mml:math display="block" id="M29"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi>R</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mo>=</mml:mo> <mml:mfrac><mml:msup><mml:mrow><mml:mo>〈</mml:mo> <mml:mi>r</mml:mi> <mml:mi>p</mml:mi> <mml:mo>〉</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mrow><mml:mrow><mml:mo>〈</mml:mo> <mml:msup><mml:mi>r</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mo>〉</mml:mo></mml:mrow> <mml:mrow><mml:mo>〈</mml:mo> <mml:msup><mml:mi>p</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mo>〉</mml:mo></mml:mrow></mml:mrow></mml:mfrac> <mml:mo>=</mml:mo> <mml:mfrac><mml:msup><mml:mrow><mml:mo>〈</mml:mo> <mml:mfenced close=")" open="(" separators=""><mml:msub><mml:mi>r</mml:mi> <mml:mtext>lin</mml:mtext></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>ϵ</mml:mi> <mml:mi>p</mml:mi></mml:msub></mml:mfenced> <mml:mfenced close=")" open="(" separators=""><mml:msub><mml:mi>r</mml:mi> <mml:mtext>lin</mml:mtext></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mtext>res</mml:mtext></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>ϵ</mml:mi> <mml:mi>r</mml:mi></mml:msub></mml:mfenced> <mml:mo>〉</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mrow><mml:mrow><mml:mo>〈</mml:mo> <mml:msup><mml:mrow><mml:mfenced close=")" open="(" separators=""><mml:msub><mml:mi>r</mml:mi> <mml:mtext>lin</mml:mtext></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>ϵ</mml:mi> <mml:mi>p</mml:mi></mml:msub></mml:mfenced></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mo>〉</mml:mo></mml:mrow> <mml:mrow><mml:mo>〈</mml:mo> <mml:msup><mml:mrow><mml:mfenced close=")" open="(" separators=""><mml:msub><mml:mi>r</mml:mi> <mml:mtext>lin</mml:mtext></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mtext>res</mml:mtext></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>ϵ</mml:mi> <mml:mi>r</mml:mi></mml:msub></mml:mfenced></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mo>〉</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(26)</label></disp-formula>
Angled brackets, 〈…〉, indicate taking the mean over time. For simplicity, we omit <italic>t</italic> from each term and assume the individual signals have mean zero (subtracting the mean from each signal has no impact on prediction correlation). If we then assume that error in the validation data, <italic>ϵ</italic><sub><italic>r</italic></sub>, is zero (having been accounted for by <xref ref-type="disp-formula" rid="pcbi.1004628.e026">Eq 23</xref>) and that correlations between <italic>r</italic><sub>lin</sub>, <italic>r</italic><sub>res</sub>, and <italic>ϵ</italic><sub><italic>p</italic></sub> are negligible (because noise is additive), then the experimentally measured prediction correlation reduces to,
<disp-formula id="pcbi.1004628.e030"><alternatives><graphic id="pcbi.1004628.e030g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004628.e030" xlink:type="simple"/><mml:math display="block" id="M30"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi>R</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mo>〈</mml:mo> <mml:msubsup><mml:mi>r</mml:mi> <mml:mtext>lin</mml:mtext> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>〉</mml:mo></mml:mrow> <mml:mrow><mml:mrow><mml:mo>〈</mml:mo> <mml:msubsup><mml:mi>r</mml:mi> <mml:mtext>lin</mml:mtext> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>〉</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mrow><mml:mo>〈</mml:mo> <mml:msubsup><mml:mi>r</mml:mi> <mml:mtext>res</mml:mtext> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>〉</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mrow><mml:mo>〈</mml:mo> <mml:msubsup><mml:mi>ϵ</mml:mi> <mml:mi>p</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>〉</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(27)</label></disp-formula></p>
<p>For linear STRFs estimated by reverse correlation, variance of the prediction error decreases proportionally to the number of samples used for model estimation, <italic>T</italic> [<xref ref-type="bibr" rid="pcbi.1004628.ref018">18</xref>],
<disp-formula id="pcbi.1004628.e031"><alternatives><graphic id="pcbi.1004628.e031g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004628.e031" xlink:type="simple"/><mml:math display="block" id="M31"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mrow><mml:mo>〈</mml:mo> <mml:msubsup><mml:mi>ϵ</mml:mi> <mml:mrow><mml:mi>p</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>〉</mml:mo></mml:mrow> <mml:mo>∝</mml:mo> <mml:msup><mml:mrow><mml:mo>∥</mml:mo> <mml:msub><mml:mi mathvariant="bold">H</mml:mi> <mml:mtext>err</mml:mtext></mml:msub> <mml:mo>∥</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mo>∝</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>T</mml:mi></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(28)</label></disp-formula>
STRFs estimated by boosting show a similar dependence on estimation dataset size [<xref ref-type="bibr" rid="pcbi.1004628.ref034">34</xref>]. For data set size <italic>T</italic>, prediction correlation is then
<disp-formula id="pcbi.1004628.e032"><alternatives><graphic id="pcbi.1004628.e032g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004628.e032" xlink:type="simple"/><mml:math display="block" id="M32"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mi>R</mml:mi> <mml:mi>T</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mo>〈</mml:mo> <mml:msubsup><mml:mi>r</mml:mi> <mml:mtext>lin</mml:mtext> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>〉</mml:mo></mml:mrow> <mml:mrow><mml:mrow><mml:mo>〈</mml:mo> <mml:msubsup><mml:mi>r</mml:mi> <mml:mtext>lin</mml:mtext> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>〉</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mrow><mml:mo>〈</mml:mo> <mml:msubsup><mml:mi>r</mml:mi> <mml:mtext>res</mml:mtext> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>〉</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mi>A</mml:mi> <mml:mo>/</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(29)</label></disp-formula>
where <italic>A</italic> is a constant reflecting the response signal-to-noise level of the neuron. As <italic>T</italic> approaches infinity, the noise term disappears leaving the prediction correlation for the optimal linear model in the absence of noise,
<disp-formula id="pcbi.1004628.e033"><alternatives><graphic id="pcbi.1004628.e033g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004628.e033" xlink:type="simple"/><mml:math display="block" id="M33"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mi>R</mml:mi> <mml:mrow><mml:mtext>inf</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mo>〈</mml:mo> <mml:msubsup><mml:mi>r</mml:mi> <mml:mtext>lin</mml:mtext> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>〉</mml:mo></mml:mrow> <mml:mrow><mml:mrow><mml:mo>〈</mml:mo> <mml:msubsup><mml:mi>r</mml:mi> <mml:mtext>lin</mml:mtext> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>〉</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mrow><mml:mo>〈</mml:mo> <mml:msubsup><mml:mi>r</mml:mi> <mml:mtext>res</mml:mtext> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>〉</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(30)</label></disp-formula>
Substituting <xref ref-type="disp-formula" rid="pcbi.1004628.e033">Eq 30</xref> into <xref ref-type="disp-formula" rid="pcbi.1004628.e032">Eq 29</xref> produces a model for the impact of estimation sampling on prediction correlation [<xref ref-type="bibr" rid="pcbi.1004628.ref018">18</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref045">45</xref>],
<disp-formula id="pcbi.1004628.e034"><alternatives><graphic id="pcbi.1004628.e034g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004628.e034" xlink:type="simple"/><mml:math display="block" id="M34"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn> <mml:msubsup><mml:mi>R</mml:mi> <mml:mi>T</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mfrac> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:msubsup><mml:mi>R</mml:mi> <mml:mrow><mml:mtext>inf</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mfrac> <mml:mo>-</mml:mo> <mml:mfrac><mml:mi>A</mml:mi> <mml:mi>T</mml:mi></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(31)</label></disp-formula>
We measured prediction correlation, <italic>R</italic><sub><italic>T</italic></sub>, for models estimated using variable sample set sizes <italic>T</italic>, and fit <xref ref-type="disp-formula" rid="pcbi.1004628.e034">eq 31</xref> to determine the limit on prediction correlation for infinite data, <italic>R</italic><sub>inf</sub>. Although estimation noise is not likely to be completely additive, this model provides a good fit to the data (see <xref ref-type="fig" rid="pcbi.1004628.g008">Fig 8</xref>).</p>
</sec>
</sec>
<sec id="sec041">
<title>Fitting algorithm</title>
<p>Our goal was to compare the ability of different analytical model structures to describe the neural data. Ideally, the details of the fitting algorithm used to fit the different models should not be relevant to this comparison, but in practice, there is no single algorithm that can be applied to different models without some bias [<xref ref-type="bibr" rid="pcbi.1004628.ref001">1</xref>]. Thus, the best fitting algorithm and model analytical structures are not separable in practice. We tested a variety of fit algorithms (<xref ref-type="fig" rid="pcbi.1004628.g002">Fig 2</xref>, <xref ref-type="supplementary-material" rid="pcbi.1004628.s001">S1 Table</xref>), but we focused on a single algorithm that performed best, on average, across all the models tested.</p>
<p>The fit algorithm consisted of nested iterations through each STRF module, initially optimizing each module with a conservative stop criterion. Once all modules had converged for the current stop criterion, its value was reduced and procedure was repeated for the smaller criterion. When fitting each module, two different coordinate descent algorithms were used. For non-parameterized modules (FIR filter, factorized spectral filter, and factorized temporal filter), a standard coordinate descent algorithm was used. For the remaining, parameterized modules (including the input filterbank and spike nonlinearities), greedy coordinate descent was used. The details of the fit algorithm are as follows:</p>
<list list-type="order">
<list-item>
<p>Remove the spike nonlinearity module.</p>
</list-item>
<list-item>
<p>Set initial stop criterion to <italic>ϵ</italic> = 10<sup>−3</sup> (NMSE cost function ranges from 0 to 1, see below).</p>
</list-item>
<list-item>
<p>For each module,</p>
<list list-type="alpha-lower">
<list-item>
<p>If module is non-parameterized, use non-greedy coordinate descent:</p>
<list list-type="roman-lower">
<list-item>
<p>Set initial step size for all parameters to <italic>δ</italic> = 1</p>
</list-item>
<list-item>
<p>For each parameter <italic>ϕ</italic><sub><italic>i</italic></sub> ∈ {<italic>ϕ</italic><sub>1</sub>, <italic>ϕ</italic><sub>2</sub>, …}, evaluate the cost function for <italic>ϕ</italic><sub><italic>i</italic></sub> + <italic>δ</italic> and <italic>ϕ</italic><sub><italic>i</italic></sub> − <italic>δ</italic></p>
</list-item>
<list-item>
<p>If no step improves performance, reduce <italic>δ</italic> by 50%.</p>
</list-item>
<list-item>
<p>If any step improves performance, update the parameter that decreases the cost function the most by <italic>δ</italic> and increase <italic>δ</italic> by 10%.</p>
</list-item>
<list-item>
<p>If improvement in cost function &gt; <italic>ϵ</italic>, <italic>δ</italic> &gt; 10<sup>−6</sup>, and fewer than 10 steps have been taken, repeat iteration for this module.</p>
</list-item>
</list>
</list-item>
<list-item>
<p>If module is parameterized, use greedy coordinate descent:</p>
<list list-type="roman-lower">
<list-item>
<p>Set initial step size for each parameter to <italic>δ</italic><sub><italic>i</italic></sub> = 1</p>
</list-item>
<list-item>
<p>For each parameter <italic>ϕ</italic><sub><italic>i</italic></sub> ∈ {<italic>ϕ</italic><sub>1</sub>, <italic>ϕ</italic><sub>2</sub>, …},</p>
<list list-type="simple">
<list-item>
<label>A</label> <p>Evaluate the cost function for <italic>ϕ</italic><sub><italic>i</italic></sub> + <italic>δ</italic><sub><italic>i</italic></sub> and <italic>ϕ</italic><sub><italic>i</italic></sub> − <italic>δ</italic><sub><italic>i</italic></sub></p>
</list-item>
<list-item>
<label>B</label> <p>If neither step improves the cost function, reduce <italic>δ</italic> by 50%.</p>
</list-item>
<list-item>
<label>C</label> <p>If the step helped, update <italic>ϕ</italic><sub><italic>i</italic></sub> by <italic>δ</italic><sub><italic>i</italic></sub> and increase <italic>δ</italic><sub><italic>i</italic></sub> by 10%.</p>
</list-item>
<list-item>
<label>D</label> <p>If improvement in cost function &gt;<italic>ϵ</italic>, <italic>δ</italic><sub><italic>i</italic></sub> &gt; 10<sup>−6</sup>, and fewer than 10 steps have been taken, repeat iteration for this parameter.</p>
</list-item>
</list>
</list-item>
</list>
</list-item>
</list>
</list-item>
<list-item>
<p>After all modules cease to show cost function improvements &gt; <italic>ϵ</italic>, decrease <italic>ϵ</italic> by 30%.</p>
</list-item>
<list-item>
<p>If <italic>ϵ</italic> &gt; 10<sup>−4</sup> (without spike nonlinearity) or <italic>ϵ</italic> &gt; 10<sup>−6</sup> (with spike nonlinearity), iterate through modules again.</p>
</list-item>
<list-item>
<p>Replace spike nonlinearity and repeat all of the above, starting with step 2.</p>
</list-item>
</list>
<p specific-use="continuation">In general, we found that fitting parameters separately within modules and iterating through modules with progressively smaller stop criteria helped avoid local minima. Fitting first without the spike nonlinearity also helped avoid local minima. The greedy algorithm increased the risk of overfitting complex models, but on average greatly improved predictions for models with nonlinear and parameterized modules. The non-greedy algorithm worked best for non-parameterized modules where all parameters are of similar scale.</p>
<sec id="sec042">
<title>Normalized mean squared error (NMSE)</title>
<p>Model parameters were optimized by minimizing a cost function based on normalized mean squared error (NMSE) between the predicted and actual neural response. For a time-varying response, <italic>r</italic>(<italic>t</italic>), averaged across repetitions of the same stimulus (mean over time, <inline-formula id="pcbi.1004628.e035"><alternatives><graphic id="pcbi.1004628.e035g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004628.e035" xlink:type="simple"/><mml:math display="inline" id="M35"><mml:mover accent="true"><mml:mi>r</mml:mi> <mml:mo>¯</mml:mo></mml:mover></mml:math></alternatives></inline-formula>), and corresponding predicted response, <italic>p</italic>(<italic>t</italic>), the NMSE is,
<disp-formula id="pcbi.1004628.e036"><alternatives><graphic id="pcbi.1004628.e036g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004628.e036" xlink:type="simple"/><mml:math display="block" id="M36"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>e</mml:mi> <mml:mtext>MSE</mml:mtext></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>p</mml:mi> <mml:mo>,</mml:mo> <mml:mi>r</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>T</mml:mi></mml:msubsup> <mml:msup><mml:mrow><mml:mfenced close=")" open="(" separators=""><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo> <mml:mo>-</mml:mo> <mml:mi>r</mml:mi> <mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mfenced></mml:mrow> <mml:mn>2</mml:mn></mml:msup></mml:mrow> <mml:mrow><mml:msubsup><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>T</mml:mi></mml:msubsup> <mml:msup><mml:mrow><mml:mfenced close=")" open="(" separators=""><mml:mi>r</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:mover accent="true"><mml:mi>r</mml:mi> <mml:mo>¯</mml:mo></mml:mover></mml:mfenced></mml:mrow> <mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(32)</label></disp-formula>
A value of <italic>e</italic><sub>MSE</sub> = 1 indicates a random prediction, <italic>e</italic><sub>MSE</sub> = 0 indicates a perfect prediction. To reduce overfitting to noise, a shrinkage factor was applied to the NMSE [<xref ref-type="bibr" rid="pcbi.1004628.ref018">18</xref>]. Shrinkage scaled the NMSE according to its reliability across the estimation dataset. Standard error on the NMSE, <italic>σ</italic><sub>MSE</sub>, was computed by a 10-fold jackknife [<xref ref-type="bibr" rid="pcbi.1004628.ref079">79</xref>]. The final NMSE was then scaled according to reliability,
<disp-formula id="pcbi.1004628.e037"><alternatives><graphic id="pcbi.1004628.e037g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004628.e037" xlink:type="simple"/><mml:math display="block" id="M37"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>e</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>p</mml:mi> <mml:mo>,</mml:mo> <mml:mi>r</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mfenced close="]" open="[" separators=""><mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>e</mml:mi> <mml:mtext>MSE</mml:mtext></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:msup><mml:mfenced close="|" open="|" separators=""><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msup><mml:mfenced close=")" open="(" separators=""><mml:mfrac><mml:msub><mml:mi>σ</mml:mi> <mml:mtext>MSE</mml:mtext></mml:msub> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>e</mml:mi> <mml:mtext>MSE</mml:mtext></mml:msub></mml:mrow></mml:mfrac></mml:mfenced> <mml:mn>2</mml:mn></mml:msup></mml:mfenced> <mml:mo>+</mml:mo></mml:msup></mml:mfenced></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(33)</label></disp-formula>
where |⋯|<sup>+</sup> indicates positive rectification. Thus if <italic>σ</italic><sub>MSE</sub> &gt; &gt;(1 − <italic>e</italic><sub>MSE</sub>), <italic>e</italic> was shrunk toward a value of 1 (<italic>i.e.</italic>, less improvement in prediction).</p>
<p>For linear systems with Gaussian noise, the NMSE is equivalent to Bayesian maximum likelihood (ML) optimization. Because noise in neural systems is non-Gaussian, alternative error metrics have been proposed, such as those based on a Poisson noise model [<xref ref-type="bibr" rid="pcbi.1004628.ref015">15</xref>] or mutual information [<xref ref-type="bibr" rid="pcbi.1004628.ref057">57</xref>]. Changing the cost function affected relative model performance for individual neurons, but we did not observe any systematic effect of alternative metrics across the dataset <xref ref-type="fig" rid="pcbi.1004628.g013">Fig 13</xref>. Other datasets may be more sensitive to the specific cost function used, but we chose to use the NMSE here for its efficiency and relative stability.</p>
</sec>
<sec id="sec043">
<title>Signal normalization</title>
<p>Not shown in <xref ref-type="fig" rid="pcbi.1004628.g001">Fig 1B</xref> are signal normalization computations, which occur inside each arrow connecting modules. Normalization prevents signals from taking arbitrarily high values and is thus helpful to avoid numerical issues during fitting. If <italic>x</italic><sub><italic>i</italic></sub>(<italic>t</italic>) is the <italic>i</italic>th input, then <italic>y</italic><sub><italic>i</italic></sub>(<italic>t</italic>) is the positive-definite output from the normalization module,
<disp-formula id="pcbi.1004628.e038"><alternatives><graphic id="pcbi.1004628.e038g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004628.e038" xlink:type="simple"/><mml:math display="block" id="M38"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mi>μ</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn> <mml:mi>N</mml:mi></mml:mfrac> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>T</mml:mi></mml:munderover> <mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(34)</label></disp-formula> <disp-formula id="pcbi.1004628.e039"><alternatives><graphic id="pcbi.1004628.e039g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004628.e039" xlink:type="simple"/><mml:math display="block" id="M39"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mi>σ</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:msqrt><mml:mrow><mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mi>N</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:mfrac> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>T</mml:mi></mml:munderover> <mml:msup><mml:mrow><mml:mfenced close=")" open="(" separators=""><mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:msub><mml:mi>μ</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow> <mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msqrt></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(35)</label></disp-formula> <disp-formula id="pcbi.1004628.e040"><alternatives><graphic id="pcbi.1004628.e040g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004628.e040" xlink:type="simple"/><mml:math display="block" id="M40"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>m</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn> <mml:msub><mml:mi>σ</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:mfrac> <mml:mfenced close=")" open="(" separators=""><mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:mi>μ</mml:mi></mml:mfenced></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(36)</label></disp-formula> <disp-formula id="pcbi.1004628.e041"><alternatives><graphic id="pcbi.1004628.e041g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004628.e041" xlink:type="simple"/><mml:math display="block" id="M41"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mi>z</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo form="prefix" movablelimits="true">min</mml:mo> <mml:mo>(</mml:mo> <mml:msub><mml:mi>m</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>m</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:mo>.</mml:mo> <mml:mo>.</mml:mo> <mml:mo>.</mml:mo> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(37)</label></disp-formula> <disp-formula id="pcbi.1004628.e042"><alternatives><graphic id="pcbi.1004628.e042g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004628.e042" xlink:type="simple"/><mml:math display="block" id="M42"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>y</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn> <mml:msub><mml:mi>σ</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:mfrac> <mml:mfenced close=")" open="(" separators=""><mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(38)</label></disp-formula>
We normalized each channel by its mean power only over the estimation dataset and applied these same scaling terms to predictions on the validation set. This approach did not introduce additional free parameters to the final model, as the scaling terms could be merged post-hoc into other fit parameters. However, it provided substantial benefit to performance on the validation set.</p>
</sec>
<sec id="sec044">
<title>Fit algorithm performance</title>
<p>In the current study, we used a single fit algorithm in an attempt to simplify comparisons between different model architectures. It is likely that better fit algorithms exist, particularly for the FIR STRF, where careful regularization can significantly improve model performance [<xref ref-type="bibr" rid="pcbi.1004628.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1004628.ref034">34</xref>]. We tested several alternative regularization schemes on performance of the FIR STRF (<xref ref-type="fig" rid="pcbi.1004628.g014">Fig 14</xref>). Several of these alternatives produced improved performance over the standard algorithm used in this study (“shrinkage, 1e-6 stop”, defined above). Incorporating a stricter stop criterion (“1e-4 stop”), an L1 norm, or both into the cost function all produced similar improvements in performance, indicating that choosing a regularization scheme appropriate to the current model architecture is critical for optimizing performance. However, the parameterized model still performed slightly better than even the best alternative FIR STRF fits, consistent with our conclusion that the linear STRF can be approximated by a much lower dimensional architecture than the FIR STRF.</p>
<fig id="pcbi.1004628.g014" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004628.g014</object-id>
<label>Fig 14</label>
<caption>
<title>Impact of alternative regularization schemes on STRF performance.</title>
<p>Bar chart compares mean prediction correlation of FIR STRFs estimated using alternative regularization schemes (black) to that of parameterized STRFs estimated using the standard algorithm used for the main model comparison (“shrinkage, 1e-6 stop”). Incorporating a shrinkage factors on NMSE measures (“shrinkage”), early stopping (“1e-4 stop” versus “1e-6 stop”), and an L1 norm on parameter estimates (“L1 norm” [<xref ref-type="bibr" rid="pcbi.1004628.ref014">14</xref>]) all lead to improvements in performance. The parameterized STRF still maintains greater prediction accuracy than the best regularization scheme (“Shrinkage, 1e-4 stop”).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004628.g014" xlink:type="simple"/>
</fig>
</sec>
</sec>
<sec id="sec045">
<title>Ethics statement</title>
<p>Experimental procedures were approved by the Oregon Health and Science University Institutional Animal Care and Use Committee and conformed to standards of the National Institutes of Health.</p>
</sec>
</sec>
<sec id="sec046">
<title>Supporting Information</title>
<supplementary-material id="pcbi.1004628.s001" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004628.s001" xlink:type="simple">
<label>S1 Table</label>
<caption>
<title>Full list of models tested.</title>
<p>Summary of performance for 1061 formulations of the linear STRF (see <xref ref-type="fig" rid="pcbi.1004628.g002">Fig 2</xref>), averaged across the <italic>N</italic> = 176 A1 vocalization datasets. Each row indicates parameter count, fit performance (estimation data), test performance (validation data), and test performance after correcting for validation sampling limitations (<xref ref-type="disp-formula" rid="pcbi.1004628.e026">Eq 23</xref>) for a single model. The first 163 rows describe models detailed in this study, and the remainder are additional suboptimal models that were tested. The key on the first two pages indicates how to interpret model names.</p>
<p>(PDF)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>The authors wish to thank Henry Cooney, Brian Jones, and Daniela Saderi for assistance with data acquisition.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1004628.ref001">
<label>1</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Wu</surname> <given-names>MCK</given-names></name>, <name name-style="western"><surname>David</surname> <given-names>SV</given-names></name>, <name name-style="western"><surname>Gallant</surname> <given-names>JL</given-names></name>. <article-title>Complete functional characterization of sensory neurons by system identification</article-title>. <source>Annual Review of Neuroscience</source>. <year>2006</year>;<volume>29</volume>:<fpage>477</fpage>–<lpage>505</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1146/annurev.neuro.29.051605.113024" xlink:type="simple">10.1146/annurev.neuro.29.051605.113024</ext-link></comment> <object-id pub-id-type="pmid">16776594</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref002">
<label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Theunissen</surname> <given-names>FE</given-names></name>, <name name-style="western"><surname>Elie</surname> <given-names>JE</given-names></name>. <article-title>Neural processing of natural sounds</article-title>. <source>Nature Reviews Neuroscience</source>. <year>2014</year> <month>May</month>;<volume>15</volume>(<issue>6</issue>):<fpage>355</fpage>–<lpage>366</lpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://www.nature.com/nrn/journal/v15/n6/full/nrn3731.html?WT.ec_id=NRN-201406" xlink:type="simple">http://www.nature.com/nrn/journal/v15/n6/full/nrn3731.html?WT.ec_id=NRN-201406</ext-link>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nrn3731" xlink:type="simple">10.1038/nrn3731</ext-link></comment> <object-id pub-id-type="pmid">24840800</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref003">
<label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Eggermont</surname> <given-names>JJ</given-names></name>. <article-title>Wiener and Volterra analysis applied to the auditory system</article-title>. <source>Hearing Research</source>. <year>1993</year>;<volume>66</volume>:<fpage>177</fpage>–<lpage>201</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/0378-5955(93)90139-R" xlink:type="simple">10.1016/0378-5955(93)90139-R</ext-link></comment> <object-id pub-id-type="pmid">8509309</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref004">
<label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>DeCharms</surname> <given-names>RC</given-names></name>, <name name-style="western"><surname>Blake</surname> <given-names>DT</given-names></name>, <name name-style="western"><surname>Merzenich</surname> <given-names>MM</given-names></name>. <article-title>Optimizing sound features for cortical neurons</article-title>. <source>Science</source>. <year>1998</year>;<volume>280</volume>:<fpage>1439</fpage>–<lpage>1443</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.280.5368.1439" xlink:type="simple">10.1126/science.280.5368.1439</ext-link></comment> <object-id pub-id-type="pmid">9603734</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref005">
<label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Eggermont</surname> <given-names>JJ</given-names></name>, <name name-style="western"><surname>Munguia</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Pienkowski</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Shaw</surname> <given-names>G</given-names></name>. <article-title>Comparison of LFP-based and spike-based spectro-temporal receptive fields and cross-correlation in cat primary auditory cortex</article-title>. <source>PloS one</source>. <year>2011</year> <month>Jan</month>;<volume>6</volume>(<issue>5</issue>):<fpage>e20046</fpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3100317&amp;tool=pmcentrez&amp;rendertype=abstract" xlink:type="simple">http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3100317&amp;tool=pmcentrez&amp;rendertype=abstract</ext-link>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0020046" xlink:type="simple">10.1371/journal.pone.0020046</ext-link></comment> <object-id pub-id-type="pmid">21625385</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref006">
<label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Thomas</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Huber</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Stecker</surname> <given-names>GC</given-names></name>, <name name-style="western"><surname>Boynton</surname> <given-names>GM</given-names></name>, <name name-style="western"><surname>Saenz</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Fine</surname> <given-names>I</given-names></name>. <article-title>Population receptive field estimates of human auditory cortex</article-title>. <source>NeuroImage</source>. <year>2015</year> <month>Jan</month>;<volume>105</volume>:<fpage>428</fpage>–<lpage>39</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuroimage.2014.10.060" xlink:type="simple">10.1016/j.neuroimage.2014.10.060</ext-link></comment> <object-id pub-id-type="pmid">25449742</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref007">
<label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Varnet</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Knoblauch</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Meunier</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Hoen</surname> <given-names>M</given-names></name>. <article-title>Using auditory classification images for the identification of fine acoustic cues used in speech perception</article-title>. <source>Frontiers in human neuroscience</source>. <year>2013</year> <month>Jan</month>;<volume>7</volume>:<fpage>865</fpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3863756&amp;tool=pmcentrez&amp;rendertype=abstract" xlink:type="simple">http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3863756&amp;tool=pmcentrez&amp;rendertype=abstract</ext-link>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fnhum.2013.00865" xlink:type="simple">10.3389/fnhum.2013.00865</ext-link></comment> <object-id pub-id-type="pmid">24379774</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref008">
<label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Aertsen</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Johannesma</surname> <given-names>PI</given-names></name>. <article-title>The spectro-temporal receptive field. A functional characteristic of auditory neurons</article-title>. <source>Biol Cybern</source>. <year>1981</year>;<volume>42</volume>(<issue>2</issue>):<fpage>133</fpage>–<lpage>143</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/BF00336731" xlink:type="simple">10.1007/BF00336731</ext-link></comment> <object-id pub-id-type="pmid">7326288</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref009">
<label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>David</surname> <given-names>SV</given-names></name>, <name name-style="western"><surname>Mesgarani</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Fritz</surname> <given-names>JB</given-names></name>, <name name-style="western"><surname>Shamma</surname> <given-names>SA</given-names></name>. <article-title>Rapid synaptic depression explains nonlinear modulation of spectro-temporal tuning in primary auditory cortex by natural stimuli</article-title>. <source>Journal of Neuroscience</source>. <year>2009</year>;<volume>29</volume>(<issue>11</issue>):<fpage>3374</fpage>–<lpage>3386</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.5249-08.2009" xlink:type="simple">10.1523/JNEUROSCI.5249-08.2009</ext-link></comment> <object-id pub-id-type="pmid">19295144</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref010">
<label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Klein</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Depireux</surname> <given-names>DA</given-names></name>, <name name-style="western"><surname>Simon</surname> <given-names>JZ</given-names></name>, <name name-style="western"><surname>Shamma</surname> <given-names>SA</given-names></name>. <article-title>Robust spectrotemporal reverse correlation for the auditory system: Optimizing stimulus design</article-title>. <source>Journal of Computational Neuroscience</source>. <year>2000</year>;<volume>9</volume>:<fpage>85</fpage>–<lpage>111</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1023/A:1008990412183" xlink:type="simple">10.1023/A:1008990412183</ext-link></comment> <object-id pub-id-type="pmid">10946994</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref011">
<label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kowalski</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Depireux</surname> <given-names>DA</given-names></name>, <name name-style="western"><surname>Shamma</surname> <given-names>SA</given-names></name>. <article-title>Analysis of dynamic spectra in ferret primary auditory cortex. I. Characteristics of single-unit responses to moving ripple spectra</article-title>. <source>Journal of Neurophysiology</source>. <year>1996</year>;<volume>76</volume>(<issue>5</issue>):<fpage>3503</fpage>–<lpage>3523</lpage>. <object-id pub-id-type="pmid">8930289</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref012">
<label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Theunissen</surname> <given-names>FE</given-names></name>, <name name-style="western"><surname>David</surname> <given-names>SV</given-names></name>, <name name-style="western"><surname>Singh</surname> <given-names>NC</given-names></name>, <name name-style="western"><surname>Hsu</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Vinje</surname> <given-names>WE</given-names></name>, <name name-style="western"><surname>Gallant</surname> <given-names>JL</given-names></name>. <article-title>Estimating spatial temporal receptive fields of auditory and visual neurons from their responses to natural stimuli</article-title>. <source>Network: Computation in Neural Systems</source>. <year>2001</year>;<volume>12</volume>:<fpage>289</fpage>–<lpage>316</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1080/net.12.3.289.316" xlink:type="simple">10.1080/net.12.3.289.316</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref013">
<label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Atencio</surname> <given-names>CA</given-names></name>, <name name-style="western"><surname>Schreiner</surname> <given-names>CE</given-names></name>. <article-title>Spectrotemporal processing in spectral tuning modules of cat primary auditory cortex</article-title>. <source>PloS one</source>. <year>2012</year> <month>Jan</month>;<volume>7</volume>(<issue>2</issue>):<fpage>e31537</fpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3288040&amp;tool=pmcentrez&amp;rendertype=abstract" xlink:type="simple">http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3288040&amp;tool=pmcentrez&amp;rendertype=abstract</ext-link>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0031537" xlink:type="simple">10.1371/journal.pone.0031537</ext-link></comment> <object-id pub-id-type="pmid">22384036</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref014">
<label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Calabrese</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Schumacher</surname> <given-names>JW</given-names></name>, <name name-style="western"><surname>Schneider</surname> <given-names>DM</given-names></name>, <name name-style="western"><surname>Paninski</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Woolley</surname> <given-names>SMN</given-names></name>. <article-title>A generalized linear model for estimating spectrotemporal receptive fields from responses to natural sounds</article-title>. <source>PloS one</source>. <year>2011</year> <month>Jan</month>;<volume>6</volume>(<issue>1</issue>):<fpage>e16104</fpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3019175&amp;tool=pmcentrez&amp;rendertype=abstract" xlink:type="simple">http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3019175&amp;tool=pmcentrez&amp;rendertype=abstract</ext-link>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0016104" xlink:type="simple">10.1371/journal.pone.0016104</ext-link></comment> <object-id pub-id-type="pmid">21264310</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref015">
<label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Paninski</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Pillow</surname> <given-names>JW</given-names></name>, <name name-style="western"><surname>Simoncelli</surname> <given-names>EP</given-names></name>. <article-title>Maximum likelihood estimation of a stochastic integrate-and-fire neural encoding model</article-title>. <source>Neural computation</source>. <year>2004</year> <month>Dec</month>;<volume>16</volume>(<issue>12</issue>):<fpage>2533</fpage>–<lpage>61</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/0899766042321797" xlink:type="simple">10.1162/0899766042321797</ext-link></comment> <object-id pub-id-type="pmid">15516273</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref016">
<label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Jones</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Stepnoski</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Palmer</surname> <given-names>LA</given-names></name>. <article-title>The two-dimensional spectral structure of simple receptive fields in cat striate cortex</article-title>. <source>Journal of Neurophysiology</source>. <year>1987</year>;<volume>58</volume>(<issue>6</issue>):<fpage>1212</fpage>–<lpage>1232</lpage>. <object-id pub-id-type="pmid">3437331</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref017">
<label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Nykamp</surname> <given-names>DQ</given-names></name>, <name name-style="western"><surname>Ringach</surname> <given-names>DL</given-names></name>. <article-title>Full identification of a linear-nonlinear system via cross-correlation analysis</article-title>. <source>Journal of Vision</source>. <year>2002</year>;<volume>2</volume>:<fpage>1</fpage>–<lpage>11</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1167/2.1.1" xlink:type="simple">10.1167/2.1.1</ext-link></comment> <object-id pub-id-type="pmid">12678593</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref018">
<label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>David</surname> <given-names>SV</given-names></name>, <name name-style="western"><surname>Gallant</surname> <given-names>JL</given-names></name>. <article-title>Predicting neuronal responses during natural vision</article-title>. <source>Network</source>. <year>2005</year>;<volume>16</volume>(<issue>2–3</issue>):<fpage>239</fpage>–<lpage>260</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1080/09548980500464030" xlink:type="simple">10.1080/09548980500464030</ext-link></comment> <object-id pub-id-type="pmid">16411498</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref019">
<label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>DiCarlo</surname> <given-names>JJ</given-names></name>, <name name-style="western"><surname>Johnson</surname> <given-names>KO</given-names></name>, <name name-style="western"><surname>Hsiao</surname> <given-names>SS</given-names></name>. <article-title>Structure of receptive fields in area 3b of primary somatosensory cortex in the alert monkey</article-title>. <source>Journal of Neuroscience</source>. <year>1998</year>;<volume>18</volume>:<fpage>2626</fpage>–<lpage>2645</lpage>. <object-id pub-id-type="pmid">9502821</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref020">
<label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ramirez</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Pnevmatikakis</surname> <given-names>EA</given-names></name>, <name name-style="western"><surname>Merel</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Paninski</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Miller</surname> <given-names>KD</given-names></name>, <name name-style="western"><surname>Bruno</surname> <given-names>RM</given-names></name>. <article-title>Spatiotemporal receptive fields of barrel cortex revealed by reverse correlation of synaptic input</article-title>. <source>Nature neuroscience</source>. <year>2014</year> <month>May</month>;<volume>17</volume>(<issue>6</issue>):<fpage>866</fpage>–<lpage>875</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.3720" xlink:type="simple">10.1038/nn.3720</ext-link></comment> <object-id pub-id-type="pmid">24836076</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref021">
<label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Nagel</surname> <given-names>KI</given-names></name>, <name name-style="western"><surname>Wilson</surname> <given-names>RI</given-names></name>. <article-title>Biophysical mechanisms underlying olfactory receptor neuron dynamics</article-title>. <source>Nature Neuroscience</source>. <year>2011</year> <month>Feb</month>;<volume>14</volume>(<issue>2</issue>):<fpage>208</fpage>–<lpage>16</lpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3030680&amp;tool=pmcentrez&amp;rendertype=abstract" xlink:type="simple">http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3030680&amp;tool=pmcentrez&amp;rendertype=abstract</ext-link>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.2725" xlink:type="simple">10.1038/nn.2725</ext-link></comment> <object-id pub-id-type="pmid">21217763</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref022">
<label>22</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Sahani</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Linden</surname> <given-names>JF</given-names></name>. <chapter-title>How linear are auditory cortical responses?</chapter-title> In: <name name-style="western"><surname>Becker</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Thrun</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Obermayer</surname> <given-names>K</given-names></name>, editors. <source>Advances in Neural Information Processing Systems</source>. <volume>vol. 15</volume>. <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>; <year>2003</year>. p. <fpage>301</fpage>–<lpage>308</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004628.ref023">
<label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Machens</surname> <given-names>CK</given-names></name>, <name name-style="western"><surname>Wehr</surname> <given-names>MS</given-names></name>, <name name-style="western"><surname>Zador</surname> <given-names>AM</given-names></name>. <article-title>Linearity of cortical receptive fields measured with natural sounds</article-title>. <source>Journal of Neuroscience</source>. <year>2004</year>;<volume>24</volume>(<issue>5</issue>):<fpage>1089</fpage>–<lpage>1100</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.4445-03.2004" xlink:type="simple">10.1523/JNEUROSCI.4445-03.2004</ext-link></comment> <object-id pub-id-type="pmid">14762127</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref024">
<label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Atencio</surname> <given-names>CA</given-names></name>, <name name-style="western"><surname>Sharpee</surname> <given-names>TO</given-names></name>, <name name-style="western"><surname>Schreiner</surname> <given-names>CE</given-names></name>. <article-title>Receptive field dimensionality increases from the auditory midbrain to cortex</article-title>. <source>Journal of neurophysiology</source>. <year>2012</year> <month>May</month>;<volume>107</volume>(<issue>10</issue>):<fpage>2594</fpage>–<lpage>603</lpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3362274&amp;tool=pmcentrez&amp;rendertype=abstract" xlink:type="simple">http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3362274&amp;tool=pmcentrez&amp;rendertype=abstract</ext-link>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.01025.2011" xlink:type="simple">10.1152/jn.01025.2011</ext-link></comment> <object-id pub-id-type="pmid">22323634</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref025">
<label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ahrens</surname> <given-names>MB</given-names></name>, <name name-style="western"><surname>Paninski</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Sahani</surname> <given-names>M</given-names></name>. <article-title>Inferring input nonlinearities in neural encoding models</article-title>. <source>Network</source>. <year>2008</year>;<volume>19</volume>(<issue>1</issue>):<fpage>35</fpage>–<lpage>67</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1080/09548980701813936" xlink:type="simple">10.1080/09548980701813936</ext-link></comment> <object-id pub-id-type="pmid">18300178</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref026">
<label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gill</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Zhang</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Woolley</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Fremouw</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Theunissen</surname> <given-names>FE</given-names></name>. <article-title>Sound representation methods for spectro-temporal receptive field estimation</article-title>. <source>Journal of Computational Neuroscience</source>. <year>2006</year>;<volume>21</volume>(<issue>1</issue>):<fpage>5</fpage>–<lpage>20</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s10827-006-7059-4" xlink:type="simple">10.1007/s10827-006-7059-4</ext-link></comment> <object-id pub-id-type="pmid">16633939</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref027">
<label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Depireux</surname> <given-names>DA</given-names></name>, <name name-style="western"><surname>Dobbins</surname> <given-names>HD</given-names></name>, <name name-style="western"><surname>Marvit</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Shechter</surname> <given-names>B</given-names></name>. <article-title>Dynamics of phase-independent spectro-temporal tuning in primary auditory cortex of the awake ferret</article-title>. <source>Neuroscience</source>. <year>2012</year> <month>Jul</month>;<volume>214</volume>:<fpage>28</fpage>–<lpage>35</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuroscience.2012.04.029" xlink:type="simple">10.1016/j.neuroscience.2012.04.029</ext-link></comment> <object-id pub-id-type="pmid">22531376</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref028">
<label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Rabinowitz</surname> <given-names>NC</given-names></name>, <name name-style="western"><surname>Willmore</surname> <given-names>BDB</given-names></name>, <name name-style="western"><surname>Schnupp</surname> <given-names>JWH</given-names></name>, <name name-style="western"><surname>King</surname> <given-names>AJ</given-names></name>. <article-title>Spectrotemporal contrast kernels for neurons in primary auditory cortex</article-title>. <source>Journal of Neuroscience</source>. <year>2012</year> <month>Aug</month>;<volume>32</volume>(<issue>33</issue>):<fpage>11271</fpage>–<lpage>84</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.1715-12.2012" xlink:type="simple">10.1523/JNEUROSCI.1715-12.2012</ext-link></comment> <object-id pub-id-type="pmid">22895711</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref029">
<label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>McFarland</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Cui</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Butts</surname> <given-names>DA</given-names></name>. <article-title>Inferring nonlinear neuronal computation based on physiologically plausible inputs</article-title>. <source>PLoS computational biology</source>. <year>2013</year> <month>Jan</month>;<volume>9</volume>(<issue>7</issue>):<fpage>e1003143</fpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3715434&amp;tool=pmcentrez&amp;rendertype=abstract" xlink:type="simple">http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3715434&amp;tool=pmcentrez&amp;rendertype=abstract</ext-link>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1003143" xlink:type="simple">10.1371/journal.pcbi.1003143</ext-link></comment> <object-id pub-id-type="pmid">23874185</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref030">
<label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>David</surname> <given-names>SV</given-names></name>, <name name-style="western"><surname>Shamma</surname> <given-names>SA</given-names></name>. <article-title>Integration over multiple timescales in primary auditory cortex</article-title>. <source>Journal of Neuroscience</source>. <year>2013</year> <month>Dec</month>;<volume>33</volume>(<issue>49</issue>):<fpage>19154</fpage>–<lpage>66</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.2270-13.2013" xlink:type="simple">10.1523/JNEUROSCI.2270-13.2013</ext-link></comment> <object-id pub-id-type="pmid">24305812</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref031">
<label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schinkel-Bielefeld</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>David</surname> <given-names>SV</given-names></name>, <name name-style="western"><surname>Shamma</surname> <given-names>SA</given-names></name>, <name name-style="western"><surname>Butts</surname> <given-names>DA</given-names></name>. <article-title>Inferring the role of inhibition in auditory processing of complex natural stimuli</article-title>. <source>Journal of Neurophysiology</source>. <year>2012</year> <month>Mar</month>;<volume>107</volume>(<issue>March</issue>):<fpage>3296</fpage>–<lpage>3307</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.01173.2011" xlink:type="simple">10.1152/jn.01173.2011</ext-link></comment> <object-id pub-id-type="pmid">22457454</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref032">
<label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Theis</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Chagas</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Arnstein</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Schwarz</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Bethge</surname> <given-names>M</given-names></name>. <article-title>Beyond GLMs: a generative mixture modeling approach to neural system identification</article-title>. <source>PLoS computational biology</source>. <year>2013</year> <month>Nov</month>;<volume>9</volume>(<issue>11</issue>):<fpage>e1003356</fpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3836720&amp;tool=pmcentrez&amp;rendertype=abstract" xlink:type="simple">http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3836720&amp;tool=pmcentrez&amp;rendertype=abstract</ext-link>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1003356" xlink:type="simple">10.1371/journal.pcbi.1003356</ext-link></comment> <object-id pub-id-type="pmid">24278006</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref033">
<label>33</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Williamson</surname> <given-names>RS</given-names></name>, <name name-style="western"><surname>Sahani</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Pillow</surname> <given-names>JW</given-names></name>. <article-title>The equivalence of information-theoretic and likelihood-based methods for neural dimensionality reduction</article-title>. <source>PLoS computational biology</source>. <year>2015</year> <month>Apr</month>;<volume>11</volume>(<issue>4</issue>):<fpage>e1004141</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1004141" xlink:type="simple">10.1371/journal.pcbi.1004141</ext-link></comment> <object-id pub-id-type="pmid">25831448</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref034">
<label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>David</surname> <given-names>SV</given-names></name>, <name name-style="western"><surname>Mesgarani</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Shamma</surname> <given-names>SA</given-names></name>. <article-title>Estimating sparse spectro-temporal receptive fields with natural stimuli</article-title>. <source>Network</source>. <year>2007</year>;<volume>18</volume>(<issue>3</issue>):<fpage>191</fpage>–<lpage>212</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1080/09548980701609235" xlink:type="simple">10.1080/09548980701609235</ext-link></comment> <object-id pub-id-type="pmid">17852750</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref035">
<label>35</label>
<mixed-citation publication-type="other" xlink:type="simple">Akaike, H. A new look at the statistical model identification. Automatic Control, IEEE Transactions on. 1974;Available from: <ext-link ext-link-type="uri" xlink:href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1100705" xlink:type="simple">http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1100705</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1004628.ref036">
<label>36</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schmidt</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Lipson</surname> <given-names>H</given-names></name>. <article-title>Distilling Natural Laws</article-title>. <source>Science</source>. <year>2009</year>;<volume>324</volume>(<issue>April</issue>):<fpage>81</fpage>–<lpage>85</lpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://creativemachines.cornell.edu/sites/default/files/Science09_Schmidt.pdf" xlink:type="simple">http://creativemachines.cornell.edu/sites/default/files/Science09_Schmidt.pdf</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1004628.ref037">
<label>37</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Simon</surname> <given-names>JZ</given-names></name>, <name name-style="western"><surname>Depireux</surname> <given-names>DA</given-names></name>, <name name-style="western"><surname>Klein</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Fritz</surname> <given-names>JB</given-names></name>, <name name-style="western"><surname>Shamma</surname> <given-names>SA</given-names></name>. <article-title>Temporal symmetry in primary auditory cortex: implications for cortical connectivity</article-title>. <source>Neural computation</source>. <year>2007</year> <month>Mar</month>;<volume>19</volume>(<issue>3</issue>):<fpage>583</fpage>–<lpage>638</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/neco.2007.19.3.583" xlink:type="simple">10.1162/neco.2007.19.3.583</ext-link></comment> <object-id pub-id-type="pmid">17298227</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref038">
<label>38</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Park</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Pillow</surname> <given-names>J</given-names></name>. <article-title>Bayesian inference for low rank spatiotemporal neural receptive fields</article-title>. <source>Advances in Neural Information Processing Systems</source>. <year>2013</year>;<volume>26</volume>. Available from: <ext-link ext-link-type="uri" xlink:href="http://papers.nips.cc/paper/4992-bayesian-inference-for-low-rank-spatiotemporal-neural-receptive-fields" xlink:type="simple">http://papers.nips.cc/paper/4992-bayesian-inference-for-low-rank-spatiotemporal-neural-receptive-fields</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1004628.ref039">
<label>39</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ozuysal</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Baccus</surname> <given-names>SAA</given-names></name>. <article-title>Linking the Computational Structure of Variance Adaptation to Biophysical Mechanisms</article-title>. <source>Neuron</source>. <year>2012</year> <month>Mar</month>;<volume>73</volume>(<issue>5</issue>):<fpage>1002</fpage>–<lpage>1015</lpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed/22405209 http://linkinghub.elsevier.com/retrieve/pii/S0896627312000797" xlink:type="simple">http://www.ncbi.nlm.nih.gov/pubmed/22405209 http://linkinghub.elsevier.com/retrieve/pii/S0896627312000797</ext-link>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2011.12.029" xlink:type="simple">10.1016/j.neuron.2011.12.029</ext-link></comment> <object-id pub-id-type="pmid">22405209</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref040">
<label>40</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Adelson</surname> <given-names>EH</given-names></name>, <name name-style="western"><surname>Bergen</surname> <given-names>JR</given-names></name>. <article-title>Spatiotemporal energy models for the perception of motion</article-title>. <source>Journal of the Optical Society of America A</source>. <year>1985</year>;<volume>2</volume>:<fpage>284</fpage>–<lpage>299</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1364/JOSAA.2.000284" xlink:type="simple">10.1364/JOSAA.2.000284</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref041">
<label>41</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Cai</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>DeAngelis</surname> <given-names>GC</given-names></name>, <name name-style="western"><surname>Freeman</surname> <given-names>RD</given-names></name>. <article-title>Spatiotemporal receptive field organization in the lateral geniculate nucleus of cats and kittens</article-title>. <source>Journal of neurophysiology</source>. <year>1997</year> <month>Aug</month>;<volume>78</volume>(<issue>2</issue>):<fpage>1045</fpage>–<lpage>61</lpage>. <object-id pub-id-type="pmid">9307134</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref042">
<label>42</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>DeAngelis</surname> <given-names>GC</given-names></name>, <name name-style="western"><surname>Ghose</surname> <given-names>GM</given-names></name>, <name name-style="western"><surname>Ohzawa</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Freeman</surname> <given-names>RD</given-names></name>. <article-title>Functional micro-organization of primary visual cortex: receptive field analysis of nearby neurons</article-title>. <source>The Journal of neuroscience: the official journal of the Society for Neuroscience</source>. <year>1999</year> <month>May</month>;<volume>19</volume>(<issue>10</issue>):<fpage>4046</fpage>–<lpage>64</lpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed/10234033" xlink:type="simple">http://www.ncbi.nlm.nih.gov/pubmed/10234033</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1004628.ref043">
<label>43</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Mante</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Bonin</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Carandini</surname> <given-names>M</given-names></name>. <article-title>Functional mechanisms shaping lateral geniculate responses to artificial and natural stimuli</article-title>. <source>Neuron</source>. <year>2008</year> <month>May</month>;<volume>58</volume>(<issue>4</issue>):<fpage>625</fpage>–<lpage>38</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2008.03.011" xlink:type="simple">10.1016/j.neuron.2008.03.011</ext-link></comment> <object-id pub-id-type="pmid">18498742</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref044">
<label>44</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Katsiamis</surname> <given-names>AG</given-names></name>, <name name-style="western"><surname>Drakakis</surname> <given-names>EM</given-names></name>, <name name-style="western"><surname>Lyon</surname> <given-names>RF</given-names></name>. <article-title>Practical Gammatone-Like Filters for Auditory Processing</article-title>. <source>EURASIP Journal on Audio, Speech, and Music Processing</source>. <year>2007</year> <month>Oct</month>;<volume>2007</volume>(<issue>4</issue>):<fpage>1</fpage>–<lpage>15</lpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://dl.acm.org/citation.cfm?id=1361176.1361179" xlink:type="simple">http://dl.acm.org/citation.cfm?id=1361176.1361179</ext-link>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1155/2007/63685" xlink:type="simple">10.1155/2007/63685</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref045">
<label>45</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hsu</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Borst</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Theunissen</surname> <given-names>FE</given-names></name>. <article-title>Quantifying variability in neural responses and its application for the validation of model predictions</article-title>. <source>Network: Computation and Neural Systems</source>. <year>2004</year>;<volume>15</volume>:<fpage>91</fpage>–<lpage>109</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1088/0954-898X_15_2_002" xlink:type="simple">10.1088/0954-898X_15_2_002</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref046">
<label>46</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Sahani</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Linden</surname> <given-names>JF</given-names></name>. <chapter-title>Evidence optimization techniques for estimating stimulus-response functions</chapter-title>. In: <name name-style="western"><surname>Becker</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Thrun</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Obermayer</surname> <given-names>K</given-names></name>, editors. <source>Advances in Neural Information Processing Systems</source>. <volume>vol. 15</volume>. <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>; <year>2003</year>. p. <fpage>317</fpage>–<lpage>324</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004628.ref047">
<label>47</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Pareto</surname> <given-names>V</given-names></name>. <source>Cours d’economie politique</source>. <publisher-name>F Rouge</publisher-name>, <publisher-loc>Lausanne</publisher-loc>. <year>1897</year>;.</mixed-citation>
</ref>
<ref id="pcbi.1004628.ref048">
<label>48</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Miller</surname> <given-names>LM</given-names></name>, <name name-style="western"><surname>Escabi</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Read</surname> <given-names>HL</given-names></name>, <name name-style="western"><surname>Schreiner</surname> <given-names>CE</given-names></name>, <name name-style="western"><surname>Escabí</surname> <given-names>MA</given-names></name>. <article-title>Spectrotemporal receptive fields in the lemniscal auditory thalamus and cortex</article-title>. <source>J Neurophysiol</source>. <year>2002</year> <month>Jan</month>;<volume>87</volume>(<issue>1</issue>):<fpage>516</fpage>–<lpage>527</lpage>. <object-id pub-id-type="pmid">11784767</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref049">
<label>49</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ohl</surname> <given-names>FW</given-names></name>, <name name-style="western"><surname>Scheich</surname> <given-names>H</given-names></name>. <article-title>Learning-induced dynamic receptive field changes in primary auditory cortex of the unanaesthetized Mongolian gerbil</article-title>. <source>Journal of comparative physiology A, Sensory, neural, and behavioral physiology</source>. <year>1997</year> <month>Dec</month>;<volume>181</volume>(<issue>6</issue>):<fpage>685</fpage>–<lpage>96</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s003590050150" xlink:type="simple">10.1007/s003590050150</ext-link></comment> <object-id pub-id-type="pmid">9449827</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref050">
<label>50</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Fritz</surname> <given-names>JB</given-names></name>, <name name-style="western"><surname>Shamma</surname> <given-names>SA</given-names></name>, <name name-style="western"><surname>Elhilali</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Klein</surname> <given-names>D</given-names></name>. <article-title>Rapid task-related plasticity of spectrotemporal receptive fields in primary auditory cortex</article-title>. <source>Nat Neurosci</source>. <year>2003</year>;<volume>6</volume>(<issue>11</issue>):<fpage>1216</fpage>–<lpage>1223</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn1141" xlink:type="simple">10.1038/nn1141</ext-link></comment> <object-id pub-id-type="pmid">14583754</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref051">
<label>51</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Massoudi</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Van Wanrooij</surname> <given-names>MM</given-names></name>, <name name-style="western"><surname>Versnel</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Van Opstal</surname> <given-names>AJ</given-names></name>. <article-title>Spectrotemporal Response Properties of Core Auditory Cortex Neurons in Awake Monkey</article-title>. <source>PLOS ONE</source>. <year>2015</year> <month>Feb</month>;<volume>10</volume>(<issue>2</issue>):<fpage>e0116118</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0116118" xlink:type="simple">10.1371/journal.pone.0116118</ext-link></comment> <object-id pub-id-type="pmid">25680187</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref052">
<label>52</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Tsodyks</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Pawelzik</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Markram</surname> <given-names>H</given-names></name>. <article-title>Neural networks with dynamic synapses</article-title>. <source>Neural Computation</source>. <year>1998</year>;<volume>10</volume>(<issue>4</issue>):<fpage>821</fpage>–<lpage>835</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/089976698300017502" xlink:type="simple">10.1162/089976698300017502</ext-link></comment> <object-id pub-id-type="pmid">9573407</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref053">
<label>53</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Yaron</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Hershenhoren</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Nelken</surname> <given-names>I</given-names></name>. <article-title>Sensitivity to complex statistical regularities in rat auditory cortex</article-title>. <source>Neuron</source>. <year>2012</year> <month>Nov</month>;<volume>76</volume>(<issue>3</issue>):<fpage>603</fpage>–<lpage>15</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2012.08.025" xlink:type="simple">10.1016/j.neuron.2012.08.025</ext-link></comment> <object-id pub-id-type="pmid">23141071</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref054">
<label>54</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bizley</surname> <given-names>JK</given-names></name>, <name name-style="western"><surname>Nodal</surname> <given-names>FR</given-names></name>, <name name-style="western"><surname>Nelken</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>King</surname> <given-names>AJ</given-names></name>. <article-title>Functional organization of ferret auditory cortex</article-title>. <source>Cerebral Cortex</source>. <year>2005</year>;<volume>15</volume>(<issue>10</issue>):<fpage>1637</fpage>–<lpage>1653</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/cercor/bhi042" xlink:type="simple">10.1093/cercor/bhi042</ext-link></comment> <object-id pub-id-type="pmid">15703254</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref055">
<label>55</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Atiani</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>David</surname> <given-names>SV</given-names></name>, <name name-style="western"><surname>Elgueda</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Locastro</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Radtke-Schuller</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Shamma</surname> <given-names>SA</given-names></name>, <etal>et al</etal>. <article-title>Emergent selectivity for task-relevant stimuli in higher-order auditory cortex</article-title>. <source>Neuron</source>. <year>2014</year> <month>Apr</month>;<volume>82</volume>(<issue>2</issue>):<fpage>486</fpage>–<lpage>499</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2014.02.029" xlink:type="simple">10.1016/j.neuron.2014.02.029</ext-link></comment> <object-id pub-id-type="pmid">24742467</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref056">
<label>56</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>McDermott</surname> <given-names>JH</given-names></name>, <name name-style="western"><surname>Wrobleski</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Oxenham</surname> <given-names>AJ</given-names></name>. <article-title>Recovering sound sources from embedded repetition</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source>. <year>2011</year> <month>Jan</month>;<volume>108</volume>(<issue>3</issue>):<fpage>1188</fpage>–<lpage>93</lpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3024660&amp;tool=pmcentrez&amp;rendertype=abstract" xlink:type="simple">http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3024660&amp;tool=pmcentrez&amp;rendertype=abstract</ext-link>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.1004765108" xlink:type="simple">10.1073/pnas.1004765108</ext-link></comment> <object-id pub-id-type="pmid">21199948</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref057">
<label>57</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Atencio</surname> <given-names>CA</given-names></name>, <name name-style="western"><surname>Sharpee</surname> <given-names>TO</given-names></name>, <name name-style="western"><surname>Schreiner</surname> <given-names>CE</given-names></name>. <article-title>Cooperative nonlinearities in auditory cortical neurons</article-title>. <source>Neuron</source>. <year>2008</year>;<volume>58</volume>(<issue>6</issue>):<fpage>956</fpage>–<lpage>966</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2008.04.026" xlink:type="simple">10.1016/j.neuron.2008.04.026</ext-link></comment> <object-id pub-id-type="pmid">18579084</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref058">
<label>58</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gaese</surname> <given-names>BH</given-names></name>, <name name-style="western"><surname>Ostwald</surname> <given-names>J</given-names></name>. <article-title>Anesthesia changes frequency tuning of neurons in the rat primary auditory cortex</article-title>. <source>Journal of neurophysiology</source>. <year>2001</year> <month>Aug</month>;<volume>86</volume>(<issue>2</issue>):<fpage>1062</fpage>–<lpage>6</lpage>. <object-id pub-id-type="pmid">11495976</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref059">
<label>59</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Massaux</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Edeline</surname> <given-names>JM</given-names></name>. <article-title>Bursts in the medial geniculate body: a comparison between anesthetized and unanesthetized states in guinea pig</article-title>. <source>Experimental brain research</source>. <year>2003</year> <month>Dec</month>;<volume>153</volume>(<issue>4</issue>):<fpage>573</fpage>–<lpage>8</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s00221-003-1516-3" xlink:type="simple">10.1007/s00221-003-1516-3</ext-link></comment> <object-id pub-id-type="pmid">12898102</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref060">
<label>60</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Theunissen</surname> <given-names>FE</given-names></name>, <name name-style="western"><surname>Sen</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Doupe</surname> <given-names>AJ</given-names></name>. <article-title>Spectral-temporal receptive fields of non-linear auditory neurons obtained using natural sounds</article-title>. <source>Journal of Neuroscience</source>. <year>2000</year>;<volume>20</volume>:<fpage>2315</fpage>–<lpage>2331</lpage>. <object-id pub-id-type="pmid">10704507</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref061">
<label>61</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Chi</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Ru</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Shamma</surname> <given-names>SA</given-names></name>. <article-title>Multiresolution spectrotemporal analysis of complex sounds</article-title>. <source>J Acoust Soc Am</source>. <year>2005</year>;<volume>118</volume>(<issue>2</issue>):<fpage>887</fpage>–<lpage>906</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1121/1.1945807" xlink:type="simple">10.1121/1.1945807</ext-link></comment> <object-id pub-id-type="pmid">16158645</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref062">
<label>62</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Reiss</surname> <given-names>LAJ</given-names></name>, <name name-style="western"><surname>Bandyopadhyay</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Young</surname> <given-names>ED</given-names></name>. <article-title>Effects of stimulus spectral contrast on receptive fields of dorsal cochlear nucleus neurons</article-title>. <source>Journal of neurophysiology</source>. <year>2007</year> <month>Oct</month>;<volume>98</volume>(<issue>4</issue>):<fpage>2133</fpage>–<lpage>43</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.01239.2006" xlink:type="simple">10.1152/jn.01239.2006</ext-link></comment> <object-id pub-id-type="pmid">17671102</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref063">
<label>63</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Nagel</surname> <given-names>KI</given-names></name>, <name name-style="western"><surname>Doupe</surname> <given-names>AJ</given-names></name>. <article-title>Organizing principles of spectro-temporal encoding in the avian primary auditory area field L</article-title>. <source>Neuron</source>. <year>2008</year>;<volume>58</volume>(<issue>6</issue>):<fpage>938</fpage>–<lpage>955</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2008.04.028" xlink:type="simple">10.1016/j.neuron.2008.04.028</ext-link></comment> <object-id pub-id-type="pmid">18579083</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref064">
<label>64</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Asari</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Zador</surname> <given-names>AM</given-names></name>. <article-title>Long-lasting context dependence constrains neural encoding models in rodent auditory cortex</article-title>. <source>Journal of Neurophysiology</source>. <year>2009</year> <month>Nov</month>;<volume>102</volume>(<issue>5</issue>):<fpage>2638</fpage>–<lpage>56</lpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2777827&amp;tool=pmcentrez&amp;rendertype=abstract" xlink:type="simple">http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2777827&amp;tool=pmcentrez&amp;rendertype=abstract</ext-link>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.00577.2009" xlink:type="simple">10.1152/jn.00577.2009</ext-link></comment> <object-id pub-id-type="pmid">19675288</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref065">
<label>65</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>McGinley</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>David</surname> <given-names>SV</given-names></name>, <name name-style="western"><surname>McCormick</surname> <given-names>DA</given-names></name>. <article-title>Cortical membrane potential signature of optimal states for sensory signal detection</article-title>. <source>Neuron</source>. <year>2015</year>;<volume>87</volume>(<issue>1</issue>):<fpage>179</fpage>–<lpage>92</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2015.05.038" xlink:type="simple">10.1016/j.neuron.2015.05.038</ext-link></comment> <object-id pub-id-type="pmid">26074005</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref066">
<label>66</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>David</surname> <given-names>SV</given-names></name>, <name name-style="western"><surname>Fritz</surname> <given-names>JB</given-names></name>, <name name-style="western"><surname>Shamma</surname> <given-names>SA</given-names></name>. <article-title>Task reward structure shapes rapid receptive field plasticity in auditory cortex</article-title>. <source>Proceedings of the National Academy of Science USA</source>. <year>2012</year>;<volume>109</volume>(<issue>6</issue>):<fpage>2150</fpage>–<lpage>55</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.1117717109" xlink:type="simple">10.1073/pnas.1117717109</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref067">
<label>67</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Polley</surname> <given-names>DB</given-names></name>, <name name-style="western"><surname>Steinberg</surname> <given-names>EE</given-names></name>, <name name-style="western"><surname>Merzenich</surname> <given-names>MM</given-names></name>. <article-title>Perceptual learning directs auditory cortical map reorganization through top-down influences</article-title>. <source>J Neurosci</source>. <year>2006</year>;<volume>26</volume>(<issue>18</issue>):<fpage>4970</fpage>–<lpage>4982</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.3771-05.2006" xlink:type="simple">10.1523/JNEUROSCI.3771-05.2006</ext-link></comment> <object-id pub-id-type="pmid">16672673</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref068">
<label>68</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Park</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Pillow</surname> <given-names>JW</given-names></name>. <article-title>Receptive field inference with localized priors</article-title>. <source>PLoS computational biology</source>. <year>2011</year> <month>Oct</month>;<volume>7</volume>(<issue>10</issue>):<fpage>e1002219</fpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3203052&amp;tool=pmcentrez&amp;rendertype=abstract" xlink:type="simple">http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3203052&amp;tool=pmcentrez&amp;rendertype=abstract</ext-link>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1002219" xlink:type="simple">10.1371/journal.pcbi.1002219</ext-link></comment> <object-id pub-id-type="pmid">22046110</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref069">
<label>69</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Deb</surname> <given-names>K</given-names></name>. <chapter-title>Multi-objective optimization</chapter-title>. In: <source>Search methodologies</source>. <publisher-name>Springer</publisher-name>; <year>2014</year>. p. <fpage>403</fpage>–<lpage>449</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004628.ref070">
<label>70</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Liénard</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Guillot</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Girard</surname> <given-names>B</given-names></name>. <chapter-title>Multi-objective evolutionary algorithms to investigate neurocomputational issues: the case study of basal ganglia models</chapter-title>. In: <source>From Animals to Animats 11</source>. <publisher-name>Springer</publisher-name>; <year>2010</year>. p. <fpage>597</fpage>–<lpage>606</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004628.ref071">
<label>71</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Santana</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Bielza</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Larrañaga</surname> <given-names>P</given-names></name>. <article-title>Optimizing brain networks topologies using multi-objective evolutionary computation</article-title>. <source>Neuroinformatics</source>. <year>2011</year>;<volume>9</volume>(<issue>1</issue>):<fpage>3</fpage>–<lpage>19</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s12021-010-9085-7" xlink:type="simple">10.1007/s12021-010-9085-7</ext-link></comment> <object-id pub-id-type="pmid">20882369</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref072">
<label>72</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Druckmann</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Banitt</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Gidon</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Schürmann</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Markram</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Segev</surname> <given-names>I</given-names></name>. <article-title>A novel multiple objective optimization framework for constraining conductance-based neuron models by experimental data</article-title>. <source>Frontiers in neuroscience</source>. <year>2007</year>;<volume>1</volume>(<issue>1</issue>):<fpage>7</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/neuro.01.1.1.001.2007" xlink:type="simple">10.3389/neuro.01.1.1.001.2007</ext-link></comment> <object-id pub-id-type="pmid">18982116</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref073">
<label>73</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Tonelli</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Mouret</surname> <given-names>JB</given-names></name>. <article-title>On the relationships between generative encodings, regularity, and learning abilities when evolving plastic artificial neural networks</article-title>. <source>PloS one</source>. <year>2013</year>;<volume>8</volume>(<issue>11</issue>):<fpage>e79138</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0079138" xlink:type="simple">10.1371/journal.pone.0079138</ext-link></comment> <object-id pub-id-type="pmid">24236099</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref074">
<label>74</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Clune</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Mouret</surname> <given-names>JB</given-names></name>, <name name-style="western"><surname>Lipson</surname> <given-names>H</given-names></name>. <article-title>The evolutionary origins of modularity</article-title>. <source>Proceedings of the Royal Society b: Biological sciences</source>. <year>2013</year>;<volume>280</volume>(<issue>1755</issue>):<fpage>20122863</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1098/rspb.2012.2863" xlink:type="simple">10.1098/rspb.2012.2863</ext-link></comment> <object-id pub-id-type="pmid">23363632</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref075">
<label>75</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Mouret</surname> <given-names>JB</given-names></name>, <name name-style="western"><surname>Doncieux</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Girard</surname> <given-names>B</given-names></name>. <chapter-title>Importing the computational neuroscience toolbox into neuro-evolution-application to basal ganglia</chapter-title>. In: <source>Proceedings of the 12th annual conference on Genetic and evolutionary computation</source>. <publisher-name>ACM</publisher-name>; <year>2010</year>. p. <fpage>587</fpage>–<lpage>594</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004628.ref076">
<label>76</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Liénard</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Girard</surname> <given-names>B</given-names></name>. <article-title>A biologically constrained model of the whole basal ganglia addressing the paradoxes of connections and selection</article-title>. <source>Journal of computational neuroscience</source>. <year>2014</year>;<volume>36</volume>(<issue>3</issue>):<fpage>445</fpage>–<lpage>468</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s10827-013-0476-2" xlink:type="simple">10.1007/s10827-013-0476-2</ext-link></comment> <object-id pub-id-type="pmid">24077957</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref077">
<label>77</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Englitz</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>David</surname> <given-names>SV</given-names></name>, <name name-style="western"><surname>Sorenson</surname> <given-names>MD</given-names></name>, <name name-style="western"><surname>Shamma</surname> <given-names>SA</given-names></name>. <article-title>MANTA-an open-source, high density electrophysiology recording suite for MATLAB</article-title>. <source>Frontiers in neural circuits</source>. <year>2013</year> <month>Jan</month>;<volume>7</volume>:<fpage>69</fpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3644699&amp;tool=pmcentrez&amp;rendertype=abstract" xlink:type="simple">http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3644699&amp;tool=pmcentrez&amp;rendertype=abstract</ext-link>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fncir.2013.00069" xlink:type="simple">10.3389/fncir.2013.00069</ext-link></comment> <object-id pub-id-type="pmid">23653593</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004628.ref078">
<label>78</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Garofolo</surname> <given-names>JS</given-names></name>. <source>Getting started with the DARPA TIMIT CD-ROM: An acoustic phonetic continuous speech database</source>. <publisher-loc>Gaithersburg, Maryland</publisher-loc>: <publisher-name>National Institute of Standards and Technology</publisher-name>; <year>1988</year>.</mixed-citation>
</ref>
<ref id="pcbi.1004628.ref079">
<label>79</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Efron</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Tibshirani</surname> <given-names>R</given-names></name>. <article-title>Bootstrap methods for standard errors, confidence intervals, and other measures of statistical accuracy</article-title>. <source>Statistical Science</source>. <year>1986</year>;<volume>1</volume>:<fpage>54</fpage>–<lpage>77</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1214/ss/1177013815" xlink:type="simple">10.1214/ss/1177013815</ext-link></comment></mixed-citation>
</ref>
</ref-list>
</back>
</article>
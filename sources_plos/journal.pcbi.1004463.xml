<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1004463</article-id>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-15-00374</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Model-Based Reasoning in Humans Becomes Automatic with Training</article-title>
<alt-title alt-title-type="running-head">Model-Based Reasoning in Humans Becomes Automatic with Training</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" equal-contrib="yes" xlink:type="simple">
<name name-style="western">
<surname>Economides</surname>
<given-names>Marcos</given-names>
</name>
<xref rid="aff001" ref-type="aff"><sup>1</sup></xref>
<xref rid="cor001" ref-type="corresp">*</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes" xlink:type="simple">
<name name-style="western">
<surname>Kurth-Nelson</surname>
<given-names>Zeb</given-names>
</name>
<xref rid="aff001" ref-type="aff"><sup>1</sup></xref>
<xref rid="aff002" ref-type="aff"><sup>2</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Lübbert</surname>
<given-names>Annika</given-names>
</name>
<xref rid="aff001" ref-type="aff"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Guitart-Masip</surname>
<given-names>Marc</given-names>
</name>
<xref rid="aff001" ref-type="aff"><sup>1</sup></xref>
<xref rid="aff003" ref-type="aff"><sup>3</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Dolan</surname>
<given-names>Raymond J.</given-names>
</name>
<xref rid="aff001" ref-type="aff"><sup>1</sup></xref>
<xref rid="aff002" ref-type="aff"><sup>2</sup></xref>
</contrib>
</contrib-group>
<aff id="aff001"><label>1</label> <addr-line>Wellcome Trust Centre for Neuroimaging, Institute of Neurology, University College London, London, United Kingdom</addr-line></aff>
<aff id="aff002"><label>2</label> <addr-line>Max Planck Centre for Computational Psychiatry and Ageing, University College London, London, United Kingdom</addr-line></aff>
<aff id="aff003"><label>3</label> <addr-line>Ageing Research Centre, Karolinska Institute, Stockholm, Sweden</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Sporns</surname>
<given-names>Olaf</given-names>
</name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1"><addr-line>Indiana University, UNITED STATES</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<fn fn-type="con" id="contrib001">
<p>Conceived and designed the experiments: ME ZKN MGM RJD. Performed the experiments: ME ZKN AL. Analyzed the data: ME ZKN AL. Wrote the paper: ME ZKN AL MGM RJD.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">m.economides@ucl.ac.uk</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>17</day>
<month>9</month>
<year>2015</year>
</pub-date>
<pub-date pub-type="collection">
<month>9</month>
<year>2015</year>
</pub-date>
<volume>11</volume>
<issue>9</issue>
<elocation-id>e1004463</elocation-id>
<history>
<date date-type="received">
<day>9</day>
<month>3</month>
<year>2015</year>
</date>
<date date-type="accepted">
<day>13</day>
<month>6</month>
<year>2015</year>
</date>
</history>
<permissions>
<copyright-year>2015</copyright-year>
<copyright-holder>Economides et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1004463" xlink:type="simple"/>
<abstract>
<p>Model-based and model-free reinforcement learning (RL) have been suggested as algorithmic realizations of goal-directed and habitual action strategies. Model-based RL is more flexible than model-free but requires sophisticated calculations using a learnt model of the world. This has led model-based RL to be identified with slow, deliberative processing, and model-free RL with fast, automatic processing. In support of this distinction, it has recently been shown that model-based reasoning is impaired by placing subjects under cognitive load—a hallmark of non-automaticity. Here, using the same task, we show that cognitive load does not impair model-based reasoning if subjects receive prior training on the task. This finding is replicated across two studies and a variety of analysis methods. Thus, task familiarity permits use of model-based reasoning in parallel with other cognitive demands. The ability to deploy model-based reasoning in an automatic, parallelizable fashion has widespread theoretical implications, particularly for the learning and execution of complex behaviors. It also suggests a range of important failure modes in psychiatric disorders.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author Summary</title>
<p>Automaticity develops with task familiarity. One possible explanation is that automaticity arises when performance of the task becomes habitual, or model-free. Here we asked whether goal-directed, or model-based, reasoning could also become automatic, or resistant to distraction. We used a well-characterized task that differentiates model-based from model-free action. We replicate previous findings that distraction strongly impairs model-based reasoning in task-naive subjects. However, in subjects with prior exposure to the task, distraction does not impair model-based reasoning. This suggests that humans can deploy sophisticated and flexible reasoning more extensively than previously thought.</p>
</abstract>
<funding-group>
<funding-statement>This work was supported by the Wellcome Trust [Ray Dolan Senior Investigator Award 098362/Z/12/Z]. ME is supported by the Medical Research Council [G1000411]. The Wellcome Trust Centre for Neuroimaging is supported by core funding from the Wellcome Trust 091593/Z/10/Z. ZKN is supported by a center award from the Max Planck Society. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="4"/>
<table-count count="0"/>
<page-count count="19"/>
</counts>
<custom-meta-group>
<custom-meta id="data-availability" xlink:type="simple">
<meta-name>Data Availability</meta-name>
<meta-value>All relevant data are within the paper and its Supporting Information files.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>A wealth of experimental data indicates the brain uses at least two distinct decision making strategies in value-guided choice. One involves prospective reasoning about action-outcome contingencies, while the other retrospectively links rewards to actions [<xref rid="pcbi.1004463.ref001" ref-type="bibr">1</xref>–<xref rid="pcbi.1004463.ref003" ref-type="bibr">3</xref>]. The interplay between these two choice strategies has substantial clinical implications. For example, over-reliance on habits could lead to inflexible decision-making in addiction [<xref rid="pcbi.1004463.ref004" ref-type="bibr">4</xref>] and compulsion [<xref rid="pcbi.1004463.ref005" ref-type="bibr">5</xref>].</p>
<p>A compelling computational account of these two control mechanisms draws on reinforcement learning (RL) theory [<xref rid="pcbi.1004463.ref001" ref-type="bibr">1</xref>]. In Daw and colleagues' framework, retrospective learning is accomplished with <italic>model-free</italic> strategies in which rewarded actions tend to be repeated, but the underlying structure of the world that gives rise to these rewards is not learned [<xref rid="pcbi.1004463.ref006" ref-type="bibr">6</xref>] [<xref rid="pcbi.1004463.ref007" ref-type="bibr">7</xref>]. Prospective reasoning, on the other hand, relies on a learned model of the world to accurately predict the outcomes of actions, even in the face of changing action-reward contingencies [<xref rid="pcbi.1004463.ref001" ref-type="bibr">1</xref>,<xref rid="pcbi.1004463.ref007" ref-type="bibr">7</xref>,<xref rid="pcbi.1004463.ref008" ref-type="bibr">8</xref>]. This is suggested to render <italic>model-based</italic> reasoning more flexible but at a heightened computational cost [<xref rid="pcbi.1004463.ref003" ref-type="bibr">3</xref>].</p>
<p>Contemporary theories posit that model-based reasoning engages limited-resource executive functions [<xref rid="pcbi.1004463.ref009" ref-type="bibr">9</xref>] that involve the dorsolateral prefrontal, ventromedial prefrontal and anterior cingulate cortices [<xref rid="pcbi.1004463.ref010" ref-type="bibr">10</xref>–<xref rid="pcbi.1004463.ref015" ref-type="bibr">15</xref>]. This is supported by observations that model-based reasoning is impaired under cognitive load [<xref rid="pcbi.1004463.ref016" ref-type="bibr">16</xref>] or acute stress [<xref rid="pcbi.1004463.ref017" ref-type="bibr">17</xref>], and following disruption of dorsolateral prefrontal cortex function via TMS [<xref rid="pcbi.1004463.ref018" ref-type="bibr">18</xref>], with the degree of impairment interacting with baseline working memory capacity.</p>
<p>However, studies of model-based decision-making often utilize tasks in which the stimuli, contingencies and other task parameters are novel to the subject. This raises the possibility that reliance on limited-resource executive functions is not an intrinsic property of model-based reasoning, but is instead a characteristic of reasoning with an unfamiliar model. In everyday life, tasks become "second-nature" with experience and are subsequently more easily used as building blocks for increasingly complex tasks. It remains untested whether this is entirely due to the formation of efficient habits, or if what is "second-nature" can include sophisticated reasoning with a model of the world.</p>
<p>Here, we used a two-step decision-task that engages both model-free and model-based reasoning [<xref rid="pcbi.1004463.ref016" ref-type="bibr">16</xref>,<xref rid="pcbi.1004463.ref019" ref-type="bibr">19</xref>]. In brief, trials consist of two stages, where each stage involves a two-alternative forced choice between a pair of adjacent fractals (<xref rid="pcbi.1004463.g001" ref-type="fig">Fig 1</xref>). Each first-stage fractal is predominantly associated (with a 70% probability) with one of two second-stage pairs. Transitions with 70% probability we call "common"; those with 30% probability we call "uncommon". The four second-stage fractals are associated with different reward probabilities that fluctuate independently across a session. Thus, subjects have to make trial-by-trial adjustments in choice so as to maximize the probability of reward.</p>
<fig id="pcbi.1004463.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004463.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Task and experimental design.</title>
<p>(<bold>A</bold>) Subjects chose between a pair of fractals at each of two stages, where a choice at the first-stage lead to one of two second-stage pairs with a fixed probability. This transition structure could be exploited by the player. The second-stage choice followed either a reward (gold coin) or no reward (0), according to independently fluctuating reward contingencies. On dual-task trials (displayed in the figure), two different numbers of physically different sizes were displayed above each fractal at the first-stage. Following second-stage feedback, the word ‘SIZE’ or ‘VALUE’ was presented on the screen, requiring the player to indicate whether the number that was larger in size, or value, respectively, had appeared on the left or right side of the screen. Correct responses were incentivized via monetary gain; incorrect responses were unrewarded. (<bold>B</bold>) On days 1 and 2 the ‘high load group’ played alternating blocks of single-task (128) and dual task (64) trials (for a total of 4 blocks), while the ‘low load group’ played 2 consecutive blocks of single-task (128) trials. On day 3 both groups played alternating blocks of single-task and dual task trials (as per the ‘high load group’ on days 1–2).</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004463.g001" position="float" xlink:type="simple"/>
</fig>
<p>Model-free and model-based decision strategies make different predictions about choice dependence on transitions and rewards from previous trials. We used computational modeling and logistic regression to quantify the contribution of model-free and model-based strategies when subjects performed the two-step task, either alone (single-task condition) or in combination with a demanding concurrent task (dual-task condition). The latter represents a high load condition. We also wanted to test whether the effect of load changed with practice.</p>
<p>To this end we trained subjects on the two-step task for 3 consecutive days and introduced intermittent periods of high load. An initial group of 22 healthy subjects, referred to as the ‘high load group’, experienced the dual-task condition on each day of training. This allowed us to characterize choice under load across the entire training period. A second group of 23 healthy subjects, referred to as the ‘low load group’, experienced the dual-task condition on day 3 only. This allowed us to determine how training on the two-step task alone would impact choice under load.</p>
<p>We hypothesized that model-based calculations would become less reliant on executive resources following training, independent of whether training included or excluded load, leading to a reduction in the detrimental effect of cognitive load on model-based choice.</p>
</sec>
<sec id="sec002" sec-type="results">
<title>Results</title>
<sec id="sec003">
<title>Computational modeling</title>
<p>We analyzed data using previously described reinforcement learning (RL) models [<xref rid="pcbi.1004463.ref001" ref-type="bibr">1</xref>,<xref rid="pcbi.1004463.ref019" ref-type="bibr">19</xref>], including a hybrid model and reduced (nested) versions that captured pure model-free and model-based choice. The hybrid model chose according to a combination of model-free and model-based valuations, weighted by the parameter <bold><italic>w</italic></bold>, such that <bold><italic>w</italic></bold> = 0 corresponded to pure model-free and <bold>w</bold> = 1 to pure model-based. Otto and colleagues [<xref rid="pcbi.1004463.ref016" ref-type="bibr">16</xref>] found that cognitive load shifted <bold><italic>w</italic></bold> towards 0. Our central question was whether this shift would be reduced if subjects had prior training on the two-step task. In other words, we asked whether the difference in <bold>w</bold> between single and dual-task trials on day 3 in the ‘low load group’ was smaller than on day 1 in the ‘high load group’ (a between-group comparison). In this comparison, the groups were matched in level of exposure to the Stroop task and the only manipulation was the amount of prior exposure to the two-step task. A secondary question was whether we could track incremental changes in <bold>w</bold> across days (a within-group comparison).</p>
<sec id="sec004">
<title>Between-group comparison</title>
<p>We first sought to validate that choice in the two-step task reflected a mix of both model-free and model-based valuations [<xref rid="pcbi.1004463.ref019" ref-type="bibr">19</xref>]. We fit the RL models to ‘high load group’ data from day 1 of training, and to ‘low load group’ data from day 3 of training, separately for single-task (two-step alone) and dual-task trials. Using Bayesian model comparison, we found that the hybrid model provided a better fit to subject data in both groups and both trial types, as indicated by a lower iBIC score (see <xref rid="pcbi.1004463.s004" ref-type="supplementary-material">S1 Table</xref>). Importantly, in the ‘high load group’ on day 1 the weighting parameter <bold><italic>w</italic></bold> was significantly higher in the single-task compared to the dual-task condition (paired t(21) = 2.85, p = 0.01, mean diff = 0.12, 95% CI = [0.03 0.21]), consistent with previous evidence that model-based reasoning is impaired under high cognitive load in untrained subjects [<xref rid="pcbi.1004463.ref016" ref-type="bibr">16</xref>] (<xref rid="pcbi.1004463.g002" ref-type="fig">Fig 2A</xref>). Conversely, we found no difference in the value of <bold><italic>w</italic></bold> between single-task and dual-task trials when fitting ‘low load group’ data from day 3 (paired t(22) = 0.29, p &gt; 0.05) (<xref rid="pcbi.1004463.g002" ref-type="fig">Fig 2B</xref>). This suggests that prior training on the two-step task permitted a strong degree of model-based reasoning under load, despite subjects having no prior experience with performing a task under load.</p>
<fig id="pcbi.1004463.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004463.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Computational modeling: Between-group comparison.</title>
<p>The weighting parameter <bold><italic>w</italic></bold> represents a measure of model-based (<bold><italic>w</italic></bold> = 1) relative to model-free (<bold><italic>w</italic></bold> = 0) control. <bold><italic>w</italic></bold> was lower in the dual-task (high load) condition compared to the single-task (low load) condition in naïve (‘high load group’, day 1) but not trained (‘low load group’, day 3) subjects. Vertical lines represent SEM. * denotes p &lt; 0.05. <italic>α = learning rate</italic>, <italic>β = inverse temperature</italic>, <italic>ε = lapse rate</italic>. (<bold>A</bold>) Mean best-fitting parameters for day 1 of training in the ‘high load group’. (<bold>B</bold>) Mean best-fitting parameters for day 3 of training in the ‘low load group’.</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004463.g002" position="float" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec005">
<title>Within-group comparison</title>
<p>Next, we fit the hybrid model to data from days 2 and 3 of training in the ‘high load group’, separately for single-task and dual-task trials. We were interested in whether subjects abruptly switch their choice strategy at the start of a given training day, or alternatively, whether a gradual shift in behavioral control emerges across days. We performed paired t-tests on parameter estimates from Bayesian model inference. In the single-task condition, we found evidence for a moderate shift towards more model-based choice, as indexed by higher <bold><italic>w</italic></bold> values on days 2 (paired t(21) = 3.10, p = 0.005, mean diff = 0.11, 95% CI = [0.04 0.18]) and 3 (paired t(21) = 3.66, p = 0.002, mean diff = 0.11, 95% CI = [0.05 0.17]) of training compared to day 1 (<xref rid="pcbi.1004463.g003" ref-type="fig">Fig 3A</xref>). During dual-task trials, we found a more pronounced shift towards model-based choice, with an approximately linear increase in the value of <bold><italic>w</italic></bold> across days (<xref rid="pcbi.1004463.g003" ref-type="fig">Fig 3B</xref>). <bold><italic>w</italic></bold> was significantly greater on day 2 compared to day 1 (paired t(21) = 4.26, p &lt; 0.001, mean diff = 0.18, 95% CI = [0.09 0.26]), and day 3 compared to day 2 (paired t(21) = 4.08, p &lt; 0.001, mean diff = 0.14, 95% CI = [0.07 0.21]) and 1 (paired t(21) = 9.19, p &lt; 0.001, mean diff = 0.32, 95% CI = [0.24 0.39]). Thus, training increased the relative contribution of model-based reasoning during high load (dual-task) trials, suggesting that the addition of load is necessary to expose training-induced changes in behavior in the two-step task.</p>
<fig id="pcbi.1004463.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004463.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Computational modeling: Within-group comparison.</title>
<p>The weighting parameter <bold><italic>w</italic></bold> represents a measure of model-based (<bold><italic>w</italic></bold> = 1) relative to model-free (<bold><italic>w</italic></bold> = 0) control. At the group level, model parameters remained relatively stable across single-task trials, indicating that performance in the absence of load was modestly influenced by training. By contrast, we observed higher <bold><italic>w</italic></bold> values and higher learning rates with increased task exposure during dual-task trials. Vertical lines represent SEM. <italic>α = learning rate</italic>, <italic>β = inverse temperature</italic>, <italic>ε = lapse rate</italic>. (<bold>A</bold>) Mean best-fitting parameters when fitting data from the ‘high load group’ and days 1–3 of training for single-task trials. (<bold>B</bold>) Mean best-fitting parameters when fitting data from the ‘high load group’ and days 1–3 of training for dual-task trials.</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004463.g003" position="float" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec006">
<title>Multi-day model comparison</title>
<p>To corroborate the finding that <bold><italic>w</italic></bold> changes with training within a fully Bayesian framework, we fit a full hybrid RL model (in addition to various nested alternatives) to ‘high load group’ data across all 3 days (combined), separately for single-task and dual-task trials. We tested model variants in which <bold><italic>w</italic></bold> could shift across days, governed by a slope parameter <bold><italic>σ</italic></bold>. Bayesian model comparison revealed an influence of <bold><italic>σ</italic></bold> for the dual-task condition but not the single-task condition, with the latter replicating in both cohorts (see <xref rid="pcbi.1004463.s005" ref-type="supplementary-material">S2</xref> and <xref rid="pcbi.1004463.s006" ref-type="supplementary-material">S3</xref> Tables). Thus, training influenced the balance between model-free and model-based control across each day of training in dual-task trials but not in single-task trials (however, we note <bold><italic>w</italic></bold> was higher on days 2 and 3 compared to day 1 of training during single-task blocks, a subtlety not captured by a slope model that is only sensitive to linear effects). Importantly, the value of <bold><italic>σ</italic></bold> was negative at the group-level, indicating a higher degree of model-based control on day 3 compared to day 1 (see <xref rid="pcbi.1004463.s006" ref-type="supplementary-material">S3 Table</xref>). Thus, subjects’ ability to perform model-based reasoning gradually became immune to cognitive load when training included both the single-task and dual-task conditions, both within a fully Bayesian framework, and when fitting behavior from each day individually.</p>
</sec>
<sec id="sec007">
<title>Other learning parameters</title>
<p>In addition to differences in the value of <bold><italic>w</italic></bold> between single-task and dual-task trials, we found differences in a number of other learning parameters (see Figs <xref rid="pcbi.1004463.g002" ref-type="fig">2</xref> and <xref rid="pcbi.1004463.g003" ref-type="fig">3</xref>, <xref rid="pcbi.1004463.s006" ref-type="supplementary-material">S3 Table</xref>). When fitting data from the ‘high load group’ on day 1, and the ‘low load group’ on day 3, we found subjects were less considerate of the most recent reward information (as indexed by a lower learning rate) and chose more stochastically (as indicated by a lower inverse temperature) during dual-task trials compared to single-task trials (high load group <bold><italic>α</italic></bold>: paired t(21) = 4.33, p &lt; 0.001; high load group <bold><italic>β</italic></bold>: paired t(21) = 2.94, p = 0.008; low load group <bold><italic>α</italic></bold>: paired t(22) = 4.61, p &lt; 0.001; low load group <bold><italic>β</italic></bold>: paired t(22) = 4.49. p &lt; 0.001) (see <xref rid="pcbi.1004463.g002" ref-type="fig">Fig 2</xref>). We identified similar differences when fitting data across all training days consecutively (<xref rid="pcbi.1004463.s006" ref-type="supplementary-material">S3 Table</xref>). However, when subjects were able to practice the dual-task condition on each day (‘high load group’), both the learning rate and inverse temperature under load increased across days (<bold><italic>α</italic></bold> day 2 vs. day 1: paired t(21) = 3.34, p = 0.003; day 3 vs. day 2: paired t(21) = 2.03, p = 0.06; day 3 vs. day 1: paired t(21) = 5.76, p &lt; 0.001; <bold><italic>β</italic></bold> day 2 vs. day 1: paired t(21) = -1.45, p &gt; 0.05, day 3 vs. day 2: paired t(21) = 7.96, p &lt; 0.001; day 3 vs. day 1: paired t(21) = 3.84, p &lt; 0.001) (<xref rid="pcbi.1004463.g003" ref-type="fig">Fig 3B</xref>).</p>
</sec>
</sec>
<sec id="sec008">
<title>Logistic regression</title>
<p>Computational modeling relies on fitting several model parameters that can exhibit a degree of shared variance, and this has a potential to complicate interpretation when the true value of more than one parameter differs between two conditions. We therefore employed a logistic regression to validate the main findings from our model. We quantified the degree to which choice on the current trial reflected a model-free and model-based influence with respect to events occurring on the preceding 3 trials (see <xref rid="sec011" ref-type="sec">Materials &amp; Methods</xref>) [<xref rid="pcbi.1004463.ref020" ref-type="bibr">20</xref>]. For example, if a player received a reward following an uncommon transition 3 trials in the past, a model-free system would be more likely to repeat the first-stage choice on the current trial, whereas a model-based system would endorse a switch in choice.</p>
<p>During single-task trials, we identified both a significant model-free and model-based influence on choice extending up to 3 trials in the past (all p &lt; 0.05), consistent with subjects utilizing a hybrid of both systems (<xref rid="pcbi.1004463.g004" ref-type="fig">Fig 4A</xref>). However, we found a reduction in model-based control in the dual-task condition compared to the single-task condition in the ‘high load group’ on day 1, an effect that propagated up to 2 trials in the past (1-back: paired t(21) = 2.59, p = 0.017, mean diff = 0.22, 95% CI = [0.04 0.40]; 2-back: paired t(21) = 2.78, p = 0.011, mean diff = 0.19, 95% CI = [0.05 0.34]). Importantly, this difference was reduced following task training (on day 3), independent of whether training included (‘high load group’, <xref rid="pcbi.1004463.g004" ref-type="fig">Fig 4A</xref>) or excluded (‘low load group’, <xref rid="pcbi.1004463.s001" ref-type="supplementary-material">S1 Fig</xref>) the high load condition (high load 1-back: paired t(21) = 1.16, p &gt; 0.05; high load 2-back: paired t(21) = 0.62, p &gt; 0.05). To visualize these effects, we derived single indices of model-free and model-based learning by summing the coefficients that correspond to an influence of events on 1, 2 or 3 trials in the past (see <xref rid="pcbi.1004463.g004" ref-type="fig">Fig 4B</xref>).</p>
<fig id="pcbi.1004463.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004463.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Model-free and model-based influences on choice.</title>
<p>Results of a logistic regression that considers model-free and model-based influences on choice in the current trial with respect to events that occurred up to 3 trials in the past. (<bold>A</bold>) Each regressor describes whether events on trial <italic>t</italic><sub><italic>-1</italic></sub>, <italic>t</italic><sub><italic>-2</italic></sub> and <italic>t</italic><sub><italic>-3</italic></sub> increase (coded as +1) or decrease (coded as -1) the probability of choosing fractal A according to a model-free or a model-based system (6 total regressors). Model-free coefficients are plotted on the left-hand side of x-axis, and model-based coefficients on the right-hand side. Data from days 1 and day 3 are plotted in the top and bottom panels respectively. Coefficients corresponding to the single-task are shown in blue, and those corresponding to the dual-task are shown in orange. Vertical lines represent SEM. * denotes p &lt; 0.05, ‡ denotes p = 0.09. (<bold>B</bold>) For each condition (single-task in blue, dual-task in orange), and separately for days 1 and 3, we summed (individually) the coefficients corresponding to trial <italic>t</italic><sub><italic>-1</italic></sub>, <italic>t</italic><sub><italic>-2</italic></sub> and <italic>t</italic><sub><italic>-3</italic></sub>, and derived single estimates of the degree to which model-free (plotted on the y-axis) and model-based (plotted on the x-axis) control were dominant in choice. Vertical lines represent 95% confidence intervals. A line through the origin represents points in which model-free and model-based valuations have an equal influence on choice.</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004463.g004" position="float" xlink:type="simple"/>
</fig>
<p>To our surprise, we were unable to identify a model-free influence in either group in the high load (dual-task) condition (see <xref rid="pcbi.1004463.g004" ref-type="fig">Fig 4A</xref> and <xref rid="pcbi.1004463.s001" ref-type="supplementary-material">S1 Fig</xref>). However, model-free coefficients were not significantly different when comparing the single-task and dual-task conditions (see <xref rid="pcbi.1004463.g004" ref-type="fig">Fig 4A</xref>). Thus, we do not draw strong inferences from this dissimilarity.</p>
<p>In keeping with other studies utilizing the two-step task [<xref rid="pcbi.1004463.ref016" ref-type="bibr">16</xref>,<xref rid="pcbi.1004463.ref018" ref-type="bibr">18</xref>,<xref rid="pcbi.1004463.ref019" ref-type="bibr">19</xref>,<xref rid="pcbi.1004463.ref021" ref-type="bibr">21</xref>], we repeated the regression analysis but now only considering the influence of events occurring on the immediately preceding trial. Our findings were consistent with the computational modeling approach and the 3-back regression, and are reported in the supplement for completeness (see <xref rid="pcbi.1004463.s002" ref-type="supplementary-material">S2 Fig</xref> and <xref rid="pcbi.1004463.s007" ref-type="supplementary-material">S4 Table</xref>). In summary, these results replicate our computational modeling in a format with more flexible parametric assumptions.</p>
</sec>
<sec id="sec009">
<title>Numerical Stroop performance</title>
<p>Mean numerical Stroop accuracy during dual-task trials was 81.9% on day 1, 85.5% on day 2, and 89.5% on day 3 for the ‘high load group’. Thus, performance on the secondary task demonstrated an approximately linear improvement across training days (day 2 vs. day 1: paired t(21) = 2.53, p = 0.019; day 3 vs. day 2: paired t(21) = 3.88, p &lt; 0.001; day 3 vs. day 1: paired t(21) = 5.34, p &lt; 0.001). Mean numerical Stroop accuracy for the ‘low load group’, in which subjects only experienced the dual-task condition on day 3 of training, was 83.2%, and thus comparable to the ‘high load group’.</p>
</sec>
</sec>
<sec id="sec010" sec-type="conclusions">
<title>Discussion</title>
<p>Here we asked whether reliance on finite executive resources [<xref rid="pcbi.1004463.ref013" ref-type="bibr">13</xref>,<xref rid="pcbi.1004463.ref014" ref-type="bibr">14</xref>,<xref rid="pcbi.1004463.ref018" ref-type="bibr">18</xref>,<xref rid="pcbi.1004463.ref022" ref-type="bibr">22</xref>–<xref rid="pcbi.1004463.ref024" ref-type="bibr">24</xref>] is a universal property of model-based reasoning, or whether, as task familiarity increases, model-based reasoning can depend less on these limited-resource functions. We found that reasoning was preserved under load in subjects who had acquired familiarity, through prior training, with the structure of a two-stage Markov decision task [<xref rid="pcbi.1004463.ref019" ref-type="bibr">19</xref>]. This was replicated in two cohorts of subjects (who received training either with or without load) using different methodological approaches. Our results show that training can enable model-based reasoning even when executive resources are devoted to another task, thereby reflecting the emergence of resource independence.</p>
<p>There are several possible accounts for these findings. First, subjects may change the way they calculate the contingencies of the task following training. From a neural perspective, model calculations may be implemented in new brain areas such that they no longer overlap with those used in the concurrent task. Training has previously been shown to cause "off-loading" in tasks requiring executive resources, including an implementational shift from prefrontal to parietal and striatal regions [<xref rid="pcbi.1004463.ref025" ref-type="bibr">25</xref>,<xref rid="pcbi.1004463.ref026" ref-type="bibr">26</xref>]. It is also possible that model calculations remain in the same brain regions, but that coding within these areas becomes more efficient. For example, only a fraction of the initial pool of neurons may be required to realize the same representational fidelity [<xref rid="pcbi.1004463.ref027" ref-type="bibr">27</xref>–<xref rid="pcbi.1004463.ref029" ref-type="bibr">29</xref>].</p>
<p>Second, resilience to load could emerge if auxiliary processes (other than reasoning with the structure of the task itself) become more efficient. For example, some cognitive resources may be required for identifying the various stimuli, for tracking events that occurred on previous trials, and for recalling learned values at the second stage. There may also be resource requirements for maintaining belief distributions over meta-parameters, such as whether the task structure changes or new fractals appear, what appropriate learning rates are, when model-based reasoning should be deployed [<xref rid="pcbi.1004463.ref001" ref-type="bibr">1</xref>,<xref rid="pcbi.1004463.ref030" ref-type="bibr">30</xref>] and how attentional resources should be allocated within a trial. Since all these depend on executive brain regions to some degree [<xref rid="pcbi.1004463.ref031" ref-type="bibr">31</xref>–<xref rid="pcbi.1004463.ref035" ref-type="bibr">35</xref>], a gain in efficiency across any of these domains is likely to free resources.</p>
<p>Third, subjects might learn to perform model-based calculations at the end of each trial ("offline"), rather than at the beginning of the next trial. When used to update a cached or habitual value accessed for the next choice, such offline calculation could relieve the need to store the current reward in memory until the beginning of the next trial. In turn, this might allow better allocation of executive resources to the concurrent task. Indeed, a recent experiment has suggested that the model-based system can “train” the model-free system by replaying and simulating experience offline, and that this in turn allows for choice under load that appears model-based [<xref rid="pcbi.1004463.ref036" ref-type="bibr">36</xref>].</p>
<p>A final consideration is that choice under load after training may not be truly model-based. Increasingly sophisticated choice heuristics (for example, applying Q-value updates to the opposite first-stage transition following an uncommon transition), can permit behavior that is increasingly difficult to distinguish from fully model-based in the two-step task [<xref rid="pcbi.1004463.ref037" ref-type="bibr">37</xref>]. Although not realizing the full Markov model of the task, these strategies implicitly embody partial models of task structure. While our data do not adjudicate between these divergent mechanisms, future experiments could aim to investigate their respective predictions using neuroimaging. Further, although our study demonstrates that model-based reasoning can become resist to load, it remains difficult to predict whether these findings would generalize to other task or load manipulations. Indeed, future studies should aim to identify the various factors that might promote or impede such resistance.</p>
<p>Our regression analysis suggests the possibility that the reduction in <bold><italic>w</italic></bold> (a parameter indexing the balance between model-based and model-free control) under load could reflect a marginal weakening of model-free reasoning, in addition to a more pronounced disruption of model-based reasoning. This contrasts with previous studies showing that model-based, but not model-free learning, is prone to interference in a range of contexts [<xref rid="pcbi.1004463.ref005" ref-type="bibr">5</xref>,<xref rid="pcbi.1004463.ref016" ref-type="bibr">16</xref>–<xref rid="pcbi.1004463.ref018" ref-type="bibr">18</xref>,<xref rid="pcbi.1004463.ref038" ref-type="bibr">38</xref>]. This subtle difference may be a consequence of dissimilarities in task design. For example, while Otto and colleagues utilized interleaved trials of low and high load [<xref rid="pcbi.1004463.ref016" ref-type="bibr">16</xref>], we employed alternating blocks of either condition. If subjects make choices by integrating over the recent trial history, then enforcing a high load over a longer period of trials could have more diffuse consequences on choice.</p>
<p>In addition, we found higher w values on day 3 of training in the ‘high load group’ than the ‘low load group’ in both trial types. Because the 'high load group' had more prior exposure to the Stroop task in this comparison, their higher <bold>w</bold> values could possibly reflect improved facility with the Stroop task itself, or indeed with the performance of any concurrent tasks [<xref rid="pcbi.1004463.ref003" ref-type="bibr">3</xref>], for example via improved working memory. Thus, we do not draw any strong conclusions from this observation.</p>
<p>In our computational model, load affected not just <bold><italic>w</italic></bold> but also prompted slower learning rates and more stochastic choice, independent of training (in the ‘low load group’). The former implies subjects inferred lower environmental volatility under load (perhaps placing stronger weight on priors) [<xref rid="pcbi.1004463.ref033" ref-type="bibr">33</xref>], or that load induced a tradeoff between working memory and more incremental learning processes that exhibit longer time-constants. More stochastic choice might reflect a reduction in decision confidence [<xref rid="pcbi.1004463.ref039" ref-type="bibr">39</xref>,<xref rid="pcbi.1004463.ref040" ref-type="bibr">40</xref>]. It is also possible that the underlying choice strategy used by subjects was not fully captured by our models, leading to some other form of variability to be absorbed by our parameters.</p>
<p>At first glance our result might appear contrary to a standard view that increasing training produces a shift from goal-directed (model-based) to habitual (model-free) control. For example, it is well established that extended training reduces sensitivity to outcome devaluation [<xref rid="pcbi.1004463.ref013" ref-type="bibr">13</xref>,<xref rid="pcbi.1004463.ref041" ref-type="bibr">41</xref>–<xref rid="pcbi.1004463.ref044" ref-type="bibr">44</xref>]. However, our experiment differs from these previous studies as subjects do not receive extended training with a particular action-reward contingency. Instead, they received training with a more sophisticated pattern of relationships between action and reward corresponding to the task structure. This difference appears to be essential for determining whether habits or model-based reasoning are strengthened with experience. Notably, although we conclude that there exist certain conditions where training can improve model reasoning under load, an important remaining question concerns the precise sets of conditions—complexity of model, type of training, and degree of load—whereby this training effect is enhanced or diminished.</p>
<p>A central feature of human learning is the ability to acquire very complex task structures, which often involve performing multiple subtasks in parallel. One way to achieve this parallelism is to reduce the subtasks to habits, reflecting fixed and inflexible action patterns. Our work suggests that even when subtasks are performed in parallel, each subtask can realize sophisticated and flexible model-based reasoning. This lends richness to ideas on the range of behavioral repertoires that humans can express. It is also consistent with the notion of "models" throughout processing hierarchies in the brain, from low-level sensory processing to high-level cognition [<xref rid="pcbi.1004463.ref045" ref-type="bibr">45</xref>,<xref rid="pcbi.1004463.ref046" ref-type="bibr">46</xref>].</p>
<p>The possibility that model-based reasoning can become automatic suggests new failure modes (and treatment avenues) in psychiatric disorders. If maladaptive models become automatic, they may lead to behavior that is both sophisticated and pernicious. Conversely, if adaptive models fail to become automatic when they should, they may fail to compete with maladaptive habits, especially under stress or cognitive load. Yet another possible failure mode is that experience calcifies models into true, inflexible habits rather than automatic models.</p>
<p>In summary, we present data that is a challenge to a widespread notion in decision-making that "goal-directed" and "deliberative" are synonymous. We suggest that a dependence of goal-directed reasoning on use of serial executive resources can lessen with task experience. This could be important in the acquisition of progressively more complex behavior, with implications for therapies that aim to restore normal decision-making in psychiatric disorders.</p>
</sec>
<sec id="sec011" sec-type="materials|methods">
<title>Materials and Methods</title>
<sec id="sec012">
<title>Ethics statement</title>
<p>Written informed consent was obtained from all participants prior to the experiment and the UCL Research Ethics Committee approved the study (project number 3450/002).</p>
</sec>
<sec id="sec013">
<title>Subjects</title>
<p>Previous studies in our laboratory and others have shown that 20 to 25 participants provide sufficient power to quantify the contribution of model-free and model-based strategies in the two-step task [<xref rid="pcbi.1004463.ref016" ref-type="bibr">16</xref>,<xref rid="pcbi.1004463.ref018" ref-type="bibr">18</xref>,<xref rid="pcbi.1004463.ref019" ref-type="bibr">19</xref>,<xref rid="pcbi.1004463.ref038" ref-type="bibr">38</xref>]. We thus decided prior to data collection to include at least 20 participants in the final analysis of each experimental group. 35 adult participants formed a group (referred to as the ‘high load group’) which received training both with and without cognitive load, of which 22 were included in the final analysis (7 male and 15 female; age range 18–34; mean 21.5, SD = 3.71 years). 30 adult participants formed a second independent group (referred to as the ‘low load group’) for which cognitive load was omitted from training on days one and two. 23 were included in the final analysis (9 male and 14 female; age range 18–26; mean 21.2, SD = 3.61 years).</p>
<sec id="sec014">
<title>Subject inclusion/exclusion criteria</title>
<p>In line with [<xref rid="pcbi.1004463.ref016" ref-type="bibr">16</xref>] we excluded 11 subjects from the ‘high load group’ and 5 subjects from the ‘low load group’ whose accuracy on the Stroop task during dual-task trials was &lt; 70% on any given day so as to ensure participants were in fact attempting to perform both tasks simultaneously. In addition we excluded 2 participants from the ‘high load group’ and 1 participant from the ‘low load group’ who chose the same first-stage fractal on &gt; 90% of trials (on any given day), irrespective of events on the previous trial. Finally we excluded 1 participant from the ‘low load group’ whose probability of repeating a first-stage action following a common-rewarded transition on the previous trial was &lt; 0.25 on day one of training.</p>
</sec>
</sec>
<sec id="sec015">
<title>General design</title>
<p>In the ‘high load group’, subjects performed alternating blocks of single-task (two-step alone) (128 trials) and dual-task (64 trials) trials until two blocks of each trial type were completed (256 single-task trials, 128 dual-task trials in total). This protocol was repeated across three consecutive days. Subjects received 20 practice trials of each trial type at the start of day one. In the ‘low load group’, subjects performed 256 trials of the single-task (two-step alone) condition for two consecutive days, while the protocol on day three was identical to the ‘high load group’. Subjects in the ‘low load group’ received 20 practice trials of the single-task condition at the start of day one, and 20 practice trials of the dual-task condition at the start of day 3.</p>
</sec>
<sec id="sec016">
<title>Task</title>
<p>Subjects performed a two-step decision task based on [<xref rid="pcbi.1004463.ref019" ref-type="bibr">19</xref>] and equivalent to that used in [<xref rid="pcbi.1004463.ref016" ref-type="bibr">16</xref>]. At the first stage, subjects had 2000 ms to choose between a fractal-pair presented on a grey background (the chosen fractal was highlighted with a yellow border for the remainder of the choice period). Each first stage fractal led to one of two second stage fractal-pairs with a 70% probability (common transition) and to the other with a 30% probability (uncommon transition). Second stage fractal-pairs were displayed on a green or blue background in accordance with whether a common or uncommon transition had occurred. In addition, the chosen first-stage fractal was minimized and moved to the top central portion of the screen. At the second stage, subjects again had 2000 ms to choose between a fractal-pair (the chosen fractal was again highlighted with a yellow border for the remainder of the choice period). An outcome was presented in the form of a golden coin (to indicate a monetary gain) or a ‘0’ (to indicate no monetary gain), followed by an inter-trial interval (fixation cross). The position of each fractal (left versus right) was counter-balanced across trials for both stages.</p>
<p>Dual-task trials followed the same procedure, except that subjects had to simultaneously perform a numerical Stroop task [<xref rid="pcbi.1004463.ref047" ref-type="bibr">47</xref>]. At the beginning of the first stage, two digits were presented, one above each choice fractal, for 200 ms, and then covered by a white mask for a further 200 ms. After second-stage choice feedback, either the word ‘SIZE’ or ‘VALUE’ appeared alone in the center of the screen on a grey background. The player had 1000 ms to indicate which first-stage number was larger in size or value respectively. In accordance with [<xref rid="pcbi.1004463.ref016" ref-type="bibr">16</xref>] and [<xref rid="pcbi.1004463.ref047" ref-type="bibr">47</xref>], the numerically larger number was physically smaller on 85% of trials. Thus, subjects had to hold incidental information in working memory whilst performing the two-step task. Following their response, feedback in the form of the word ‘CORRECT’ or ‘INCORRECT’ was presented a further 1000 ms. If participants failed to respond during the Stroop task probe, a red “X” appeared for 1000 ms. Trial lengths were equated across two-step and dual task trials (7200 ms per trial).</p>
<p>The reward probabilities associated with second-stage fractals were governed by independently drifting Gaussian random walks (SD = 0.025). We generated a pool of fifteen random walks for which reward probabilities did not exceed ~0.75 or fall below ~0.25. For each subject, three walks were selected at random from the pool for use on each successive day of training. Thus, walks were continuous between blocks of single-task and dual task trials.</p>
</sec>
<sec id="sec017">
<title>Computational modeling</title>
<p>Based on [<xref rid="pcbi.1004463.ref019" ref-type="bibr">19</xref>], the task was modelled as consisting of three states (<italic>s</italic><sub><italic>A</italic></sub> for the first-stage fractal pair; <italic>s</italic><sub><italic>B</italic></sub> and <italic>s</italic><sub><italic>C</italic></sub> for the second-stage fractal pairs) where two possible actions (<italic>a</italic><sub><italic>A</italic></sub>,<italic>a</italic><sub><italic>B</italic></sub>) can be taken from each state. The goal of each RL algorithm is to learn a state-action value function <italic>Q</italic>(<italic>s</italic>,<italic>a</italic>) that maps each state-action pair to its expected future value. In each trial <italic>t</italic>, the first and second-stage states are indicated as <italic>s</italic><sub>1,<italic>t</italic></sub> and <italic>s</italic><sub>2,<italic>t</italic></sub> respectively, while first and second-stage choices (actions) are indicated as <italic>a</italic><sub>1,<italic>t</italic></sub> and <italic>a</italic><sub>2,<italic>t</italic></sub> Since there is no reward at the first stage, <italic>r</italic><sub>1,<italic>t</italic></sub> is always zero, while <italic>r</italic><sub>1,<italic>t</italic></sub> can be zero or one.</p>
<sec id="sec018">
<title>Model-free</title>
<p>The model-free algorithm was temporal difference Q-learning [<xref rid="pcbi.1004463.ref006" ref-type="bibr">6</xref>] in which the value of a given state is assumed to be equivalent to the expected reward from taking the best available action from that state. At each stage <italic>i</italic> of each trial <italic>t</italic>, the value of the chosen state-action pair was updated according to:
<disp-formula id="pcbi.1004463.e001">
<alternatives>
<graphic id="pcbi.1004463.e001g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004463.e001" xlink:type="simple"/>
<mml:math display="block" id="M1" overflow="scroll">
<mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>T</mml:mi><mml:mi>D</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>T</mml:mi><mml:mi>D</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mo> </mml:mo><mml:mi>α</mml:mi><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
where <italic>δ</italic>, the reward prediction error (RPE), is defined as
<disp-formula id="pcbi.1004463.e002">
<alternatives>
<graphic id="pcbi.1004463.e002g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004463.e002" xlink:type="simple"/>
<mml:math display="block" id="M2" overflow="scroll">
<mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:mo> </mml:mo><mml:munder><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow><mml:mi>a</mml:mi></mml:munder><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>T</mml:mi><mml:mi>D</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>a</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>T</mml:mi><mml:mi>D</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
where <italic>α</italic> is a learning rate fit for each subject and <italic>γ</italic> is a discount factor that trades off the importance of sooner versus later rewards (fixed at 1).</p>
<p>Note that for the first stage choice, <italic>r</italic><sub><italic>i</italic>,<italic>t</italic></sub> is always zero and <italic>δ</italic> is instead driven by the second-stage value.</p>
<p>After outcome delivery, the second stage RPE is used to update the first-stage action <italic>Q</italic><sub><italic>TD</italic></sub>(<italic>s</italic><sub>1,<italic>t</italic></sub>,<italic>a</italic><sub>1,<italic>t</italic></sub>) according to the eligibility trace λ, which assigns credit to the first-stage action without the need for an additional step.</p>
<disp-formula id="pcbi.1004463.e003">
<alternatives>
<graphic id="pcbi.1004463.e003g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004463.e003" xlink:type="simple"/>
<mml:math display="block" id="M3" overflow="scroll">
<mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>T</mml:mi><mml:mi>D</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>T</mml:mi><mml:mi>D</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mo> </mml:mo><mml:mi>α</mml:mi><mml:mi>λ</mml:mi><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
<p>Thus, in the event that λ = 0, choice is driven by the estimated value of the second-stage state on the previous trial. Consistent with previous studies [<xref rid="pcbi.1004463.ref016" ref-type="bibr">16</xref>,<xref rid="pcbi.1004463.ref019" ref-type="bibr">19</xref>], this model assumes that eligibility traces are cleared between trials.</p>
</sec>
<sec id="sec019">
<title>Model-based</title>
<p>A model-based RL algorithm involves learning a set of contingencies between actions and states (a state-transition function), estimating a reward value for each state, and then combining the two by iterative expectation. Here, since first-stage transitions are probabilistic, a player must map action-state pairs to a probability distribution over subsequent states.</p>
<p>One can approximate subjects’ estimate of the transition probabilities by assuming they believe one of two alternatives:
<disp-formula id="pcbi.1004463.e004">
<alternatives>
<graphic id="pcbi.1004463.e004g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004463.e004" xlink:type="simple"/>
<mml:math display="block" id="M4" overflow="scroll">
<mml:mrow><mml:mi>P</mml:mi><mml:mtext>(</mml:mtext><mml:msub><mml:mi>s</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo> </mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0.7</mml:mn><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>P</mml:mi><mml:mtext>(</mml:mtext><mml:msub><mml:mi>s</mml:mi><mml:mi>C</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo> </mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0.3</mml:mn><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>P</mml:mi><mml:mtext>(</mml:mtext><mml:msub><mml:mi>s</mml:mi><mml:mi>C</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo> </mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0.7</mml:mn><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>P</mml:mi><mml:mtext>(</mml:mtext><mml:msub><mml:mi>s</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo> </mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0.3</mml:mn></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
or
<disp-formula id="pcbi.1004463.e005">
<alternatives>
<graphic id="pcbi.1004463.e005g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004463.e005" xlink:type="simple"/>
<mml:math display="block" id="M5" overflow="scroll">
<mml:mrow><mml:mi>P</mml:mi><mml:mtext>(</mml:mtext><mml:msub><mml:mi>s</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo> </mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0.3</mml:mn><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>P</mml:mi><mml:mtext>(</mml:mtext><mml:msub><mml:mi>s</mml:mi><mml:mi>C</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo> </mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0.7</mml:mn><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>P</mml:mi><mml:mtext>(</mml:mtext><mml:msub><mml:mi>s</mml:mi><mml:mi>C</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo> </mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0.3</mml:mn><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>P</mml:mi><mml:mtext>(</mml:mtext><mml:msub><mml:mi>s</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo> </mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0.7</mml:mn></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
based on the number of previous transitions from <italic>s</italic><sub><italic>A</italic></sub> to <italic>s</italic><sub><italic>B</italic></sub> given <italic>a</italic><sub><italic>A</italic></sub> and from <italic>s</italic><sub><italic>A</italic></sub> to <italic>s</italic><sub><italic>C</italic></sub> given <italic>a</italic><sub><italic>B</italic></sub> (or vice versa). A previous study has shown this scheme settles on the true transition matrix after the first few trials and fits subjects’ choices better than implementing a traditional trial-by-trial learning algorithm [<xref rid="pcbi.1004463.ref019" ref-type="bibr">19</xref>]. Therefore, we assume the true transition probabilities are learnt during practice trials and are known by the start of the first experimental block.</p>
<p>Since the second-stage action is the only choice associated with immediate reward, and is the final step in a trial, an agent can learn the value of the second-stage state in a manner equivalent to temporal difference Q-learning (as above). Thus, <italic>Q</italic><sub><italic>TD</italic></sub>(<italic>s</italic><sub>2,<italic>t</italic></sub>,<italic>a</italic><sub>2,<italic>t</italic></sub>) is simply an estimate of the immediate reward <italic>r</italic><sub>2,<italic>t</italic>,</sub> and the model-based algorithm converges with model-free learning at this stage.</p>
<p>By combining the transition function with the second-stage values we can define the values of the two first-level actions (using Bellman’s equation) as follows:
<disp-formula id="pcbi.1004463.e006">
<alternatives>
<graphic id="pcbi.1004463.e006g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004463.e006" xlink:type="simple"/>
<mml:math display="block" id="M6" overflow="scroll">
<mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:munder><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow><mml:mi>a</mml:mi></mml:munder><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>T</mml:mi><mml:mi>D</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>a</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mo> </mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>C</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:munder><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow><mml:mi>a</mml:mi></mml:munder><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>T</mml:mi><mml:mi>D</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>C</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>a</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
where these are computed on every trial based on the updated second-stage Q-values.</p>
</sec>
<sec id="sec020">
<title>Hybrid model</title>
<p>For the hybrid model we consider contributions from both model-free and model-based RL. First-stage action values were defined as the weighted sum of values from the algorithms described above as follows:
<disp-formula id="pcbi.1004463.e007">
<alternatives>
<graphic id="pcbi.1004463.e007g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004463.e007" xlink:type="simple"/>
<mml:math display="block" id="M7" overflow="scroll">
<mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>H</mml:mi><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>w</mml:mi><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>w</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>T</mml:mi><mml:mi>D</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
where <bold><italic>w</italic></bold> is a weighting parameter.</p>
<p>When fitting data across all sessions, we included a slope parameter sigma (<bold><italic>σ</italic></bold>) that allowed <bold><italic>w</italic></bold> to shift across days:
<disp-formula id="pcbi.1004463.e008">
<alternatives>
<graphic id="pcbi.1004463.e008g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004463.e008" xlink:type="simple"/>
<mml:math display="block" id="M8" overflow="scroll">
<mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>D</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>w</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtext>exp</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>D</mml:mi><mml:mi>a</mml:mi><mml:mi>y</mml:mi><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
and used <bold><italic>w</italic></bold><sub><bold><italic>D</italic></bold></sub> as the new weighting parameter.</p>
<p>At the second-stage, all three models (model-free, model-based, hybrid) converge.</p>
</sec>
<sec id="sec021">
<title>Action selection</title>
<p>For each model, values were converted to action probabilities using a sigmoid (softmax) function:
<disp-formula id="pcbi.1004463.e009">
<alternatives>
<graphic id="pcbi.1004463.e009g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004463.e009" xlink:type="simple"/>
<mml:math display="block" id="M9" overflow="scroll">
<mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>ε</mml:mi><mml:mo>+</mml:mo><mml:mo> </mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mi>ε</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mtext>exp</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>β</mml:mi><mml:mo>⋅</mml:mo><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mtext>exp</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>β</mml:mi><mml:mo>⋅</mml:mo><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mo> </mml:mo><mml:mtext>exp</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>β</mml:mi><mml:mo>⋅</mml:mo><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
Where <bold><italic>ε</italic></bold> is a lapse rate, and <bold><italic>β</italic></bold> is an inverse temperature parameter that governs the stochasticity of choice options. When <bold><italic>ε</italic></bold> &gt; 0 the boundaries of the sigmoid function are compressed and deviations from the model are less harshly punished (see <xref rid="pcbi.1004463.s003" ref-type="supplementary-material">S3A Fig</xref>). Including a lapse rate in the softmax may reduce the impact of choices unrelated to the value function of our model (for example choices that result from lapses in concentration, or pressing the wrong button) on the estimation of the remaining parameters (see <xref rid="pcbi.1004463.s008" ref-type="supplementary-material">S1 Text</xref> and <xref rid="pcbi.1004463.s003" ref-type="supplementary-material">S3B Fig</xref> for further explanation).</p>
</sec>
<sec id="sec022">
<title>Model sets</title>
<p>When fitting data from individual days, we considered a hybrid RL model that included a single learning rate (<bold><italic>α</italic></bold>) and softmax temperature (<bold><italic>β</italic></bold>), a weighting parameter that governs the balance between model-free/model-based control (<bold><italic>w</italic></bold>), and a lapse rate (<bold><italic>ε</italic></bold>). The eligibility trace (<bold><italic>λ</italic></bold>) was fixed at 1. Model-free and model-based algorithms were nested versions of the hybrid model where <bold><italic>w</italic></bold> was set to 0 and 1 respectively.</p>
<p>When fitting data across all days, we considered a family of (nested) hybrid RL models in which specific parameters were omitted or included as fixed versus free parameters. More complex models included separate RL parameters for first and second stage choices, an eligibility trace, and a slope parameter that permitted the weighting between model-free and model-based control to shift across days. See <xref rid="pcbi.1004463.s005" ref-type="supplementary-material">S2 Table</xref> for the full model set.</p>
</sec>
<sec id="sec023">
<title>Model fitting and comparison</title>
<p>The model fitting routine follows that previously described by Huys and colleagues [<xref rid="pcbi.1004463.ref048" ref-type="bibr">48</xref>]. Each model yielded a parameter vector, <italic>θ</italic><sub><italic>i</italic></sub>, for each subject, <italic>i</italic>. Before inference, all parameters were suitably transformed to enforce constraints (log and inverse sigmoid transforms). Model fitting at the individual level aimed to find the maximum a posteriori estimate of <italic>θ</italic><sub><italic>i</italic></sub>, given a vector of each subject’s choices,<italic>C</italic><sub><italic>i</italic></sub>:
<disp-formula id="pcbi.1004463.e010">
<alternatives>
<graphic id="pcbi.1004463.e010g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004463.e010" xlink:type="simple"/>
<mml:math display="block" id="M10" overflow="scroll">
<mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mi>θ</mml:mi></mml:msub><mml:mo> </mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mi>ϑ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow>
</mml:math>
</alternatives>
</disp-formula></p>
<p>We used a hierarchical (random effects) model-fitting approach, with the assumption that parameter estimates were normally distributed at the group level, where <italic>ϑ</italic> are the parameters of the empirical normal prior distribution (hyperparameters) on <italic>θ</italic>. The hierarchical approach allows the population-level distribution of data to constrain unreliable parameter estimates at the individual level. We estimated the maximum-likelihood hyperparameters, given the data from all <italic>N</italic> subjects:
<disp-formula id="pcbi.1004463.e011">
<alternatives>
<graphic id="pcbi.1004463.e011g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004463.e011" xlink:type="simple"/>
<mml:math display="block" id="M11" overflow="scroll">
<mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>ϑ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mi>ϑ</mml:mi></mml:msub><mml:mo> </mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>…</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>N</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mi>ϑ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mi>ϑ</mml:mi></mml:msub><mml:munder><mml:mrow><mml:msup><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>∏</mml:mo></mml:mstyle><mml:mo>​</mml:mo></mml:msup></mml:mrow><mml:mi>i</mml:mi></mml:munder><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mi>ϑ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
where:
<disp-formula id="pcbi.1004463.e012">
<alternatives>
<graphic id="pcbi.1004463.e012g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004463.e012" xlink:type="simple"/>
<mml:math display="block" id="M12" overflow="scroll">
<mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mi>ϑ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:msup><mml:mrow><mml:msup><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>∫</mml:mo></mml:mstyle><mml:mo>​</mml:mo></mml:msup></mml:mrow><mml:mo>​</mml:mo></mml:msup><mml:mi>d</mml:mi><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo> </mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mi>ϑ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow>
</mml:math>
</alternatives>
</disp-formula></p>
<p>The intractable integral above was estimated by Expectation-Maximization (EM). The E-step at the <italic>k</italic>th iteration sought the maximum a posteriori parameter estimates for each subject (given an estimate of the empirical prior from the preceding iteration, achieved by unconstrained nonlinear optimization in Matlab, Mathworks, MA, USA):
<disp-formula id="pcbi.1004463.e013">
<alternatives>
<graphic id="pcbi.1004463.e013g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004463.e013" xlink:type="simple"/>
<mml:math display="block" id="M13" overflow="scroll">
<mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msup><mml:mrow/><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mi>θ</mml:mi></mml:msub><mml:mo> </mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:msup><mml:mi>ϑ</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow>
</mml:math>
</alternatives>
</disp-formula></p>
<p>We used a Laplace approximation, which assumes that the likelihood surface is normally distributed around the maximum a posteriori parameter estimate:
<disp-formula id="pcbi.1004463.e014">
<alternatives>
<graphic id="pcbi.1004463.e014g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004463.e014" xlink:type="simple"/>
<mml:math display="block" id="M14" overflow="scroll">
<mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>≈</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msup><mml:mrow/><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:msup><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mo>​</mml:mo></mml:msup></mml:mrow><mml:mo>​</mml:mo></mml:msup><mml:msubsup><mml:mrow/><mml:mi>i</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
Where <inline-formula id="pcbi.1004463.e015"><alternatives><graphic id="pcbi.1004463.e015g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004463.e015" xlink:type="simple"/><mml:math display="inline" id="M15" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:msup><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mo>​</mml:mo></mml:msup></mml:mrow><mml:mo>​</mml:mo></mml:msup><mml:msubsup><mml:mrow/><mml:mi>i</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> is the second moment around <inline-formula id="pcbi.1004463.e016"><alternatives><graphic id="pcbi.1004463.e016g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004463.e016" xlink:type="simple"/><mml:math display="inline" id="M16" overflow="scroll"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msup><mml:mrow/><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>, which approximates the variance. In the M-step, the estimated hyperparameters <italic>ϑ</italic><sup><italic>(k)</italic></sup> of the normal prior distribution, mean <italic>μ</italic>, and factorized variance, <italic>σ</italic><sup>2</sup>, were updated as follows:
<disp-formula id="pcbi.1004463.e017">
<alternatives>
<graphic id="pcbi.1004463.e017g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004463.e017" xlink:type="simple"/>
<mml:math display="block" id="M17" overflow="scroll">
<mml:mrow><mml:msup><mml:mi>μ</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munder><mml:mrow><mml:msup><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mo>​</mml:mo></mml:msup></mml:mrow><mml:mi>i</mml:mi></mml:munder><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msup><mml:mrow/><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
<disp-formula id="pcbi.1004463.e018">
<alternatives>
<graphic id="pcbi.1004463.e018g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004463.e018" xlink:type="simple"/>
<mml:math display="block" id="M18" overflow="scroll">
<mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munder><mml:mrow><mml:msup><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mo>​</mml:mo></mml:msup></mml:mrow><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msup><mml:mrow/><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:msup><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mo>​</mml:mo></mml:msup></mml:mrow><mml:mo>​</mml:mo></mml:msup><mml:msubsup><mml:mrow/><mml:mi>i</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>μ</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow>
</mml:math>
</alternatives>
</disp-formula></p>
<p>We compared models by Bayesian model evidence, <italic>p</italic>(<italic>C</italic><sub>1</sub> … <italic>C</italic><sub><italic>N</italic></sub>|<italic>M</italic>), approximated as <italic>BIC</italic><sub><italic>int</italic></sub>:
<disp-formula id="pcbi.1004463.e019">
<alternatives>
<graphic id="pcbi.1004463.e019g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004463.e019" xlink:type="simple"/>
<mml:math display="block" id="M19" overflow="scroll">
<mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>B</mml:mi><mml:mi>I</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mtext>log</mml:mtext><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>…</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>N</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>ϑ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:msup><mml:mtext>)</mml:mtext><mml:mo>−</mml:mo><mml:mo> </mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo>|</mml:mo><mml:mi>M</mml:mi><mml:mo>|</mml:mo></mml:mrow><mml:mtext>log</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>…</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>N</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
Where |<italic>C</italic><sub><italic>1</italic></sub> … <italic>C</italic><sub><italic>N</italic></sub>| is the total number of choices made by all subjects, and |<italic>M</italic>| is number of hyperparameters fitted. Notably here, by distinction from conventional BIC, <inline-formula id="pcbi.1004463.e020"><alternatives><graphic id="pcbi.1004463.e020g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004463.e020" xlink:type="simple"/><mml:math display="inline" id="M20" overflow="scroll"><mml:mrow><mml:mtext>log</mml:mtext><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>…</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>N</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>ϑ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:msup><mml:mtext>)</mml:mtext></mml:mrow></mml:math></alternatives></inline-formula> is a sum over the model evidence at the subject level by integrating over subject-level parameters:
<disp-formula id="pcbi.1004463.e021">
<alternatives>
<graphic id="pcbi.1004463.e021g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004463.e021" xlink:type="simple"/>
<mml:math display="inline" id="M21" overflow="scroll"><mml:mrow><mml:mtext>log</mml:mtext><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>…</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>N</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>ϑ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:msup><mml:mtext>)</mml:mtext><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:munder><mml:mrow><mml:msup><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mo>​</mml:mo></mml:msup></mml:mrow><mml:mi>i</mml:mi></mml:munder><mml:mtext>log</mml:mtext><mml:msup><mml:mrow><mml:msup><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>∫</mml:mo></mml:mstyle><mml:mo>​</mml:mo></mml:msup></mml:mrow><mml:mo>​</mml:mo></mml:msup><mml:mi>d</mml:mi><mml:mi>θ</mml:mi><mml:mo> </mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo> </mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>θ</mml:mi><mml:mo>|</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>ϑ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo> </mml:mo><mml:mo>≈</mml:mo><mml:mo> </mml:mo><mml:munder><mml:mrow><mml:msup><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mo>​</mml:mo></mml:msup></mml:mrow><mml:mi>i</mml:mi></mml:munder><mml:mtext>log</mml:mtext><mml:mfrac><mml:mn>1</mml:mn><mml:mi>K</mml:mi></mml:mfrac><mml:munderover><mml:mrow><mml:msup><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mo>​</mml:mo></mml:msup></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msup><mml:mi>θ</mml:mi><mml:mi>k</mml:mi></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
</p>
<p>The right hand expression approximates the integral by summing over <italic>K</italic> samples, drawn from the empirical prior, <inline-formula id="pcbi.1004463.e022"><alternatives><graphic id="pcbi.1004463.e022g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004463.e022" xlink:type="simple"/><mml:math display="inline" id="M22" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>θ</mml:mi><mml:mo>|</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>ϑ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>. Thus the individual-level parameters intervene between the data and the group-level inference, but are averaged out when comparing models.</p>
</sec>
</sec>
<sec id="sec024">
<title>3-back logistic regression</title>
<p>In line with recent studies using the two-step task, we considered model-free and model-based influences on choice in the current trial, with respect to events that occurred up to 3 trials in the past [<xref rid="pcbi.1004463.ref020" ref-type="bibr">20</xref>]. Here, the dependent variable on trial <italic>t</italic> was 1 when stimulus A was chosen and 0 when stimulus B was chosen at the first-stage. Each regressor then described whether events on trial <italic>t</italic><sub><italic>-1</italic></sub>, <italic>t</italic><sub><italic>-2</italic></sub> and <italic>t</italic><sub><italic>-3</italic></sub> would increase (coded as +1) or decrease (coded as -1) the probability of choosing A according to a model-free or a model-based system (6 regressors in total). Importantly, if a trial involved a common transition, both systems make identical predictions. However, opposing predictions emerge following uncommon transitions. We implemented a random-effects logistic regression in Matlab (MathWorks) and performed one-sample t-tests on the resulting coefficient estimates for the 6 regressors, separately for trained (day 3) versus untrained (day 1), and dual-task (high load) versus single-task (low load) conditions (see <xref rid="pcbi.1004463.g004" ref-type="fig">Fig 4</xref> and <xref rid="pcbi.1004463.s002" ref-type="supplementary-material">S2 Fig</xref>).</p>
</sec>
</sec>
<sec id="sec025">
<title>Supporting Information</title>
<supplementary-material id="pcbi.1004463.s001" xlink:href="info:doi/10.1371/journal.pcbi.1004463.s001" mimetype="image/tiff" position="float" xlink:type="simple">
<label>S1 Fig</label>
<caption>
<title>Model-free and model-based influences on choice: ‘Low load group’.</title>
<p>We performed a logistic regression on data from the ‘low load group ‘ on day 3 of training to estimate the relationship between choice on trial <italic>t</italic> and events occurring on trial <italic>t</italic><sub><italic>-1</italic></sub> up to <italic>t</italic><sub><italic>-3</italic></sub>. Here, regression coefficients can be interpreted as reflecting a model-free or model-based influence on choice, where larger coefficients indicate a stronger influence. In the single-task condition (blue bars), model-free and model-based coefficients were significantly different from 0 (up to 3 trials in the past), suggesting that subjects used a hybrid of both strategies. In the dual-task (high load) condition (orange bars), we observed a significant influence of a model-based system, that did not differ from the single-task condition, up to 3 trials in the past. In contrast, we found no significant influence of a model-free system. These results are consistent with data from the ‘high load group’ (see <xref rid="pcbi.1004463.g004" ref-type="fig">Fig 4</xref>). Vertical lines represent SEM. * denotes p = &lt; 0.05, ‡ denotes p = 0.08.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004463.s002" xlink:href="info:doi/10.1371/journal.pcbi.1004463.s002" mimetype="image/tiff" position="float" xlink:type="simple">
<label>S2 Fig</label>
<caption>
<title>Switch-stay choice pairs.</title>
<p>Bar plots show the average probability with which subjects chose to repeat their first-stage action on the subsequent trial as a function of the transition (common vs. uncommon) and outcome (rewarded vs. unrewarded) on the previous trial. Blue bars correspond to common transitions and red bars correspond to uncommon transitions. Vertical lines represent SEM. (<bold>A</bold>) Data from the ‘high load group’. The upper panel corresponds to the single-task condition and the lower panel to the dual-task condition. Choice is plotted separately for all 3 days. (<bold>B</bold>) Data from the ‘low load group’. Behavior is plotted across all 3 days for the single-task condition, and for day 3 alone in the dual-task condition.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004463.s003" xlink:href="info:doi/10.1371/journal.pcbi.1004463.s003" mimetype="image/tiff" position="float" xlink:type="simple">
<label>S3 Fig</label>
<caption>
<title>The effect of utilizing a softmax lapse rate.</title>
<p><bold>(A)</bold> The left-hand side shows an empirical softmax function generated using data from the ‘high load group’ on day 1 and the single-task condition. For each subject, we grouped the values generated from the winning hybrid model (see <xref rid="pcbi.1004463.s004" ref-type="supplementary-material">S1 Table</xref>) into 10 bins, and calculated the mean probability with which the best action was chosen in each bin, including both first and second-stage choices. The plot is averaged over all 22 subjects in the ‘high load group’. Vertical bars represent SEM. The right-hand side shows a simulated softmax function with an inverse temperature (<bold><italic>β</italic></bold>) of 1, with and without including a lapse rate (<bold><italic>ε</italic></bold>) set to 0.1. The lapse rate compresses the boundaries of the softmax such that the probability of choosing a given action is forced to lie between the range of 1-2<italic>ε</italic>. <bold>(B)</bold> Here we show slices through the likelihood surface of a single subject when the lapse rate (<bold><italic>ε</italic></bold>) is set to 0 (left-hand side), or fit as a free parameter (right-hand side), respectively. The red crosses represent the peak of the likelihood surface. On the right-hand side, the black arrow represents the shift in the peak of the surface (and the equivalent shift in the best-fitting values of our model parameters) when <bold><italic>ε</italic></bold> is fit as a free parameter compared to when it is fixed at 0.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004463.s004" xlink:href="info:doi/10.1371/journal.pcbi.1004463.s004" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:type="simple">
<label>S1 Table</label>
<caption>
<title>Bayesian model comparison: Single days.</title>
<p>Results of a Bayesian model comparison that accounted for differences in model complexity. The hybrid model, which incorporated influences from both model-free and model-based control, fit subject data better than pure model-free and model-based RL algorithms across both trial types (single-task versus dual-task) and both groups (‘high load group’ day 1, ‘low load group’ day 3). Bold-face denotes the winning model (lowest iBIC score) for each condition. α = learning rate; β = softmax inverse temperature; ε = lapse rate; w = model-free/model-based weight. The eligibility trace, λ (not shown), was set to 1 in all cases. w was set to 0 and 1 for pure model-free and pure model-based RL respectively.</p>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004463.s005" xlink:href="info:doi/10.1371/journal.pcbi.1004463.s005" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:type="simple">
<label>S2 Table</label>
<caption>
<title>Bayesian model comparison: Multiple days.</title>
<p>Results of a Bayesian model comparison that accounts for differences in model complexity. More complex model variants include those that have separate parameters for first and second stage choices, an eligibility trace, and a parameter for capturing shifts in model-free versus model-based control across days (σ). In simpler models, RL parameters were fixed between first and second stage choices, the eligibility trace was fixed at 1, and σ was set to 0. Bold-face denotes the winning model (lowest iBIC score) for each condition. Parameters followed by a superscript of 1 or 2 correspond to first-stage or second-stage choices respectively. α = learning rate; β = softmax inverse temperature; ε = lapse rate; w = model-free/model-based weight; λ = eligibility trace; σ = slope governing a shift in model-free/model-based weight (w) across days.</p>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004463.s006" xlink:href="info:doi/10.1371/journal.pcbi.1004463.s006" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:type="simple">
<label>S3 Table</label>
<caption>
<title>Inferred group-level parameters.</title>
<p>Best-fitting parameter estimates shown separately for each group and condition (single-task versus dual-task), using data concatenated across all 3 days of training. Values represent mean parameter fits across all subjects. * represents fixed parameter values. Parameters followed by a superscript of 1 or 2 correspond to first-stage or second-stage choices respectively. In simpler models, λ was fixed at 1 and σ was set to 0. α = learning rate; β = softmax inverse temperature; ε = lapse rate; w = model-free/model-based weight; λ = eligibility trace; σ = slope governing a shift in model-free/model-based weight (w) across days.</p>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004463.s007" xlink:href="info:doi/10.1371/journal.pcbi.1004463.s007" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:type="simple">
<label>S4 Table</label>
<caption>
<title>Results of a logistic regression across days.</title>
<p>Table shows the group-level output of a logistic regression on first-stage switch-stay behavior, separately for single-task (‘high load group’ and ‘low load group’) and dual-task trials, from data concatenated across all 3 training sessions. We note that ‘reward x day’ was orthogonalized with respect to reward, and in turn ‘reward x transition x day’ was orthogonalized with respect to ‘reward x transition’. These regressors thus account for variance unexplained by the simpler main effect or 2-way interaction respectively (see <xref rid="sec011" ref-type="sec">Materials &amp; Methods</xref>). Bold-face denotes p &lt; 0.05 uncorrected for multiple comparisons. <italic>rew = reward</italic>; <italic>trans = transition</italic>.</p>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004463.s008" xlink:href="info:doi/10.1371/journal.pcbi.1004463.s008" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:type="simple">
<label>S1 Text</label>
<caption>
<title>Supporting Information.</title>
<p>(DOCX)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>We would like to thank Peter Dayan, Peter Smittenaar, Ross Otto and Kevin Miller for helpful discussions.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1004463.ref001"><label>1</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Daw</surname> <given-names>ND</given-names></name>, <name name-style="western"><surname>Niv</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name> (<year>2005</year>) <article-title>Uncertainty-based competition between prefrontal and dorsolateral striatal systems for behavioral control</article-title>. <source>Nat Neurosci</source> <volume>8</volume>: <fpage>1704</fpage>–<lpage>1711</lpage>. <object-id pub-id-type="pmid">16286932</object-id></mixed-citation></ref>
<ref id="pcbi.1004463.ref002"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Balleine</surname> <given-names>BW</given-names></name>, <name name-style="western"><surname>O'Doherty</surname> <given-names>JP</given-names></name> (<year>2010</year>) <article-title>Human and rodent homologies in action control: corticostriatal determinants of goal-directed and habitual action</article-title>. <source>Neuropsychopharmacology</source> <volume>35</volume>: <fpage>48</fpage>–<lpage>69</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/npp.2009.131" xlink:type="simple">10.1038/npp.2009.131</ext-link></comment> <object-id pub-id-type="pmid">19776734</object-id></mixed-citation></ref>
<ref id="pcbi.1004463.ref003"><label>3</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name> (<year>2013</year>) <article-title>Goals and habits in the brain</article-title>. <source>Neuron</source> <volume>80</volume>: <fpage>312</fpage>–<lpage>325</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2013.09.007" xlink:type="simple">10.1016/j.neuron.2013.09.007</ext-link></comment> <object-id pub-id-type="pmid">24139036</object-id></mixed-citation></ref>
<ref id="pcbi.1004463.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Everitt</surname> <given-names>BJ</given-names></name>, <name name-style="western"><surname>Robbins</surname> <given-names>TW</given-names></name> (<year>2005</year>) <article-title>Neural systems of reinforcement for drug addiction: from actions to habits to compulsion</article-title>. <source>Nat Neurosci</source> <volume>8</volume>: <fpage>1481</fpage>–<lpage>1489</lpage>. <object-id pub-id-type="pmid">16251991</object-id></mixed-citation></ref>
<ref id="pcbi.1004463.ref005"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Voon</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Derbyshire</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Ruck</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Irvine</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Worbe</surname> <given-names>Y</given-names></name>, <etal>et al</etal>. (<year>2014</year>) <article-title>Disorders of compulsivity: a common bias towards learning habits</article-title>. <source>Mol Psychiatry</source>.</mixed-citation></ref>
<ref id="pcbi.1004463.ref006"><label>6</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Sutton</surname> <given-names>RSB</given-names></name>, <name name-style="western"><surname>A.</surname> <given-names>G</given-names></name>. (<year>1998</year>) <source>Reinforcement Learning: An Introduction</source>: <publisher-name>MIT Press</publisher-name>, <publisher-loc>Cambridge, Massachusetts</publisher-loc>.</mixed-citation></ref>
<ref id="pcbi.1004463.ref007"><label>7</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Niv</surname> <given-names>Y</given-names></name> (<year>2008</year>) <article-title>Reinforcement learning: the good, the bad and the ugly</article-title>. <source>Curr Opin Neurobiol</source> <volume>18</volume>: <fpage>185</fpage>–<lpage>196</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.conb.2008.08.003" xlink:type="simple">10.1016/j.conb.2008.08.003</ext-link></comment> <object-id pub-id-type="pmid">18708140</object-id></mixed-citation></ref>
<ref id="pcbi.1004463.ref008"><label>8</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name> (<year>2008</year>) <chapter-title>The Role of Value Systems in Decision Making</chapter-title>. In: <name name-style="western"><surname>Engel</surname> <given-names>CaS</given-names></name>, <name name-style="western"><surname>Wolf</surname></name>, editor. <source>Better Than Conscious? Decision Making, the Human Mind, and Implications For Institutions</source>: <publisher-name>MIT Press</publisher-name>. pp. <fpage>51</fpage>–<lpage>70</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004463.ref009"><label>9</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Donald</surname> <given-names>NA</given-names></name>, <name name-style="western"><surname>Tim</surname> <given-names>S</given-names></name> (<year>1986</year>) <source>Attention to action: Willed and automatic control of behavior</source>. In: <name name-style="western"><surname>Davidson</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Schwartz</surname> <given-names>GE</given-names></name>, <name name-style="western"><surname>Shapiro</surname> <given-names>D</given-names></name>, editors. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Plenum</publisher-name>. pp. pp <fpage>1</fpage>–<lpage>18</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004463.ref010"><label>10</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Owen</surname> <given-names>AM</given-names></name> (<year>1997</year>) <article-title>Cognitive planning in humans: neuropsychological, neuroanatomical and neuropharmacological perspectives</article-title>. <source>Prog Neurobiol</source> <volume>53</volume>: <fpage>431</fpage>–<lpage>450</lpage>. <object-id pub-id-type="pmid">9421831</object-id></mixed-citation></ref>
<ref id="pcbi.1004463.ref011"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Alvarez</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Emory</surname> <given-names>E</given-names></name> (<year>2006</year>) <article-title>Executive function and the frontal lobes: a meta-analytic review</article-title>. <source>Neuropsychol Rev</source> <volume>16</volume>: <fpage>17</fpage>–<lpage>42</lpage>. <object-id pub-id-type="pmid">16794878</object-id></mixed-citation></ref>
<ref id="pcbi.1004463.ref012"><label>12</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kennerley</surname> <given-names>SW</given-names></name>, <name name-style="western"><surname>Walton</surname> <given-names>ME</given-names></name>, <name name-style="western"><surname>Behrens</surname> <given-names>TE</given-names></name>, <name name-style="western"><surname>Buckley</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Rushworth</surname> <given-names>MF</given-names></name> (<year>2006</year>) <article-title>Optimal decision making and the anterior cingulate cortex</article-title>. <source>Nat Neurosci</source> <volume>9</volume>: <fpage>940</fpage>–<lpage>947</lpage>. <object-id pub-id-type="pmid">16783368</object-id></mixed-citation></ref>
<ref id="pcbi.1004463.ref013"><label>13</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Valentin</surname> <given-names>VV</given-names></name>, <name name-style="western"><surname>Dickinson</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>O'Doherty</surname> <given-names>JP</given-names></name> (<year>2007</year>) <article-title>Determining the neural substrates of goal-directed learning in the human brain</article-title>. <source>J Neurosci</source> <volume>27</volume>: <fpage>4019</fpage>–<lpage>4026</lpage>. <object-id pub-id-type="pmid">17428979</object-id></mixed-citation></ref>
<ref id="pcbi.1004463.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Glascher</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Daw</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>O'Doherty</surname> <given-names>JP</given-names></name> (<year>2010</year>) <article-title>States versus rewards: dissociable neural prediction error signals underlying model-based and model-free reinforcement learning</article-title>. <source>Neuron</source> <volume>66</volume>: <fpage>585</fpage>–<lpage>595</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2010.04.016" xlink:type="simple">10.1016/j.neuron.2010.04.016</ext-link></comment> <object-id pub-id-type="pmid">20510862</object-id></mixed-citation></ref>
<ref id="pcbi.1004463.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Barbey</surname> <given-names>AK</given-names></name>, <name name-style="western"><surname>Koenigs</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Grafman</surname> <given-names>J</given-names></name> (<year>2012</year>) <article-title>Dorsolateral prefrontal contributions to human working memory</article-title>. <source>Cortex</source>.</mixed-citation></ref>
<ref id="pcbi.1004463.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Otto</surname> <given-names>AR</given-names></name>, <name name-style="western"><surname>Gershman</surname> <given-names>SJ</given-names></name>, <name name-style="western"><surname>Markman</surname> <given-names>AB</given-names></name>, <name name-style="western"><surname>Daw</surname> <given-names>ND</given-names></name> (<year>2013</year>) <article-title>The curse of planning: dissecting multiple reinforcement-learning systems by taxing the central executive</article-title>. <source>Psychol Sci</source> <volume>24</volume>: <fpage>751</fpage>–<lpage>761</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1177/0956797612463080" xlink:type="simple">10.1177/0956797612463080</ext-link></comment> <object-id pub-id-type="pmid">23558545</object-id></mixed-citation></ref>
<ref id="pcbi.1004463.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Otto</surname> <given-names>AR</given-names></name>, <name name-style="western"><surname>Raio</surname> <given-names>CM</given-names></name>, <name name-style="western"><surname>Chiang</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Phelps</surname> <given-names>EA</given-names></name>, <name name-style="western"><surname>Daw</surname> <given-names>ND</given-names></name> (<year>2013</year>) <article-title>Working-memory capacity protects model-based learning from stress</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>110</volume>: <fpage>20941</fpage>–<lpage>20946</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.1312011110" xlink:type="simple">10.1073/pnas.1312011110</ext-link></comment> <object-id pub-id-type="pmid">24324166</object-id></mixed-citation></ref>
<ref id="pcbi.1004463.ref018"><label>18</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Smittenaar</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>FitzGerald</surname> <given-names>TH</given-names></name>, <name name-style="western"><surname>Romei</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Wright</surname> <given-names>ND</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name> (<year>2013</year>) <article-title>Disruption of dorsolateral prefrontal cortex decreases model-based in favor of model-free control in humans</article-title>. <source>Neuron</source> <volume>80</volume>: <fpage>914</fpage>–<lpage>919</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2013.08.009" xlink:type="simple">10.1016/j.neuron.2013.08.009</ext-link></comment> <object-id pub-id-type="pmid">24206669</object-id></mixed-citation></ref>
<ref id="pcbi.1004463.ref019"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Daw</surname> <given-names>ND</given-names></name>, <name name-style="western"><surname>Gershman</surname> <given-names>SJ</given-names></name>, <name name-style="western"><surname>Seymour</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name> (<year>2011</year>) <article-title>Model-based influences on humans' choices and striatal prediction errors</article-title>. <source>Neuron</source> <volume>69</volume>: <fpage>1204</fpage>–<lpage>1215</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2011.02.027" xlink:type="simple">10.1016/j.neuron.2011.02.027</ext-link></comment> <object-id pub-id-type="pmid">21435563</object-id></mixed-citation></ref>
<ref id="pcbi.1004463.ref020"><label>20</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Smittenaar</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Prichard</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>FitzGerald</surname> <given-names>TH</given-names></name>, <name name-style="western"><surname>Diedrichsen</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name> (<year>2014</year>) <article-title>Transcranial direct current stimulation of right dorsolateral prefrontal cortex does not affect model-based or model-free reinforcement learning in humans</article-title>. <source>PLoS One</source> <volume>9</volume>: <fpage>e86850</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0086850" xlink:type="simple">10.1371/journal.pone.0086850</ext-link></comment> <object-id pub-id-type="pmid">24475185</object-id></mixed-citation></ref>
<ref id="pcbi.1004463.ref021"><label>21</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Skatova</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Chan</surname> <given-names>PA</given-names></name>, <name name-style="western"><surname>Daw</surname> <given-names>ND</given-names></name> (<year>2013</year>) <article-title>Extraversion differentiates between model-based and model-free strategies in a reinforcement learning task</article-title>. <source>Front Hum Neurosci</source> <volume>7</volume>: <fpage>525</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fnhum.2013.00525" xlink:type="simple">10.3389/fnhum.2013.00525</ext-link></comment> <object-id pub-id-type="pmid">24027514</object-id></mixed-citation></ref>
<ref id="pcbi.1004463.ref022"><label>22</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dux</surname> <given-names>PE</given-names></name>, <name name-style="western"><surname>Ivanoff</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Asplund</surname> <given-names>CL</given-names></name>, <name name-style="western"><surname>Marois</surname> <given-names>R</given-names></name> (<year>2006</year>) <article-title>Isolation of a central bottleneck of information processing with time-resolved FMRI</article-title>. <source>Neuron</source> <volume>52</volume>: <fpage>1109</fpage>–<lpage>1120</lpage>. <object-id pub-id-type="pmid">17178412</object-id></mixed-citation></ref>
<ref id="pcbi.1004463.ref023"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sigman</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Dehaene</surname> <given-names>S</given-names></name> (<year>2008</year>) <article-title>Brain mechanisms of serial and parallel processing during dual-task performance</article-title>. <source>J Neurosci</source> <volume>28</volume>: <fpage>7585</fpage>–<lpage>7598</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.0948-08.2008" xlink:type="simple">10.1523/JNEUROSCI.0948-08.2008</ext-link></comment> <object-id pub-id-type="pmid">18650336</object-id></mixed-citation></ref>
<ref id="pcbi.1004463.ref024"><label>24</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wunderlich</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name> (<year>2012</year>) <article-title>Mapping value based planning and extensively trained choice in the human brain</article-title>. <source>Nat Neurosci</source> <volume>15</volume>: <fpage>786</fpage>–<lpage>791</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.3068" xlink:type="simple">10.1038/nn.3068</ext-link></comment> <object-id pub-id-type="pmid">22406551</object-id></mixed-citation></ref>
<ref id="pcbi.1004463.ref025"><label>25</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kelly</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Garavan</surname> <given-names>H</given-names></name> (<year>2005</year>) <article-title>Human functional neuroimaging of brain changes associated with practice</article-title>. <source>Cereb Cortex</source> <volume>15</volume>: <fpage>1089</fpage>–<lpage>1102</lpage>. <object-id pub-id-type="pmid">15616134</object-id></mixed-citation></ref>
<ref id="pcbi.1004463.ref026"><label>26</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yildiz</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Beste</surname> <given-names>C</given-names></name> (<year>2014</year>) <article-title>Parallel and serial processing in dual-tasking differentially involves mechanisms in the striatum and the lateral prefrontal cortex</article-title>. <source>Brain Struct Funct</source>.</mixed-citation></ref>
<ref id="pcbi.1004463.ref027"><label>27</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bush</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Whalen</surname> <given-names>PJ</given-names></name>, <name name-style="western"><surname>Rosen</surname> <given-names>BR</given-names></name>, <name name-style="western"><surname>Jenike</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>McInerney</surname> <given-names>SC</given-names></name>, <etal>et al</etal>. (<year>1998</year>) <article-title>The counting Stroop: an interference task specialized for functional neuroimaging—validation study with functional MRI</article-title>. <source>Hum Brain Mapp</source> <volume>6</volume>: <fpage>270</fpage>–<lpage>282</lpage>. <object-id pub-id-type="pmid">9704265</object-id></mixed-citation></ref>
<ref id="pcbi.1004463.ref028"><label>28</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Poldrack</surname> <given-names>RA</given-names></name> (<year>2000</year>) <article-title>Imaging brain plasticity: conceptual and methodological issues—a theoretical review</article-title>. <source>Neuroimage</source> <volume>12</volume>: <fpage>1</fpage>–<lpage>13</lpage>. <object-id pub-id-type="pmid">10875897</object-id></mixed-citation></ref>
<ref id="pcbi.1004463.ref029"><label>29</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Beauchamp</surname> <given-names>MH</given-names></name>, <name name-style="western"><surname>Dagher</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Aston</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Doyon</surname> <given-names>J</given-names></name> (<year>2003</year>) <article-title>Dynamic functional changes associated with cognitive skill learning of an adapted version of the Tower of London task</article-title>. <source>Neuroimage</source> <volume>20</volume>: <fpage>1649</fpage>–<lpage>1660</lpage>. <object-id pub-id-type="pmid">14642475</object-id></mixed-citation></ref>
<ref id="pcbi.1004463.ref030"><label>30</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Keramati</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Dezfouli</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Piray</surname> <given-names>P</given-names></name> (<year>2011</year>) <article-title>Speed/accuracy trade-off between the habitual and the goal-directed processes</article-title>. <source>PLoS Comput Biol</source> <volume>7</volume>: <fpage>e1002055</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1002055" xlink:type="simple">10.1371/journal.pcbi.1002055</ext-link></comment> <object-id pub-id-type="pmid">21637741</object-id></mixed-citation></ref>
<ref id="pcbi.1004463.ref031"><label>31</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Knight</surname> <given-names>RT</given-names></name>, <name name-style="western"><surname>Grabowecky</surname> <given-names>MF</given-names></name>, <name name-style="western"><surname>Scabini</surname> <given-names>D</given-names></name> (<year>1995</year>) <article-title>Role of human prefrontal cortex in attention control</article-title>. <source>Adv Neurol</source> <volume>66</volume>: <fpage>21</fpage>–<lpage>34</lpage>; discussion 34–26. <object-id pub-id-type="pmid">7771302</object-id></mixed-citation></ref>
<ref id="pcbi.1004463.ref032"><label>32</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Smith</surname> <given-names>EE</given-names></name>, <name name-style="western"><surname>Jonides</surname> <given-names>J</given-names></name> (<year>1999</year>) <article-title>Storage and executive processes in the frontal lobes</article-title>. <source>Science</source> <volume>283</volume>: <fpage>1657</fpage>–<lpage>1661</lpage>. <object-id pub-id-type="pmid">10073923</object-id></mixed-citation></ref>
<ref id="pcbi.1004463.ref033"><label>33</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Behrens</surname> <given-names>TE</given-names></name>, <name name-style="western"><surname>Woolrich</surname> <given-names>MW</given-names></name>, <name name-style="western"><surname>Walton</surname> <given-names>ME</given-names></name>, <name name-style="western"><surname>Rushworth</surname> <given-names>MF</given-names></name> (<year>2007</year>) <article-title>Learning the value of information in an uncertain world</article-title>. <source>Nat Neurosci</source> <volume>10</volume>: <fpage>1214</fpage>–<lpage>1221</lpage>. <object-id pub-id-type="pmid">17676057</object-id></mixed-citation></ref>
<ref id="pcbi.1004463.ref034"><label>34</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Badre</surname> <given-names>D</given-names></name> (<year>2008</year>) <article-title>Cognitive control, hierarchy, and the rostro-caudal organization of the frontal lobes</article-title>. <source>Trends Cogn Sci</source> <volume>12</volume>: <fpage>193</fpage>–<lpage>200</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.tics.2008.02.004" xlink:type="simple">10.1016/j.tics.2008.02.004</ext-link></comment> <object-id pub-id-type="pmid">18403252</object-id></mixed-citation></ref>
<ref id="pcbi.1004463.ref035"><label>35</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Waskom</surname> <given-names>ML</given-names></name>, <name name-style="western"><surname>Kumaran</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Gordon</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Rissman</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Wagner</surname> <given-names>AD</given-names></name> (<year>2014</year>) <article-title>Frontoparietal representations of task context support the flexible control of goal-directed cognition</article-title>. <source>J Neurosci</source> <volume>34</volume>: <fpage>10743</fpage>–<lpage>10755</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.5282-13.2014" xlink:type="simple">10.1523/JNEUROSCI.5282-13.2014</ext-link></comment> <object-id pub-id-type="pmid">25100605</object-id></mixed-citation></ref>
<ref id="pcbi.1004463.ref036"><label>36</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gershman</surname> <given-names>SJ</given-names></name>, <name name-style="western"><surname>Markman</surname> <given-names>AB</given-names></name>, <name name-style="western"><surname>Otto</surname> <given-names>AR</given-names></name> (<year>2014</year>) <article-title>Retrospective Revaluation in Sequential Decision Making: A Tale of Two Systems</article-title>. <source>Journal of Experimental Psychology-General</source> <volume>143</volume>: <fpage>182</fpage>–<lpage>194</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/a0030844" xlink:type="simple">10.1037/a0030844</ext-link></comment> <object-id pub-id-type="pmid">23230992</object-id></mixed-citation></ref>
<ref id="pcbi.1004463.ref037"><label>37</label><mixed-citation publication-type="other" xlink:type="simple">Miller KJ, Erlich JC, Kopec CD, Botvinick MM, Brody CD (2013) A multi-step decision task to distinguish model-based from model-free reinforcement learning in rats. Presented at Society for Neuroscience, San Diego (855.13).</mixed-citation></ref>
<ref id="pcbi.1004463.ref038"><label>38</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wunderlich</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Smittenaar</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name> (<year>2012</year>) <article-title>Dopamine enhances model-based over model-free choice behavior</article-title>. <source>Neuron</source> <volume>75</volume>: <fpage>418</fpage>–<lpage>424</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2012.03.042" xlink:type="simple">10.1016/j.neuron.2012.03.042</ext-link></comment> <object-id pub-id-type="pmid">22884326</object-id></mixed-citation></ref>
<ref id="pcbi.1004463.ref039"><label>39</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kepecs</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Uchida</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Zariwala</surname> <given-names>HA</given-names></name>, <name name-style="western"><surname>Mainen</surname> <given-names>ZF</given-names></name> (<year>2008</year>) <article-title>Neural correlates, computation and behavioural impact of decision confidence</article-title>. <source>Nature</source> <volume>455</volume>: <fpage>227</fpage>–<lpage>231</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature07200" xlink:type="simple">10.1038/nature07200</ext-link></comment> <object-id pub-id-type="pmid">18690210</object-id></mixed-citation></ref>
<ref id="pcbi.1004463.ref040"><label>40</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>De Martino</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Fleming</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Garrett</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name> (<year>2013</year>) <article-title>Confidence in value-based choice</article-title>. <source>Nat Neurosci</source> <volume>16</volume>: <fpage>105</fpage>–<lpage>110</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.3279" xlink:type="simple">10.1038/nn.3279</ext-link></comment> <object-id pub-id-type="pmid">23222911</object-id></mixed-citation></ref>
<ref id="pcbi.1004463.ref041"><label>41</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Adams</surname> <given-names>CD</given-names></name>, <name name-style="western"><surname>Dickinson</surname> <given-names>A</given-names></name> (<year>1981</year>) <article-title>Instrumental Responding Following Reinforcer Devaluation</article-title>. <source>Quarterly Journal of Experimental Psychology Section B-Comparative and Physiological Psychology</source> <volume>33</volume>: <fpage>109</fpage>–<lpage>121</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004463.ref042"><label>42</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dickinson</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Nicholas</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Adams</surname> <given-names>CD</given-names></name> (<year>1983</year>) <article-title>The Effect of the Instrumental Training Contingency on Susceptibility to Reinforcer Devaluation</article-title>. <source>Quarterly Journal of Experimental Psychology Section B-Comparative and Physiological Psychology</source> <volume>35</volume>: <fpage>35</fpage>–<lpage>51</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004463.ref043"><label>43</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Balleine</surname> <given-names>BW</given-names></name>, <name name-style="western"><surname>Dickinson</surname> <given-names>A</given-names></name> (<year>1998</year>) <article-title>Goal-directed instrumental action: contingency and incentive learning and their cortical substrates</article-title>. <source>Neuropharmacology</source> <volume>37</volume>: <fpage>407</fpage>–<lpage>419</lpage>. <object-id pub-id-type="pmid">9704982</object-id></mixed-citation></ref>
<ref id="pcbi.1004463.ref044"><label>44</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tricomi</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Balleine</surname> <given-names>BW</given-names></name>, <name name-style="western"><surname>O'Doherty</surname> <given-names>JP</given-names></name> (<year>2009</year>) <article-title>A specific role for posterior dorsolateral striatum in human habit learning</article-title>. <source>Eur J Neurosci</source> <volume>29</volume>: <fpage>2225</fpage>–<lpage>2232</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1111/j.1460-9568.2009.06796.x" xlink:type="simple">10.1111/j.1460-9568.2009.06796.x</ext-link></comment> <object-id pub-id-type="pmid">19490086</object-id></mixed-citation></ref>
<ref id="pcbi.1004463.ref045"><label>45</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Friston</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Kilner</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Harrison</surname> <given-names>L</given-names></name> (<year>2006</year>) <article-title>A free energy principle for the brain</article-title>. <source>J Physiol Paris</source> <volume>100</volume>: <fpage>70</fpage>–<lpage>87</lpage>. <object-id pub-id-type="pmid">17097864</object-id></mixed-citation></ref>
<ref id="pcbi.1004463.ref046"><label>46</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Friston</surname> <given-names>K</given-names></name> (<year>2008</year>) <article-title>Hierarchical models in the brain</article-title>. <source>PLoS Comput Biol</source> <volume>4</volume>: <fpage>e1000211</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1000211" xlink:type="simple">10.1371/journal.pcbi.1000211</ext-link></comment> <object-id pub-id-type="pmid">18989391</object-id></mixed-citation></ref>
<ref id="pcbi.1004463.ref047"><label>47</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Waldron</surname> <given-names>EM</given-names></name>, <name name-style="western"><surname>Ashby</surname> <given-names>FG</given-names></name> (<year>2001</year>) <article-title>The effects of concurrent task interference on category learning: evidence for multiple category learning systems</article-title>. <source>Psychon Bull Rev</source> <volume>8</volume>: <fpage>168</fpage>–<lpage>176</lpage>. <object-id pub-id-type="pmid">11340863</object-id></mixed-citation></ref>
<ref id="pcbi.1004463.ref048"><label>48</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Huys</surname> <given-names>QJ</given-names></name>, <name name-style="western"><surname>Cools</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Golzer</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Friedel</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Heinz</surname> <given-names>A</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <article-title>Disentangling the roles of approach, activation and valence in instrumental and pavlovian responding</article-title>. <source>PLoS Comput Biol</source> <volume>7</volume>: <fpage>e1002028</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1002028" xlink:type="simple">10.1371/journal.pcbi.1002028</ext-link></comment> <object-id pub-id-type="pmid">21556131</object-id></mixed-citation></ref>
</ref-list>
</back>
</article>
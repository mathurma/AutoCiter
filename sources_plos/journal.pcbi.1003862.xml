<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id><journal-title-group>
<journal-title>PLoS Computational Biology</journal-title></journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-14-00382</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1003862</article-id>
<article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Biology and life sciences</subject><subj-group><subject>Computational biology</subject><subj-group><subject>Population modeling</subject></subj-group></subj-group><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognition</subject><subj-group><subject>Animal cognition</subject></subj-group></subj-group></subj-group></subj-group><subj-group><subject>Zoology</subject><subj-group><subject>Animal behavior</subject><subj-group><subject>Animal signaling and communication</subject><subject>Collective animal behavior</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Computer and information sciences</subject><subj-group><subject>Information theory</subject></subj-group><subj-group><subject>Network analysis</subject><subj-group><subject>Social networks</subject></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Confidence Sharing: An Economic Strategy for Efficient Information Flows in Animal Groups</article-title>
<alt-title alt-title-type="running-head">Confidence Sharing in Animal Groups</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Korman</surname><given-names>Amos</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Greenwald</surname><given-names>Efrat</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Feinerman</surname><given-names>Ofer</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
</contrib-group>
<aff id="aff1"><label>1</label><addr-line>Laboratoire d'Informatique Algorithmique: Fondements et Applications (LIAFA), CNRS &amp; University Paris Diderot, Paris, France</addr-line></aff>
<aff id="aff2"><label>2</label><addr-line>Department of Physics of Complex Systems, Weizmann Institute of Science, Rehovot, Israel</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Maloney</surname><given-names>Laurence T.</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group>
<aff id="edit1"><addr-line>New York University, United States of America</addr-line></aff>
<author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">ofer.feinerman@weizmann.ac.il</email></corresp>
<fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn>
<fn fn-type="con"><p>Conceived and designed the experiments: AK EG OF. Performed the experiments: AK EG OF. Analyzed the data: AK EG OF. Contributed reagents/materials/analysis tools: AK EG OF. Wrote the paper: AK EG OF.</p></fn>
</author-notes>
<pub-date pub-type="collection"><month>10</month><year>2014</year></pub-date>
<pub-date pub-type="epub"><day>2</day><month>10</month><year>2014</year></pub-date>
<volume>10</volume>
<issue>10</issue>
<elocation-id>e1003862</elocation-id>
<history>
<date date-type="received"><day>2</day><month>3</month><year>2014</year></date>
<date date-type="accepted"><day>18</day><month>8</month><year>2014</year></date>
</history>
<permissions>
<copyright-year>2014</copyright-year>
<copyright-holder>Korman et al</copyright-holder><license xlink:type="simple"><license-p>This is an open-access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions>
<abstract>
<p>Social animals may share information to obtain a more complete and accurate picture of their surroundings. However, physical constraints on communication limit the flow of information between interacting individuals in a way that can cause an accumulation of errors and deteriorated collective behaviors. Here, we theoretically study a general model of information sharing within animal groups. We take an algorithmic perspective to identify efficient communication schemes that are, nevertheless, economic in terms of communication, memory and individual internal computation. We present a simple and natural algorithm in which each agent compresses all information it has gathered into a single parameter that represents its confidence in its behavior. Confidence is communicated between agents by means of active signaling. We motivate this model by novel and existing empirical evidences for confidence sharing in animal groups. We rigorously show that this algorithm competes extremely well with the best possible algorithm that operates without any computational constraints. We also show that this algorithm is minimal, in the sense that further reduction in communication may significantly reduce performances. Our proofs rely on the Cramér-Rao bound and on our definition of a Fisher Channel Capacity. We use these concepts to quantify information flows within the group which are then used to obtain lower bounds on collective performance. The abstract nature of our model makes it rigorously solvable and its conclusions highly general. Indeed, our results suggest confidence sharing as a central notion in the context of animal communication.</p>
</abstract>
<abstract abstract-type="summary"><title>Author Summary</title>
<p>Cooperative groups are abundant on all scales of the biological world. Despite much empirical evidence on a wide variety of natural communication schemes, there is still a growing need for rigorous tools to quantify and understand the information flows involved. Here, we borrow techniques from information theory and theoretical distributed computing to study information sharing within animal groups. We consider a group of individuals that integrate personal and social information to obtain improved knowledge of their surroundings. We rigorously show that communication between such individuals can be compressed into simple messages that contain an opinion and a corresponding confidence parameter. While this algorithm is extremely efficient, further reduction in communication capacity may greatly hamper collective performances.</p>
</abstract>
<funding-group><funding-statement>This research was supported by the Clore Foundation, the Israel Science Foundation (FIRST grant no. 1694/10), the ANR grant DISPLEXITY, the INRIA grant GANG, and the Minerva Foundation. OF is the incumbent of the Shlomo and Michla Tomarin Career Development Chair. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="10"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<sec id="s1a">
<title>Background and motivation</title>
<p>Animals living in groups sense their surroundings both directly, by environmental cues, and indirectly, through countless social interactions. There is an abundance of experimental evidence for the usefulness of social information in increasing both the range (the “many eyes” principle) <xref ref-type="bibr" rid="pcbi.1003862-Treherne1">[1]</xref>–<xref ref-type="bibr" rid="pcbi.1003862-Berdahl1">[5]</xref> and the accuracy (the “many wrongs” principle) <xref ref-type="bibr" rid="pcbi.1003862-Simons1">[6]</xref>–<xref ref-type="bibr" rid="pcbi.1003862-Faria1">[9]</xref> at which environmental signals are perceived. Despite these advantages, there are many scenarios in which animals tend to prefer personal knowledge and direct environmental cues to social information <xref ref-type="bibr" rid="pcbi.1003862-Templeton1">[10]</xref>, <xref ref-type="bibr" rid="pcbi.1003862-Giraldeau2">[11]</xref>. Indeed, second hand information about the environment can become increasingly obsolete <xref ref-type="bibr" rid="pcbi.1003862-Laland1">[12]</xref>, <xref ref-type="bibr" rid="pcbi.1003862-Rieucau1">[13]</xref>, distorted <xref ref-type="bibr" rid="pcbi.1003862-Razin1">[14]</xref>, and partial <xref ref-type="bibr" rid="pcbi.1003862-Dall1">[15]</xref> as it passes from one individual to the next and, subsequently, lead to maladaptive responses <xref ref-type="bibr" rid="pcbi.1003862-Giraldeau2">[11]</xref>. These contradicting evidences call for a more comprehensive understanding of the usefulness of social information exchange and its limitations under noise.</p>
<p>A distinction can be made between passive and active social messaging <xref ref-type="bibr" rid="pcbi.1003862-Wilkinson1">[16]</xref>. Passive information <xref ref-type="bibr" rid="pcbi.1003862-Barclay1">[17]</xref>, <xref ref-type="bibr" rid="pcbi.1003862-Theraulaz1">[18]</xref> is transferred as inadvertent cues <xref ref-type="bibr" rid="pcbi.1003862-Danchin1">[19]</xref>, <italic>i.e.</italic>, with no direct intention of signaling, evident by the behavior of one animal are perceived by others. As an example, models of complex flocking behaviors typically rely exclusively on passive interactions in which animals align their movements to those performed by their neighbors <xref ref-type="bibr" rid="pcbi.1003862-Simons1">[6]</xref>, <xref ref-type="bibr" rid="pcbi.1003862-Couzin1">[20]</xref>. However, there is evidence that passive information is often accompanied by active, or intentional, signals that communicate part of the animal's internal state. In cooperative situations <xref ref-type="bibr" rid="pcbi.1003862-Krebs1">[21]</xref> active signals may enhance the effectiveness of passive cues and lead to faster and more accurate performance <xref ref-type="bibr" rid="pcbi.1003862-Rieucau1">[13]</xref>, <xref ref-type="bibr" rid="pcbi.1003862-Razin1">[14]</xref>.</p>
<p>While elaborate active communication has its advantages, simplicity is, nonetheless, important. Indeed, it is required that communication remain energetically cheap <xref ref-type="bibr" rid="pcbi.1003862-Horn1">[22]</xref>, cognitively manageable <xref ref-type="bibr" rid="pcbi.1003862-Laughlin1">[23]</xref>, <xref ref-type="bibr" rid="pcbi.1003862-Burns1">[24]</xref> and concise <xref ref-type="bibr" rid="pcbi.1003862-Krebs1">[21]</xref>. A main goal of this work is to identify <italic>simple</italic> active communication schemes that enhance the reliability and the benefits of social information.</p>
<p>Animal groups, together with numerous other biological ensembles, are naturally described as entities that collect, share and process information. Unfortunately, with the exception of neuroscience <xref ref-type="bibr" rid="pcbi.1003862-Rieke1">[25]</xref>, the potential of information theory in providing rigorous descriptions of such ensembles remains, largely, unrealized <xref ref-type="bibr" rid="pcbi.1003862-Dall1">[15]</xref>. For example, the term “information flow” is often used to describe the gradual process in which messages are being relayed between agents <xref ref-type="bibr" rid="pcbi.1003862-Detrain1">[26]</xref>, <xref ref-type="bibr" rid="pcbi.1003862-Franks1">[27]</xref>. Although the speeds and directionality of information flows have been described for several systems <xref ref-type="bibr" rid="pcbi.1003862-Treherne1">[1]</xref>, <xref ref-type="bibr" rid="pcbi.1003862-Blonder1">[28]</xref>–<xref ref-type="bibr" rid="pcbi.1003862-Handegard1">[30]</xref>, it remains unclear how to rigorously analyze such flows to quantify the amount of transferred information. A second goal of this paper lies in introducing information theoretical tools as a means of quantifying information flows within a group of agents.</p>
<p>In what follows, we use an algorithmic perspective <xref ref-type="bibr" rid="pcbi.1003862-Kleinberg1">[31]</xref>–<xref ref-type="bibr" rid="pcbi.1003862-Chazelle1">[33]</xref> to tackle the question of information sharing within a population of cooperative agents. The agents use environmental cues intertwined with social interactions to obtain ever refined estimates of some fixed, unknown environmental target value <xref ref-type="bibr" rid="pcbi.1003862-McNamara1">[34]</xref>. Interactions include both passive and active components. A passive observation amounts to obtaining a noisy measurement of the observed agent's behavior. An active signal exposes some part of the observed agent's internal state. We are interested in how active signals may be economically used to best enhance the flow and benefits of passive communication.</p>
<p>To study this question we compare two models. The <italic>non-restrictive</italic> model allows for infinite resources in terms of memory, active communication and individual computation. On the other hand, the <italic>compact</italic> model restricts active communication and memory to a single parameter and individual computation to a constant number of the basic arithmetic operations. We present recent experimental observations <xref ref-type="bibr" rid="pcbi.1003862-Razin1">[14]</xref>, <xref ref-type="bibr" rid="pcbi.1003862-Harcourt1">[35]</xref>–<xref ref-type="bibr" rid="pcbi.1003862-Couzin2">[37]</xref> as well as novel evidence regarding ant interactions that suggest that the communication of a self-confidence parameter is a relevant process within animal populations. Inspired by such observations, we propose a simple and natural algorithm for the compact model that relies on the sharing of confidence. This model can serve as a basic representative of the family of confidence-sharing algorithms. We show that the performances of this algorithm are highly competitive with those of the best possible algorithm for the non-restrictive case.</p>
<p>One may be tempted to reduce active communication below what is permitted by the compact model, but we show that this may incur a heavy price in performance.</p>
</sec><sec id="s1b">
<title>The model</title>
<sec id="s1b1">
<title>Formulation of the problem</title>
<p>We study a simple model for the sharing and dissemination of information within a population of anonymous agents (see section 1 in <xref ref-type="supplementary-material" rid="pcbi.1003862.s003">Text S1</xref>). Each agent, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e001" xlink:type="simple"/></inline-formula>, is associated with an external state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e002" xlink:type="simple"/></inline-formula> which represents, for example, its physical location or direction of motion. The goal of each agent (following <xref ref-type="bibr" rid="pcbi.1003862-McNamara1">[34]</xref>) is to modify this state so as to be as close as possible to a target value, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e003" xlink:type="simple"/></inline-formula>. More formally, for each agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e004" xlink:type="simple"/></inline-formula>, we view its external state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e005" xlink:type="simple"/></inline-formula> at time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e006" xlink:type="simple"/></inline-formula> as an <italic>estimator</italic> of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e007" xlink:type="simple"/></inline-formula>. At any given time, the agent may modify its external state such that it is maintained as an unbiased estimator with minimal mean square error (MSE). We stress here that this work is restricted to this specific cost function and that other estimators require further study (see, for example, <xref ref-type="bibr" rid="pcbi.1003862-Biro1">[7]</xref>, <xref ref-type="bibr" rid="pcbi.1003862-Couzin2">[37]</xref>, <xref ref-type="bibr" rid="pcbi.1003862-Couzin3">[38]</xref>). For the sake of conciseness, from here onwards, we refer to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e008" xlink:type="simple"/></inline-formula> as “location” and to a change in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e009" xlink:type="simple"/></inline-formula> as a “move”.</p>
<p>To initialize the system, the location <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e010" xlink:type="simple"/></inline-formula> of each agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e011" xlink:type="simple"/></inline-formula> is randomly chosen according to some arbitrary distribution <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e012" xlink:type="simple"/></inline-formula> centered at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e013" xlink:type="simple"/></inline-formula>. We assume that the variance of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e014" xlink:type="simple"/></inline-formula> is known to agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e015" xlink:type="simple"/></inline-formula>. The agent may store this and other pieces of information it collects in its <italic>memory</italic>.</p>
<p>Agents improve their estimation of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e016" xlink:type="simple"/></inline-formula> by relying on both social interactions and environmental cues, where in-between such events they are free to perform moves and adjust their memory state. Technically, environmental cues are included by having a particular, immobile set of agents represent the environment. For simplicity of notation, we focus on pair-wise interactions which can be either uni- or bi-directional (our results transfer to interactions that involve a larger number of agents in a straightforward manner). The information transferred in such interactions may contain both active and passive signals. Passive information is obtained as agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e017" xlink:type="simple"/></inline-formula> measures its current relative distance <xref ref-type="bibr" rid="pcbi.1003862-Patwari1">[39]</xref> from agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e018" xlink:type="simple"/></inline-formula>, that is, <disp-formula id="pcbi.1003862.e019"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003862.e019" xlink:type="simple"/></disp-formula>where the additive noise term, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e020" xlink:type="simple"/></inline-formula>, is chosen from some arbitrary distribution <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e021" xlink:type="simple"/></inline-formula> whose variance, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e022" xlink:type="simple"/></inline-formula>, is known to the agents. Active signals are modeled as messages that expose some part of the internal memory of agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e023" xlink:type="simple"/></inline-formula> to the observing agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e024" xlink:type="simple"/></inline-formula>.</p>
</sec><sec id="s1b2">
<title>A remark regarding related problems in other disciplines</title>
<p>The problem we address is somewhat related to the <italic>Relative Location Estimation</italic> problem studied within the context of sensor networks <xref ref-type="bibr" rid="pcbi.1003862-Patwari1">[39]</xref>. There are, however, important differences of emphasis between these two cases. First, most sensor localization algorithms are designed for static sensors <xref ref-type="bibr" rid="pcbi.1003862-Patwari1">[39]</xref> and are often, to some extent, centralized <xref ref-type="bibr" rid="pcbi.1003862-Amundson1">[40]</xref>. Our setting is inherently distributed and moreover, mobile; agents continuously update their location in a way that effects subsequent distance measurement by others. Second, restrictions on internal memory and computation of sensors are typically not as constraining as those we consider here (especially in the case of actively mobile sensors <xref ref-type="bibr" rid="pcbi.1003862-Amundson1">[40]</xref>). Finally, while sensor localization algorithms typically focus on triangulation solutions that rely on fixed communication networks with unique identities <xref ref-type="bibr" rid="pcbi.1003862-Rydstrom1">[41]</xref>, our setting is anonymous and does not allow agents to control with whom they interact. The question we face is further related to computer science problems such as <italic>consensus</italic> and <italic>gossip</italic> <xref ref-type="bibr" rid="pcbi.1003862-Kempe1">[42]</xref>, however these are typically discrete in nature, and do not take communication noise into account.</p>
</sec></sec></sec><sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>The optimal algorithm</title>
<p>To evaluate the performances of algorithms, we compare them to Opt (see section 2 in <xref ref-type="supplementary-material" rid="pcbi.1003862.s003">Text S1</xref>), the best possible algorithm operating under the non-restrictive model.</p>
<p>Being as liberal as possible, we further assume that active communication is completely reliable. This is since any definition of active noise must depend on a particular choice of a communication scheme which, in turn, may restrict an optimal algorithm. Moreover, here, agents are initially provided not only with the variances of the noise and initial distributions but also with their full functional forms. That is, the memory of an agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e025" xlink:type="simple"/></inline-formula> initially contains <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e026" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e027" xlink:type="simple"/></inline-formula>. Without loss of generality, the memory of an agent further includes a vector that contains all prior moves and distance measurements it took. Following an interaction, the observing agent adds to its memory not only the new noisy distance measurement but also the full memory content of the observed agent. This leads to the accumulation of large nested data-structures. The agent may then perform arbitrarily sophisticated computations over its memory to adjust its location <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e028" xlink:type="simple"/></inline-formula> to its best possible estimate of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e029" xlink:type="simple"/></inline-formula>.</p>
<p>We stress that none of the proofs in this manuscript rely on the identification of an optimal algorithm. Nevertheless, for the sake of completeness, we specify Opt for independent meeting patterns (section 1.1.3 in <xref ref-type="supplementary-material" rid="pcbi.1003862.s003">Text S1</xref>), which are especially meaningful on short timescales or if the system is highly mixed. Indeed, in such cases, algorithm Opt can be precisely described (section 2.2 in <xref ref-type="supplementary-material" rid="pcbi.1003862.s003">Text S1</xref>). Specifically, each agent maintains a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e030" xlink:type="simple"/></inline-formula> that represents the relative positioning of the target value <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e031" xlink:type="simple"/></inline-formula> with respect to its current location. The pdf is initialized to be <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e032" xlink:type="simple"/></inline-formula>. Upon observing another agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e033" xlink:type="simple"/></inline-formula> at time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e034" xlink:type="simple"/></inline-formula>, agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e035" xlink:type="simple"/></inline-formula> performs the following operations:</p>
<p><bold>Algorithm Opt</bold></p>
<list list-type="bullet"><list-item>
<p><bold>Compute:</bold> normalize the next integral to obtain a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e036" xlink:type="simple"/></inline-formula> (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e037" xlink:type="simple"/></inline-formula> is a normalization constant):</p>
</list-item></list>
<p><disp-formula id="pcbi.1003862.e038"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003862.e038" xlink:type="simple"/></disp-formula></p>
<list list-type="bullet"><list-item>
<p><bold>Update external state:</bold> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e039" xlink:type="simple"/></inline-formula></p>
</list-item><list-item>
<p><bold>Update memory:</bold> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e040" xlink:type="simple"/></inline-formula></p>
</list-item></list>
<p>In general, as time passes, the description of the stored <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e041" xlink:type="simple"/></inline-formula> requires an increasing number of moments and its communication a more elaborate encoding scheme. Moreover, the calculations required for updates become increasingly complex.</p>
</sec><sec id="s2b">
<title>Difficulties towards efficient information fusion</title>
<p>Algorithm Opt relies on the transmission and updates of probability functions and on relatively complex calculations. We wish to identify a simple algorithm whose performance is highly competitive with that of Opt. To do this one faces several difficulties.</p>
<p>A first difficulty lies in the fact that the partial knowledge held by each agent is relative (<italic>e.g.</italic>, an estimation to the distance between this agent and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e042" xlink:type="simple"/></inline-formula>) and hence may require the agents to carefully fuse other perspectives than their own. This difficulty is enhanced, as the agents are constantly on the move. We have shown how <italic>non-restrictive</italic> algorithms may overcome such difficulties if each agent encodes all its previous moves in memory and then uses this information to deduce absolute measurements (section 2.1 in <xref ref-type="supplementary-material" rid="pcbi.1003862.s003">Text S1</xref>). In compact models, such tactics lose their effectiveness and it is not clear how agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e043" xlink:type="simple"/></inline-formula> should treat distance measurements to an agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e044" xlink:type="simple"/></inline-formula> whose position constantly changes over time.</p>
<p>It is known that a reasonable way to combine estimators is to form linear combinations in which each estimator is weighed by its inverse variance <xref ref-type="bibr" rid="pcbi.1003862-Graybill1">[43]</xref>. Although this is the best estimator that could be formed as a linear combination it is not overall optimal. Indeed, maintaining and communicating highly detailed memories can, in some cases, significantly improve an agent's assessment of the target value (for example, see <xref ref-type="fig" rid="pcbi-1003862-g001">Figure 1</xref>).</p>
<fig id="pcbi-1003862-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003862.g001</object-id><label>Figure 1</label><caption>
<title>Storing and communicating detailed assessments of target location is, in some cases, extremely beneficial.</title><p><bold>A.</bold> The memories of (pink) agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e045" xlink:type="simple"/></inline-formula> and (black) agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e046" xlink:type="simple"/></inline-formula> are represented by a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e047" xlink:type="simple"/></inline-formula> (capital F's) that summarizes their full information regarding the target. The agents locate themselves at the mean of their corresponding <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e048" xlink:type="simple"/></inline-formula> (marked by filled diamonds). We consider an interaction in which agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e049" xlink:type="simple"/></inline-formula> observes agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e050" xlink:type="simple"/></inline-formula> and updates its position and memory to those depicted in red. <bold>B.</bold> The agents are initiated as in A. However, before they interact, their memories are compressed into Gaussians (lowercase f's) that agree in mean and variance with their previous assessments. Note that since the mean values have not changed, the initial locations of the agents in both panels are identical. Following the interaction, agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e051" xlink:type="simple"/></inline-formula> has moved to a different location (compare red diamond to red circle) and has gained less information (compare variances of red curves) when compared to the case in which compression had been avoided. For simplicity, all interactions in this figure were taken to be noiseless.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003862.g001" position="float" xlink:type="simple"/></fig>
<p>This problem worsens in the context of an interacting population. Here, maintaining a high degree of detail requires storing an arbitrary number of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e052" xlink:type="simple"/></inline-formula> moments which may grow with every interaction. Discarding this accumulating information by repeatedly using simple (<italic>e.g.</italic> linear) estimators could, therefore, lead to performances that deteriorate with time. Hence, it is not clear how to compress the information held by agents into few meaningful parameters while avoiding the accumulation of errors and runaway behavior.</p>
<p>Another of the analysis difficulties corresponds to the fact that the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e053" xlink:type="simple"/></inline-formula> held by an agent at time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e054" xlink:type="simple"/></inline-formula> depends on many previous deviation measurements in a non-trivial way, and hence the variance of a realization of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e055" xlink:type="simple"/></inline-formula> does not necessarily correspond to the variance of the agents' opinion, when taking into account all possible realizations of all measurements. Hence, one must regard each <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e056" xlink:type="simple"/></inline-formula> as a multi-variable distribution. A further problem has to do with dependencies. The independent meeting pattern guarantees that the memory <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e057" xlink:type="simple"/></inline-formula>'s of two interacting agents are independent, yet, given the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e058" xlink:type="simple"/></inline-formula> of the observing agent, the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e059" xlink:type="simple"/></inline-formula> of the observed agent and the deviation measurement become dependent. Such dependencies make it difficult to track the evolution of an agent's accuracy of estimation over time. Indeed, to tackle this issue, we had to extend the Fisher information inequality <xref ref-type="bibr" rid="pcbi.1003862-Stam1">[44]</xref>, <xref ref-type="bibr" rid="pcbi.1003862-Zamir1">[45]</xref> to a multi-variable dependent convolution case.</p>
</sec><sec id="s2c">
<title>The biological relevance of confidence based algorithms</title>
<p>Internal representations of confidence have been shown to affect animal behavior over a wide range of species <xref ref-type="bibr" rid="pcbi.1003862-Blough1">[46]</xref>–<xref ref-type="bibr" rid="pcbi.1003862-Smith2">[49]</xref>. Confidence as an internal parameter that builds up as a passive agent gathers external evidence has been measured in pre-decision neuronal responses (see, for example, <xref ref-type="bibr" rid="pcbi.1003862-Cook1">[50]</xref>). The notion of confidence as an internal parameter carries over into group contexts wherein animals were demonstrated to become more responsive to social information as their own certainty drops <xref ref-type="bibr" rid="pcbi.1003862-Couzin2">[37]</xref>, <xref ref-type="bibr" rid="pcbi.1003862-vanBergen1">[51]</xref>, <xref ref-type="bibr" rid="pcbi.1003862-Fletcher1">[52]</xref>.</p>
<p>Furthermore, evidence also suggests that animals are capable of communicating their confidence as well as assessing that of their conspecifics <xref ref-type="bibr" rid="pcbi.1003862-Rieucau1">[13]</xref>, <xref ref-type="bibr" rid="pcbi.1003862-Razin1">[14]</xref>, <xref ref-type="bibr" rid="pcbi.1003862-Harcourt1">[35]</xref>, <xref ref-type="bibr" rid="pcbi.1003862-Simmons1">[53]</xref>. One such example comes in the context of conflict, where threat behaviors may indicate the communication of confidence. While no single work directly binds all elements of confidence sharing many supportive evidences exist: Dominance hierarchies, like confidence, are constructed according to the accumulation of evidence <xref ref-type="bibr" rid="pcbi.1003862-Hsu1">[54]</xref>. Further, threats are correlated with large differences in dominance rank <xref ref-type="bibr" rid="pcbi.1003862-Wilson1">[55]</xref> and are often non-deceptive <xref ref-type="bibr" rid="pcbi.1003862-Zahavi1">[56]</xref>–<xref ref-type="bibr" rid="pcbi.1003862-Ballentine1">[58]</xref> and convey the animal's actual chances of winning the next fight. Moreover, threats are generated and perceived at different levels of intensity <xref ref-type="bibr" rid="pcbi.1003862-Wilson1">[55]</xref>, <xref ref-type="bibr" rid="pcbi.1003862-Hurd1">[59]</xref> to the extent of causing an opponent to back away from confrontation <xref ref-type="bibr" rid="pcbi.1003862-Simmons1">[53]</xref>, <xref ref-type="bibr" rid="pcbi.1003862-Stout1">[60]</xref>.</p>
<p>Other examples come from more cooperative scenarios such as house hunting behavior in honeybees (<italic>Apis mellifera</italic>). It was shown that swarming bees collectively move towards a new nest site by communicating two-component messages: The direction in which bees fly encodes the desired direction towards the new site while the speed of flight determines the degree of responsiveness this message will elicit in others <xref ref-type="bibr" rid="pcbi.1003862-Schultz1">[61]</xref>, <xref ref-type="bibr" rid="pcbi.1003862-Latty1">[62]</xref>. Furthermore, it was shown that high speed is associated with bees that have been to the new site (streakers) as well as bees that do not have first hand accounts but whose flight is generally directed towards the desired site <xref ref-type="bibr" rid="pcbi.1003862-Schultz1">[61]</xref>. These evidences are consistent with an analogy between flight speed and confidence regarding the correct direction to the new site. Another example occurs earlier in the house-hunting process. The messages which scouts convey regarding the location of prospect nest sites contain (at least) two components: While the direction to the advertised site is encoded by the waggle dance, the intensity of the message is encoded in the number of times the bee performs this dance <xref ref-type="bibr" rid="pcbi.1003862-Seeley1">[63]</xref>, <xref ref-type="bibr" rid="pcbi.1003862-Seeley2">[64]</xref>. The intensity of the message correlates with the quality of the advertised site and could be interpreted as the confidence of the bee that the site she advertises is the best of all options. This interpretation is strengthened if, similar to what has been shown for ants <xref ref-type="bibr" rid="pcbi.1003862-Robinson1">[65]</xref>, <xref ref-type="bibr" rid="pcbi.1003862-Robinson2">[66]</xref>, bees have some internal scale to the quality of a site.</p>
<p>A further example for the role of confidence during interactions comes from recruitment behavior in the desert ant <italic>Cataglyphis niger</italic> <xref ref-type="bibr" rid="pcbi.1003862-Razin1">[14]</xref>. Here, ants within the nest interact with their nest-mates to accumulate indirect evidence regarding the presence of food and towards an active decision to exit themselves (recruitment). Similar to the accumulation of neuronal activity that proceeds a decision <xref ref-type="bibr" rid="pcbi.1003862-Cook1">[50]</xref>, ants were observed to gradually increase their speed of movement before deciding to exit the nest <xref ref-type="bibr" rid="pcbi.1003862-Razin1">[14]</xref>. Furthermore, ants which have been in direct contact with the food are certain of its presence and indeed maintain high speeds for extended periods of time <xref ref-type="bibr" rid="pcbi.1003862-Razin1">[14]</xref>. These evidences suggest that an analogy between the speed of an ant and her confidence may be useful. In <xref ref-type="fig" rid="pcbi-1003862-g002">Figure 2</xref> we present novel empirical evidence of the way ants update their speed following an interaction. This data confirms that speed (confidence under this analogy) is both transmitted and perceived by the ants. Moreover, the speed of an ant after the interaction is an increasing function of both her speed and the speed of her interacting partner prior to the interaction.</p>
<fig id="pcbi-1003862-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003862.g002</object-id><label>Figure 2</label><caption>
<title><italic>C. niger</italic> recruitment behavior exhibits interactions that resemble Conf.</title>
<p>The figure summarized the speed change of ants directly before and after an interaction within the nest. We refer to the two interacting ants as the fast/slow ant according to their speed before the interaction. Identifying speed with confidence about the presence of a food source <xref ref-type="bibr" rid="pcbi.1003862-Razin1">[14]</xref> reveals an interaction rule similar to that suggested by Conf. <bold>A.</bold> Mean speed of the slow ant following an interaction. <bold>B.</bold> Mean speed of the fast ant following an interaction. The figure summarizes (n = 429) interactions and demonstrates how the speed of an ant after an interaction increases as either her prior speed or the prior speed of the ant she interacts with are larger. For example, we find that the mean speed at which an initially slow ant (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e060" xlink:type="simple"/></inline-formula>) exits an interaction with a relatively fast faster ant (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e061" xlink:type="simple"/></inline-formula>) is higher than the her speed after an interaction with a relatively slow faster ant (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e062" xlink:type="simple"/></inline-formula>), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e063" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e064" xlink:type="simple"/></inline-formula> by the one-sided two-sample Kolmogorov-Smironov test. Similarly, the mean speed of a fast ant (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e065" xlink:type="simple"/></inline-formula>) increases more after encountering a relatively fast slower ant (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e066" xlink:type="simple"/></inline-formula>) than a relatively slow slower ant (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e067" xlink:type="simple"/></inline-formula>): <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e068" xlink:type="simple"/></inline-formula>. Using the same speed ranges we also find that the mean speed of a slow ant after an interaction is an increasing function of her speed prior to the meeting: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e069" xlink:type="simple"/></inline-formula> and that the same holds for fast ants: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e070" xlink:type="simple"/></inline-formula>. For further details regarding a general slow-down in speed evident after each interactions see <xref ref-type="bibr" rid="pcbi.1003862-Razin1">[14]</xref>.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003862.g002" position="float" xlink:type="simple"/></fig></sec><sec id="s2d">
<title>A basic confidence-based algorithm</title>
<p>Having identified confidence sharing as a relevant communication scheme in animal groups, we turn to study the compact algorithm Conf: a <italic>basic</italic> representative of the family of algorithms that rely on the active communication of confidence. This algorithm is basic in being both simple and natural: It is simple as it is highly economical in terms of communication, memory usage and internal computations. It is natural since it relies on linear combination information fusing techniques. Below, we describe Conf and show that it displays near optimal performance.</p>
<p>In algorithm Conf each agent, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e071" xlink:type="simple"/></inline-formula>, stores in its memory a single parameter <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e072" xlink:type="simple"/></inline-formula> that represents its <italic>confidence</italic> regarding its current distance from the target <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e073" xlink:type="simple"/></inline-formula>. The initial confidence of agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e074" xlink:type="simple"/></inline-formula> is set to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e075" xlink:type="simple"/></inline-formula>. When agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e076" xlink:type="simple"/></inline-formula> observes agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e077" xlink:type="simple"/></inline-formula>, it receives both the passive noisy distance measurement <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e078" xlink:type="simple"/></inline-formula> and an active message containing the confidence parameter of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e079" xlink:type="simple"/></inline-formula>. This information will then allow agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e080" xlink:type="simple"/></inline-formula> to relocate itself by using a <italic>weighted average</italic> procedure <xref ref-type="bibr" rid="pcbi.1003862-McNamara1">[34]</xref>, <xref ref-type="bibr" rid="pcbi.1003862-Graybill1">[43]</xref>. Then, a suitable update is made for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e081" xlink:type="simple"/></inline-formula> to reflect <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e082" xlink:type="simple"/></inline-formula>'s confidence of its updated location.</p>
<p>Specifically, upon receiving <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e083" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e084" xlink:type="simple"/></inline-formula>, agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e085" xlink:type="simple"/></inline-formula> proceeds as follows:</p>
<p><bold>Algorithm Conf</bold></p>
<list list-type="bullet"><list-item>
<p><bold>Compute:</bold> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e086" xlink:type="simple"/></inline-formula>.</p>
</list-item><list-item>
<p><bold>Update external state:</bold> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e087" xlink:type="simple"/></inline-formula></p>
</list-item><list-item>
<p><bold>Update confidence:</bold> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e088" xlink:type="simple"/></inline-formula></p>
</list-item></list>
</sec><sec id="s2e">
<title>Competitive analysis</title>
<p>We provide a rigorous proof (section 5  in <xref ref-type="supplementary-material" rid="pcbi.1003862.s003">Text S1</xref>) that the performances of Conf are very close to those of Opt when the meeting patterns are independent and active communication is noiseless. Specifically, we first show (section 5.1 in <xref ref-type="supplementary-material" rid="pcbi.1003862.s003">Text S1</xref>) that under these conditions, the rules of Conf guarantee that the location <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e089" xlink:type="simple"/></inline-formula> of any agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e090" xlink:type="simple"/></inline-formula> serves as an unbiased estimator of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e091" xlink:type="simple"/></inline-formula> and that the confidence <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e092" xlink:type="simple"/></inline-formula> satisfies: <disp-formula id="pcbi.1003862.e093"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003862.e093" xlink:type="simple"/><label>(1)</label></disp-formula></p>
<p>We further show (section 5.2 in <xref ref-type="supplementary-material" rid="pcbi.1003862.s003">Text S1</xref>) that although approximation errors that result from the information compression of Conf are inevitable, they do not accumulate with time and through repeated interactions. Indeed, the quotient between the variance of the population under Conf and its variance under Opt remains bounded, at all times, by the initial Fisher-deviation <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e094" xlink:type="simple"/></inline-formula> (as defined in the Materials and Methods). More specifically, under algorithm Conf, the variance of any agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e095" xlink:type="simple"/></inline-formula> at time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e096" xlink:type="simple"/></inline-formula> is bounded by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e097" xlink:type="simple"/></inline-formula> times the corresponding variance under Opt (see <xref ref-type="fig" rid="pcbi-1003862-g003">Figure 3A</xref>):<disp-formula id="pcbi.1003862.e098"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003862.e098" xlink:type="simple"/><label>(2)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e105" xlink:type="simple"/></inline-formula> denotes the location of agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e106" xlink:type="simple"/></inline-formula> at time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e107" xlink:type="simple"/></inline-formula> under algorithm Opt.</p>
<fig id="pcbi-1003862-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003862.g003</object-id><label>Figure 3</label><caption>
<title>Comparing the performances of the confidence based algorithm, Conf, to those of other algorithms.</title>
<p><bold>A.</bold> Optimal algorithms. We look at the convergence of an optimal algorithm for two different initial distributions. Double Gaussian initial conditions (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e099" xlink:type="simple"/></inline-formula>) possess higher Fisher information than Gaussian initial conditions with the same variance (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e100" xlink:type="simple"/></inline-formula>) and thus converge faster. As the Conf algorithm uses only variances it performs equally well under the two conditions. Note that for Gaussian initial conditions, Conf is optimal while, for the double Gaussian case, the competitiveness of Conf is, at any time, much smaller than the theoretically predicted upper bound of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e101" xlink:type="simple"/></inline-formula>. <bold>B.</bold> When compared to Conf, linear combination algorithms exhibit a large deterioration in performances and a speed-accuracy tradeoff: The simple average algorithm (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e102" xlink:type="simple"/></inline-formula>) converges relatively fast but to a steady state that is dominated by the amplitude of the communication noise. The linear combination algorithm with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e103" xlink:type="simple"/></inline-formula> (where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e104" xlink:type="simple"/></inline-formula> can be taken to be arbitrarily small) reaches a tight steady state at the cost of long convergence time.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003862.g003" position="float" xlink:type="simple"/></fig>
<p>To prove <xref ref-type="disp-formula" rid="pcbi.1003862.e098">Equation 2</xref>, we relate the variance of Opt to a measure of information which we call the <italic>relative Fisher information</italic>. This measure, denoted <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e108" xlink:type="simple"/></inline-formula> (formally defined in <xref ref-type="supplementary-material" rid="pcbi.1003862.s003">Text S1</xref>,  section 3.2), quantifies the agent's current knowledge regarding <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e109" xlink:type="simple"/></inline-formula>. Intuitively speaking, this notion can be thought of as the Fisher information of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e110" xlink:type="simple"/></inline-formula> family that describes the random samples held by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e111" xlink:type="simple"/></inline-formula> under algorithm Opt with respect to the translational parameter <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e112" xlink:type="simple"/></inline-formula> (see <xref ref-type="sec" rid="s4">Materials and Methods</xref>). We then use the Cramér-Rao bound to deduce that: <disp-formula id="pcbi.1003862.e113"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003862.e113" xlink:type="simple"/><label>(3)</label></disp-formula>where the mean is taken over all possible random initial locations and communication noises, as well as, possibly, over all random choices made by the agents themselves.</p>
<p>We then show that the confidence of an agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e114" xlink:type="simple"/></inline-formula> under algorithm Conf satisfies: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e115" xlink:type="simple"/></inline-formula> which establishes <xref ref-type="disp-formula" rid="pcbi.1003862.e098">Equation 2</xref> and proves that the competitiveness of Conf with respect to Opt is, at most, the initial Fisher deviation <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e116" xlink:type="simple"/></inline-formula>.</p>
<p>Note that for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e117" xlink:type="simple"/></inline-formula>, the optimal algorithm Opt cannot, in fact, achieve the Cramér-Rao bound at all times (t = 0 being a trivial example). Therefore the competitiveness of Conf with respect to Opt can be expected to be even tighter than <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e118" xlink:type="simple"/></inline-formula>. This is indeed verified by simulation (see <xref ref-type="fig" rid="pcbi-1003862-g003">Figure 3A</xref>). Moreover, we show that in the case of Gaussian noise, and regardless of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e119" xlink:type="simple"/></inline-formula>, the performance of Conf will approach that of Opt at large times (section 5.2.3 in <xref ref-type="supplementary-material" rid="pcbi.1003862.s003">Text S1</xref> and <xref ref-type="fig" rid="pcbi-1003862-g003">Figure 3A</xref>). Note that in the case in which the noise and initial distributions are all Gaussian, the Fisher deviation satisfies <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e120" xlink:type="simple"/></inline-formula> so that Conf is optimal (<xref ref-type="fig" rid="pcbi-1003862-g003">Figure 3A</xref>).</p>
</sec><sec id="s2f">
<title>Algorithms without active communication</title>
<p>We next compare the Conf algorithm to even simpler algorithms that rely solely on passive communication.</p>
<p>We first consider algorithms in which the interaction update rule is a simple linear combination of the observing agent's location, and the estimated location of the observed agent: <disp-formula id="pcbi.1003862.e121"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003862.e121" xlink:type="simple"/></disp-formula>for some constant <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e122" xlink:type="simple"/></inline-formula> (note that in algorithm Conf, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e123" xlink:type="simple"/></inline-formula> is not constant and is set according to the active message and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e124" xlink:type="simple"/></inline-formula>'s current confidence). A simple average algorithm is obtained by setting <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e125" xlink:type="simple"/></inline-formula>.</p>
<p>The performance of constant linear combination algorithms is of interest since they require minimal resources: agents are not required to store any memory of their current internal state. We find that, in general, when communication noise is substantial, linear combination algorithms do not perform well. They exhibit a speed accuracy tradeoff converging within a time scale of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e126" xlink:type="simple"/></inline-formula> (which diverges for small values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e127" xlink:type="simple"/></inline-formula>) to a steady state with a variance that scales as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e128" xlink:type="simple"/></inline-formula> (section 7  in <xref ref-type="supplementary-material" rid="pcbi.1003862.s003">Text S1</xref> and <xref ref-type="fig" rid="pcbi-1003862-g003">Figure 3B</xref>). On the other hand, in the case of uniformly informed populations and negligible communication noise, the performances of the simple average algorithm (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e129" xlink:type="simple"/></inline-formula>) approach those of Conf in terms of both convergence rate and steady state variance. Intuitively, simple averaging functions well under these circumstances since the information held by two interacting agents, at any time, is of equal quality.</p>
<p>Active communication can also become redundant when passive communication noise is very large with respect to the uncertainty of the agents. Indeed, in this case, a “passive” algorithm is obtained by translating the rules Conf into a high noise regime. The effective confidence of any observed agent becomes <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e130" xlink:type="simple"/></inline-formula> which is independent of its actual internal state.</p>
<p>Conversely, “passive” algorithms are expected to fail in situations where noise levels are comparable to agent uncertainty and knowledge is non-uniformity distributed among the agents. In this case, the assumption that an observed agent's confidence is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e131" xlink:type="simple"/></inline-formula> fails and could lead to irreparable mistakes in the observing agent's position and confidence after the interaction. For intuition, consider the extreme case in which a single agent has very accurate knowledge of the target value while all other agents have no information at all. In this case, Conf would allow for very fast convergence typical of rumor spread: roughly within <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e132" xlink:type="simple"/></inline-formula> rounds, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e133" xlink:type="simple"/></inline-formula> is the number of agents. On the other hand, if no active communication is allowed, it becomes difficult to distinguish the knowledgeable agent within a large population of anonymous agents (see section 7.1  in <xref ref-type="supplementary-material" rid="pcbi.1003862.s003">Text S1</xref>).</p>
</sec><sec id="s2g">
<title>Generalizations</title>
<sec id="s2g1">
<title>Information flows, Fisher capacity and convergence times</title>
<p>We now set to find lower bounds on the convergence time of a group of agents applying an arbitrary algorithm. First, we note that an agent's relative Fisher information, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e134" xlink:type="simple"/></inline-formula>, remains well-defined with respect to any algorithm <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e135" xlink:type="simple"/></inline-formula>, any interaction pattern and any noise in either active or passive communication (section 3 in <xref ref-type="supplementary-material" rid="pcbi.1003862.s003">Text S1</xref>). An inequality similar to that formulated for Opt (<xref ref-type="disp-formula" rid="pcbi.1003862.e113">equation 3</xref>) also holds for this, more general, case: <disp-formula id="pcbi.1003862.e136"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003862.e136" xlink:type="simple"/><label>(4)</label></disp-formula></p>
<p>Next, we combine <xref ref-type="disp-formula" rid="pcbi.1003862.e136">equation 4</xref> and a bound on the relative Fisher information an agent can gain through an interaction to produce lower bounds on collective convergence times.</p>
<p>By generalizing the Fisher information inequality <xref ref-type="bibr" rid="pcbi.1003862-Stam1">[44]</xref>, <xref ref-type="bibr" rid="pcbi.1003862-Zamir1">[45]</xref>, we prove (section 4 in <xref ref-type="supplementary-material" rid="pcbi.1003862.s003">Text S1</xref>) that, under an independent meeting pattern, when agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e137" xlink:type="simple"/></inline-formula> observes agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e138" xlink:type="simple"/></inline-formula> at time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e139" xlink:type="simple"/></inline-formula> then: <disp-formula id="pcbi.1003862.e140"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003862.e140" xlink:type="simple"/><label>(5)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e141" xlink:type="simple"/></inline-formula> is the Fisher Information of the noise distribution family <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e142" xlink:type="simple"/></inline-formula> (see, also, <xref ref-type="fig" rid="pcbi-1003862-g004">Figure 4</xref>) In particular, this implies that:</p>
<fig id="pcbi-1003862-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003862.g004</object-id><label>Figure 4</label><caption>
<title>Information flow.</title>
<p>The table on the left hand side relates the terms used, their notations in the text, and their graphic representation per panels A–C. In A–C the pink agent observes the black agent and updates its state (dashed arrow) to be the one depicted by red. <bold>A.</bold> An agent with high Fisher information effectively ignores one with less knowledge. <bold>B.</bold> A weighted average. Following this interaction, the observing agent updates its orientation and increases its Fisher information. <bold>C.</bold> Although the information held by the black agent is much higher than in panel B, its effect does not grow. This is a consequence of the restricted Fisher Channel Capacity.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003862.g004" position="float" xlink:type="simple"/></fig>
<p><disp-formula id="pcbi.1003862.e143"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003862.e143" xlink:type="simple"/><label>(6)</label></disp-formula></p>
<p>Intuitively speaking, agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e144" xlink:type="simple"/></inline-formula> cannot obtain more information than that stored in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e145" xlink:type="simple"/></inline-formula> or a measurement more precise than allowed by communication noise. This equation holds with respect to any level of noise in active communication, and in particular, when active communication is noiseless. The bound of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e146" xlink:type="simple"/></inline-formula> on information increase holds with respect to any algorithm <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e147" xlink:type="simple"/></inline-formula>, hence, we can view it as a property of the information channel itself. In analogy to Channel Capacity as defined by Shannon <xref ref-type="bibr" rid="pcbi.1003862-Cover1">[67]</xref> we term <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e148" xlink:type="simple"/></inline-formula> as the <italic>Fisher Channel Capacity</italic>. This definition is not to be confused with the notion of “Channel Capacity” previously used by Frieden <italic>et al.</italic>, in a different, non-distributed context. <xref ref-type="fig" rid="pcbi-1003862-g004">Figure 4</xref> illustrates and summarizes the above stated ideas.</p>
<p>These restrictions on information flow can be translated into lower bounds for convergence times, <italic>i.e.</italic> the time in takes the whole population of agents to enter a certain tight window <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e149" xlink:type="simple"/></inline-formula> around <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e150" xlink:type="simple"/></inline-formula>. Convergence requires that the estimator applied by a typical agent have a variance that is on the order of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e151" xlink:type="simple"/></inline-formula>. As this variance must comply with the Cramér-Rao bound, the Fisher information of the typical agent in the system has to exceed <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e152" xlink:type="simple"/></inline-formula>.</p>
<p>To get some intuition on the convergence time, let <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e153" xlink:type="simple"/></inline-formula> denote the median initial Fisher information of an agent (this is the median Fisher information over the distributions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e154" xlink:type="simple"/></inline-formula>), and assume <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e155" xlink:type="simple"/></inline-formula>. <xref ref-type="disp-formula" rid="pcbi.1003862.e143">Equation 6</xref> implies (section 6 in <xref ref-type="supplementary-material" rid="pcbi.1003862.s003">Text S1</xref>) a bound for the best possible convergence time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e156" xlink:type="simple"/></inline-formula>: <disp-formula id="pcbi.1003862.e157"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003862.e157" xlink:type="simple"/><label>(7)</label></disp-formula></p>
<p>Let <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e158" xlink:type="simple"/></inline-formula> denote the maximal initial Fisher information over all agents. In the case where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e159" xlink:type="simple"/></inline-formula>, one can obtain a tighter upper bound for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e160" xlink:type="simple"/></inline-formula>. Note that the Fisher information at an agent is always at most the corresponding Fisher information in the analogue scenario where there is no noise in both passive and active communication. For this noiseless scenario, the additive property of Fisher information implies that the maximum Fisher information over all agents grows by, at most, a factor of 2 in each round. This leads to the following bound: <disp-formula id="pcbi.1003862.e161"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003862.e161" xlink:type="simple"/></disp-formula></p>
</sec><sec id="s2g2">
<title>Dependent interaction patterns</title>
<p>Our proofs pertain to an independent interaction regime which, in the strict sense, restricts our analysis to highly connected interaction graphs or short enough times. We used simulations to test the effectiveness of Conf on small populations that may better capture a natural settings where interactions are spatially constrained. This was done by comparing the MSE achieved by an agent employing Conf to the reciprocal of the Fisher information of this agent's under algorithm Opt. For simplicity, we considered a noiseless scenario; this allowed us to precisely calculate the corresponding Fisher information. We found that, on average, algorithm Conf remains extremely efficient for dependent meeting patterns that result from small population sizes. Deviations from optimality are both extremely small and transient (<xref ref-type="fig" rid="pcbi-1003862-g005">Figure 5A</xref>).</p>
<fig id="pcbi-1003862-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003862.g005</object-id><label>Figure 5</label><caption>
<title>Performance of Conf under general conditions.</title>
<p><bold>A.</bold> Dependent interaction patterns. Quality of the convergence for small populations as depicted by the population variance normalized by the optimal variance allowed by the Cramér-Rao bound. A ratio of 1 implies optimality. The inset shows the MSE of Conf (red curve) and lower bound (black curve) for the case <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e162" xlink:type="simple"/></inline-formula>. <bold>B.</bold> Convergence performance of Conf for different levels of noise in the active communication. The x-axis specifies the variance of the random Gaussian term that multiplies confidence transmissions. The dashed line signifies the performance of a simple-average algorithm.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003862.g005" position="float" xlink:type="simple"/></fig></sec><sec id="s2g3">
<title>Noisy transmissions of confidence</title>
<p>The continuous nature of algorithm Conf suggests that it may also be robust under noise in confidence transmission. We therefore used simulations to test the effects of noisy active communication. Noise was realized as a multiplicative Gaussian term to maintain the non-negativity of confidence. <xref ref-type="fig" rid="pcbi-1003862-g005">Figure 5B</xref> agrees with our hypothesis showing that Conf is highly robust to communication noise. Note that for all levels of noise, Conf still outperforms the simple average algorithm. The robustness of Conf further implies that the transmission of confidence is not required to be analog but could be binned into a restricted number of bits.</p>
</sec><sec id="s2g4">
<title>Dynamic environments</title>
<p>We have proven that algorithm Conf is highly competitive in static environments. However, it cannot be expected to perform well in dynamic environments. This is due, for example, to an erroneous buildup in confidence amongst interacting agents with similar opinions <xref ref-type="bibr" rid="pcbi.1003862-Rieucau1">[13]</xref>. In this case, agents may ignore subsequent environmental changes due to over-confidence. Alternative, more complex algorithms that rectify this phenomenon have previously been suggested <xref ref-type="bibr" rid="pcbi.1003862-Biro1">[7]</xref>.</p>
<p>To resolve such issues, we present two extensions of Conf (see section 8 in <xref ref-type="supplementary-material" rid="pcbi.1003862.s003">Text S1</xref>). The first algorithm, fully described in <xref ref-type="supplementary-material" rid="pcbi.1003862.s003">Text S1</xref> section 8.1, relies on a single extra bit that is stored in the agents' memory and is turned “on” if an agent is updated. The agents are further required to be able to measure time in a way that allows them set this extra bit to zero when their information becomes obsolete. In <xref ref-type="supplementary-material" rid="pcbi.1003862.s001">figure S1A</xref>, we show that while this algorithm coincides with Conf in periods where the environment is stable it also allows very rapid population shifts that track a sudden change in environmental conditions.</p>
<p>A second algorithm relies on a weighted-average rule that is corrected for non-independent observations (see Oruç <italic>et al.</italic> <xref ref-type="bibr" rid="pcbi.1003862-Oru1">[68]</xref>). This algorithm assures, for example, that confidence will only marginally increase following an interaction between agents with highly correlated information. We ran a simulation that uses this rule in an interacting population of uniformly informed agents. Indeed, we found that at steady state, the Fisher information in each agent exactly equals the initial Fisher information of the entire population (see section 8.2 in <xref ref-type="supplementary-material" rid="pcbi.1003862.s003">Text S1</xref> and <xref ref-type="supplementary-material" rid="pcbi.1003862.s001">figure S1B</xref>). In other words, all initial information has disseminated between the agents while over-confidence has been avoided. Since the agents are not over confident, they remain responsive to environmental changes which they quickly track (see section 8.2 in <xref ref-type="supplementary-material" rid="pcbi.1003862.s003">Text S1</xref> and <xref ref-type="supplementary-material" rid="pcbi.1003862.s001">figure S1C</xref>). Thus, this algorithm improves on the flexibility of Conf. However, this extended algorithm cannot function, as is, in non-uniform populations as two interacting agents have no simple method for assessing the correlation between their estimates prior to an interaction.</p>
</sec><sec id="s2g5">
<title>Heterogeneous populations</title>
<p>Experiments have demonstrated how, when two humans make a joint decision, they weigh their opinions not by the variance of their uncertainty (as could be expected for optimality) but by its standard-deviation <xref ref-type="bibr" rid="pcbi.1003862-Bahrami1">[69]</xref>. A possible explanation for this was suggested by Ernst <xref ref-type="bibr" rid="pcbi.1003862-Ernst1">[70]</xref> who noted that dividing a measurement by its standard deviation yields a unit-less quantity that may facilitate communication between people who may differ in their perception of distance or happen to be using different units of measurement.</p>
<p>As differences in perception are also bound to occur in animal populations it is interesting to test how Conf, which uses inverse-variance weights, performs in this setting. For this, we simulated heterogeneous populations in which each individual perceives distance differently, for example a 1.5-biased individual will measure a distance to be <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e163" xlink:type="simple"/></inline-formula> larger than it actually is while a 1/3-biased individuals will perceive distances to be smaller by a factor of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e164" xlink:type="simple"/></inline-formula>. Simulating algorithm Conf on such populations, we found (see section 9 in <xref ref-type="supplementary-material" rid="pcbi.1003862.s003">Text S1</xref> and <xref ref-type="supplementary-material" rid="pcbi.1003862.s002">figure S2</xref>) that it continues to perform well in populations with a perception heterogeneity that goes as high as a factor of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e165" xlink:type="simple"/></inline-formula> (implying differences of up to a factor of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e166" xlink:type="simple"/></inline-formula> between the perception of different individuals). When biases bypass the order of the signal itself Conf starts to lose its absolute advantage over an algorithm that does not communicate confidence at all.</p>
</sec></sec></sec><sec id="s3">
<title>Discussion</title>
<p>In this work we theoretically studied an abstract model of animal communication within a group which generalizes the work of McNamara and Houston <xref ref-type="bibr" rid="pcbi.1003862-McNamara1">[34]</xref>. Similar to their approach, we considered a basic model which enabled us to perform rigorous analysis, often impossible in more complex scenarios. We have shown that weighted averaging algorithms, previously known to be efficient for fusing multiple pieces of evidence <xref ref-type="bibr" rid="pcbi.1003862-Graybill1">[43]</xref>, naturally carry over to a scenario in which a group of agents share and aggregate information. The weights used may be interpreted as the agents' confidence in their opinion.</p>
<p>We have theoretically shown, that, remembering and <italic>actively</italic> communicating confidence is, in fact, sufficient for near-optimal decisions in cooperative group contexts. Using the confidence measure is straightforward: individuals with high confidence are more persuasive while those with low confidence more fickle. Finally, the fundamental nature of our model makes our results potentially relevant to a large number of natural systems.</p>
<p>We have used the framework of Fisher information to study information flows within cooperative groups. In particular, we have defined the <italic>Fisher Channel Capacity</italic> and demonstrated how it bounds collective reaction times. This opens the door for further rigorous quantifications of information flows within animal groups.</p>
<p>We introduced Conf, a simple weighted-average based algorithm that uses compact memory and communication in a way that overcomes the anticipated shortcomings of information compression (<italic>e.g.</italic>, see <xref ref-type="fig" rid="pcbi-1003862-g001">Figure 1</xref>). We have shown that Conf is highly competitive when compared to an optimal algorithm that utilizes maximal memory, communication capacity, and computational resources. In fact, we bound the difference in performance by a constant factor - the <italic>initial Fisher-deviation</italic>.</p>
<p>We have presented evidence that supports the relevance of Conf to actual biological groups and turn to suggest how this may be helpful for analyzing experimental data. A most intriguing result would be to utilize <xref ref-type="disp-formula" rid="pcbi.1003862.e157">Equation 7</xref> to obtain a lower bound on communication noise levels. Indeed, <xref ref-type="disp-formula" rid="pcbi.1003862.e157">Equation 7</xref> holds with respect to any algorithm operating in the corresponding setting, and with respect to any level of noise in active communication. If the setting is matched in an experiment, the initial variance is large, and the convergence time fast, <xref ref-type="disp-formula" rid="pcbi.1003862.e157">Equation 7</xref> would yield a lower bound on <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e167" xlink:type="simple"/></inline-formula>, the Fisher information in the noise corresponding to the passive communication. Such a result would demonstrate the usefulness of the indirect methodology, based on algorithmic lower bounds as suggested in <xref ref-type="bibr" rid="pcbi.1003862-Feinerman1">[71]</xref>. Moreover, such a lower bound on the amount of noise seems to be difficult to obtain by other, more direct, methodologies.</p>
<p>Further practical implications of our results include the identification of scenarios in which active communication is likely to be employed. These include cases in which the noise level is intermediate and situations of populations that are variable in terms of initial knowledge as is the case in effective leadership scenarios <xref ref-type="bibr" rid="pcbi.1003862-Stroeymeyt1">[36]</xref>, <xref ref-type="bibr" rid="pcbi.1003862-Couzin3">[38]</xref>. In such cases, our results suggest that it may be useful to search for the active transmission of “confidence” signals, which can be encoded <italic>e.g.</italic>, in the speed of agents <xref ref-type="bibr" rid="pcbi.1003862-Razin1">[14]</xref>, <xref ref-type="bibr" rid="pcbi.1003862-Schultz1">[61]</xref>.</p>
<p>Our analysis for the performances of Conf assumes independent meeting patterns. Such patterns are especially meaningful when agents rely on few interactions each, or when the system is highly mixed. We have used simulation to demonstrate that algorithm Conf continues to perform well for small groups in which interaction patterns are no longer independent. In addition, our simulations show that Conf is robust under active communication noise, heterogenic populations, and that simple extensions of this algorithm may be expected to perform well in dynamic environments.</p>
<p>It is interesting to identify those scenarios in which active communication appears to be of lesser importance. When personal information is reliable and frequently updated there is, trivially, no requirement for any sort of communication. It is when personal information is less accurate that social information becomes useful. We have shown that simple averaging algorithms (operating without long term memory) behave well in uniform populations with communication noise that is negligible in comparison to the desired convergence state. We further showed that when communication noise is very large then an algorithm in which each agent maintains an internal confidence measure but does not communicate it <xref ref-type="bibr" rid="pcbi.1003862-Couzin3">[38]</xref>, <xref ref-type="bibr" rid="pcbi.1003862-Shklarsh1">[72]</xref> performs extremely well. This implies that in such cases, the system can perform well without resorting to active communication.</p>
<p>Although our results were formulated in the language of animal group behavior they can readily be generalized to a large range of cooperative biological ensembles. For example, bacterial quorum sensing is mediated by both passive cues (<italic>e.g.</italic> one cell senses another's waste products) and active signaling mediated by designated quorum-sensing molecules <xref ref-type="bibr" rid="pcbi.1003862-Diggle1">[73]</xref>.</p>
</sec><sec id="s4" sec-type="materials|methods">
<title>Materials and Methods</title>
<sec id="s4a">
<title>Fisher information, and the Cramér-Rao bound</title>
<p>We consider parameterized probability density function (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e168" xlink:type="simple"/></inline-formula>) families <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e169" xlink:type="simple"/></inline-formula> where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e170" xlink:type="simple"/></inline-formula> is the functional form and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e171" xlink:type="simple"/></inline-formula> is a translation parameter <xref ref-type="bibr" rid="pcbi.1003862-Zamir1">[45]</xref>. The Fisher information of a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e172" xlink:type="simple"/></inline-formula> family is defined as: <disp-formula id="pcbi.1003862.e173"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003862.e173" xlink:type="simple"/></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e174" xlink:type="simple"/></inline-formula> denotes all variables on which <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e175" xlink:type="simple"/></inline-formula> depends. Note, that since <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e176" xlink:type="simple"/></inline-formula> is a translational parameter, the Fisher information is both unique (there is no freedom in choosing the parametrization) and independent of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e177" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pcbi.1003862-Zamir1">[45]</xref>. The Cramér-Rao inequality sets a lower bound on the variance of any unbiased estimator, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e178" xlink:type="simple"/></inline-formula> based on a random sample taken from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e179" xlink:type="simple"/></inline-formula>, for the parameter <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e180" xlink:type="simple"/></inline-formula>: <disp-formula id="pcbi.1003862.e181"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003862.e181" xlink:type="simple"/></disp-formula></p>
</sec><sec id="s4b">
<title>Initial Fisher-deviation</title>
<p>To define the initial Fisher-deviation, denoted <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e182" xlink:type="simple"/></inline-formula>, we first define the <italic>Fisher-deviation</italic> of a distribution <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e183" xlink:type="simple"/></inline-formula> as <disp-formula id="pcbi.1003862.e184"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003862.e184" xlink:type="simple"/></disp-formula></p>
<p>Note that, by the Cramér-Rao bound, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e185" xlink:type="simple"/></inline-formula> for any unbiased distribution <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e186" xlink:type="simple"/></inline-formula>.</p>
<p>The <italic>initial Fisher-deviation</italic> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e187" xlink:type="simple"/></inline-formula> is the supremum of the Fisher-deviations over all the (unbiased) distributions involved, namely, the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e188" xlink:type="simple"/></inline-formula> distributions governing the initial locations and the noise distribution <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e189" xlink:type="simple"/></inline-formula>. Specifically, let <disp-formula id="pcbi.1003862.e190"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003862.e190" xlink:type="simple"/></disp-formula>and finally define <disp-formula id="pcbi.1003862.e191"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003862.e191" xlink:type="simple"/></disp-formula></p>
<p>Observe that if the distributions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e192" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e193" xlink:type="simple"/></inline-formula> are all Gaussians then <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003862.e194" xlink:type="simple"/></inline-formula>.</p>
</sec></sec><sec id="s5">
<title>Supporting Information</title>
<supplementary-material id="pcbi.1003862.s001" mimetype="image/tiff" xlink:href="info:doi/10.1371/journal.pcbi.1003862.s001" position="float" xlink:type="simple"><label>Figure S1</label><caption>
<p><bold>Extensions of Conf to dynamic environments.</bold></p>
<p>(TIF)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1003862.s002" mimetype="image/tiff" xlink:href="info:doi/10.1371/journal.pcbi.1003862.s002" position="float" xlink:type="simple"><label>Figure S2</label><caption>
<p><bold>Algorithm Conf in heterogenic populations.</bold></p>
<p>(TIF)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1003862.s003" mimetype="application/pdf" xlink:href="info:doi/10.1371/journal.pcbi.1003862.s003" position="float" xlink:type="simple"><label>Text S1</label><caption>
<p><bold>Additional definitions, proofs, and simulations.</bold></p>
<p>(PDF)</p>
</caption></supplementary-material></sec></body>
<back>
<ack>
<p>We thank Nitzan Razin, Jean-Pierre Eckmann, Ehud Fonio and Elad Schneidmann for their helpful suggestions.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1003862-Treherne1"><label>1</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Treherne</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Foster</surname><given-names>W</given-names></name> (<year>1981</year>) <article-title>Group transmission of predator avoidance behaviour in a marine insect: the Trafalgar effect</article-title>. <source>Animal Behaviour</source> <volume>29</volume>: <fpage>911</fpage>–<lpage>917</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Giraldeau1"><label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Giraldeau</surname><given-names>LA</given-names></name>, <name name-style="western"><surname>Lefebvre</surname><given-names>L</given-names></name> (<year>1986</year>) <article-title>Exchangeable producer and scrounger roles in a captive flock of feral pigeons: a case for the skill pool effect</article-title>. <source>Animal Behaviour</source> <volume>34</volume>: <fpage>797</fpage>–<lpage>803</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Leadbeater1"><label>3</label>
<mixed-citation publication-type="other" xlink:type="simple">Leadbeater E, Chittka L (2009) Social information use in foraging insects. In: Food exploitation by social insects: ecological, behavioral, and theoretical approaches. CRC Press. pp.135–146.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Ward1"><label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ward</surname><given-names>AJW</given-names></name>, <name name-style="western"><surname>Herbert-Read</surname><given-names>JE</given-names></name>, <name name-style="western"><surname>Sumpter</surname><given-names>DJT</given-names></name>, <name name-style="western"><surname>Krause</surname><given-names>J</given-names></name> (<year>2011</year>) <article-title>Fast and accurate decisions through collective vigilance in fish shoals</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>108</volume>: <fpage>E27</fpage>–<lpage>E27</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Berdahl1"><label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Berdahl</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Torney</surname><given-names>CJ</given-names></name>, <name name-style="western"><surname>Ioannou</surname><given-names>CC</given-names></name>, <name name-style="western"><surname>Faria</surname><given-names>JJ</given-names></name>, <name name-style="western"><surname>Couzin</surname><given-names>ID</given-names></name> (<year>2013</year>) <article-title>Emergent sensing of complex environments by mobile animal groups</article-title>. <source>Science (New York, NY)</source> <volume>339</volume>: <fpage>574</fpage>–<lpage>6</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Simons1"><label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Simons</surname><given-names>AM</given-names></name> (<year>2004</year>) <article-title>Many wrongs: the advantage of group navigation</article-title>. <source>Trends in ecology &amp; evolution</source> <volume>19</volume>: <fpage>453</fpage>–<lpage>5</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Biro1"><label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Biro</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Sumpter</surname><given-names>DJT</given-names></name>, <name name-style="western"><surname>Meade</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Guilford</surname><given-names>T</given-names></name> (<year>2006</year>) <article-title>From compromise to leadership in pigeon homing</article-title>. <source>Current biology: CB</source> <volume>16</volume>: <fpage>2123</fpage>–<lpage>8</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-DellAriccia1"><label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dell'Ariccia</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Dell'Omo</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Wolfer</surname><given-names>DP</given-names></name>, <name name-style="western"><surname>Lipp</surname><given-names>HP</given-names></name> (<year>2008</year>) <article-title>Flock flying improves pigeons' homing: GPS track analysis of individual flyers versus small groups</article-title>. <source>Animal Behaviour</source> <volume>76</volume>: <fpage>1165</fpage>–<lpage>1172</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Faria1"><label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Faria</surname><given-names>JJ</given-names></name>, <name name-style="western"><surname>Codling</surname><given-names>Ea</given-names></name>, <name name-style="western"><surname>Dyer</surname><given-names>JR</given-names></name>, <name name-style="western"><surname>Trillmich</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Krause</surname><given-names>J</given-names></name> (<year>2009</year>) <article-title>Navigation in human crowds; testing the many-wrongs principle</article-title>. <source>Animal Behaviour</source> <volume>78</volume>: <fpage>587</fpage>–<lpage>591</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Templeton1"><label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Templeton</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Giraldeau</surname><given-names>L</given-names></name> (<year>1995</year>) <article-title>Patch assessment in foraging flocks of European starlings: evidence for the use of public information</article-title>. <source>Behavioral Ecology</source> <volume>6</volume>: <fpage>65</fpage>–<lpage>72</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Giraldeau2"><label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Giraldeau</surname><given-names>LA</given-names></name>, <name name-style="western"><surname>Valone</surname><given-names>TJ</given-names></name>, <name name-style="western"><surname>Templeton</surname><given-names>JJ</given-names></name> (<year>2002</year>) <article-title>Potential disadvantages of using socially acquired information</article-title>. <source>Philosophical transactions of the Royal Society of London Series B, Biological sciences</source> <volume>357</volume>: <fpage>1559</fpage>–<lpage>66</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Laland1"><label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Laland</surname><given-names>KN</given-names></name>, <name name-style="western"><surname>Williams</surname><given-names>K</given-names></name> (<year>1998</year>) <article-title>Social transmission of maladaptive information in the guppy</article-title>. <source>Behavioral Ecology</source> <volume>9</volume>: <fpage>493</fpage>–<lpage>499</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Rieucau1"><label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rieucau</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Giraldeau</surname><given-names>La</given-names></name> (<year>2009</year>) <article-title>Persuasive companions can be wrong: the use of misleading social information in nutmeg mannikins</article-title>. <source>Behavioral Ecology</source> <volume>20</volume>: <fpage>1217</fpage>–<lpage>1222</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Razin1"><label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Razin</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Eckmann</surname><given-names>Jp</given-names></name>, <name name-style="western"><surname>Feinerman</surname><given-names>O</given-names></name> (<year>2013</year>) <article-title>Desert ants achieve reliable recruitment across noisy interactions</article-title>. <source>Journal of the Royal Society Interface</source> <volume>10</volume>: <fpage>20130079</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Dall1"><label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dall</surname><given-names>SRX</given-names></name>, <name name-style="western"><surname>Giraldeau</surname><given-names>LA</given-names></name>, <name name-style="western"><surname>Olsson</surname><given-names>O</given-names></name>, <name name-style="western"><surname>McNamara</surname><given-names>JM</given-names></name>, <name name-style="western"><surname>Stephens</surname><given-names>DW</given-names></name> (<year>2005</year>) <article-title>Information and its use by animals in evolutionary ecology</article-title>. <source>Trends in ecology &amp; evolution</source> <volume>20</volume>: <fpage>187</fpage>–<lpage>93</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Wilkinson1"><label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wilkinson</surname><given-names>GS</given-names></name> (<year>1992</year>) <article-title>Information transfer at evening bat colonies</article-title>. <source>Animal Behaviour</source> <volume>44</volume>: <fpage>501</fpage>–<lpage>518</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Barclay1"><label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Barclay</surname><given-names>RMR</given-names></name> (<year>1982</year>) <article-title>Interindividual use of echolocation calls: Eavesdropping by bats</article-title>. <source>Behavioral Ecology and Sociobiology</source> <volume>10</volume>: <fpage>271</fpage>–<lpage>275</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Theraulaz1"><label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Theraulaz</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Gautrais</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Camazine</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Deneubourg</surname><given-names>JL</given-names></name> (<year>2003</year>) <article-title>The formation of spatial patterns in social insects: from simple behaviours to complex structures</article-title>. <source>Philosophical transactions Series A, Mathematical, physical, and engineering sciences</source> <volume>361</volume>: <fpage>1263</fpage>–<lpage>82</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Danchin1"><label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Danchin</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Giraldeau</surname><given-names>LA</given-names></name>, <name name-style="western"><surname>Valone</surname><given-names>TJ</given-names></name>, <name name-style="western"><surname>Wagner</surname><given-names>RH</given-names></name> (<year>2004</year>) <article-title>Public information: from nosy neighbors to cultural evolution</article-title>. <source>Science (New York, NY)</source> <volume>305</volume>: <fpage>487</fpage>–<lpage>91</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Couzin1"><label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Couzin</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Krause</surname><given-names>J</given-names></name>, <name name-style="western"><surname>James</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Ruxton</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Franks</surname><given-names>N</given-names></name> (<year>2002</year>) <article-title>Collective memory and spatial sorting in animal groups</article-title>. <source>Journal of Theoretical Biology</source> <volume>218</volume>: <fpage>1</fpage>–<lpage>11</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Krebs1"><label>21</label>
<mixed-citation publication-type="other" xlink:type="simple">Krebs JR, Dawkins R (1984) Animal signals: mind-reading and manipulation. In: Behavioural Ecology: an evolutionary approach 2. pp.380–402.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Horn1"><label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Horn</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Leonard</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Weary</surname><given-names>D</given-names></name> (<year>1995</year>) <article-title>Oxygen consumption during crowing by roosters: talk is cheap</article-title>. <source>Animal Behaviour</source> <volume>50</volume>: <fpage>1171</fpage>–<lpage>1175</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Laughlin1"><label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Laughlin</surname><given-names>SB</given-names></name>, <name name-style="western"><surname>de Ruyter van Steveninck</surname><given-names>RR</given-names></name>, <name name-style="western"><surname>Anderson</surname><given-names>JC</given-names></name> (<year>1998</year>) <article-title>The metabolic cost of neural information</article-title>. <source>Nature neuroscience</source> <volume>1</volume>: <fpage>36</fpage>–<lpage>41</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Burns1"><label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Burns</surname><given-names>JG</given-names></name>, <name name-style="western"><surname>Foucaud</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Mery</surname><given-names>F</given-names></name> (<year>2011</year>) <article-title>Costs of memory: lessons from ‘mini’ brains</article-title>. <source>Proceedings Biological sciences/The Royal Society</source> <volume>278</volume>: <fpage>923</fpage>–<lpage>9</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Rieke1"><label>25</label>
<mixed-citation publication-type="other" xlink:type="simple">Rieke F, Warland D, de Ruyter van Steveninck R, Bialek W (1999) Spikes: exploring the neural code. A Bradford Book, 416 pp.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Detrain1"><label>26</label>
<mixed-citation publication-type="other" xlink:type="simple">Detrain C, Deneubourg J, Pasteels J (1999) Information Processing in Social Insects. Birkhauser Basel, 415 pp.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Franks1"><label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Franks</surname><given-names>NR</given-names></name>, <name name-style="western"><surname>Pratt</surname><given-names>SC</given-names></name>, <name name-style="western"><surname>Mallon</surname><given-names>EB</given-names></name>, <name name-style="western"><surname>Britton</surname><given-names>NF</given-names></name>, <name name-style="western"><surname>Sumpter</surname><given-names>DJT</given-names></name> (<year>2002</year>) <article-title>Information flow, opinion polling and collective intelligence in house-hunting social insects</article-title>. <source>Philosophical transactions of the Royal Society of London Series B, Biological sciences</source> <volume>357</volume>: <fpage>1567</fpage>–<lpage>83</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Blonder1"><label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Blonder</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Dornhaus</surname><given-names>A</given-names></name> (<year>2011</year>) <article-title>Time-ordered networks reveal limitations to information flow in ant colonies</article-title>. <source>PloS one</source> <volume>6</volume>: <fpage>e20298</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Marras1"><label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Marras</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Batty</surname><given-names>RS</given-names></name>, <name name-style="western"><surname>Domenici</surname><given-names>P</given-names></name> (<year>2011</year>) <article-title>Information transfer and antipredator maneuvers in schooling herring</article-title>. <source>Adaptive Behavior</source> <volume>20</volume>: <fpage>44</fpage>–<lpage>56</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Handegard1"><label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Handegard</surname><given-names>NO</given-names></name>, <name name-style="western"><surname>Boswell</surname><given-names>KM</given-names></name>, <name name-style="western"><surname>Ioannou</surname><given-names>CC</given-names></name>, <name name-style="western"><surname>Leblanc</surname><given-names>SP</given-names></name>, <name name-style="western"><surname>Tjostheim</surname><given-names>DB</given-names></name>, <etal>et al</etal>. (<year>2012</year>) <article-title>The dynamics of coordinated group hunting and collective information transfer among schooling prey</article-title>. <source>Current biology</source> <volume>22</volume>: <fpage>1213</fpage>–<lpage>7</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Kleinberg1"><label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kleinberg</surname><given-names>J</given-names></name> (<year>2000</year>) <article-title>Navigation in a small world</article-title>. <source>Nature</source> <volume>406</volume>: <fpage>845</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Livnat1"><label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Livnat</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Papadimitriou</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Dushoff</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Feldman</surname><given-names>MW</given-names></name> (<year>2008</year>) <article-title>A mixability theory for the role of sex in evolution</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source> <volume>105</volume>: <fpage>19803</fpage>–<lpage>8</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Chazelle1"><label>33</label>
<mixed-citation publication-type="other" xlink:type="simple">Chazelle B (2010) Analytical tools for natural algorithms. In: Innovations in Theoretical Computer Science. pp.32–41.</mixed-citation>
</ref>
<ref id="pcbi.1003862-McNamara1"><label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>McNamara</surname><given-names>JM</given-names></name>, <name name-style="western"><surname>Houston</surname><given-names>aI</given-names></name> (<year>1987</year>) <article-title>Memory and the efficient use of information</article-title>. <source>Journal of theoretical biology</source> <volume>125</volume>: <fpage>385</fpage>–<lpage>95</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Harcourt1"><label>35</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Harcourt</surname><given-names>JL</given-names></name>, <name name-style="western"><surname>Ang</surname><given-names>TZ</given-names></name>, <name name-style="western"><surname>Sweetman</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Johnstone</surname><given-names>Ra</given-names></name>, <name name-style="western"><surname>Manica</surname><given-names>A</given-names></name> (<year>2009</year>) <article-title>Social feedback and the emergence of leaders and followers</article-title>. <source>Current biology: CB</source> <volume>19</volume>: <fpage>248</fpage>–<lpage>52</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Stroeymeyt1"><label>36</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Stroeymeyt</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Franks</surname><given-names>NR</given-names></name>, <name name-style="western"><surname>Giurfa</surname><given-names>M</given-names></name> (<year>2011</year>) <article-title>Knowledgeable individuals lead collective decisions in ants</article-title>. <source>The Journal of experimental biology</source> <volume>214</volume>: <fpage>3046</fpage>–<lpage>3054</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Couzin2"><label>37</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Couzin</surname><given-names>ID</given-names></name>, <name name-style="western"><surname>Ioannou</surname><given-names>CC</given-names></name>, <name name-style="western"><surname>Demirel</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Gross</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Torney</surname><given-names>CJ</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <article-title>Uninformed individuals promote democratic consensus in animal groups</article-title>. <source>Science (New York, NY)</source> <volume>334</volume>: <fpage>1578</fpage>–<lpage>80</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Couzin3"><label>38</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Couzin</surname><given-names>ID</given-names></name>, <name name-style="western"><surname>Krause</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Franks</surname><given-names>NR</given-names></name>, <name name-style="western"><surname>Levin</surname><given-names>Sa</given-names></name> (<year>2005</year>) <article-title>Effective leadership and decision-making in animal groups on the move</article-title>. <source>Nature</source> <volume>433</volume>: <fpage>513</fpage>–<lpage>6</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Patwari1"><label>39</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Patwari</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Hero</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Perkins</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Correal</surname><given-names>N</given-names></name>, <name name-style="western"><surname>O'Dea</surname><given-names>R</given-names></name> (<year>2003</year>) <article-title>Relative location estimation in wireless sensor networks</article-title>. <source>IEEE Transactions on Signal Processing</source> <volume>51</volume>: <fpage>2137</fpage>–<lpage>2148</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Amundson1"><label>40</label>
<mixed-citation publication-type="other" xlink:type="simple">Amundson I, Koutsoukos X (2009) Mobile Entity Localization and Tracking in GPS-less Environnments, volume 5801 of <italic>Lecture Notes in Computer Science</italic>. Berlin, Heidelberg: Springer Berlin Heidelberg, 235–254 pp.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Rydstrom1"><label>41</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rydstrom</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Urruela</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Ström</surname><given-names>EG</given-names></name>, <name name-style="western"><surname>Svensson</surname><given-names>A</given-names></name> (<year>2006</year>) <article-title>Autonomous Positioning Techniques Based on Cramér-Rao Lower Bound Analysis</article-title>. <source>EURASIP Journal on Advances in Signal Processing</source> <volume>2006</volume>: <fpage>1</fpage>–<lpage>11</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Kempe1"><label>42</label>
<mixed-citation publication-type="other" xlink:type="simple">Kempe D, Dobra A, Gehrke J. Gossip-based computation of aggregate information. 44th Annual IEEE Symposium on Foundations of Computer Science, 2003 Proceedings: 482–491.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Graybill1"><label>43</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Graybill</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Deal</surname><given-names>R</given-names></name> (<year>1959</year>) <article-title>Combining unbiased estimators</article-title>. <source>Biometrics</source> <volume>15</volume>: <fpage>543</fpage>–<lpage>550</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Stam1"><label>44</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Stam</surname><given-names>A</given-names></name> (<year>1959</year>) <article-title>Some inequalities satisfied by the quantities of information of Fisher and Shannon</article-title>. <source>Information and Control</source> <volume>2</volume>: <fpage>101</fpage>–<lpage>112</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Zamir1"><label>45</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zamir</surname><given-names>R</given-names></name> (<year>1998</year>) <article-title>A proof of the Fisher Information inequality via a data processing arguement</article-title>. <source>IEEE Transactions on Information Theory</source> <volume>44</volume>: <fpage>1246</fpage>–<lpage>1250</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Blough1"><label>46</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Blough</surname><given-names>DS</given-names></name> (<year>1967</year>) <article-title>Stimulus generalization as signal detection in pigeons</article-title>. <source>Science (New York, NY)</source> <volume>158</volume>: <fpage>940</fpage>–<lpage>1</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Yager1"><label>47</label>
<mixed-citation publication-type="other" xlink:type="simple">Yager D, Duncan I (1971) Signal-detection analysis of luminance generalization in goldfish using latency as a graded response measure. Perception &amp; Psychophysics: 353–355.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Smith1"><label>48</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Smith</surname><given-names>JD</given-names></name>, <name name-style="western"><surname>Shields</surname><given-names>WE</given-names></name>, <name name-style="western"><surname>Washburn</surname><given-names>Da</given-names></name> (<year>2003</year>) <article-title>The comparative psychology of uncertainty monitoring and metacognition</article-title>. <source>The Behavioral and brain sciences</source> <volume>26</volume>: <fpage>317</fpage>–<lpage>39</lpage> discussion 340–73.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Smith2"><label>49</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Smith</surname><given-names>JD</given-names></name>, <name name-style="western"><surname>Washburn</surname><given-names>Da</given-names></name> (<year>2005</year>) <article-title>Uncertainty Monitoring and Metacognition by Animals</article-title>. <source>Current Directions in Psychological Science</source> <volume>14</volume>: <fpage>19</fpage>–<lpage>24</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Cook1"><label>50</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cook</surname><given-names>EP</given-names></name>, <name name-style="western"><surname>Maunsell</surname><given-names>JHR</given-names></name> (<year>2002</year>) <article-title>Dynamics of neuronal responses in macaque MT and VIP during motion detection</article-title>. <source>Nature neuroscience</source> <volume>5</volume>: <fpage>985</fpage>–<lpage>94</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-vanBergen1"><label>51</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>van Bergen</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Coolen</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Laland</surname><given-names>KN</given-names></name> (<year>2004</year>) <article-title>Nine-spined sticklebacks exploit the most reliable source when public and private information conflict</article-title>. <source>Proceedings Biological sciences/The Royal Society</source> <volume>271</volume>: <fpage>957</fpage>–<lpage>62</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Fletcher1"><label>52</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fletcher</surname><given-names>RJ</given-names></name>, <name name-style="western"><surname>Miller</surname><given-names>CW</given-names></name> (<year>2008</year>) <article-title>The type and timing of social information alters offspring production</article-title>. <source>Biology letters</source> <volume>4</volume>: <fpage>482</fpage>–<lpage>5</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Simmons1"><label>53</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Simmons</surname><given-names>L</given-names></name> (<year>1986</year>) <article-title>Inter-male competition and mating success in the field cricket, Gryllus bimaculatus(de Geer)</article-title>. <source>Animal Behaviour</source>: <fpage>567</fpage>–<lpage>579</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Hsu1"><label>54</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hsu</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Earley</surname><given-names>RL</given-names></name>, <name name-style="western"><surname>Wolf</surname><given-names>LL</given-names></name> (<year>2006</year>) <article-title>Modulation of aggressive behaviour by fighting experience: mechanisms and contest outcomes</article-title>. <source>Biological reviews of the Cambridge Philosophical Society</source> <volume>81</volume>: <fpage>33</fpage>–<lpage>74</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Wilson1"><label>55</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wilson</surname><given-names>J</given-names></name> (<year>1994</year>) <article-title>Variation in initiator strategy in fighting by silvereyes</article-title>. <source>Animal behaviour</source> <volume>47</volume>: <fpage>153</fpage>–<lpage>162</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Zahavi1"><label>56</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zahavi</surname><given-names>A</given-names></name> (<year>1982</year>) <article-title>The pattern of vocal signals and the information they convey</article-title>. <source>Behaviour</source> <volume>80</volume>: <fpage>1</fpage>–<lpage>8</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Adams1"><label>57</label>
<mixed-citation publication-type="other" xlink:type="simple">Adams ES (2001) Threat Displays in Animal Communication: Handicaps, Reputations, and Commitments. In: Nesse R, editor, Evolution and the Capacity for Commitment. p. 352.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Ballentine1"><label>58</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ballentine</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Searcy</surname><given-names>Wa</given-names></name>, <name name-style="western"><surname>Nowicki</surname><given-names>S</given-names></name> (<year>2008</year>) <article-title>Reliable aggressive signalling in swamp sparrows</article-title>. <source>Animal Behaviour</source> <volume>75</volume>: <fpage>693</fpage>–<lpage>703</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Hurd1"><label>59</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hurd</surname><given-names>PL</given-names></name>, <name name-style="western"><surname>Enquist</surname><given-names>M</given-names></name> (<year>2001</year>) <article-title>Threat display in birds</article-title>. <source>Canadian Journal of Zoology</source> <volume>79</volume>: <fpage>931</fpage>–<lpage>942</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Stout1"><label>60</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Stout</surname><given-names>J</given-names></name> (<year>1975</year>) <article-title>Aggressive communication by Larus glaucescens III. Description of the displays related to territorial protection</article-title>. <source>Behaviour</source> <volume>55</volume>: <fpage>181</fpage>–<lpage>208</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Schultz1"><label>61</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schultz</surname><given-names>KM</given-names></name>, <name name-style="western"><surname>Passino</surname><given-names>KM</given-names></name>, <name name-style="western"><surname>Seeley</surname><given-names>TD</given-names></name> (<year>2008</year>) <article-title>The mechanism of flight guidance in honeybee swarms: subtle guides or streaker bees?</article-title> <source>The Journal of experimental biology</source> <volume>211</volume>: <fpage>3287</fpage>–<lpage>95</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Latty1"><label>62</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Latty</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Duncan</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Beekman</surname><given-names>M</given-names></name> (<year>2009</year>) <article-title>High bee traffic disrupts transfer of directional information in flying honeybee swarms</article-title>. <source>Animal Behaviour</source> <volume>78</volume>: <fpage>117</fpage>–<lpage>121</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Seeley1"><label>63</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Seeley</surname><given-names>TD</given-names></name>, <name name-style="western"><surname>Buhrman</surname><given-names>SC</given-names></name> (<year>1999</year>) <article-title>Group decision making in swarms of honey bees</article-title>. <source>Behavioral Ecology and Sociobiology</source> <volume>45</volume>: <fpage>19</fpage>–<lpage>31</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Seeley2"><label>64</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Seeley</surname><given-names>TD</given-names></name>, <name name-style="western"><surname>Visscher</surname><given-names>PK</given-names></name>, <name name-style="western"><surname>Passino</surname><given-names>KM</given-names></name> (<year>2006</year>) <article-title>Group Decision Making in Honey Bee Swarms</article-title>. <source>American Scientist</source> <volume>94</volume>: <fpage>220</fpage>–<lpage>229</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Robinson1"><label>65</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Robinson</surname><given-names>EJH</given-names></name>, <name name-style="western"><surname>Franks</surname><given-names>NR</given-names></name>, <name name-style="western"><surname>Ellis</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Okuda</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Marshall</surname><given-names>JaR</given-names></name> (<year>2011</year>) <article-title>A simple threshold rule is sufficient to explain sophisticated collective decision-making</article-title>. <source>PloS one</source> <volume>6</volume>: <fpage>e19981</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Robinson2"><label>66</label>
<mixed-citation publication-type="other" xlink:type="simple">Robinson EJH, Feinerman O, Franks NR (2014) How collective comparisons emerge without individual comparisons of the options. Proceedings Biological sciences/The Royal Society 281.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Cover1"><label>67</label>
<mixed-citation publication-type="other" xlink:type="simple">Cover TM, Thomas JA (2006) Elements of Information Theory. John Wiley &amp; Sons, 2nd edition, 748 pp.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Oru1"><label>68</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Oruç</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Maloney</surname><given-names>LT</given-names></name>, <name name-style="western"><surname>Landy</surname><given-names>MS</given-names></name> (<year>2003</year>) <article-title>Weighted linear cue combination with possibly correlated error</article-title>. <source>Vision Research</source> <volume>43</volume>: <fpage>2451</fpage>–<lpage>2468</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Bahrami1"><label>69</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bahrami</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Olsen</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Latham</surname><given-names>PE</given-names></name>, <name name-style="western"><surname>Roepstorff</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Rees</surname><given-names>G</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>Optimally interacting minds</article-title>. <source>Science (New York, NY)</source> <volume>329</volume>: <fpage>1081</fpage>–<lpage>5</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Ernst1"><label>70</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ernst</surname><given-names>MO</given-names></name> (<year>2010</year>) <article-title>Behavior. Decisions made better</article-title>. <source>Science (New York, NY)</source> <volume>329</volume>: <fpage>1022</fpage>–<lpage>3</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Feinerman1"><label>71</label>
<mixed-citation publication-type="other" xlink:type="simple">Feinerman O, Korman A (2012) Memory lower bounds for randomized collaborative search and implications for biology. In: Proceedings of International Symposium on Distributed COmputing (DISC). pp.61–75.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Shklarsh1"><label>72</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shklarsh</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Ariel</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Schneidman</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Ben-Jacob</surname><given-names>E</given-names></name> (<year>2011</year>) <article-title>Smart swarms of bacteria-inspired agents with performance adaptable interactions</article-title>. <source>PLoS computational biology</source> <volume>7</volume>: <fpage>e1002177</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003862-Diggle1"><label>73</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Diggle</surname><given-names>SP</given-names></name>, <name name-style="western"><surname>Gardner</surname><given-names>A</given-names></name>, <name name-style="western"><surname>West</surname><given-names>Sa</given-names></name>, <name name-style="western"><surname>Griffin</surname><given-names>AS</given-names></name> (<year>2007</year>) <article-title>Evolutionary theory of bacterial quorum sensing: when is a signal not a signal?</article-title> <source>Philosophical transactions of the Royal Society of London Series B, Biological sciences</source> <volume>362</volume>: <fpage>1241</fpage>–<lpage>9</lpage>.</mixed-citation>
</ref>
</ref-list></back>
</article>
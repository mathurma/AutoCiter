<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article article-type="research-article" dtd-version="3.0" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1004860</article-id>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-15-01215</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Cell biology</subject><subj-group><subject>Cellular types</subject><subj-group><subject>Animal cells</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cellular neuroscience</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Hearing</subject><subj-group><subject>Pitch perception</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Hearing</subject><subj-group><subject>Pitch perception</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Hearing</subject><subj-group><subject>Pitch perception</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Membrane potential</subject><subj-group><subject>Action potentials</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Membrane potential</subject><subj-group><subject>Action potentials</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Neurophysiology</subject><subj-group><subject>Action potentials</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Neurophysiology</subject><subj-group><subject>Action potentials</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neurophysiology</subject><subj-group><subject>Action potentials</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Linguistics</subject><subj-group><subject>Phonetics</subject><subj-group><subject>Vowels</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Sensory physiology</subject><subj-group><subject>Auditory system</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Sensory physiology</subject><subj-group><subject>Auditory system</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory systems</subject><subj-group><subject>Auditory system</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Nervous system</subject><subj-group><subject>Nerves</subject><subj-group><subject>Auditory nerves</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Nervous system</subject><subj-group><subject>Nerves</subject><subj-group><subject>Auditory nerves</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Membrane potential</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Membrane potential</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Learning and memory</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Learning Pitch with STDP: A Computational Model of Place and Temporal Pitch Perception Using Spiking Neural Networks</article-title>
<alt-title alt-title-type="running-head">Learning Pitch with STDP</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<name name-style="western">
<surname>Erfanian Saeedi</surname>
<given-names>Nafise</given-names>
</name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Blamey</surname>
<given-names>Peter J.</given-names>
</name>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Burkitt</surname>
<given-names>Anthony N.</given-names>
</name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Grayden</surname>
<given-names>David B.</given-names>
</name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="aff" rid="aff004"><sup>4</sup></xref>
</contrib>
</contrib-group>
<aff id="aff001"><label>1</label> <addr-line>NeuroEngineering Laboratory, Department of Electrical and Electronic Engineering, University of Melbourne, Melbourne, Victoria, Australia</addr-line></aff>
<aff id="aff002"><label>2</label> <addr-line>The Bionics Institute, East Melbourne, Victoria, Australia</addr-line></aff>
<aff id="aff003"><label>3</label> <addr-line>Department of Medical Bionics, University of Melbourne, Melbourne, Victoria, Australia</addr-line></aff>
<aff id="aff004"><label>4</label> <addr-line>Centre for Neural Engineering, University of Melbourne, Melbourne, Victoria, Australia</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Battaglia</surname>
<given-names>Francesco P.</given-names>
</name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1"><addr-line>Radboud Universiteit Nijmegen, NETHERLANDS</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<fn fn-type="con" id="contrib001">
<p>Conceived and designed the experiments: NES PJB ANB DBG. Performed the experiments: NES. Analyzed the data: NES. Contributed reagents/materials/analysis tools: NES. Wrote the paper: NES PJB ANB DBG.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">n.erfaniansaeedi@student.unimelb.edu.au</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>6</day>
<month>4</month>
<year>2016</year>
</pub-date>
<pub-date pub-type="collection">
<month>4</month>
<year>2016</year>
</pub-date>
<volume>12</volume>
<issue>4</issue>
<elocation-id>e1004860</elocation-id>
<history>
<date date-type="received">
<day>20</day>
<month>7</month>
<year>2015</year>
</date>
<date date-type="accepted">
<day>8</day>
<month>3</month>
<year>2016</year>
</date>
</history>
<permissions>
<copyright-year>2016</copyright-year>
<copyright-holder>Erfanian Saeedi et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1004860"/>
<abstract>
<p>Pitch perception is important for understanding speech prosody, music perception, recognizing tones in tonal languages, and perceiving speech in noisy environments. The two principal pitch perception theories consider the place of maximum neural excitation along the auditory nerve and the temporal pattern of the auditory neurons’ action potentials (spikes) as pitch cues. This paper describes a biophysical mechanism by which fine-structure temporal information can be extracted from the spikes generated at the auditory periphery. Deriving meaningful pitch-related information from spike times requires neural structures specialized in capturing synchronous or correlated activity from amongst neural events. The emergence of such pitch-processing neural mechanisms is described through a computational model of auditory processing. Simulation results show that a correlation-based, unsupervised, spike-based form of Hebbian learning can explain the development of neural structures required for recognizing the pitch of simple and complex tones, with or without the fundamental frequency. The temporal code is robust to variations in the spectral shape of the signal and thus can explain the phenomenon of pitch constancy.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author Summary</title>
<p>Pitch is the perceptual correlate of sound frequency. Our auditory system has a sophisticated mechanism to process and perceive the neural information corresponding to pitch. This mechanism employs both the place and the temporal pattern of pitch-evoked neural events. Based on the known functions of the auditory system, we develop a computational model of pitch perception using a network of neurons with modifiable connections. We demonstrate that a well-known neural learning rule that is based on the timing of the neural events can identify and strengthen the neuronal connections that are most effective for the extraction of pitch. By providing an insight into how the auditory system interprets pitch information, the results of our study can be used to develop improved sound processing strategies for cochlear implants. In cochlear implant hearing, auditory percept is generated by stimulating the auditory neurons with controlled electrical impulses, enhancing which with the help of the model would lead to a better representation of pitch and would subsequently improve music perception and speech understanding in noisy environments in cochlear implant users.</p>
</abstract>
<funding-group>
<funding-statement>This work was supported by the Australian Research Council Discovery Project Grant DP1094830 (DBG) and a Victorian Life Sciences Computation Initiative grant number VR0003 (DBG) on its Peak Computing Facility at the University of Melbourne, an initiative of the Victorian Government, Australia. The Bionics Institute acknowledges the support it receives from the Victorian Government through its Operational Infrastructure Support Program. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="6"/>
<table-count count="2"/>
<page-count count="21"/>
</counts>
<custom-meta-group>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>All audio files are available from GitHub: <ext-link ext-link-type="uri" xlink:href="https://github.com/nerfanian/Data-for-Publication-Learning-Pitch-with-STDP" xlink:type="simple">https://github.com/nerfanian/Data-for-Publication-Learning-Pitch-with-STDP</ext-link>.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>The existence of a pitch processing center or a group of specialized “pitch neurons” in the mammalian auditory system has been debated in recent years. For example, through single unit recordings, Bendor and Wang [<xref ref-type="bibr" rid="pcbi.1004860.ref001">1</xref>] found a potential pitch center in the anterolateral border of primary auditory cortex in marmoset monkeys. These pitch neurons were characterized by sustained spiking in response to their preferred pitch, evoked by a pure tone or a harmonic complex. Human brain analogues of monkey’s lateral primary auditory cortex, postulated by Bendor and Wang [<xref ref-type="bibr" rid="pcbi.1004860.ref001">1</xref>] to be the pitch center, has also been found to perform pitch-related processing. For example, through positron emission tomography (PET), Zatorre and Belin [<xref ref-type="bibr" rid="pcbi.1004860.ref002">2</xref>] found that areas in the lateral Heschl’s gyrus responded to the pitch of pure tones. Using functional magnetic resonance imaging (fMRI), Patterson et al. [<xref ref-type="bibr" rid="pcbi.1004860.ref003">3</xref>] found the same cortical area to be consistently activated by periodic stimuli with a defined pitch. Penagos et al. [<xref ref-type="bibr" rid="pcbi.1004860.ref004">4</xref>] also confirmed the sensitivity of the Heschl’s gyrus area to the pitch of harmonic complexes through fMRI investigations.</p>
<p>Possible locations for pitch sensitive neural units along the auditory pathway have been postulated in a number of modelling studies. For example, the coincidence detector neurons of the model of Shamma and Klein [<xref ref-type="bibr" rid="pcbi.1004860.ref005">5</xref>] required strong phase-locked inputs; therefore, Shamma and Klein proposed the inferior colliculus as a possible pitch processing site. Inferior colliculus neurons receive inputs from the cochlear nucleus neurons that, due to having onset type cells [<xref ref-type="bibr" rid="pcbi.1004860.ref006">6</xref>], generate spectrally and temporally sharp responses suitable for coincidence detector units.</p>
<p>The functional role of the cochlear nucleus in varying the timing of spikes has been observed in earlier studies [<xref ref-type="bibr" rid="pcbi.1004860.ref007">7</xref>]. Spike time variation in the auditory nerve is partially caused by the cochlear travelling wave and results in the spiking of neurons with high characteristic frequency (CF) several milliseconds prior to low-CF neurons in response to a stimulus. Through experimental studies, Oertel et al. [<xref ref-type="bibr" rid="pcbi.1004860.ref008">8</xref>] showed that it was particularly octopus cells in the cochlear nucleus that had the ability to detect spiking coincidences among a population of innervating auditory nerve fibers. The octopus cells were found to compensate for the different arrival times of the auditory nerve spikes. The ability of octopus cells to extract precise temporal information from the auditory nerve was related to their special anatomical structure and biophysical characteristics [<xref ref-type="bibr" rid="pcbi.1004860.ref009">9</xref>]. The compensating role of octopus cells was further investigated in a modelling study by Spencer et al. [<xref ref-type="bibr" rid="pcbi.1004860.ref010">10</xref>]. They showed that different arrival times of the auditory nerve spikes were compensated by proportional dendritic delays in the octopus cells, thus enabling the detection of the spike coincidences to be carried out more effectively in later stages.</p>
<p>Given the uncertainties that still exist about the physiology of pitch centers in the auditory system, the focus of this paper is on modelling the known <italic>functions</italic> of the possible pitch neurons rather than replicating the anatomical stages (and their interactions) involved in extracting the pitch information. According to existing literature, pitch sensitive neurons have a preferred pitch [<xref ref-type="bibr" rid="pcbi.1004860.ref011">11</xref>], exhibit sustained spiking activity [<xref ref-type="bibr" rid="pcbi.1004860.ref012">12</xref>,<xref ref-type="bibr" rid="pcbi.1004860.ref013">13</xref>], respond to pitch as a unified entity (regardless of the spectral shape of the stimuli) [<xref ref-type="bibr" rid="pcbi.1004860.ref001">1</xref>], and are located in the subcortical part of the auditory pathway [<xref ref-type="bibr" rid="pcbi.1004860.ref005">5</xref>,<xref ref-type="bibr" rid="pcbi.1004860.ref007">7</xref>].</p>
<p>In the model developed in this paper, it was assumed that the spectral (place) and temporal pitch information were processed by different populations of neurons. These neuronal populations, despite being connected to each other, used different mechanisms to extract their component of pitch information. One reason for considering such a neuronal architecture was the functioning differences between the two hemispheres of the brain in processing the pitch of stimulus. For example, Zatorre and Belin [<xref ref-type="bibr" rid="pcbi.1004860.ref002">2</xref>] found that the right hemisphere exhibited a stronger response to pitch-related spectral variations, while the left hemisphere showed higher degrees of activation in response to temporal variations of the stimulus. Based on these observations, Zatorre and Belin [<xref ref-type="bibr" rid="pcbi.1004860.ref002">2</xref>] suggested that the auditory system had two parallel processing sub-systems that provided different spectral and temporal resolutions required for perceiving a wide range of stimuli, such as speech and music. Poeppel [<xref ref-type="bibr" rid="pcbi.1004860.ref014">14</xref>] proposed that the hemispheric functional differences were a result of different timescale integration windows applied by each hemisphere (i.e., shorter for the left and longer for the right hemisphere) when processing auditory information. In a lesion study, Johnsrude et al. [<xref ref-type="bibr" rid="pcbi.1004860.ref015">15</xref>] identified the right Heschl’s gyrus as responsible for making judgments on the direction of pitch changes (i.e., pitch ranking) because patients whose right temporal lobes were partially resected showed higher pitch-difference thresholds compared to the control group. They also found that, unlike pitch ranking, a pitch discrimination task (detecting a pitch difference regardless of direction) could be performed by either hemisphere.</p>
<p>Another observation that inspired the use of a separate population of neurons for temporal pitch processing in the auditory system is the special organization of brain tissue [<xref ref-type="bibr" rid="pcbi.1004860.ref016">16</xref>] as illustrated in <xref ref-type="fig" rid="pcbi.1004860.g001">Fig 1A</xref>. Inputs to the auditory cortex can be presented in terms of spatio-temporal maps that describe the activity of spatially different neurons over time [<xref ref-type="bibr" rid="pcbi.1004860.ref017">17</xref>]. <xref ref-type="fig" rid="pcbi.1004860.g001">Fig 1B</xref> shows an example of a spatio-temporal pattern for a synthesized vowel /ɑ/, with F0 of 110 Hz and the first three formants located at 710 Hz, 1150 Hz, and 2700 Hz, using a model of auditory periphery developed by Zilany et al. [<xref ref-type="bibr" rid="pcbi.1004860.ref018">18</xref>]. Observations have shown that tonotopicity (viz., neurons responding to a frequency based on their location, leading to a place-frequency map) exists in the areas of higher auditory processing centers like the auditory cortex [<xref ref-type="bibr" rid="pcbi.1004860.ref019">19</xref>]. Tonotopicity (indicated by the color map in <xref ref-type="fig" rid="pcbi.1004860.g001">Fig 1A</xref>) thus accounts for the extraction of power-based or place features from the signal. Spectral features including the first two formants are strongly represented in the spatio-temporal patterns. The first two formants are indicated with grey arrows in <xref ref-type="fig" rid="pcbi.1004860.g001">Fig 1B</xref>. The role of the tonotopically-arranged areas could be interpreted as averaging the spatio-temporal patterns over time, resulting in a profile of activity rates across the auditory nerve. <xref ref-type="fig" rid="pcbi.1004860.g001">Fig 1C</xref> shows the corresponding rate profile (normalized to maximum) that is considered as the place code of pitch. The first two formants (indicated with grey arrows) have strong representation in the place code shown in <xref ref-type="fig" rid="pcbi.1004860.g001">Fig 1C</xref>. The cortex also has columnar divisions with connections to the tonotopically-arranged areas. According to this area-column synergy, measuring the activity across columns would provide a temporal code for pitch. <xref ref-type="fig" rid="pcbi.1004860.g001">Fig 1D</xref> represents a possible temporal code, extraction of which is the topic of this paper. Of note is the spacing between the peaks of the temporal code in <xref ref-type="fig" rid="pcbi.1004860.g001">Fig 1D</xref> that corresponds to the period of stimulus (i.e., ~9 ms), which is the F0 of the vowel.</p>
<fig id="pcbi.1004860.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004860.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Cortical structure consisting of tonotopically-arranged areas of columns and their expected processed outputs.</title>
<p>(A) Tonotopically-arranged areas of columns. Colors of the exemplar tonotopicity represent tuning to different frequencies. (B) A spatio-temporal map for a periodic stimulus is generated by the auditory nerve and provided to the next processing level. The stimulus is a synthesized /ɑ/ vowel, with F0 = 110 Hz and the first three formants at 710 Hz, 1150 Hz, and 2700 Hz indicated with grey arrows. Dark areas show stronger activities. (C) The average neural activity as a measure of the signal power originates from the tonotopical arrangement. Dominant spectral peaks (grey arrows) correspond to the first two vowel formants. (D) Expected extracted temporal code from the columns that would serve as a measure of phase or synchrony between the neurons. The stimulus period is manifested through the inter-peak time intervals and their relative amplitudes. Both spectral and temporal codes are normalized to maximum for better visualization. (E-F) Computational analogue of the cortical structure shown in (A). Phase I and Phase II are responsible for extracting the place and temporal pitch codes, respectively. A model of the auditory periphery constitutes Phase I. The outputs of Phase I are converted into spike times and input to Phase II. The input/output synapses of the spiking neural network in the second phase are modified by a neural learning algorithm in order to generate precisely-timed spike trains in the output, from which a meaningful code for pitch can be extracted. (G) The shape of the STDP learning window used in the learning rule described in the Methods section. The notation shown in the figure is used in the learning equations presented in the Methods section.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004860.g001" xlink:type="simple"/>
</fig>
<p>Unlike the place code, simple averaging would not capture the temporal code because of the temporal variations (e.g., jitter) that naturally exists in the neural code generated by the auditory nerve. Therefore, capturing the fine-time structures, such as spike coincidences, from the neural code required an intermediate processing stage that adjusted the spike timings before any sort of averaging occurred. This intermediate processing stage would possibly replicate the functional role of the cochlear nucleus [<xref ref-type="bibr" rid="pcbi.1004860.ref007">7</xref>]. Enabling a model of cochlear nucleus to perform this function required specific neural connectivity that could arise through neural plasticity.</p>
<p>The computational analogue of the cortical structure shown in <xref ref-type="fig" rid="pcbi.1004860.g001">Fig 1A</xref> is depicted in <xref ref-type="fig" rid="pcbi.1004860.g001">Fig 1E and 1F</xref>. The two phases were defined by the set of modelling components that together extracted the place (Phase I) or temporal (Phase II) cues for pitch perception. Phase I performed temporal averaging for auditory neurons. Phase II provided a biologically-inspired computational substrate for producing precisely-timed spikes that would lead to an efficient temporal pitch code. A spiking neural network with plastic input/output synapses constituted the second phase. It is apparent that <xref ref-type="fig" rid="pcbi.1004860.g001">Fig 1C and 1D</xref> represent the outputs of Phase I and Phase II of the analogue shown in <xref ref-type="fig" rid="pcbi.1004860.g001">Fig 1E and 1F</xref>, respectively.</p>
</sec>
<sec id="sec002" sec-type="materials|methods">
<title>Methods</title>
<p>This section describes the data used in the simulations and the process of place and temporal pitch information extraction. Extraction of the place code is described jointly with the model of auditory periphery in the Auditory periphery (Phase I) section. Extracting the temporal code requires a neural setup that is properly adjusted to fit the pitch perception task. The neural components and associated learning equations are presented in the Neural setup and Synaptic adjustments sections, respectively.</p>
<sec id="sec003">
<title>Data</title>
<p>Sound stimuli for this study were synthesized and real-world sounds that a typical listener might experience. Synthesized sounds are advantageous because they can be generated easily and precisely. However, for the sake of generality, real-world recordings from various musical instruments were also included in the simulations. Types of stimuli and their descriptions are given in <xref ref-type="table" rid="pcbi.1004860.t001">Table 1</xref>. All stimuli were 0.5 s long, had a loudness of 60 dB SPL, and were sampled at 16,000 sample/s.</p>
<table-wrap id="pcbi.1004860.t001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004860.t001</object-id>
<label>Table 1</label> <caption><title>Types of sound stimuli and associated parameters used in this study.</title></caption>
<alternatives>
<graphic id="pcbi.1004860.t001g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004860.t001" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="justify"/>
<th align="justify">Type</th>
<th align="justify"># Samples</th>
<th align="justify">Parameters</th>
<th align="center">Notation</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><bold>1</bold></td>
<td align="center">Pure Tones</td>
<td align="center">29</td>
<td align="left">Sinusoids of 29 frequencies, spaced one semitone apart and covering the [98 Hz, 493 Hz] range.</td>
<td align="center">—</td>
</tr>
<tr>
<td align="center"><bold>2</bold></td>
<td align="center">Vowels</td>
<td align="center">58</td>
<td align="left">Sustained vowels /ɑ/ and /i/, synthesized using the cascade branch of the KLATT speech synthesizer [20]. The vowels’ first three formant frequencies (in Hz) and their associated bandwidths (shown in brackets, also in Hz) were 710 [40], 1150 [43], and 2700 [105] for /ɑ/ and 230 [68], 2000 [63], and 3000 [129] for /i/.</td>
<td align="center">/ɑ/, /i/</td>
</tr>
<tr>
<td align="center"><bold>3</bold></td>
<td align="center">Telephone Vowels</td>
<td align="center">58</td>
<td align="left">The synthesized vowels were filtered through a high-pass filter with a cut-off frequency of 300 Hz, simulating the effect of telephone transmission line.</td>
<td align="center">/ɑ/<sub>T</sub>, /i/<sub>T</sub></td>
</tr>
<tr>
<td align="center"><bold>5</bold></td>
<td align="center">Musical Instruments</td>
<td align="center">79</td>
<td align="left">Includes 29 piano, 17 violin, 13 flute, and 20 cello recorded sounds with pitch labels matching those of the pure tones. All sound files were retrieved from the Electronic Music Studios of the University of Iowa (<ext-link ext-link-type="uri" xlink:href="http://theremin.music.uiowa.edu/index.html" xlink:type="simple">http://theremin.music.uiowa.edu/index.html</ext-link>). Only one recorded audio channel was used. The sampling rate was changed to 16,000 sample/s.</td>
<td align="center">—</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p>Pure tones were desirable stimuli because they have simple spectral shapes and evoke salient pitches. Speech is possibly the most common sound stimulus that one might experience; therefore, voiced speech tokens (sung vowels /ɑ/ and /i/) were well-suited to the purpose of this study. Synthetically generated variations of the vowel stimuli (/ɑ/<sub>T</sub> and /i/<sub>T</sub>) were also included in this study. This enabled the investigation of how the auditory system encoded pitch in real-life listening conditions such as telephone conversation, wherein the low-frequency contents of speech, including the F0 for most speakers, would be eliminated. The telephone line was simulated by high-pass filtering the original vowels using a high-pass FIR (finite impulse response) filter with a sharp cut-off frequency of 300 Hz. The filter was designed using MATLAB Filter Design &amp; Analysis Tool with Fstop = 300 Hz, Fpass = 350 Hz, Astop = 80 dB, and Apass = 1dB. Filter order was 110 (minimum) and sampling rate was 16,000 sample/s.</p>
<p>Musical instruments provide a variety of spectral shapes and were included in the simulations to investigate the behavior of the model in response to spectrally-different sounds. The instruments were selected based on availability in the database, spectral shape variety, and the range of pitches that each instrument could generate.</p>
</sec>
<sec id="sec004">
<title>Extraction of pitch information</title>
<p>The purpose of this study was to investigate how place and temporal pitch cues were extracted from the spatio-temporal maps generated by the auditory nerve. The former was assumed to be a profile of rates (temporal averages) associated with different auditory neurons. Extraction of the place cues is described jointly with the generation of the spatio-temporal maps in the Auditory periphery (Phase I) section. The Temporal code of pitch (Phase II) section explains the neural structure configuration and the associated learning process leading to pitch-related temporal information.</p>
<sec id="sec005">
<title>Auditory periphery (Phase I)</title>
<p>The auditory periphery was modelled by a middle ear filter, followed by a 200-channel cochlear filter bank. Each filter simulated a single cochlear position and its output was interpreted as the activity of an inner hair cell (IHC) with a characteristic frequency (CF) equal to the center frequency of the filter. The structure of the middle ear and cochlear filters are described by Zilany and Bruce [<xref ref-type="bibr" rid="pcbi.1004860.ref021">21</xref>]. In the simulations in this study, the updated implementation of the cochlear filters, available online at <ext-link ext-link-type="uri" xlink:href="http://goo.gl/MCTzjT" xlink:type="simple">http://goo.gl/MCTzjT</ext-link>, was used. CFs were determined based on the cochlear positions that the filters represented using the Greenwood function [<xref ref-type="bibr" rid="pcbi.1004860.ref022">22</xref>],
<disp-formula id="pcbi.1004860.e001">
<alternatives>
<graphic id="pcbi.1004860.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004860.e001" xlink:type="simple"/>
<mml:math display="block" id="M1">
<mml:mrow><mml:mi>C</mml:mi><mml:mi>F</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>d</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>165.4</mml:mn><mml:mo>×</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mn>2.1</mml:mn><mml:mo>×</mml:mo><mml:mfrac><mml:mi>d</mml:mi><mml:mrow><mml:mn>34</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(1)</label>
</disp-formula>
where <italic>d</italic> is the position of the cochlear filter (measured from the apex of the cochlea in mm) and was incremented in 0.1 mm steps. Cochlear positions in the range 3–22.9 mm were modelled. This led to cochlear filters with center frequencies from 88 Hz up to nearly 4 kHz.</p>
<p>Spatio-temporal maps were generated by stacking the activity of the 200 tonotopically-ordered IHCs at different time steps. <xref ref-type="fig" rid="pcbi.1004860.g002">Fig 2</xref> shows the temporal representation of the acoustical waveform (A-D) and simulated spatio-temporal maps (E-H) for pure tone, /ɑ/ stimuli, /i/ stimuli, and piano notes, respectively, all eliciting the same pitch of 110 Hz. Dark areas in the spatio-temporal maps show stronger rate of activity across cochlear positions, represented by their CF on the ordinate. The periodic behavior of the waveform is reflected in the spatio-temporal maps for the four stimuli.</p>
<fig id="pcbi.1004860.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004860.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Acoustical waveforms and spatio-temporal maps for four types of stimuli eliciting a pitch of 110 Hz.</title>
<p>(A) Temporal representation of a pure tone of 110 Hz. (B) Temporal representation of an /ɑ/ stimulus with F0 = 110 Hz. (C) Temporal representation of an /i/ stimulus with F0 = 110 Hz. (D) Temporal representation of a piano key with an absolute frequency of 110 Hz. (E) Spatio-temporal map for a pure tone of 110 Hz. (F) Spatio-temporal map for an /ɑ/ stimulus with F0 = 110 Hz. (G) Spatio-temporal map for an /i/ stimulus with F0 = 110 Hz. (H) Spatio-temporal map for a piano key with an absolute frequency of 110 Hz. Amplitude scale is arbitrary but consistent in (A-D). The 200 auditory neurons are sorted based on their CFs on the ordinate in (E-H). Dark areas show stronger activity in (E-H). (I) Averaged spatio-temporal map (extracted place code of pitch) for a pure tone of 110 Hz. (J) Averaged spatio-temporal map for an /ɑ/ stimulus with F0 = 110 Hz (solid line) and its high-pass filtered version (dashed). (K) Averaged spatio-temporal map for an /i/ stimulus with F0 = 110 Hz (solid) and its high-pass filtered version (dashed). (L) Averaged spatio-temporal map for a piano key with an absolute frequency of 110 Hz. Averaging interval is 100 ms long in (I-L) and resulting activities have been normalized to maximum for better visualization. The 200 auditory neurons are sorted based on their CFs on the abscissa in (I-L).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004860.g002" xlink:type="simple"/>
</fig>
<p>For the pure tone, activities show a simple pattern repeating approximately every 10 ms (corresponding to the period of a 110 Hz tone) and are concentrated only at low-CF cochlear regions (towards the apex of the cochlea). For the two vowels, on the other hand, activity patterns are spread across a wider cochlear range and have a more complex periodic structure due to formants. The piano key sound activated lower-CF cochlear regions and the patterns were more oscillatory compared to the vowels due to the percussive nature of this instrument.</p>
<p>The place code of pitch refers to the rate of activity across different cochlear locations. To extract the rate of activity, the output of each cochlear filter was averaged over a 100 ms interval. This led to a vector of 200 rates for each sound stimulus. Extracted place code for the four stimuli presented in <xref ref-type="fig" rid="pcbi.1004860.g002">Fig 2A–2D</xref> are shown in <xref ref-type="fig" rid="pcbi.1004860.g002">Fig 2I–2L</xref>. The latter presents average activities or rate profiles as a function of cochlear position. The rate profiles derived from the pure tone (<xref ref-type="fig" rid="pcbi.1004860.g002">Fig 2I</xref>) has a single peak at a cochlear position with a CF similar to its frequency. The vowels (<xref ref-type="fig" rid="pcbi.1004860.g002">Fig 2J and 2K</xref>-solid lines) show a weak representation of the pitch-related low-frequency peak, plus formant-related peaks in the middle-frequency range. Consistent with the vowels’ characteristics, the formant-related peaks occur at approximately 700 Hz and 1100 Hz for /ɑ/ (<xref ref-type="fig" rid="pcbi.1004860.g002">Fig 2B</xref>) and at 230 Hz and 2000 Hz for /i/ (<xref ref-type="fig" rid="pcbi.1004860.g002">Fig 2C</xref>). The place codes associated with the telephone simulated vowels are shown with dashed lines in <xref ref-type="fig" rid="pcbi.1004860.g002">Fig 2J and 2K</xref>. It is observed that removing the low-frequency content of the signal suppresses the place code at these regions. For /ɑ/, this also affects the frequency region between the second and third formants. The place code of pitch is, therefore, highly dependent on the spectral shape of the stimulus. For the piano sound (<xref ref-type="fig" rid="pcbi.1004860.g002">Fig 2L</xref>), the extracted place code shows stronger dips and peaks compared to the vowels, indicating a clear-cut harmonic structure for this type of sound.</p>
</sec>
<sec id="sec006">
<title>Temporal code of pitch (Phase II)</title>
<p>As shown in the Auditory periphery (Phase I) section, the auditory nerve contained information on pitch combined with other sound attributes such as spectral shape or timbre. In addition to pitch and timbre, loudness and sound source location also have neural representations [<xref ref-type="bibr" rid="pcbi.1004860.ref023">23</xref>,<xref ref-type="bibr" rid="pcbi.1004860.ref024">24</xref>]. The purpose of Phase II was to develop a biologically-plausible neural substrate that would enable capturing the pitch-related temporal information from the activity of the auditory neurons. The ultimate goal was to generate phase-locked responses at the output of Phase II so that averaging over pitch neurons would not lead to loss of temporal pitch information. Temporal adjustment of the post-synaptic spikes required employing a spiking interface and modifying the synaptic connections of the spiking neural network through a plasticity rule that was capable of capturing the correlated activity among pre-synaptic neurons. These two requirements are described in the following two sections.</p>
</sec>
<sec id="sec007">
<title>Neural setup</title>
<p>Each auditory neuron was simulated by an inhomogeneous Poisson process with an intensity, <bold><italic>λ</italic></bold><sub><bold><italic>j</italic></bold></sub>, <bold>1 ≤ <italic>j</italic> ≤ 200</bold>, equal to the amplitude of IHC activity innervated by the auditory neuron. The IHC output was, therefore, interpreted as the time-dependent instantaneous rate of spike arrival at each synapse, indicated by <bold><italic>w</italic></bold><sub><bold><italic>ij</italic></bold></sub>, <bold>1 ≤ <italic>j</italic> ≤ 200</bold>. The refractory effect was included in the synapse model [<xref ref-type="bibr" rid="pcbi.1004860.ref021">21</xref>,<xref ref-type="bibr" rid="pcbi.1004860.ref025">25</xref>] and so was not included in the spike generation process.</p>
<p>The spike train generated by each auditory neuron was represented by
<disp-formula id="pcbi.1004860.e002">
<alternatives>
<graphic id="pcbi.1004860.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004860.e002" xlink:type="simple"/>
<mml:math display="block" id="M2">
<mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mspace width="0.15em"/><mml:msub><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:msubsup><mml:mi>t</mml:mi><mml:mi>j</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:msub><mml:mi>δ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msubsup><mml:mi>t</mml:mi><mml:mi>j</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(2)</label>
</disp-formula>
where <inline-formula id="pcbi.1004860.e003"><alternatives><graphic id="pcbi.1004860.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004860.e003" xlink:type="simple"/><mml:math display="inline" id="M3"><mml:mrow><mml:msubsup><mml:mi>t</mml:mi><mml:mi>j</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> denotes individual spiking times for neuron <italic>j</italic> and <italic>δ</italic> is the Dirac delta function.</p>
<p>In the output layer of Phase II, 29 leaky integrate-and-fire (LIF) neurons received the spike trains generated by tonotopically-ordered auditory neurons through plastic synaptic connections. The dynamics of each LIF neuron was described by its membrane potential, <italic>V</italic><sub><italic>i</italic></sub>(<italic>t</italic>), and was expressed in terms of all the synaptic currents that the neuron received [<xref ref-type="bibr" rid="pcbi.1004860.ref026">26</xref>],
<disp-formula id="pcbi.1004860.e004">
<alternatives>
<graphic id="pcbi.1004860.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004860.e004" xlink:type="simple"/>
<mml:math display="block" id="M4">
<mml:mrow><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>V</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mspace width="0.15em"/><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mo stretchy="false">∑</mml:mo><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="0.2em"/><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>v</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mspace width="0.2em"/><mml:msub><mml:mo stretchy="false">∑</mml:mo><mml:mi>f</mml:mi></mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msubsup><mml:mi>t</mml:mi><mml:mi>j</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(3)</label>
</disp-formula>
where <italic>τ</italic><sub><italic>m</italic></sub> is the membrane time-constant, <italic>V</italic><sub><italic>p</italic></sub> is the resting membrane potential, and <inline-formula id="pcbi.1004860.e005"><alternatives><graphic id="pcbi.1004860.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004860.e005" xlink:type="simple"/><mml:math display="inline" id="M5"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>v</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> is the synaptic reversal potential for neuron <italic>j</italic>. The term <inline-formula id="pcbi.1004860.e006"><alternatives><graphic id="pcbi.1004860.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004860.e006" xlink:type="simple"/><mml:math display="inline" id="M6"><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula> constitutes the leak current. The remaining terms on the right-hand side of (3) describe the input synaptic currents originating from the auditory neurons. <italic>ϵ</italic>(<italic>t</italic>) characterizes the shape of the post-synaptic conductance in the conductance-based LIF model considered in this study. Δ<sub><italic>j</italic></sub> is the axonal delay for neuron <italic>j</italic>. The post-synaptic spikes were generated when the membrane potential crossed the threshold, <italic>V</italic><sub><italic>th</italic></sub>, following which the membrane threshold was set to <italic>V</italic><sub><italic>r</italic></sub>.</p>
<p>The weights specified the contribution of each auditory neuron in changing the membrane potential and evolved as learning (see the <xref ref-type="sec" rid="sec008">Synaptic adjustments</xref> section) proceeded. Inputs to the LIF neurons were all assumed to be excitatory and modulated by a double-exponential excitatory post-synaptic conductance (EPSC) kernel of the following form
<disp-formula id="pcbi.1004860.e007">
<alternatives>
<graphic id="pcbi.1004860.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004860.e007" xlink:type="simple"/>
<mml:math display="block" id="M7">
<mml:mrow><mml:mi>ϵ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mspace width="0.15em"/><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>A</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mi>t</mml:mi><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mi>t</mml:mi><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>A</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="0.4em"/><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(4)</label>
</disp-formula>
where <italic>τ</italic><sub><italic>A</italic></sub> and <italic>τ</italic><sub><italic>B</italic></sub> are the EPSC rise time and decay time, respectively. <italic>H</italic>(<italic>t</italic>) is a Heaviside function, with <italic>H</italic>(<italic>t</italic>) = 1 for <italic>t</italic> ≥ 0 and <italic>H</italic>(<italic>t</italic>) = 0 otherwise.</p>
</sec>
<sec id="sec008">
<title>Synaptic adjustments</title>
<p>Correlation-based plasticity rules have been widely used to describe the underlying processes that contributed to neural circuit development and memory storage (e.g., [<xref ref-type="bibr" rid="pcbi.1004860.ref027">27</xref>]). Spike-timing-dependent plasticity (STDP) is a well-known unsupervised correlation-based plasticity rule inspired by electrophysiological observations [<xref ref-type="bibr" rid="pcbi.1004860.ref028">28</xref>,<xref ref-type="bibr" rid="pcbi.1004860.ref029">29</xref>]. General STDP and its variations have been widely used in neural modelling studies. For example, Gerstner et al. [<xref ref-type="bibr" rid="pcbi.1004860.ref030">30</xref>] used STDP to explain the temporal precision of the spike times required for detecting the interaural time differences (~5 μs) in the nucleus laminaris of the auditory system in barn owls. They showed that STDP could successfully adjust the timing of the action potentials in an unsupervised fashion by identifying and strengthening the incoming synapses that had a particular delay, leading to a high temporal precision.</p>
<p>Hebbian learning requires both pre- and post-synaptic neurons to be active simultaneously for a synaptic change to take place [<xref ref-type="bibr" rid="pcbi.1004860.ref031">31</xref>]. STDP provides a reformulation of the simplified rate-based Hebbian rule to account for temporal correlation aspects of learning, such as the pre- and post-synaptic spike-timing coherency that is required to extract the temporal cues for pitch perception. It is a fundamental requirement of STDP that the pre- and post-synaptic spike times be present within a limited time window [<xref ref-type="bibr" rid="pcbi.1004860.ref032">32</xref>], whose time course is measured by electrophysiology. Evidence shows that the contribution of pre-synaptic/post-synaptic spike pairs to learning vanishes faster than the post-synaptic/pre-synaptic spike pairs [<xref ref-type="bibr" rid="pcbi.1004860.ref033">33</xref>]. In other words, depression lasts longer than potentiation. In this study, this condition was satisfied by applying an asymmetric learning window with a wider extent towards depression,
<disp-formula id="pcbi.1004860.e008">
<alternatives>
<graphic id="pcbi.1004860.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004860.e008" xlink:type="simple"/>
<mml:math display="block" id="M8">
<mml:mrow><mml:mi>W</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mspace width="0.15em"/><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mspace width="0.2em"/><mml:mtext>exp</mml:mtext><mml:mspace width="0.2em"/><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mi>s</mml:mi><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="0.15em"/><mml:mo>,</mml:mo><mml:mspace width="0.15em"/><mml:mi>s</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>d</mml:mi></mml:msub><mml:mspace width="0.2em"/><mml:mtext>exp</mml:mtext><mml:mspace width="0.2em"/><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mi>s</mml:mi><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="0.15em"/><mml:mo>,</mml:mo><mml:mspace width="0.15em"/><mml:mi>s</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(5)</label>
</disp-formula>
where <italic>s</italic> is the post-synaptic spike time minus the pre-synaptic spike time and <italic>τ</italic><sub><italic>p</italic></sub> and <italic>τ</italic><sub><italic>d</italic></sub> are the time-constants for potentiation and depression, respectively. <italic>A</italic><sub><italic>p</italic></sub> and <italic>A</italic><sub><italic>d</italic></sub> are constant gains for potentiation and depression, respectively. The shape of this particular learning window is shown in <xref ref-type="fig" rid="pcbi.1004860.g001">Fig 1G</xref>. Chosen parameters for the learning window in this paper are <italic>A</italic><sub><italic>p</italic></sub> = 15 and <italic>τ</italic><sub><italic>p</italic></sub> = 1 ms, as gain and time-constant, respectively, for potentiation (<italic>s</italic> &gt; 0) and <italic>A</italic><sub><italic>d</italic></sub> = 10 and <italic>τ</italic><sub><italic>d</italic></sub> = 5 ms, as gain and time-constant, respectively, for depression (<italic>s</italic> &lt; 0).</p>
<p>Although the time-constants of the learning window used in this study were much shorter than those reported for hippocampal neurons by Bi and Poo [<xref ref-type="bibr" rid="pcbi.1004860.ref027">27</xref>] (viz., <italic>τ</italic><sub><italic>p</italic></sub> = 17 ms and <italic>τ</italic><sub><italic>d</italic></sub> = 34 ms), studies have shown that the auditory pathway has specialized neurons that enable the processing and transmitting of fine-grained temporal information. For example, Gerstner et al. [<xref ref-type="bibr" rid="pcbi.1004860.ref030">30</xref>] used time-constants as short as 0.5 ms in their model of the barn owl sound source localization system.</p>
<p>The STDP rule considered in this study modified the synaptic efficacies based on two terms according to
<disp-formula id="pcbi.1004860.e009">
<alternatives>
<graphic id="pcbi.1004860.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004860.e009" xlink:type="simple"/>
<mml:math display="block" id="M9">
<mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mspace width="0.15em"/><mml:mi>η</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mo stretchy="false">∫</mml:mo><mml:mn>0</mml:mn><mml:mi>T</mml:mi></mml:msubsup><mml:msubsup><mml:mo stretchy="false">∫</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>−</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="0.15em"/><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>s</mml:mi><mml:mspace width="0.25em"/><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:msubsup><mml:mo stretchy="false">∫</mml:mo><mml:mn>0</mml:mn><mml:mi>T</mml:mi></mml:msubsup><mml:msub><mml:mi>S</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(6)</label>
</disp-formula>
where <italic>S</italic><sub><italic>j</italic></sub> and <italic>S</italic><sub><italic>i</italic></sub> are the spikes of the pre- and post-synaptic neurons, respectively, <italic>W</italic>(<italic>s</italic>) is the learning window, <italic>T</italic> is the learning time, and <italic>η</italic> is the learning rate. <italic>b</italic><sub><italic>j</italic></sub> is a constant coefficient specifying the contribution of the pre-synaptic neurons to changing the weights. The first term on the right-hand side of (6) corresponds to the temporal correlations between the pre- and post-synaptic neurons and is responsible for shaping the neural structure (by selecting correlated synapses), while, with an appropriate <italic>b</italic><sub><italic>j</italic></sub>, the second term on the right-hand side of (6) maintains the post-synaptic spiking rate within a defined regime.</p>
<p>The learning proceeds for a much longer time than the temporal extent of the learning window so the learning window integral limits can be changed to infinity with a minor error and the spike-counting integrals in (6) can be replaced by temporal averages, i.e., <inline-formula id="pcbi.1004860.e010"><alternatives><graphic id="pcbi.1004860.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004860.e010" xlink:type="simple"/><mml:math display="inline" id="M10"><mml:mrow><mml:mi>〈</mml:mi><mml:mover accent="true"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">¯</mml:mo></mml:mover><mml:mi>〉</mml:mi></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1004860.e011"><alternatives><graphic id="pcbi.1004860.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004860.e011" xlink:type="simple"/><mml:math display="inline" id="M11"><mml:mrow><mml:mi>〈</mml:mi><mml:mover accent="true"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">¯</mml:mo></mml:mover><mml:mi>〉</mml:mi></mml:mrow></mml:math></alternatives></inline-formula> [<xref ref-type="bibr" rid="pcbi.1004860.ref034">34</xref>]. When the temporal correlation between the pre- and post-synaptic neurons is insignificant, the ensemble temporal average, <inline-formula id="pcbi.1004860.e012"><alternatives><graphic id="pcbi.1004860.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004860.e012" xlink:type="simple"/><mml:math display="inline" id="M12"><mml:mrow><mml:mi>〈</mml:mi><mml:mover accent="true"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">¯</mml:mo></mml:mover><mml:mi>〉</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>, can be estimated by individual temporal averages, <inline-formula id="pcbi.1004860.e013"><alternatives><graphic id="pcbi.1004860.e013g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004860.e013" xlink:type="simple"/><mml:math display="inline" id="M13"><mml:mrow><mml:mi>〈</mml:mi><mml:mover accent="true"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">¯</mml:mo></mml:mover><mml:mi>〉</mml:mi><mml:mi>〈</mml:mi><mml:mover accent="true"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">¯</mml:mo></mml:mover><mml:mi>〉</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>. Then (6) can be simplified to a rate-based learning rule given by
<disp-formula id="pcbi.1004860.e014">
<alternatives>
<graphic id="pcbi.1004860.e014g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004860.e014" xlink:type="simple"/>
<mml:math display="block" id="M14">
<mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mspace width="0.15em"/><mml:mi>α</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>ν</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mspace width="0.15em"/><mml:mover accent="true"><mml:mi>ν</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>ν</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(7)</label>
</disp-formula>
where <italic>ν</italic><sub><italic>j</italic></sub> and <italic>ν</italic><sub><italic>i</italic></sub> are the pre- and post-synaptic spiking rates, respectively, <inline-formula id="pcbi.1004860.e015"><alternatives><graphic id="pcbi.1004860.e015g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004860.e015" xlink:type="simple"/><mml:math display="inline" id="M15"><mml:mover accent="true"><mml:mi>ν</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math></alternatives></inline-formula> is the desired average post-synaptic spiking rate, and <italic>α</italic> is the learning rate. For α &lt; 0, (7) modifies the synaptic weights in order to maintain <italic>ν</italic><sub><italic>i</italic></sub> close to <inline-formula id="pcbi.1004860.e016"><alternatives><graphic id="pcbi.1004860.e016g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004860.e016" xlink:type="simple"/><mml:math display="inline" id="M16"><mml:mover accent="true"><mml:mi>ν</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math></alternatives></inline-formula> [<xref ref-type="bibr" rid="pcbi.1004860.ref034">34</xref>]. Similarly, for a negative learning window integral (we set <inline-formula id="pcbi.1004860.e017"><alternatives><graphic id="pcbi.1004860.e017g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004860.e017" xlink:type="simple"/><mml:math display="inline" id="M17"><mml:mrow><mml:msubsup><mml:mo stretchy="false">∫</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>∞</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:msub><mml:mi>τ</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>d</mml:mi></mml:msub><mml:msub><mml:mi>τ</mml:mi><mml:mi>d</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>0.035</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>) and <inline-formula id="pcbi.1004860.e018"><alternatives><graphic id="pcbi.1004860.e018g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004860.e018" xlink:type="simple"/><mml:math display="inline" id="M18"><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mover accent="true"><mml:mi>ν</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:msubsup><mml:mo stretchy="false">∫</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>∞</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>1.05</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>, (6) keeps the post-synaptic spiking rates at around <inline-formula id="pcbi.1004860.e019"><alternatives><graphic id="pcbi.1004860.e019g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004860.e019" xlink:type="simple"/><mml:math display="inline" id="M19"><mml:mrow><mml:mover accent="true"><mml:mi>ν</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>30</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> spike/s. Furthermore, applying the learning window would result in strengthening correlated synapses, which is shown in the Neural learning section of the Results to lead to structure formation corresponding to pitch.</p>
<p>The synaptic connections for each pitch neuron, <italic>i</italic>, were modified by STDP in the presence of a sound with the same pitch as the pitch neuron’s dedicated label. For example, sounds with 110 Hz pitch were presented to the Poisson neurons and the connections of the 110 Hz pitch neuron were subsequently adjusted by STDP. Learning time for each pitch category was 5000 s (= learning time, <italic>T</italic>). The initial synaptic weights for all the input/output connections were set to a fixed value, <italic>w</italic><sub>0</sub> = 0.0075. This resulted in high spiking rates (~80 spike/s) in LIF neurons for all the pitch categories. The advantage of inducing a high initial spiking rate was that it led to faster plasticity due to more spikes falling within the learning window. Synaptic weights were restricted to remain in the [<italic>w</italic><sub><italic>min</italic></sub>, <italic>w</italic><sub><italic>max</italic></sub>] range.</p>
<p>For a better exploration of the model’s dynamics in response to different spectral shapes, single-type and mixed-type STDP learning were implemented. In the former, all the pitch categories were learned exclusively through a single type of stimuli. Single-type learning was simulated for pure tone, vowel, and piano stimuli because these types had samples for all the pitch categories. In the mixed-type stimuli, for each pitch category, a stimulus type (pure tone, vowel, and the four musical instruments) was chosen randomly and the corresponding spatio-temporal pattern was used as training material. Ideally, a full mixed-type learning would require each pitch category to be learnt through all the existing stimulus types, however, this might not be the case in a real world listening environment. To make the learning process more realistic and at the same time provide sufficient spectral variations to the model, mixed-type learning was repeated five times–with different randomly chosen types—and the corresponding emerged dynamics were averaged.</p>
<p>For a complete list of Phase II parameters see <xref ref-type="table" rid="pcbi.1004860.t002">Table 2</xref>. The LIF neurons and STDP parameters (except for the learning window potentiation and depression time-constants) were taken from previous studies by Kerr et al. [<xref ref-type="bibr" rid="pcbi.1004860.ref035">35</xref>,<xref ref-type="bibr" rid="pcbi.1004860.ref036">36</xref>]. The spiking neural network was simulated and trained with STDP using an in-house C++ program called “SpikeSim” [<xref ref-type="bibr" rid="pcbi.1004860.ref035">35</xref>,<xref ref-type="bibr" rid="pcbi.1004860.ref037">37</xref>].</p>
<table-wrap id="pcbi.1004860.t002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004860.t002</object-id>
<label>Table 2</label> <caption><title>Spiking neural network and learning parameters.</title></caption>
<alternatives>
<graphic id="pcbi.1004860.t002g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004860.t002" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="justify"><bold>Type</bold></th>
<th align="justify"><bold>Parameter</bold></th>
<th align="justify"><bold>Notation</bold></th>
<th align="justify"><bold>Value</bold></th>
</tr>
</thead>
<tbody>
<tr>
<td align="justify">Neuron</td>
<td align="left">Membrane time-constant</td>
<td align="justify"><italic>τ</italic><sub><italic>m</italic></sub></td>
<td align="justify">10 ms</td>
</tr>
<tr>
<td align="justify"/>
<td align="left">Threshold potential</td>
<td align="justify"><italic>V</italic><sub><italic>th</italic></sub></td>
<td align="justify">-50 mV</td>
</tr>
<tr>
<td align="justify"/>
<td align="left">Resting potential</td>
<td align="justify"><italic>V</italic><sub><italic>p</italic></sub></td>
<td align="justify">-65 mV</td>
</tr>
<tr>
<td align="justify"/>
<td align="left">Reset potential</td>
<td align="justify"><italic>V</italic><sub><italic>r</italic></sub></td>
<td align="justify">-65 mV</td>
</tr>
<tr>
<td align="justify"/>
<td align="left">Reversal potential</td>
<td align="justify"><italic>V</italic><sub><italic>rev</italic></sub></td>
<td align="justify">0 mV</td>
</tr>
<tr>
<td align="justify"/>
<td align="left">Refractory period</td>
<td align="justify"><italic>t</italic><sub><italic>ref</italic></sub></td>
<td align="justify">1 ms</td>
</tr>
<tr>
<td align="justify">Learning</td>
<td align="left">Initial synaptic weights</td>
<td align="justify"><italic>w</italic><sub>0</sub></td>
<td align="justify">0.0075</td>
</tr>
<tr>
<td align="justify"/>
<td align="left">Upper-bound for weights</td>
<td align="justify"><italic>w</italic><sub><italic>max</italic></sub></td>
<td align="justify">0.2</td>
</tr>
<tr>
<td align="justify"/>
<td align="left">Lower-bound for weights</td>
<td align="justify"><italic>w</italic><sub><italic>min</italic></sub></td>
<td align="justify">-0.2</td>
</tr>
<tr>
<td align="justify"/>
<td align="left">Synaptic delay</td>
<td align="justify">Δ</td>
<td align="justify">10 ms</td>
</tr>
<tr>
<td align="justify"/>
<td align="left">EPSC rise time</td>
<td align="justify"><italic>τ</italic><sub><italic>A</italic></sub></td>
<td align="justify">0.5 ms</td>
</tr>
<tr>
<td align="justify"/>
<td align="left">EPSC decay time</td>
<td align="justify"><italic>τ</italic><sub><italic>B</italic></sub></td>
<td align="justify">1 ms</td>
</tr>
<tr>
<td align="justify"/>
<td align="left">Potentiation time-constant</td>
<td align="justify"><italic>τ</italic><sub><italic>p</italic></sub></td>
<td align="justify">1 ms</td>
</tr>
<tr>
<td align="justify"/>
<td align="left">Depression time-constant</td>
<td align="justify"><italic>τ</italic><sub><italic>d</italic></sub></td>
<td align="justify">5 ms</td>
</tr>
<tr>
<td align="justify"/>
<td align="left">Window height (potentiation)</td>
<td align="justify"><italic>A</italic><sub><italic>p</italic></sub></td>
<td align="justify">15</td>
</tr>
<tr>
<td align="justify"/>
<td align="left">Window height (depression)</td>
<td align="justify"><italic>A</italic><sub><italic>d</italic></sub></td>
<td align="justify">10</td>
</tr>
<tr>
<td align="justify"/>
<td align="left">Contribution of the input spikes</td>
<td align="justify"><italic>b</italic><sub><italic>j</italic></sub></td>
<td align="justify">-1.05</td>
</tr>
<tr>
<td align="justify"/>
<td align="left">Learning rate</td>
<td align="justify"><italic>η</italic></td>
<td align="justify">10<sup>−7</sup></td>
</tr>
<tr>
<td align="justify"/>
<td align="left">Learning time</td>
<td align="justify"><italic>T</italic></td>
<td align="justify">5000 s</td>
</tr>
<tr>
<td align="justify"/>
<td align="left">Desired post-synaptic rate</td>
<td align="justify"><inline-formula id="pcbi.1004860.e020"><alternatives><graphic id="pcbi.1004860.e020g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004860.e020" xlink:type="simple"/><mml:math display="inline" id="M20"><mml:mover accent="true"><mml:mi>ν</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math></alternatives></inline-formula></td>
<td align="justify">30 spike/s</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
</sec>
</sec>
</sec>
<sec id="sec009" sec-type="results">
<title>Results</title>
<sec id="sec010">
<title>Neural learning</title>
<p>During the course of learning, synaptic weight changes directed by STDP gradually decreased the initial spiking rate for each pitch neuron to an asymptote rate of ~30 spike/s. Synaptic weights were recorded as the learning progressed. <xref ref-type="fig" rid="pcbi.1004860.g003">Fig 3</xref> shows the input/output connectivity patterns (<italic>w</italic><sub><italic>ij</italic></sub>) that developed for different types of stimuli at an initial (top row) and a final (bottom row) stage of learning. Graphs (A-D) are associated with the weight patterns recorded after 500 s presentation of pure tones, /ɑ/ vowels, /i/ vowels, and piano sounds, respectively, examples of each were shown in <xref ref-type="fig" rid="pcbi.1004860.g002">Fig 2A–2D</xref>. In each graph, input neurons (<italic>j</italic> index) are shown along the abscissa, sorted by their CF (in kHz). Output or pitch neurons (<italic>i</italic> index) are presented along the ordinate, sorted based on the pitch that they represent. Graphs (E-H) show the corresponding emerged patterns when learning progressed for 5000 s. <xref ref-type="fig" rid="pcbi.1004860.g003">Fig 3I and 3J</xref> show the average synaptic weight patterns that emerged after 500 s of mixed-stimulus learning and after 5000 s of mixed-stimulus learning, respectively.</p>
<fig id="pcbi.1004860.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004860.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Plots of synaptic weight patterns at an initial and a final stage of STDP learning.</title>
<p>(A) Patterns recorded after 500 s of learning with pure tone stimuli. (B) Patterns recorded after 500 s of learning with /ɑ/ stimuli. (C) Patterns recorded after 500 s of learning with /i/ stimuli. (D) Patterns recorded after 500 s of learning with piano keys. (E) Patterns recorded after 5000 s of learning with pure tone stimuli. (F) Patterns recorded after 5000 s of learning with /ɑ/ stimuli. (G) Patterns recorded after 5000 s of learning with /i/ stimuli. (H) Patterns recorded after 5000 s of learning with piano keys. (I) Patterns recorded after 500 s of learning with mixed stimuli. (J) Patterns recorded after 5000 s of learning with mixed stimuli. In (A-J) CFs of input neurons are presented along the abscissa and the ordinate shows the pitch category that each output neuron represents. The colormap is consistent among all graphs.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004860.g003" xlink:type="simple"/>
</fig>
<p>Because pitch categories, as opposed to spectral shapes, were consistent during the course of learning leading to the patterns in <xref ref-type="fig" rid="pcbi.1004860.g003">Fig 3E–3H</xref>, it could be inferred that the common behavior observed amongst the four patterns in <xref ref-type="fig" rid="pcbi.1004860.g003">Fig 3E–3H</xref> would be associated with pitch. Therefore, the “wrinkle” (peak-trough-peak sequence) that started from the bottom-left and moved towards the top-middle in each graph would correspond to pitch. In all the four patterns, for each pitch neuron, the trough of the wrinkle appeared at input neurons with CFs similar to the pitch categories. This “pitch curve” was the only apparent feature in pure tone patterns (<xref ref-type="fig" rid="pcbi.1004860.g003">Fig 3E</xref>) due to their simple spectra. Vowels (<xref ref-type="fig" rid="pcbi.1004860.g003">Fig 3F and 3G</xref>), on the other hand, had spectral power concentrated around the formants. Connections originating from formant locations were strongly affected by STDP due to high driving rates. Formants thus resulted in vertical stripes in the synaptic patterns in <xref ref-type="fig" rid="pcbi.1004860.g003">Fig 3F and 3G</xref>. As shown in <xref ref-type="fig" rid="pcbi.1004860.g002">Fig 2L</xref>, piano stimuli led to a distinct harmonic structure with evenly-distributed energy across the low-frequency half of the cochlear regions, which resulted in harmonically-related pitch patterns (<xref ref-type="fig" rid="pcbi.1004860.g003">Fig 3H</xref>). The timbre-independent pitch curve was replicated by the mixed-stimuli model (<xref ref-type="fig" rid="pcbi.1004860.g003">Fig 3J</xref>) as well; however, due to various spectral shapes presented to the model during learning, type-specific behavior observed in <xref ref-type="fig" rid="pcbi.1004860.g003">Fig 3F–3H</xref> is absent in the weight patterns of the mixed-stimuli model.</p>
</sec>
<sec id="sec011">
<title>Temporal adjustments</title>
<p>In order to measure the efficiency of STDP in adjusting the spike timings (e.g., in terms of producing phase-locked responses), vector strength was calculated for pitch neurons during early and late stages of learning. Vector strength is a well-known measure of phase locking or stimulus-response synchrony; it describes a phase relationship between the periodic input stimuli and the discharge of the output neuron [<xref ref-type="bibr" rid="pcbi.1004860.ref038">38</xref>]. <xref ref-type="fig" rid="pcbi.1004860.g004">Fig 4</xref> presents vector strength matrices (stacked vector strengths from all the pitch neurons) computed from 5 s initial (A) and final (B) intervals, using the mixed-stimuli model. According to the noisy pattern of <xref ref-type="fig" rid="pcbi.1004860.g004">Fig 4A</xref>, during the early stages of learning − when the initial uniform synaptic weights had not been modified by the plasticity rule–the pitch neurons generated spikes at random times. However, after sufficient learning (<xref ref-type="fig" rid="pcbi.1004860.g004">Fig 4B</xref>), it was observed that for each pitch neuron, vector strength was strongest for the input stimuli that had the same pitch as that represented by the pitch neuron (the diagonal lines). This indicated that STDP had adjusted the connection strengths so that the spikes were more likely generated in-phase with a sinusoid of the same frequency, i.e., one spike per sinusoidal peak.</p>
<fig id="pcbi.1004860.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004860.g004</object-id>
<label>Fig 4</label>
<caption>
<title>The effect of learning on pitch neurons’ spike timings.</title>
<p>(A) Matrix of vector strength for an initial 5 s intervals during mixed-stimuli learning. (B) Matrix of vector strength for a final 5 s interval during mixed-stimuli learning. (C) Matrix of vector strength for a final 5 s interval during learning with high-pass filtered vowels only.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004860.g004" xlink:type="simple"/>
</fig>
<p>A question was then posed as to whether the temporal adjustment of the spikes would be affected by the absence of F0. To investigate this matter, in another simulation, the spiking neural network was exclusively presented with high-pass filtered vowels during the course of STDP learning. <xref ref-type="fig" rid="pcbi.1004860.g004">Fig 4C</xref> shows the resulting vector strength matrix for a final 5 s interval. It was observed that spike times became entrained to F0 by STDP, even when F0 was missing.</p>
</sec>
<sec id="sec012">
<title>Extracting the temporal cues</title>
<p>The inter-spike-interval histogram (ISIH), has proven to be an efficient measure of pitch, compatible with pitch-related psychophysical findings for a wide range of stimuli and levels [<xref ref-type="bibr" rid="pcbi.1004860.ref023">23</xref>]. Cariani and Delgutte [<xref ref-type="bibr" rid="pcbi.1004860.ref023">23</xref>] found that peak locations and relative amplitudes in a histogram of inter-spike-intervals provided a cue for pitch that was robust against sound level changes and spectral shape variations. The latter thus provided an explanation for pitch constancy at a neural level.</p>
<p>In this study, the most frequent or the dominant interval was considered as the temporal code of pitch. Although deriving the most common interval was possible by taking into account the spiking activity of a single pitch neuron [<xref ref-type="bibr" rid="pcbi.1004860.ref039">39</xref>], it was decided to use the ISIH of the population of pitch neurons (a.k.a., pooled ISIH) to account for the role of higher-order pitch processing centers in integrating information across pitch neurons. This was necessary to explain phenomena such as perception of the missing-F0 pitch that reportedly engages higher-order auditory processing centers [<xref ref-type="bibr" rid="pcbi.1004860.ref040">40</xref>].</p>
<p>To calculate the ISIH for each pitch category, the mixed-stimuli trained model shown in <xref ref-type="fig" rid="pcbi.1004860.g003">Fig 3J</xref> was presented with each of the 29 pure tones for 0.5 s. The resulting inter-spike intervals were pooled across the 29 pitch neurons and distributed in 1 ms bins. <xref ref-type="fig" rid="pcbi.1004860.g005">Fig 5A–5C</xref> shows examples of the first 50 ms of the pooled ISIHs for pitch categories of 370 Hz, 131 Hz, and 104 Hz, respectively. For better visualization, all the histograms were smoothed (using a moving average filter with a span of three) and normalized to maximum. Pitch values presented in <xref ref-type="fig" rid="pcbi.1004860.g005">Fig 5A–5C</xref> were selected as representatives of high-, medium-, and low-pitch stimuli in order to demonstrate how the temporal pitch information changed as a result of pitch increase.</p>
<fig id="pcbi.1004860.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004860.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Pooled ISIH for different types of stimuli.</title>
<p>(A) Histogram associated with the pitch category of 370 Hz (pure tone). (B) Histogram associated with the pitch category of 131 Hz (pure tone). (C) Histogram associated with the pitch category of 104 Hz (pure tone). (D) Stacked pooled ISIH for the 29 pitch categories of pure tones. (E) Stacked pooled ISIH for the 29 pitch categories of /ɑ/ vowels. (F) Stacked pooled ISIH for the 29 pitch categories of /i/ vowels. (G) Stacked pooled ISIH for the 29 pitch categories of high-pass filtered /ɑ/ vowels. (H) Stacked pooled ISIH for the 29 pitch categories of high-pass filtered /i/ vowels. Pitch categories are shown on the ordinate and ISIH amplitudes are shown in color in D-H. Histograms are slightly smoothed and normalized to maximum for better visualization in (A-H).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004860.g005" xlink:type="simple"/>
</fig>
<p>A stacked pooled ISIH graph was generated by accumulating all the 29 pooled ISIHs (e.g., <xref ref-type="fig" rid="pcbi.1004860.g005">Fig 5A–5C</xref>), arranged by the stimulus pitch. The stacked pooled ISIH is shown in <xref ref-type="fig" rid="pcbi.1004860.g005">Fig 5D</xref>, with pitch categories shown along the ordinate in Hz and histogram amplitude represented by color. Similar stacked pooled ISIH are shown for vowels /ɑ/ and /i/ in <xref ref-type="fig" rid="pcbi.1004860.g005">Fig 5E and 5F</xref>, respectively. <xref ref-type="fig" rid="pcbi.1004860.g005">Fig 5G and 5H</xref> show the stacked pooled ISIHs for high-pass filtered vowels /ɑ/ and /i/, respectively.</p>
<p>It was observed that for all stimuli types, as the pitch of stimuli increased, the amplitude and the number of histogram peaks became stronger and fewer, respectively, indicating that the model used shorter inter-spike-intervals (viz., rapidly-occurring spikes) to encode higher pitches. Stacked histograms thus provide a representation of how the model temporally processes the pitch.</p>
</sec>
<sec id="sec013">
<title>Pitch perception using temporal cues</title>
<p>To demonstrate the effectiveness of the temporal cues in providing pitch information, a pitch ranking model using the pooled ISIHs as input was simulated. Pitch ranking is a typical psychophysical experiment wherein listeners are asked to decide which of the two presented sound stimuli has a higher pitch. Normal-hearing humans score about 70%-100% depending on the pitch difference in a sound pair and type of stimuli. For example, at one-semitone pitch difference using sustained vowels, subjects scored about 81% [<xref ref-type="bibr" rid="pcbi.1004860.ref041">41</xref>], which increased to about 100% when the pitch difference was increased to six semitones.</p>
<p>The pitch ranking model in this study consisted of an artificial neural network (a single layer perceptron with two neurons) that received two sets of inputs corresponding to a pair of stimuli and generated two outputs, the higher of which would indicate the higher-pitch stimulus. For 20 trials, the model was trained on 1500 pitch pairs (10% reserved for validation) and tested on 500 unseen pitch pairs. Performance at each trial was computed as the number of correct answers divided by the total number of presentations (i.e., 500). At each trial, pitch pairs were selected randomly from a pool of all eligible combinations of vowel stimuli. For a fair comparison between simulated results and available psychophysical data, only same-type vowel pairs (e.g., /ɑ/-/ɑ/ and /i/-/i/) with pitch differences between one and twelve semitones were allowed in the pool. The weights of the artificial neural network were adjusted using the error back-propagation method [<xref ref-type="bibr" rid="pcbi.1004860.ref042">42</xref>]. The overall performance of the model was calculated as the average performance over the 20 trials. The exact same simulations were performed using the high-pass filtered vowels. <xref ref-type="fig" rid="pcbi.1004860.g006">Fig 6</xref> presents the overall performance of the model as a function of pitch difference for the original and high-pass filtered vowels.</p>
<fig id="pcbi.1004860.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004860.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Simulated pitch ranking scores at different pitch interval sizes.</title>
<p>Model performance using the extracted ISIHs from original (i.e., <xref ref-type="fig" rid="pcbi.1004860.g005">Fig 5E and 5F</xref>) and high-pass filtered (i.e., <xref ref-type="fig" rid="pcbi.1004860.g005">Fig 5G and 5H</xref>) vowels are shown with solid and dotted lines, respectively. Error bars show standard errors of the means within simulations trials and where not visible, indicate a very small standard error. Chance level is 50%.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004860.g006" xlink:type="simple"/>
</fig>
</sec>
</sec>
<sec id="sec014" sec-type="conclusions">
<title>Discussion</title>
<p>Humans are born with some pitch perception abilities [<xref ref-type="bibr" rid="pcbi.1004860.ref043">43</xref>,<xref ref-type="bibr" rid="pcbi.1004860.ref044">44</xref>]. For example, through measuring event-related potentials, Leppänen et al. [<xref ref-type="bibr" rid="pcbi.1004860.ref043">43</xref>] reported that newborns were able to detect pitch changes in sequential tones. However, perceiving the missing-F0 pitch does not happen until 3–4 months of age [<xref ref-type="bibr" rid="pcbi.1004860.ref045">45</xref>]. He and Trainor [<xref ref-type="bibr" rid="pcbi.1004860.ref045">45</xref>] concluded that unlike pure tones and complete harmonic complexes that possibly relied only on a <italic>peripheral</italic> representation of the stimulus, processing the pitch of missing-F0 stimuli required <italic>cortical</italic> engagement to integrate the information from across the auditory periphery and elicit a single pitch percept. Auditory cortical development is an unsupervised process that happens naturally during early infancy.</p>
<p>In this study, it was observed that a correlation-based, unsupervised, spike-based form of Hebbian learning could explain the development of the neural structure required for recognizing the pitch of simple and complex tones, with or without F0. The emerged neural structure led to precisely-timed responses that were necessary for a reliable population code for pitch. More specifically, the synaptic wrinkles (<xref ref-type="fig" rid="pcbi.1004860.g003">Fig 3J</xref>) constituted a mechanism to compensate for the travelling wave delay that was the main cause of temporal misalignment between the spikes coming from different cochlear positions. Similar compensatory mechanisms (i.e., through developing proportional dendritic delays) were found by Greenwood and Maruyama [<xref ref-type="bibr" rid="pcbi.1004860.ref007">7</xref>] and Oertel et al. [<xref ref-type="bibr" rid="pcbi.1004860.ref008">8</xref>] in the cochlear nucleus.</p>
<p>Another interesting finding of this study was that although the emerged synaptic connection patterns followed the spectral power of the signal (i.e., the rate profiles), which varied amongst different stimulus types (<xref ref-type="fig" rid="pcbi.1004860.g003">Fig 3E–3H</xref>), the ISIH pattern extracted from the mixed-stimuli learning (<xref ref-type="fig" rid="pcbi.1004860.g005">Fig 5D–5H</xref>) emerged regardless. In other words, the temporal pattern shown in <xref ref-type="fig" rid="pcbi.1004860.g005">Fig 5D–5H</xref> would appear for any type of sound source, given that the model has experienced sufficient variations of the spectral shapes. It can thus be concluded that the temporal code for pitch could successfully extract invariances (F0) among inputs, although the inputs were spectrally different. The temporal code of pitch, therefore, can explain the pitch constancy phenomenon.</p>
<p>From a computational standpoint, the resemblance between the rate profiles (<xref ref-type="fig" rid="pcbi.1004860.g002">Fig 2I–2L</xref>) and the evolved synaptic weight patterns (<xref ref-type="fig" rid="pcbi.1004860.g003">Fig 3E–3H</xref>) indicated that STDP was mainly driven by the average activity or spiking rate of the pre-synaptic (auditory) neurons. However, applying the learning window enabled this correlation-based learning rule to incorporate temporal precision and generate responses that were indicative of pitch, regardless of the spectral shape of the stimulus. That is, the learning algorithm could successfully compensate for rate-place inconsistencies among different types of stimuli and provide a rate-independent temporal code. The ability of the model to replicate the above-mentioned phenomenon was of special importance because finding a spectrum-independent code for pitch has been considered a substantial step forward in the research field of pitch perception [<xref ref-type="bibr" rid="pcbi.1004860.ref046">46</xref>]. Neural correlates for “pitch constancy” have been detected in the auditory cortex of primates by Bendor and Wang [<xref ref-type="bibr" rid="pcbi.1004860.ref001">1</xref>]. They found that the pitch selective neurons would respond to both pure tones and harmonic complexes of the same pitch, even when F0 was eliminated from the latter’s spectrum. Simulated cortical columns in this study, therefore, could be considered as a computational substrate for what Bendor and Wang [<xref ref-type="bibr" rid="pcbi.1004860.ref001">1</xref>] labelled as pitch neurons.</p>
<p>As demonstrated in <xref ref-type="fig" rid="pcbi.1004860.g002">Fig 2J and 2K</xref>, eliminating the low-frequency content of the vowels led to flat lines in the place code corresponding to low-CF neurons. As <xref ref-type="fig" rid="pcbi.1004860.g004">Fig 4C</xref> suggested, STDP was still able to fine-tune the timing of the spikes, despite the missing fundamental. Compared to the original vowels, high-pass filtering the vowels did, however, lead to a noisier vector strength matrix (<xref ref-type="fig" rid="pcbi.1004860.g004">Fig 4B vs. 4C</xref>), indicating that entraining the spikes to a correct phase became a more challenging task for STDP when the fundamental frequency was not available in the spectrum. This was nevertheless an issue when the spiking neural network learnt mixed-stimuli due to exposure to many more representations and spectral variations. The absence of the fundamental frequency did not impair the performance of the pitch ranking model (<xref ref-type="fig" rid="pcbi.1004860.g006">Fig 6</xref>), confirming that the extracted temporal cues were independent of the fundamental frequency.</p>
<sec id="sec015">
<title>Advancing the modelling field</title>
<p>The place and the temporal codes of pitch are the roots of current pitch perception models, dividing the modern models into pattern matching- and autocorrelation-themed classes [<xref ref-type="bibr" rid="pcbi.1004860.ref047">47</xref>], respectively. The former estimates pitch based on a pattern or template, which is normally derived from an auditory model simulating the frequency analysis of the cochlea. Better-known examples of this category are the harmonic sieves model of Cohen [<xref ref-type="bibr" rid="pcbi.1004860.ref048">48</xref>] and the harmonic templates of Shamma and Klein [<xref ref-type="bibr" rid="pcbi.1004860.ref005">5</xref>]. The autocorrelation class, however, requires self-similarity measures, such as autocorrelation, to estimate periodicity. Examples of this category include Licklider’s [<xref ref-type="bibr" rid="pcbi.1004860.ref049">49</xref>] duplex theory-themed models such as the ones developed by Meddis et al. [<xref ref-type="bibr" rid="pcbi.1004860.ref050">50</xref>] and Patterson et al. [<xref ref-type="bibr" rid="pcbi.1004860.ref003">3</xref>].</p>
<p>The pitch perception model developed in this study employed elements of both modelling approaches in a more biologically-plausible platform. In fact, the present model followed closely the schematic pitch perception model suggested by Moore [<xref ref-type="bibr" rid="pcbi.1004860.ref051">51</xref>] that also combined the place and temporal code of pitch to explain how the pitch of complex sounds might be perceived by the auditory system. Similar to the model presented in this study, Moore’s schematic model also consisted of a bank of cochlear filters (similar to <xref ref-type="fig" rid="pcbi.1004860.g001">Fig 1E</xref>), a spike generation process (Poisson neurons in <xref ref-type="fig" rid="pcbi.1004860.g001">Fig 1F</xref>) and a spike analyzer that computed the pooled ISIH. A final decision making step would pick the most prominent interval as an estimate of the stimulus period. The learning phase employed in the current model, additionally provided a description of the development of the neural structure leading to the required ISIHs. The learning phase would also provide a biological analogue to Shamma and Kleins’ detector units [<xref ref-type="bibr" rid="pcbi.1004860.ref005">5</xref>], as well as eliminating the need for long neural lags in autocorrelational models.</p>
<p>It should be noted that the current model could reproduce the inter-spike interval statistics similar to the actual auditory nerve recorded by Cariani and Delgutte [<xref ref-type="bibr" rid="pcbi.1004860.ref023">23</xref>] and taken into account in Moore’s [<xref ref-type="bibr" rid="pcbi.1004860.ref051">51</xref>] model. However, the artificial neural network that made pitch judgments based on the received ISIHs was a simple model to demonstrate the effectiveness of the temporal cues in performing a simple pitch perception task and was not intended to be a biologically-plausible model of higher-order auditory system. In addition, in future work, the STDP learning step would present all pitches to all neurons, with a soft winner-take-all mechanism implemented to achieve competition between the neurons to create the pitch map across them.</p>
</sec>
<sec id="sec016">
<title>Implications for cochlear implant research</title>
<p>The cochlear implant or “Bionic Ear” is one of the most successful neural prosthesis that restores partial hearing in profoundly deaf people by directly stimulating the auditory nerve with controlled electrical current pulses. Many implantees have obtained functional speech perception in favorable conditions similar to their normal hearing peers [<xref ref-type="bibr" rid="pcbi.1004860.ref052">52</xref>]. However, there are still unresolved issues like tone perception in tonal languages and speech perception in noisy environments [<xref ref-type="bibr" rid="pcbi.1004860.ref053">53</xref>,<xref ref-type="bibr" rid="pcbi.1004860.ref054">54</xref>]. Music melody appreciation is also very limited in cochlear implant users [<xref ref-type="bibr" rid="pcbi.1004860.ref055">55</xref>]. It has been shown that pitch perception in implant hearing is correlated with the users’ abilities in performing the abovementioned tasks [<xref ref-type="bibr" rid="pcbi.1004860.ref056">56</xref>]. Accordingly, if pitch perception is improved in cochlear implant patients, their auditory performance should also get better.</p>
<p>Similar to normal hearing, pitch information in multi-channel cochlear implant hearing is also carried through place and temporal cues [<xref ref-type="bibr" rid="pcbi.1004860.ref055">55</xref>,<xref ref-type="bibr" rid="pcbi.1004860.ref057">57</xref>]. In electrical hearing, place cues for pitch perception are associated with the tonotopically-arranged electrodes. For example, Nelson et al. [<xref ref-type="bibr" rid="pcbi.1004860.ref058">58</xref>] reported that the pitch elicited by stimulating basal electrodes was generally consistently higher than that of the apically-located electrodes. On the other hand, the rate of stimulation and the frequency of amplitude-modulation of the stimulation pulses have impacts on the perceived pitch that could only be explained by the temporal cues for pitch perception. For example, Tong et al. [<xref ref-type="bibr" rid="pcbi.1004860.ref059">59</xref>] found that, in a cochlear implant listener, high-rate stimulation (in an isolated electrode) resulted in a high-pitch sensation and vice versa. The modulation frequency has a similar effect on pitch as that of the rate of stimulation [<xref ref-type="bibr" rid="pcbi.1004860.ref060">60</xref>,<xref ref-type="bibr" rid="pcbi.1004860.ref061">61</xref>].</p>
<p>Although cochlear implants are able to induce cues for pitch perception similar to those used by normal hearing listeners, the quality of the cues is considerably limited in electrical hearing. For instance, a limited number of electrodes and depth of electrode insertion confine the place cues to a limited frequency range [<xref ref-type="bibr" rid="pcbi.1004860.ref062">62</xref>,<xref ref-type="bibr" rid="pcbi.1004860.ref063">63</xref>]. Moreover, the tonotopic order in electrical hearing may be distorted in cochlear implant subjects (e.g., Schatzer et al. [<xref ref-type="bibr" rid="pcbi.1004860.ref064">64</xref>]), resulting in a poor frequency-to-place mapping. Temporal cues are also restricted to a cap rate of about 300 Hz in cochlear implant hearing. This means that stimulation rates or modulation frequencies above this limit do not induce distinctive pitch percepts [<xref ref-type="bibr" rid="pcbi.1004860.ref059">59</xref>,<xref ref-type="bibr" rid="pcbi.1004860.ref065">65</xref>,<xref ref-type="bibr" rid="pcbi.1004860.ref066">66</xref>].</p>
<p>Due to limited depth of electrode array insertion and implant filters suppressing the low-frequency content of the signal (lowest band-pass filters in cochlear implants have a center frequency of ~125 Hz), cochlear implants are not normally able to convey F0 information through the place code. From this point of view, hearing through a cochlear implant is analogous to hearing through a telephone transmission line. The results of this study showed how normal hearing listeners could perceive the missing-F0 pitch by using the temporal cues. Therefore, it can be inferred that improving the temporal cues in cochlear implant users may compensate for the impaired place cues and eventually lead to a better pitch perception. Application of a pitch perception model using the place code in evaluating the effect of stimulation field spread on pitch perception in cochlear implant hearing can be found in a study by Erfanian Saeedi et al. [<xref ref-type="bibr" rid="pcbi.1004860.ref067">67</xref>]. Similarly, with a modified auditory periphery (<xref ref-type="fig" rid="pcbi.1004860.g001">Fig 1E</xref>), the model developed in this study can be used to estimate the efficiency of experimental sound processing strategies (e.g., [<xref ref-type="bibr" rid="pcbi.1004860.ref068">68</xref>,<xref ref-type="bibr" rid="pcbi.1004860.ref069">69</xref>]) in terms of providing better temporal pitch perception cues. Extending the application of the current model to cochlear implant research would require replacing the normal hearing cochlear filters with descriptors of auditory neuron responses to electrical stimulation, examples of which can be found in [<xref ref-type="bibr" rid="pcbi.1004860.ref070">70</xref>–<xref ref-type="bibr" rid="pcbi.1004860.ref074">74</xref>].</p>
</sec>
</sec>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="pcbi.1004860.ref001"><label>1</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bendor</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>X</given-names></name> (<year>2005</year>) <article-title>The neuronal representation of pitch in primate auditory cortex</article-title>. <source>Nature</source> <volume>436</volume>: <fpage>1161</fpage>–<lpage>1165</lpage>. <object-id pub-id-type="pmid">16121182</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref002"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zatorre</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Belin</surname> <given-names>P</given-names></name> (<year>2001</year>) <article-title>Spectral and temporal processing in human auditory cortex</article-title>. <source>Cereb Cortex</source> <volume>11</volume>: <fpage>946</fpage>–<lpage>953</lpage>. <object-id pub-id-type="pmid">11549617</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref003"><label>3</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Patterson</surname> <given-names>RD</given-names></name>, <name name-style="western"><surname>Uppenkamp</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Johnsrude</surname> <given-names>IS</given-names></name>, <name name-style="western"><surname>Griffiths</surname> <given-names>TD</given-names></name> (<year>2002</year>) <article-title>The processing of temporal pitch and melody information in auditory cortex</article-title>. <source>Neuron</source> <volume>36</volume>: <fpage>767</fpage>–<lpage>776</lpage>. <object-id pub-id-type="pmid">12441063</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Penagos</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Melcher</surname> <given-names>JR</given-names></name>, <name name-style="western"><surname>Oxenham</surname> <given-names>AJ</given-names></name> (<year>2004</year>) <article-title>A neural representation of pitch salience in nonprimary human auditory cortex revealed with functional magnetic resonance imaging</article-title>. <source>J Neurosci</source> <volume>24</volume>: <fpage>6810</fpage>–<lpage>6815</lpage>. <object-id pub-id-type="pmid">15282286</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref005"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shamma</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Klein</surname> <given-names>D</given-names></name> (<year>2000</year>) <article-title>The case of the missing pitch templates: How harmonic templates emerge in the early auditory system</article-title>. <source>J Acoust Soc Am</source> <volume>107</volume>: <fpage>2631</fpage>–<lpage>2644</lpage>. <object-id pub-id-type="pmid">10830385</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rhode</surname> <given-names>WS</given-names></name> (<year>1995</year>) <article-title>Interspike intervals as a correlate of periodicity pitch in cat cochlear nucleus</article-title>. <source>J Acoust Soc Am</source> <volume>97</volume>: <fpage>2414</fpage>–<lpage>2429</lpage>. <object-id pub-id-type="pmid">7714259</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref007"><label>7</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Greenwood</surname> <given-names>DD</given-names></name>, <name name-style="western"><surname>Maruyama</surname> <given-names>N</given-names></name> (<year>1965</year>) <article-title>Excitatory and inhibitory response areas of auditory neurons in the cochlear nucleus</article-title>. <source>J Neurophysiol</source> <volume>28</volume>: <fpage>863</fpage>–<lpage>892</lpage>. <object-id pub-id-type="pmid">5867883</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref008"><label>8</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Oertel</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Bal</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Gardner</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Smith</surname> <given-names>PH</given-names></name>, <name name-style="western"><surname>Joris</surname> <given-names>PX</given-names></name> (<year>2000</year>) <article-title>Detection of synchrony in the activity of auditory nerve fibers by octopus cells of the mammalian cochlear nucleus</article-title>. <source>PNAS</source> <volume>97</volume>: <fpage>11773</fpage>–<lpage>11779</lpage>. <object-id pub-id-type="pmid">11050208</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref009"><label>9</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>McGinley</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Liberman</surname> <given-names>MC</given-names></name>, <name name-style="western"><surname>Bal</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Oertel</surname> <given-names>D</given-names></name> (<year>2012</year>) <article-title>Generating synchrony from the asynchronous: compensation for cochlear traveling wave delays by the dendrites of individual brainstem neurons</article-title>. <source>J Neurosci</source> <volume>32</volume>: <fpage>9301</fpage>–<lpage>9311</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.0272-12.2012" xlink:type="simple">10.1523/JNEUROSCI.0272-12.2012</ext-link></comment> <object-id pub-id-type="pmid">22764237</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref010"><label>10</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Spencer</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Grayden</surname> <given-names>DB</given-names></name>, <name name-style="western"><surname>Bruce</surname> <given-names>IC</given-names></name>, <name name-style="western"><surname>Meffin</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Burkitt</surname> <given-names>AN</given-names></name> (<year>2012</year>) <article-title>An investigation of dendritic delay in octopus cells of the mammalian cochlear nucleus</article-title>. <source>Front Comput Neurosci</source> <volume>6</volume>: <fpage>1</fpage>–<lpage>19</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004860.ref011"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bendor</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>X</given-names></name> (<year>2006</year>) <article-title>Cortical representations of pitch in monkeys and humans</article-title>. <source>Curr Opin Neurobiol</source> <volume>16</volume>: <fpage>391</fpage>–<lpage>399</lpage>. <object-id pub-id-type="pmid">16842992</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref012"><label>12</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wang</surname> <given-names>X</given-names></name> (<year>2007</year>) <article-title>Neural coding strategies in auditory cortex</article-title>. <source>Hear Res</source> <volume>229</volume>: <fpage>81</fpage>–<lpage>93</lpage>. <object-id pub-id-type="pmid">17346911</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref013"><label>13</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wang</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Lu</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Snider</surname> <given-names>RK</given-names></name>, <name name-style="western"><surname>Liang</surname> <given-names>L</given-names></name> (<year>2005</year>) <article-title>Sustained firing in auditory cortex evoked by preferred stimuli</article-title>. <source>Nature</source> <volume>435</volume>: <fpage>341</fpage>–<lpage>346</lpage>. <object-id pub-id-type="pmid">15902257</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Poeppel</surname> <given-names>D</given-names></name> (<year>2003</year>) <article-title>The analysis of speech in different temporal integration windows: cerebral lateralization as asymmetric sampling in time</article-title>. <source>Speech Commun</source> <volume>41</volume>: <fpage>245</fpage>–<lpage>255</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004860.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Johnsrude</surname> <given-names>IS</given-names></name>, <name name-style="western"><surname>Penhune</surname> <given-names>VB</given-names></name>, <name name-style="western"><surname>Zatorre</surname> <given-names>RJ</given-names></name> (<year>2000</year>) <article-title>Functional specificity in the right human auditory cortex for perceiving pitch direction</article-title>. <source>Brain</source> <volume>123</volume>: <fpage>155</fpage>–<lpage>163</lpage>. <object-id pub-id-type="pmid">10611129</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lyon</surname> <given-names>RF</given-names></name> (<year>1984</year>) <article-title>Computational models of neural auditory processing</article-title>. <source>Proc IEEE Int Conf Acoust Speech Signal Process</source> <volume>9</volume>: <fpage>41</fpage>–<lpage>44</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004860.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shamma</surname> <given-names>SA</given-names></name> (<year>1985a</year>) <article-title>Speech processing in the auditory system. I: The representation of speech sounds in the responses in the auditory nerve</article-title>. <source>J Acoust Soc Am</source> <volume>78</volume>: <fpage>1612</fpage>–<lpage>1621</lpage>. <object-id pub-id-type="pmid">4067077</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref018"><label>18</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zilany</surname> <given-names>MS</given-names></name>, <name name-style="western"><surname>Bruce</surname> <given-names>IC</given-names></name>, <name name-style="western"><surname>Carney</surname> <given-names>LH</given-names></name> (<year>2014</year>) <article-title>Updated parameters and expanded simulation options for a model of the auditory periphery</article-title>. <source>J Acoust Soc Am</source> <volume>135</volume>: <fpage>283</fpage>–<lpage>286</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1121/1.4837815" xlink:type="simple">10.1121/1.4837815</ext-link></comment> <object-id pub-id-type="pmid">24437768</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref019"><label>19</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Pandya</surname> <given-names>DN</given-names></name>, <name name-style="western"><surname>Yeterian</surname> <given-names>EH</given-names></name> (<year>1985</year>) <chapter-title>Architecture and connections of cortical association areas</chapter-title>. <source>Cerebral Cortex</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Plenum Press</publisher-name>.</mixed-citation></ref>
<ref id="pcbi.1004860.ref020"><label>20</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Klatt</surname> <given-names>DH</given-names></name> (<year>1980</year>) <article-title>Software for a cascade/parallel formant synthesizer</article-title>. <source>J Acoust Soc Am</source> <volume>67</volume>: <fpage>971</fpage>–<lpage>995</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004860.ref021"><label>21</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zilany</surname> <given-names>MSA</given-names></name>, <name name-style="western"><surname>Bruce</surname> <given-names>IC</given-names></name> (<year>2006</year>) <article-title>Modelling auditory-nerve response for high sound pressure levels in the normal and impaired auditory periphery</article-title>. <source>J Acoust Soc Am</source> <volume>120</volume>: <fpage>1446</fpage>–<lpage>1466</lpage>. <object-id pub-id-type="pmid">17004468</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref022"><label>22</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Greenwood</surname> <given-names>DD</given-names></name> (<year>1990</year>) <article-title>A cochlear frequency-position function for several species – 29 years later</article-title>. <source>J Acoust Soc Am</source> <volume>87</volume>: <fpage>2592</fpage>–<lpage>2605</lpage>. <object-id pub-id-type="pmid">2373794</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref023"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cariani</surname> <given-names>PA</given-names></name>, <name name-style="western"><surname>Delgutte</surname> <given-names>B</given-names></name> (<year>1996</year>) <article-title>Neural correlates of the pitch of complex tones. I. Pitch and pitch salience</article-title>. <source>J Neurophysiol</source> <volume>76</volume>: <fpage>1698</fpage>–<lpage>1716</lpage>. <object-id pub-id-type="pmid">8890286</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref024"><label>24</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Delgutte</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Kiang</surname> <given-names>NY</given-names></name> (<year>1984</year>) <article-title>Speech coding in the auditory nerve: I. Vowel like sounds</article-title>. <source>J Acoust Soc Am</source> <volume>75</volume>: <fpage>866</fpage>–<lpage>878</lpage>. <object-id pub-id-type="pmid">6707316</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref025"><label>25</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zhang</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Heinz</surname> <given-names>MG</given-names></name>, <name name-style="western"><surname>Bruce</surname> <given-names>IC</given-names></name>, <name name-style="western"><surname>Carney</surname> <given-names>LH</given-names></name> (<year>2001</year>) <article-title>A phenomenological model for the responses of auditory-nerve fibers: I. Nonlinear tuning with compression and suppression</article-title>. <source>J Acoust Soc Am</source> <volume>109</volume>: <fpage>648</fpage>–<lpage>670</lpage>. <object-id pub-id-type="pmid">11248971</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref026"><label>26</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Burkitt</surname> <given-names>AN</given-names></name> (<year>2006a</year>) <article-title>A review of the integrate-and-fire neuron model: I. Homogeneous synaptic input</article-title>. <source>Biol Cybern</source> <volume>95</volume>: <fpage>1</fpage>–<lpage>19</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004860.ref027"><label>27</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bi</surname> <given-names>G-Q</given-names></name>, <name name-style="western"><surname>Poo</surname> <given-names>M-M</given-names></name> (<year>2001</year>) <article-title>Synaptic modification by correlated activity: Hebb's postulate revisited</article-title>. <source>Annu Rev Neurosci</source> <volume>24</volume>: <fpage>139</fpage>–<lpage>166</lpage>. <object-id pub-id-type="pmid">11283308</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref028"><label>28</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bell</surname> <given-names>CC</given-names></name>, <name name-style="western"><surname>Han</surname> <given-names>VZ</given-names></name>, <name name-style="western"><surname>Sugawara</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Grant</surname> <given-names>K</given-names></name> (<year>1997</year>) <article-title>Synaptic plasticity in a cerebellum-like structure depends on temporal order</article-title>. <source>Nature</source> <volume>387</volume>: <fpage>278</fpage>–<lpage>281</lpage>. <object-id pub-id-type="pmid">9153391</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref029"><label>29</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Markram</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Lübke</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Frotscher</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Sakmann</surname> <given-names>B</given-names></name> (<year>1997</year>) <article-title>Regulation of synaptic efficacy by coincidence of postsynaptic APs and EPSPs</article-title>. <source>Science</source> <volume>275</volume>: <fpage>213</fpage>–<lpage>215</lpage>. <object-id pub-id-type="pmid">8985014</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref030"><label>30</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gerstner</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Kempter</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>van Hemmen</surname> <given-names>JL</given-names></name>, <name name-style="western"><surname>Wagner</surname> <given-names>H</given-names></name> (<year>1996</year>) <article-title>A neural learning rule for sub-millisecond temporal coding</article-title>. <source>Nature</source> <volume>383</volume>: <fpage>76</fpage>–<lpage>78</lpage>. <object-id pub-id-type="pmid">8779718</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref031"><label>31</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Hebb</surname> <given-names>DO</given-names></name> (<year>1949</year>) <chapter-title>The organization of behavior</chapter-title>. <publisher-loc>New York</publisher-loc>: <publisher-name>Wiley</publisher-name>.</mixed-citation></ref>
<ref id="pcbi.1004860.ref032"><label>32</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kempter</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Gerstner</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>van Hemmen</surname> <given-names>JL</given-names></name> (<year>1999</year>) <article-title>Hebbian learning and spiking neurons</article-title>. <source>Phys Rev E</source> <volume>59</volume>: <fpage>4498</fpage>.</mixed-citation></ref>
<ref id="pcbi.1004860.ref033"><label>33</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bi</surname> <given-names>G-Q</given-names></name>, <name name-style="western"><surname>Poo</surname> <given-names>M-M</given-names></name> (<year>1998</year>) <article-title>Synaptic modifications in cultured hippocampal neurons: dependence on spike timing, synaptic strength, and postsynaptic cell type</article-title>. <source>J Neurosci</source> <volume>18</volume>: <fpage>10464</fpage>–<lpage>10472</lpage>. <object-id pub-id-type="pmid">9852584</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref034"><label>34</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Gerstner</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Kempter</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>van Hemmen</surname> <given-names>JL</given-names></name>, <name name-style="western"><surname>Wagner</surname> <given-names>H</given-names></name> (<year>1998</year>) <source>Hebbian Learning of Pulse Timing in the Barn Owl Auditory System Pulsed Neural Networks</source>. <publisher-loc>Cambridge</publisher-loc>: <publisher-name>MIT-Press</publisher-name>. pp. <fpage>353</fpage>–<lpage>377</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004860.ref035"><label>35</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kerr</surname> <given-names>RR</given-names></name>, <name name-style="western"><surname>Burkitt</surname> <given-names>AN</given-names></name>, <name name-style="western"><surname>Thomas</surname> <given-names>DA</given-names></name>, <name name-style="western"><surname>Gilson</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Grayden</surname> <given-names>DB</given-names></name> (<year>2013</year>) <article-title>Delay selection by spike-timing-dependent plasticity in recurrent networks of spiking neurons receiving oscillatory inputs</article-title>. <source>PLoS Comp Biol</source> <volume>9</volume>: <fpage>e1002897</fpage>.</mixed-citation></ref>
<ref id="pcbi.1004860.ref036"><label>36</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kerr</surname> <given-names>RR</given-names></name>, <name name-style="western"><surname>Grayden</surname> <given-names>DB</given-names></name>, <name name-style="western"><surname>Thomas</surname> <given-names>DA</given-names></name>, <name name-style="western"><surname>Gilson</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Burkitt</surname> <given-names>AN</given-names></name> (<year>2014</year>) <article-title>Coexistence of Reward and Unsupervised Learning During the Operant Conditioning of Neural Firing Rates</article-title>. <source>PLoS ONE</source> <volume>9</volume>: <fpage>e87123</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0087123" xlink:type="simple">10.1371/journal.pone.0087123</ext-link></comment> <object-id pub-id-type="pmid">24475240</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref037"><label>37</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gilson</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Burkitt</surname> <given-names>AN</given-names></name>, <name name-style="western"><surname>Grayden</surname> <given-names>DB</given-names></name>, <name name-style="western"><surname>Thomas</surname> <given-names>DA</given-names></name>, <name name-style="western"><surname>van Hemmen</surname> <given-names>JL</given-names></name> (<year>2009</year>) <article-title>Emergence of network structure due to spike-timing-dependent plasticity in recurrent neuronal networks. I. Input selectivity–strengthening correlated input pathways</article-title>. <source>Biol Cybern</source> <volume>101</volume>: <fpage>81</fpage>–<lpage>102</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s00422-009-0319-4" xlink:type="simple">10.1007/s00422-009-0319-4</ext-link></comment> <object-id pub-id-type="pmid">19536560</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref038"><label>38</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Goldberg</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Brown</surname> <given-names>PB</given-names></name> (<year>1969</year>) <article-title>Response of binaural neurons of dog superior olivary complex to dichotic tonal stimuli: some physiological mechanisms of sound localization</article-title>. <source>J Neurophysiol</source> <volume>32</volume>: <fpage>613</fpage>–<lpage>636</lpage>. <object-id pub-id-type="pmid">5810617</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref039"><label>39</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rose</surname> <given-names>JE</given-names></name>, <name name-style="western"><surname>Brugge</surname> <given-names>JF</given-names></name>, <name name-style="western"><surname>Anderson</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Hind</surname> <given-names>JE</given-names></name> (<year>1969</year>) <article-title>Some possible neural correlates of combination tones</article-title>. <source>J Neurophysiol</source> <volume>32</volume>: <fpage>402</fpage>–<lpage>423</lpage>. <object-id pub-id-type="pmid">4306899</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref040"><label>40</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zatorre</surname> <given-names>RJ</given-names></name> (<year>1988</year>) <article-title>Pitch perception of complex tones and human temporal lobe function</article-title>. <source>J Acoust Soc Am</source> <volume>84</volume>: <fpage>566</fpage>–<lpage>572</lpage>. <object-id pub-id-type="pmid">3170948</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref041"><label>41</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sucher</surname> <given-names>CM</given-names></name>, <name name-style="western"><surname>McDermott</surname> <given-names>HJ</given-names></name> (<year>2007</year>) <article-title>Pitch ranking of complex tones by normally hearing subjects and cochlear implant users</article-title>. <source>Hear Res</source> <volume>230</volume>: <fpage>80</fpage>–<lpage>87</lpage>. <object-id pub-id-type="pmid">17604582</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref042"><label>42</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Demuth</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Beale</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Hagan</surname> <given-names>M</given-names></name> (<year>2008</year>) <source>Neural Network Toolbox™, MATLAB Version 6</source>: <publisher-name>The Mathworks Inc.</publisher-name></mixed-citation></ref>
<ref id="pcbi.1004860.ref043"><label>43</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Leppänen</surname> <given-names>PH</given-names></name>, <name name-style="western"><surname>Eklund</surname> <given-names>KM</given-names></name>, <name name-style="western"><surname>Lyytinen</surname> <given-names>H</given-names></name> (<year>1997</year>) <article-title>Event‐related brain potentials to change in rapidly presented acoustic stimuli in newborns</article-title>. <source>Dev Neuropsychol</source> <volume>13</volume>: <fpage>175</fpage>–<lpage>204</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004860.ref044"><label>44</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Draganova</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Eswaran</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Murphy</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Huotilainen</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Lowery</surname> <given-names>C</given-names></name>, <etal>et al</etal>. (<year>2005</year>) <article-title>Sound frequency change detection in fetuses and newborns, a magnetoencephalographic study</article-title>. <source>Neuroimage</source> <volume>28</volume>: <fpage>354</fpage>–<lpage>361</lpage>. <object-id pub-id-type="pmid">16023867</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref045"><label>45</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>He</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Trainor</surname> <given-names>LJ</given-names></name> (<year>2009</year>) <article-title>Finding the pitch of the missing fundamental in infants</article-title>. <source>J Neurosci</source> <volume>29</volume>: <fpage>7718</fpage>–<lpage>8822</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.0157-09.2009" xlink:type="simple">10.1523/JNEUROSCI.0157-09.2009</ext-link></comment> <object-id pub-id-type="pmid">19535583</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref046"><label>46</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Plack</surname> <given-names>CJ</given-names></name>, <name name-style="western"><surname>Oxenham</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Fay</surname> <given-names>RR</given-names></name>, <name name-style="western"><surname>Popper</surname> <given-names>AN</given-names></name> (<year>2005</year>) <source>Pitch Neural Coding and Perception</source>; <name name-style="western"><surname>Fay</surname> <given-names>RR</given-names></name>, <name name-style="western"><surname>Popper</surname> <given-names>AN</given-names></name>, editors. <publisher-loc>New York</publisher-loc>: <publisher-name>Springer</publisher-name>.</mixed-citation></ref>
<ref id="pcbi.1004860.ref047"><label>47</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>De Cheveigné</surname> <given-names>A</given-names></name> (<year>2005</year>) <chapter-title>Pitch perception models</chapter-title>. <source>Pitch</source>: <publisher-name>Springer</publisher-name>. pp. <fpage>169</fpage>–<lpage>233</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004860.ref048"><label>48</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cohen</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Grossberg</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Wyse</surname> <given-names>LL</given-names></name> (<year>1995</year>) <article-title>A spectral network model of pitch perception</article-title>. <source>J Acoust Soc Am</source> <volume>98</volume>: <fpage>862</fpage>–<lpage>879</lpage>. <object-id pub-id-type="pmid">7642825</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref049"><label>49</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Licklider</surname> <given-names>JCR</given-names></name> (<year>1951</year>) <article-title>A Duplex Theory of Pitch Perception</article-title>. <source>Experientia</source> <volume>VII</volume>: <fpage>128</fpage>–<lpage>134</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004860.ref050"><label>50</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Meddis</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>O’Mard</surname> <given-names>L</given-names></name> (<year>1997</year>) <article-title>A unitary model of pitch perception</article-title>. <source>J Acoust Soc Am</source> <volume>102</volume>: <fpage>1811</fpage>–<lpage>1820</lpage>. <object-id pub-id-type="pmid">9301058</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref051"><label>51</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Moore</surname> <given-names>BC</given-names></name> (<year>2013</year>) <chapter-title>An introduction to the psychology of hearing</chapter-title>. <publisher-loc>Leiden</publisher-loc>: <publisher-name>Brill</publisher-name>.</mixed-citation></ref>
<ref id="pcbi.1004860.ref052"><label>52</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gifford</surname> <given-names>RH</given-names></name>, <name name-style="western"><surname>Shallop</surname> <given-names>JK</given-names></name>, <name name-style="western"><surname>Peterson</surname> <given-names>AM</given-names></name> (<year>2008</year>) <article-title>Speech recognition materials and ceiling effects: Considerations for cochlear implant programs</article-title>. <source>Audiol Neurotol</source> <volume>13</volume>: <fpage>193</fpage>–<lpage>205</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004860.ref053"><label>53</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Loizou</surname> <given-names>PC</given-names></name>, <name name-style="western"><surname>Poroy</surname> <given-names>O</given-names></name>, <string-name>M D</string-name> (<year>2000</year>) <article-title>The effect of parametric variations of cochlear implant processors on speech understanding</article-title>. <source>J Acoust Soc Am</source> <volume>108</volume>: <fpage>790</fpage>–<lpage>802</lpage>. <object-id pub-id-type="pmid">10955646</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref054"><label>54</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Loizou</surname> <given-names>PC</given-names></name>, <name name-style="western"><surname>Yi</surname> <given-names>Hu</given-names></name>, <name name-style="western"><surname>Litovsky</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Gongqiang</surname> <given-names>Yu</given-names></name>, <name name-style="western"><surname>Peters</surname> <given-names>R</given-names></name>, <etal>et al</etal>. (<year>2009</year>) <article-title>Speech recognition by bilateral cochlear implant users in a cocktail-party setting</article-title>. <source>J Acoust Soc Am</source> <volume>125</volume>: <fpage>372</fpage>–<lpage>383</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1121/1.3036175" xlink:type="simple">10.1121/1.3036175</ext-link></comment> <object-id pub-id-type="pmid">19173424</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref055"><label>55</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>McDermott</surname> <given-names>HJ</given-names></name> (<year>2004</year>) <article-title>Music perception with cochlear implants: a review</article-title>. <source>Trends Amplif</source> <volume>8</volume>: <fpage>49</fpage>–<lpage>82</lpage>. <object-id pub-id-type="pmid">15497033</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref056"><label>56</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gfeller</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Turner</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Oleson</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Zhang</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Gantz</surname> <given-names>B</given-names></name>, <etal>et al</etal>. (<year>2007</year>) <article-title>Accuracy of cochlear implant recipients on pitch perception, melody recognition, and speech reception in noise</article-title>. <source>Ear Hear</source> <volume>28</volume>: <fpage>412</fpage>–<lpage>423</lpage>. <object-id pub-id-type="pmid">17485990</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref057"><label>57</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Moore</surname> <given-names>BC</given-names></name>, <name name-style="western"><surname>Carlyon</surname> <given-names>RP</given-names></name> (<year>2005</year>) <chapter-title>Perception of pitch by people with cochlear hearing loss and by cochlear implant users</chapter-title>. <source>Pitch</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Springer</publisher-name>. pp. <fpage>234</fpage>–<lpage>277</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004860.ref058"><label>58</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nelson</surname> <given-names>DA</given-names></name>, <name name-style="western"><surname>Van Tasell</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Schroder</surname> <given-names>AC</given-names></name>, <name name-style="western"><surname>Soli</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Levine</surname> <given-names>S</given-names></name> (<year>1995</year>) <article-title>Electrode ranking of ‘‘place pitch”and speech recognition in electrical hearing</article-title>. <source>J Acoust Soc Am</source> <volume>98</volume>: <fpage>1987</fpage>–<lpage>1999</lpage>. <object-id pub-id-type="pmid">7593921</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref059"><label>59</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tong</surname> <given-names>YC</given-names></name>, <name name-style="western"><surname>Blamey</surname> <given-names>PJ</given-names></name>, <name name-style="western"><surname>Dowell</surname> <given-names>RC</given-names></name>, <name name-style="western"><surname>Clark</surname> <given-names>GM</given-names></name> (<year>1983</year>) <article-title>Psychophysical studies evaluating the feasibility of a speech processing strategy for a multiple-channel cochlear implant</article-title>. <source>J Acoust Soc Am</source> <volume>74</volume>: <fpage>73</fpage>–<lpage>80</lpage>. <object-id pub-id-type="pmid">6688434</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref060"><label>60</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shannon</surname> <given-names>RV</given-names></name> (<year>1992</year>) <article-title>Temporal modulation transfer functions in patients with cochlear implants</article-title>. <source>J Acoust Soc Am</source> <volume>91</volume>: <fpage>2156</fpage>–<lpage>2164</lpage>. <object-id pub-id-type="pmid">1597606</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref061"><label>61</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>McKay</surname> <given-names>CM</given-names></name>, <name name-style="western"><surname>McDermott</surname> <given-names>HJ</given-names></name>, <name name-style="western"><surname>Clark</surname> <given-names>GM</given-names></name> (<year>1994</year>) <article-title>Pitch percepts associated with amplitude-modulated current pulse trains in cochlear implantees</article-title>. <source>J Acoust Soc Am</source> <volume>96</volume>: <fpage>2664</fpage>–<lpage>2673</lpage>. <object-id pub-id-type="pmid">7983272</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref062"><label>62</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Blamey</surname> <given-names>PJ</given-names></name>, <name name-style="western"><surname>Dooley</surname> <given-names>GJ</given-names></name>, <name name-style="western"><surname>Parisi</surname> <given-names>ES</given-names></name>, <name name-style="western"><surname>Clark</surname> <given-names>GM</given-names></name> (<year>1996</year>) <article-title>Pitch comparisons of acoustically and electrically evoked auditory sensations</article-title>. <source>Hear Res</source> <volume>99</volume>: <fpage>139</fpage>–<lpage>150</lpage>. <object-id pub-id-type="pmid">8970822</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref063"><label>63</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Başkent</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Shannon</surname> <given-names>RV</given-names></name> (<year>2005</year>) <article-title>Interactions between cochlear implant electrode insertion depth and frequency-place mapping</article-title>. <source>J Acoust Soc Am</source> <volume>117</volume>: <fpage>1405</fpage>–<lpage>1416</lpage>. <object-id pub-id-type="pmid">15807028</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref064"><label>64</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schatzer</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Vermeire</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Visser</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Krenmayr</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Kals</surname> <given-names>M</given-names></name>, <etal>et al</etal>. (<year>2014</year>) <article-title>Electric-acoustic pitch comparisons in single-sided-deaf cochlear implant users: Frequency-place functions and rate pitch</article-title>. <source>Hear Res</source> <volume>309</volume>: <fpage>26</fpage>–<lpage>35</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.heares.2013.11.003" xlink:type="simple">10.1016/j.heares.2013.11.003</ext-link></comment> <object-id pub-id-type="pmid">24252455</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref065"><label>65</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zeng</surname> <given-names>F-G</given-names></name> (<year>2002</year>) <article-title>Temporal pitch in electric hearing</article-title>. <source>Hear Res</source> <volume>174</volume>: <fpage>101</fpage>–<lpage>106</lpage>. <object-id pub-id-type="pmid">12433401</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref066"><label>66</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Carlyon</surname> <given-names>RP</given-names></name>, <name name-style="western"><surname>Deeks</surname> <given-names>JM</given-names></name> (<year>2002</year>) <article-title>Limitations on rate discrimination</article-title>. <source>J Acoust Soc Am</source> <volume>112</volume>: <fpage>1009</fpage>–<lpage>1025</lpage>. <object-id pub-id-type="pmid">12243150</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref067"><label>67</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Erfanian</surname> <given-names>Saeedi N</given-names></name>, <name name-style="western"><surname>Blamey</surname> <given-names>PJ</given-names></name>, <name name-style="western"><surname>Burkitt</surname> <given-names>AN</given-names></name>, <name name-style="western"><surname>Grayden</surname> <given-names>DB</given-names></name> (<year>2014</year>) <article-title>Application of a pitch perception model to investigate the effect of stimulation field spread on the pitch ranking abilities of cochlear implant recipients</article-title>. <source>Hear Res</source> <volume>316</volume>: <fpage>129</fpage>–<lpage>137</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.heares.2014.08.006" xlink:type="simple">10.1016/j.heares.2014.08.006</ext-link></comment> <object-id pub-id-type="pmid">25193552</object-id></mixed-citation></ref>
<ref id="pcbi.1004860.ref068"><label>68</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chen</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Zhang</surname> <given-names>Y-T</given-names></name> (<year>2008</year>) <article-title>A novel temporal fine structure-based speech synthesis model for cochlear implant</article-title>. <source>Signal Process</source> <volume>88</volume>: <fpage>2693</fpage>–<lpage>2699</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004860.ref069"><label>69</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Harczos</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Chilian</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Husar</surname> <given-names>P</given-names></name> (<year>2013</year>) <article-title>Making use of auditory models for better mimicking of normal hearing processes with cochlear implants: the SAM coding strategy</article-title>. <source>IEEE Trans Biomed Circuts Syst</source> <volume>7</volume>: <fpage>414</fpage>–<lpage>425</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004860.ref070"><label>70</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cohen</surname> <given-names>LT</given-names></name> (<year>2009a</year>) <article-title>Practical model description of peripheral neural excitation in cochlear implant recipients: 1. Growth of loudness and ECAP amplitude with current</article-title>. <source>Hear Res</source> <volume>247</volume>: <fpage>87</fpage>–<lpage>99</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004860.ref071"><label>71</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cohen</surname> <given-names>LT</given-names></name> (<year>2009b</year>) <article-title>Practical model description of peripheral neural excitation in cochlear implant recipients: 2. Spread of the effective stimulation field (ESF), from ECAP and FEA</article-title>. <source>Hear Res</source> <volume>247</volume>: <fpage>100</fpage>–<lpage>111</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004860.ref072"><label>72</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cohen</surname> <given-names>LT</given-names></name> (<year>2009c</year>) <article-title>Practical model description of peripheral neural excitation in cochlear implant recipients: 3. ECAP during bursts and loudness as function of burst duration</article-title>. <source>Hear Res</source> <volume>247</volume>: <fpage>112</fpage>–<lpage>121</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004860.ref073"><label>73</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cohen</surname> <given-names>LT</given-names></name> (<year>2009d</year>) <article-title>Practical model description of peripheral neural excitation in cochlear implant recipients: 4. Model development at low pulse rates: general model and application to individuals</article-title>. <source>Hear Res</source> <volume>248</volume>: <fpage>15</fpage>–<lpage>30</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004860.ref074"><label>74</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cohen</surname> <given-names>LT</given-names></name> (<year>2009e</year>) <article-title>Practical model description of peripheral neural excitation in cochlear implant recipients: 5. Refractory recovery and facilitation</article-title>. <source>Hear Res</source> <volume>248</volume>: <fpage>1</fpage>–<lpage>14</lpage>.</mixed-citation></ref>
</ref-list>
</back>
</article>
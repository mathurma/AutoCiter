<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN" "http://jats.nlm.nih.gov/publishing/1.1d3/JATS-journalpublishing1.dtd">
<article article-type="research-article" dtd-version="1.1d3" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-16-00131</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1004963</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Cell biology</subject><subj-group><subject>Cellular types</subject><subj-group><subject>Animal cells</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cellular neuroscience</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Network analysis</subject><subj-group><subject>Network motifs</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Membrane potential</subject><subj-group><subject>Action potentials</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Membrane potential</subject><subj-group><subject>Action potentials</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Neurophysiology</subject><subj-group><subject>Action potentials</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Neurophysiology</subject><subj-group><subject>Action potentials</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neurophysiology</subject><subj-group><subject>Action potentials</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Plant science</subject><subj-group><subject>Plant anatomy</subject><subj-group><subject>Leaves</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Probability theory</subject><subj-group><subject>Random variables</subject><subj-group><subject>Covariance</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Network analysis</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Data visualization</subject><subj-group><subject>Infographics</subject><subj-group><subject>Graphs</subject></subj-group></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Interplay between Graph Topology and Correlations of Third Order in Spiking Neuronal Networks</article-title>
<alt-title alt-title-type="running-head">Topology and Third-Order Correlations</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<name name-style="western">
<surname>Jovanović</surname> <given-names>Stojan</given-names></name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-3534-6530</contrib-id>
<name name-style="western">
<surname>Rotter</surname> <given-names>Stefan</given-names></name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
</contrib-group>
<aff id="aff001">
<label>1</label>
<addr-line>Bernstein Center Freiburg &amp; Faculty of Biology, University of Freiburg, Freiburg, Germany</addr-line>
</aff>
<aff id="aff002">
<label>2</label>
<addr-line>CB, CSC, KTH Royal Institute of Technology, Stockholm, Sweden</addr-line>
</aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Sporns</surname> <given-names>Olaf</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>Indiana University, UNITED STATES</addr-line>
</aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<fn fn-type="con" id="contrib001">
<p>Conceived and designed the experiments: SJ SR. Performed the experiments: SJ. Analyzed the data: SJ. Wrote the paper: SJ SR.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">stojan.jovanovic@ntnu.no</email></corresp>
</author-notes>
<pub-date pub-type="collection">
<month>6</month>
<year>2016</year>
</pub-date>
<pub-date pub-type="epub">
<day>6</day>
<month>6</month>
<year>2016</year>
</pub-date>
<volume>12</volume>
<issue>6</issue>
<elocation-id>e1004963</elocation-id>
<history>
<date date-type="received">
<day>26</day>
<month>1</month>
<year>2016</year>
</date>
<date date-type="accepted">
<day>2</day>
<month>5</month>
<year>2016</year>
</date>
</history>
<permissions>
<copyright-year>2016</copyright-year>
<copyright-holder>Jovanović, Rotter</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1004963"/>
<abstract>
<p>The study of processes evolving on networks has recently become a very popular research field, not only because of the rich mathematical theory that underpins it, but also because of its many possible applications, a number of them in the field of biology. Indeed, molecular signaling pathways, gene regulation, predator-prey interactions and the communication between neurons in the brain can be seen as examples of networks with complex dynamics. The properties of such dynamics depend largely on the topology of the underlying network graph. In this work, we want to answer the following question: Knowing network connectivity, what can be said about the level of third-order correlations that will characterize the network dynamics? We consider a linear point process as a model for pulse-coded, or spiking activity in a neuronal network. Using recent results from theory of such processes, we study third-order correlations between spike trains in such a system and explain which features of the network graph (i.e. which topological motifs) are responsible for their emergence. Comparing two different models of network topology—random networks of Erdős-Rényi type and networks with highly interconnected hubs—we find that, in random networks, the average measure of third-order correlations does not depend on the local connectivity properties, but rather on global parameters, such as the connection probability. This, however, ceases to be the case in networks with a geometric out-degree distribution, where topological specificities have a strong impact on average correlations.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author Summary</title>
<p>Many biological phenomena can be viewed as dynamical processes on a graph. Understanding coordinated activity of nodes in such a network is of some importance, as it helps to characterize the behavior of the complex system. Of course, the topology of a network plays a pivotal role in determining the level of coordination among its different vertices. In particular, correlations between triplets of events (here: action potentials generated by neurons) have recently garnered some interest in the theoretical neuroscience community. In this paper, we present a decomposition of an average measure of third-order coordinated activity of neurons in a spiking neuronal network in terms of the relevant topological motifs present in the underlying graph. We study different network topologies and show, in particular, that the presence of certain tree motifs in the synaptic connectivity graph greatly affects the strength of third-order correlations between spike trains of different neurons.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution>Erasmus Mundus Joint Doctoral programme EuroSPIN</institution>
</funding-source>
<principal-award-recipient>
<name name-style="western">
<surname>Jovanovic</surname> <given-names>Stojan</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award002">
<funding-source>
<institution>German Federal Ministry of Education and Research</institution>
</funding-source>
<award-id>BFNT 01GQ0830</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Rotter</surname> <given-names>Stefan</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award003">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100001659</institution-id>
<institution>Deutsche Forschungsgemeinschaft</institution>
</institution-wrap>
</funding-source>
<award-id>EXC 1086</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Rotter</surname> <given-names>Stefan</given-names></name>
</principal-award-recipient>
</award-group>
<funding-statement>This work was supported by the Erasmus Mundus Joint Doctoral program EuroSPIN, the German Federal Ministry of Education and Research (BFNT, grant 01GQ0830), and the German Research Foundation (BLBT, grant EXC 1086). The article processing charge was covered by the open access publication fund of the University of Freiburg. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="7"/>
<table-count count="1"/>
<page-count count="28"/>
</counts>
<custom-meta-group>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>Data are available on the Open Science Framework database at <ext-link ext-link-type="uri" xlink:href="https://osf.io/dm9g8/" xlink:type="simple">https://osf.io/dm9g8/</ext-link>.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Analyzing networks of interacting elements has become the tool of choice in many areas of biology. In recent years, network models have been used to study the interactions between predator and prey [<xref ref-type="bibr" rid="pcbi.1004963.ref001">1</xref>], gene interactions [<xref ref-type="bibr" rid="pcbi.1004963.ref002">2</xref>] and neural network dynamics [<xref ref-type="bibr" rid="pcbi.1004963.ref003">3</xref>, <xref ref-type="bibr" rid="pcbi.1004963.ref004">4</xref>]. A fundamental question in the study of complex networks is how the topology of the graph on which a dynamic process evolves influences its activity. A particularly interesting issue is the emergence of synchronized, or correlated patterns of events. While it is obvious that the presence or absence of such patterns of activity depends largely on how individual nodes in the network are connected, it is by no means a trivial task to explain exactly how this happens.</p>
<p>In theoretical neuroscience, the connection between network topology and correlated activity continues to be an important topic of study. Not only are correlations between neuronal spike trains believed to have an important function in information processing [<xref ref-type="bibr" rid="pcbi.1004963.ref005">5</xref>, <xref ref-type="bibr" rid="pcbi.1004963.ref006">6</xref>] and coincidence detection [<xref ref-type="bibr" rid="pcbi.1004963.ref007">7</xref>], but they are also believed to be tied to expectation and attention (see [<xref ref-type="bibr" rid="pcbi.1004963.ref007">7</xref>] for details). In addition, it been shown that nerve cells can be extremely sensitive to synchronous input from large groups of neurons [<xref ref-type="bibr" rid="pcbi.1004963.ref008">8</xref>].</p>
<p>While there has been much work on elucidating the causes and effects of pairwise correlations between spike trains [<xref ref-type="bibr" rid="pcbi.1004963.ref003">3</xref>], it seems that correlations beyond second order also have a role to play in the brain. For example, it was indicated that a nonlinear neuron’s firing rate profile depends on higher-order correlations between the presynaptic spikes [<xref ref-type="bibr" rid="pcbi.1004963.ref009">9</xref>]. Higher-order correlations have also been reported in the rat somatosensory cortex and the visual cortex of the behaving macaque [<xref ref-type="bibr" rid="pcbi.1004963.ref010">10</xref>]. Indeed, it has been suggested that these correlations are inherent properties of cortical dynamics in many species [<xref ref-type="bibr" rid="pcbi.1004963.ref011">11</xref>, <xref ref-type="bibr" rid="pcbi.1004963.ref012">12</xref>]. As a result, neural data has recently been intensively investigated for signs of higher-order synchrony using classical means such as maximum entropy models [<xref ref-type="bibr" rid="pcbi.1004963.ref013">13</xref>–<xref ref-type="bibr" rid="pcbi.1004963.ref018">18</xref>]. In addition, new methods are being developed in order to shed more light on what seems to be a very important property of networks in the brain [<xref ref-type="bibr" rid="pcbi.1004963.ref019">19</xref>–<xref ref-type="bibr" rid="pcbi.1004963.ref021">21</xref>].</p>
<p>In this work, we study the relation between the topology (i.e. synaptic connectivity) and correlations of third order between neuronal spike trains. Our aim was to show how triplet correlations depend on topological motifs in a network with known connectivity. We hope our results can be used to facilitate thought experiments to relate hypothetical connectivity to third-order correlations by, for example, assuming specific network topologies and then computing how these assumptions affect the dynamics.</p>
<p>In the following text, the word “connection” is meant to be translated as “synapse”. While this might be a point of contention, in previous work, it was clearly shown that that a mapping between synaptically coupled spiking networks (e.g. comprising LIF neurons) and statistical, point process models, such as Hawkes process exist, with exactly the same underlying connectivity [<xref ref-type="bibr" rid="pcbi.1004963.ref022">22</xref>]. In addition, it has been demonstrated that synaptic connectivity can be reconstructed from simulated spike trains with very high fidelity, provided the network has a connectivity which is not too dense and not too sparse [<xref ref-type="bibr" rid="pcbi.1004963.ref023">23</xref>]. On the basis of these two results, we feel enough confidence to claim that in the Hawkes process network models considered here “connections” in terms of coupling kernels can be safely identified with “synapses” in a spiking neuronal network.</p>
<p>However, we would also like to point out that knowing the true connectivity in an experimental setting is close to impossible. Indeed, the connectivity matrices, obtained by statistical inference methods applied to neural data are rarely more than a proxy for the actual “anatomical” connectivity. In other words, the existence of a statistical relationship between the firings of two neural cells (“correlation”) does generally not imply the existence of an actual synapse between them. In addition, the inference of connectivity from neural data is confounded by undersampling. One can typically only record from a tiny fraction of all neurons that constitute the network, while most of the population remains effectively hidden to the experimenter.</p>
<p>Similar work, pertaining to the influence of connectivity on correlations of second order has already been published [<xref ref-type="bibr" rid="pcbi.1004963.ref003">3</xref>, <xref ref-type="bibr" rid="pcbi.1004963.ref024">24</xref>–<xref ref-type="bibr" rid="pcbi.1004963.ref026">26</xref>]. In it, the authors dissect the contribution of specific structural motifs to the emergence of pairwise correlations in a recurrent network of interconnected point processes, meant to represent neurons communicating via spikes. Interpreting known mathematical results [<xref ref-type="bibr" rid="pcbi.1004963.ref027">27</xref>] in an original fashion, they show how the influence of recurrent input can be disentangled to take into account not only effects of direct connections, but also indirect connectivity. However, no such result exists in the case of more complex patterns, stemming from correlations of higher order. With this paper, we aim to fill this gap.</p>
<p>Analogously to [<xref ref-type="bibr" rid="pcbi.1004963.ref003">3</xref>], we show that measures of third-order correlations (known in the statistical literature as “third-order joint cumulants”) are also heavily influenced by the presence of certain topological motifs in the network graph. We find that the motifs in question can be thought of representing “common input to triplets of neurons” and that, in graph theory terms, they represent rooted trees with three leaf nodes. Furthermore, we obtain an expansion of the joint third cumulants in terms of a sum of weights of all such subgraphs and show that, in a regular network (that is, a network with fixed in- and out-degrees), this expansion can be approximated by a formula that doesn’t depend on the specific adjacency matrix, but rather on global connectivity parameters, such as the connection probability <italic>p</italic>. In addition, our result extends to large random Erdős-Rényi type networks, as they are approximately regular when the number of nodes grows without bound. We find that the formula we derive is a useful approximation for quantifying the level of third-order correlations in networks with a narrow out-degree distribution. In addition, we look at networks of highly interconnected hubs and show that, in this case, the average joint third cumulant depends strongly on the details of the connectivity pattern.</p>
</sec>
<sec id="sec002" sec-type="materials|methods">
<title>Methods</title>
<sec id="sec003">
<title>The Hawkes process as a model of spiking neural networks</title>
<p>To study higher-order correlations in networks of spiking neurons with a fixed network topology, we apply a point process model introduced in [<xref ref-type="bibr" rid="pcbi.1004963.ref027">27</xref>, <xref ref-type="bibr" rid="pcbi.1004963.ref028">28</xref>], which we will refer to as the “Hawkes process”. As the theory of Hawkes processes is rich and rather technical, we will only summarize the important definitions and equations needed to present our results. A more formal and thorough treatment of the model can be found in Hawkes’ original papers.</p>
<p>In what follows, we will use capital letters to denote matrices. Vectors will not be explicitly marked, as their identity will be clear from the context. Individual components of matrices and vectors are referred to by indices attached to the symbol. Furthermore, note that, from here onwards, the phrase “third-order correlations” should always be interpreted as referring to “third-order joint cumulants” (defined below).</p>
<p>Our spiking neuronal network consists of <italic>N</italic> neurons, of which <italic>N</italic><sub><italic>E</italic></sub> are excitatory and <italic>N</italic><sub><italic>I</italic></sub> are inhibitory. Spike trains of neuron <italic>i</italic>, <inline-formula id="pcbi.1004963.e001"><alternatives><graphic id="pcbi.1004963.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e001" xlink:type="simple"/><mml:math display="inline" id="M1"><mml:mrow><mml:msub><mml:mi>S</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msub><mml:mo>∑</mml:mo> <mml:mi>n</mml:mi></mml:msub> <mml:mi>δ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi>t</mml:mi> <mml:mi>n</mml:mi> <mml:mi>i</mml:mi></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, are modeled as realizations of point processes with time-dependent firing rates Λ<sub><italic>i</italic></sub>(<italic>t</italic>). In other words, we have
<disp-formula id="pcbi.1004963.e002"><alternatives><graphic id="pcbi.1004963.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e002" xlink:type="simple"/><mml:math display="block" id="M2"><mml:mrow><mml:msub><mml:mo>Λ</mml:mo> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mi mathvariant="double-struck">E</mml:mi> <mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>S</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>|</mml:mo> <mml:msub><mml:mi>S</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi>t</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msup><mml:mi>t</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>≤</mml:mo> <mml:mi>t</mml:mi> <mml:mo>,</mml:mo> <mml:mn>1</mml:mn> <mml:mo>≤</mml:mo> <mml:mi>j</mml:mi> <mml:mo>≤</mml:mo> <mml:mi>N</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(1)</label></disp-formula>
where <inline-formula id="pcbi.1004963.e003"><alternatives><graphic id="pcbi.1004963.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e003" xlink:type="simple"/><mml:math display="inline" id="M3"><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi> <mml:mo>[</mml:mo> <mml:mo>·</mml:mo> <mml:mo>]</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> is the (conditional) expectation operator. In the Hawkes process framework, the vector Λ(<italic>t</italic>) of instantaneous firing rates (conditional on <italic>S</italic><sub><italic>i</italic></sub>(<italic>t</italic>′), for <italic>t</italic>′ ≤ <italic>t</italic>) is given by
<disp-formula id="pcbi.1004963.e004"><alternatives><graphic id="pcbi.1004963.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e004" xlink:type="simple"/><mml:math display="block" id="M4"><mml:mrow><mml:mo>Λ</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mi>μ</mml:mi> <mml:mo>+</mml:mo> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>∞</mml:mi></mml:mrow> <mml:mi>t</mml:mi></mml:msubsup> <mml:mi>G</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:msup><mml:mi>t</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>·</mml:mo> <mml:mi>S</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi>t</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>d</mml:mi> <mml:msup><mml:mi>t</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>≡</mml:mo> <mml:mi>μ</mml:mi> <mml:mo>+</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>G</mml:mi> <mml:mo>⋆</mml:mo> <mml:mi>S</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(2)</label></disp-formula>
The vector <italic>μ</italic> can be interpreted as the rate of spontaneous activity (due to constant external input) in the network. The neurons in the network would independently spike at rates, given by components of vector <italic>μ</italic>, if there were no synaptic connections between neurons in the network.</p>
<p>Recurrent synaptic interaction in the network is governed by the matrix of interaction kernels <italic>G</italic>(<italic>t</italic>), an <italic>N</italic> × <italic>N</italic> matrix of causal functions <italic>g</italic><sub><italic>ij</italic></sub>(<italic>t</italic>), describing the influence of a spike in neuron <italic>j</italic> imposed on the future rate of neuron <italic>i</italic>. Typically, this is a sparse matrix with most entries being zero, and only few of them being nonzero. In principle, all of the functions <italic>g</italic><sub><italic>ij</italic></sub>(<italic>t</italic>) can be different. However, for the sake of simplicity, we will assume that all source neurons in the excitatory subpopulation have interaction kernels equal to <italic>g</italic><sub><italic>E</italic></sub>(<italic>t</italic>) to contact their targets, and all inhibitory neurons have interaction kernels <italic>g</italic><sub><italic>I</italic></sub>(<italic>t</italic>). Thus, the total synaptic weight of excitatory neurons equals <italic>g</italic><sub><italic>E</italic></sub> ≡ ∫<italic>g</italic><sub><italic>E</italic></sub>(<italic>t</italic>) <italic>dt</italic> and is positive, i.e. <italic>g</italic><sub><italic>E</italic></sub> &gt; 0. Similarly, for inhibitory neurons, <italic>g</italic><sub><italic>I</italic></sub> ≡ ∫<italic>g</italic><sub><italic>I</italic></sub> (<italic>t</italic>) <italic>dt</italic> &lt; 0.</p>
<p>The number <italic>g</italic><sub><italic>E</italic></sub> represents the expected number of extra spikes in the postsynaptic (target) neuron induced by a spike of the presynaptic (source) neuron. Analogously, for inhibitory neurons, the number <italic>g</italic><sub><italic>I</italic></sub> represents the expected reduction in the total number of spikes produced by the postsynaptic neuron.</p>
<p>The exact connectivity between neurons in the network is chosen randomly, according to various rules, as will be explained in the sections to follow.</p>
<p>One important thing to note is that the Hawkes model only allows for pairwise interactions, and yet possesses correlations of all orders. Furthermore, the Hawkes process is a probabilistic spike generator and, as such, may exhibit a different behavior than an encoder with a deterministic threshold mechanism. It is, however, important to realize that real neurons that are embedded in a large network possess both stochastic and deterministic features. Another potential limitation of the Hawkes model is that it provides a good approximation when synapses are weak, but strong synapses may more thoroughly explore neuronal nonlinearities. Finally, the Hawkes process is formally correctly defined only for positive interaction kernels. Negative interactions may lead to a rate vector Λ(<italic>t</italic>) with negative entries, which is of course not a meaningful configuration. Thus, technically, one should use the rectified rate [Λ(<italic>t</italic>)]<sub>+</sub> as a basis for spike generation in simulations. In the following, we will assume that the probability of having negative entries in the rate vector is negligibly low and will ignore the rectifying non-linearity. The goodness of this approximation is illustrated in <xref ref-type="fig" rid="pcbi.1004963.g001">Fig 1</xref>.</p>
<fig id="pcbi.1004963.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004963.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Hawkes process theory reproduces rates, correlations and third cumulants in a simulated network with Erdős-Rényi type random connectivity.</title>
<p>Network parameters are <italic>N</italic> = 1000, <italic>N</italic><sub><italic>E</italic></sub> = 800, <italic>N</italic><sub><italic>I</italic></sub> = 200, <italic>p</italic> = 0.1, <italic>g</italic><sub><italic>E</italic></sub> = 0.015 and <italic>g</italic><sub><italic>I</italic></sub> = −0.075. Top left: Fluctuating firing rates of 50 randomly chosen neurons (gray traces) and their average (red line). The average rate only rarely goes below 0 (dashed line). Top right: Estimated temporal averages of firing rates scattered vs. rates predicted by Hawkes theory. The diagonal (green line) indicates a perfect match. Note that there is a slight discrepancy between theory and simulation for very low rates. Bottom left: Estimated integrated pairwise covariances (of all possible neuron pairs) scattered vs. integrated covariances predicted by Hawkes theory. Bottom right: Estimated integrated joint third cumulants (see the following sections for a definition) of a 100 randomly chosen neurons, scattered vs. integrated joint cumulants computed from Hawkes theory. The larger discrepancies are due to finite simulation time and a relatively small sample size.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004963.g001" xlink:type="simple"/>
</fig>
<p>At equilibrium, the expected firing rate vector of the Hawkes process, <inline-formula id="pcbi.1004963.e005"><alternatives><graphic id="pcbi.1004963.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e005" xlink:type="simple"/><mml:math display="inline" id="M5"><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi> <mml:mo>[</mml:mo> <mml:mo>Λ</mml:mo> <mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo> <mml:mo>]</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, no longer depends on time. We can compute the stationary rate vector, denoted Λ, as follows
<disp-formula id="pcbi.1004963.e006"><alternatives><graphic id="pcbi.1004963.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e006" xlink:type="simple"/><mml:math display="block" id="M6"><mml:mrow><mml:mo>Λ</mml:mo> <mml:mo>=</mml:mo> <mml:mi>μ</mml:mi> <mml:mo>+</mml:mo> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>∞</mml:mi></mml:mrow> <mml:mrow><mml:mo>+</mml:mo> <mml:mi>∞</mml:mi></mml:mrow></mml:msubsup> <mml:mo>Λ</mml:mo> <mml:mi>G</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:msup><mml:mi>t</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>d</mml:mi> <mml:msup><mml:mi>t</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>=</mml:mo> <mml:mi>μ</mml:mi> <mml:mo>+</mml:mo> <mml:mo>Λ</mml:mo> <mml:mfenced close=")" open="(" separators=""><mml:msubsup><mml:mo>∫</mml:mo> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>∞</mml:mi></mml:mrow> <mml:mrow><mml:mo>+</mml:mo> <mml:mi>∞</mml:mi></mml:mrow></mml:msubsup> <mml:mi>G</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>d</mml:mi> <mml:mi>t</mml:mi></mml:mfenced> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(3)</label></disp-formula>
from which we obtain the stationary rate of the network as
<disp-formula id="pcbi.1004963.e007"><alternatives><graphic id="pcbi.1004963.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e007" xlink:type="simple"/><mml:math display="block" id="M7"><mml:mrow><mml:mo>Λ</mml:mo> <mml:mo>=</mml:mo> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="double-struck">I</mml:mi> <mml:mo>-</mml:mo> <mml:mi>G</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mi>μ</mml:mi> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(4)</label></disp-formula>
where we have used <italic>G</italic> as a shortcut for the matrix of integrated interaction kernels, i.e. <italic>G</italic> ≡ ∫<italic>G</italic>(<italic>t</italic>) <italic>dt</italic> and <inline-formula id="pcbi.1004963.e008"><alternatives><graphic id="pcbi.1004963.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e008" xlink:type="simple"/><mml:math display="inline" id="M8"><mml:mi mathvariant="double-struck">I</mml:mi></mml:math></alternatives></inline-formula> denotes the <italic>N</italic> × <italic>N</italic> unit matrix. A summary of symbols, used in the text can be found in <xref ref-type="table" rid="pcbi.1004963.t001">Table 1</xref>.</p>
<table-wrap id="pcbi.1004963.t001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004963.t001</object-id>
<label>Table 1</label>
<caption>
<title>Symbols used in text (in order of appearance).</title>
</caption>
<alternatives>
<graphic id="pcbi.1004963.t001g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004963.t001" xlink:type="simple"/>
<table border="0" frame="box" rules="all">
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="center">Symbol</th>
<th align="center">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><italic>N</italic></td>
<td align="center">total number of neurons</td>
</tr>
<tr>
<td align="center"><italic>N</italic><sub><italic>E</italic></sub></td>
<td align="center">number of excitatory neurons</td>
</tr>
<tr>
<td align="center"><italic>N</italic><sub><italic>I</italic></sub></td>
<td align="center">number of inhibitory neurons</td>
</tr>
<tr>
<td align="center"><italic>S</italic>(<italic>t</italic>)</td>
<td align="center">spike train vector</td>
</tr>
<tr>
<td align="center">Λ(<italic>t</italic>)</td>
<td align="center">conditional firing rate vector</td>
</tr>
<tr>
<td align="center"><italic>G</italic>(<italic>t</italic>), <italic>g</italic><sub><italic>ij</italic></sub>(<italic>t</italic>)</td>
<td align="center">matrix of interaction kernels, its components</td>
</tr>
<tr>
<td align="center">(<italic>g</italic><sub><italic>E</italic></sub>) <italic>g</italic><sub><italic>E</italic></sub>(<italic>t</italic>)</td>
<td align="center">(integrated) excitatory neuron interaction kernel</td>
</tr>
<tr>
<td align="center">(<italic>g</italic><sub><italic>I</italic></sub>) <italic>g</italic><sub><italic>I</italic></sub>(<italic>t</italic>)</td>
<td align="center">(integrated) inhibitory neuron interaction kernel</td>
</tr>
<tr>
<td align="center"><italic>μ</italic>, <italic>μ</italic><sub><italic>i</italic></sub></td>
<td align="center">external input vector, external input to neuron <italic>i</italic></td>
</tr>
<tr>
<td align="center">Λ</td>
<td align="center">stationary firing rate vector, <inline-formula id="pcbi.1004963.e009"><alternatives><graphic id="pcbi.1004963.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e009" xlink:type="simple"/><mml:math display="inline" id="M9"><mml:mrow><mml:mo>Λ</mml:mo> <mml:mo>=</mml:mo> <mml:mi mathvariant="double-struck">E</mml:mi> <mml:mo>[</mml:mo> <mml:mo>Λ</mml:mo> <mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo> <mml:mo>]</mml:mo></mml:mrow></mml:math></alternatives></inline-formula></td>
</tr>
<tr>
<td align="center"><italic>G</italic></td>
<td align="center">integrated matrix of interaction kernels</td>
</tr>
<tr>
<td align="center"><italic>C</italic>(<italic>τ</italic>)</td>
<td align="center">covariance density matrix</td>
</tr>
<tr>
<td align="center"><italic>R</italic>(<italic>t</italic>)</td>
<td align="center">convolution power series of the matrix <italic>G</italic>(<italic>t</italic>)</td>
</tr>
<tr>
<td align="center"><italic>κ</italic><sup><italic>ijk</italic></sup>(<italic>t</italic><sub>1</sub>, <italic>t</italic><sub>2</sub>, <italic>t</italic><sub>3</sub>)</td>
<td align="center">third-order joint cumulant density of neurons <italic>i</italic>, <italic>j</italic> and <italic>k</italic></td>
</tr>
<tr>
<td align="center"><italic>N</italic><sub><italic>i</italic></sub>(<italic>T</italic>)</td>
<td align="center">spike count of neuron <italic>i</italic> in a bin of size <italic>T</italic></td>
</tr>
<tr>
<td align="center"><italic>κ</italic><sup><italic>ijk</italic></sup>(<italic>T</italic>)</td>
<td align="center">third cumulant of spike counts of neurons <italic>i</italic>, <italic>j</italic> and <italic>k</italic></td>
</tr>
<tr>
<td align="center">Ψ(<italic>t</italic>)</td>
<td align="center">
<inline-formula id="pcbi.1004963.e010">
<alternatives>
<graphic id="pcbi.1004963.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e010" xlink:type="simple"/>
<mml:math display="inline" id="M10">
<mml:mrow>
<mml:mo>Ψ</mml:mo>
<mml:mo>(</mml:mo>
<mml:mi>t</mml:mi>
<mml:mo>)</mml:mo>
<mml:mo>=</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo>(</mml:mo>
<mml:mi>t</mml:mi>
<mml:mo>)</mml:mo>
<mml:mo>-</mml:mo>
<mml:mi mathvariant="double-struck">I</mml:mi>
<mml:mi>δ</mml:mi>
<mml:mo>(</mml:mo>
<mml:mi>t</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:math>
</alternatives>
</inline-formula>
</td>
</tr>
<tr>
<td align="center"><italic>κ</italic><sup><italic>ijk</italic></sup></td>
<td align="center">integrated joint third cumulant of neurons <italic>i</italic>, <italic>j</italic> and <italic>k</italic></td>
</tr>
<tr>
<td align="center"><italic>B</italic></td>
<td align="center">power series of matrix <italic>G</italic></td>
</tr>
<tr>
<td align="center"><italic>C</italic></td>
<td align="center">integrated covariance density matrix</td>
</tr>
<tr>
<td align="center"><italic>N</italic><sub>pop</sub>(<italic>T</italic>)</td>
<td align="center">population spike count in a bin of size <italic>T</italic></td>
</tr>
<tr>
<td align="center">
<inline-formula id="pcbi.1004963.e011">
<alternatives>
<graphic id="pcbi.1004963.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e011" xlink:type="simple"/>
<mml:math display="inline" id="M11">
<mml:msub>
<mml:mover accent="true">
<mml:mi>κ</mml:mi>
<mml:mo>¯</mml:mo>
</mml:mover>
<mml:mn>3</mml:mn>
</mml:msub>
</mml:math>
</alternatives>
</inline-formula>
</td>
<td align="center">average joint third cumulant</td>
</tr>
<tr>
<td align="center"><italic>p</italic></td>
<td align="center">connection probability</td>
</tr>
<tr>
<td align="center"><italic>μ</italic><sup>(<italic>k</italic>)</sup></td>
<td align="center">average common input, shared by <italic>k</italic> neurons</td>
</tr>
<tr>
<td align="center">
<inline-formula id="pcbi.1004963.e012">
<alternatives>
<graphic id="pcbi.1004963.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e012" xlink:type="simple"/>
<mml:math display="inline" id="M12">
<mml:msub>
<mml:mover accent="true">
<mml:mi>κ</mml:mi>
<mml:mo>˜</mml:mo>
</mml:mover>
<mml:mn>3</mml:mn>
</mml:msub>
</mml:math>
</alternatives>
</inline-formula>
</td>
<td align="center">quadratic approximation of the average third cumulant <inline-formula id="pcbi.1004963.e013"><alternatives><graphic id="pcbi.1004963.e013g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e013" xlink:type="simple"/><mml:math display="inline" id="M13"><mml:msub><mml:mover accent="true"><mml:mi>κ</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mn>3</mml:mn></mml:msub></mml:math></alternatives></inline-formula></td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p>In what follows, we will also restrict ourselves to systems in which the spectral radius of the matrix <italic>G</italic> (the largest eigenvalue of <italic>G</italic>), which we denote by <italic>ρ</italic>(<italic>G</italic>), is less than 1. Indeed, this condition insures the existence of the matrix inverse in the rate <xref ref-type="disp-formula" rid="pcbi.1004963.e007">Eq 4</xref>. Furthermore, if <italic>ρ</italic>(<italic>G</italic>) &gt; 1, it may happen that no stable equilibrium of the system exists and the spiking activity exhibits runaway solutions.</p>
</sec>
<sec id="sec004">
<title>Pairwise correlations in the Hawkes process framework</title>
<p>An important result, originally presented in Hawkes’ original work [<xref ref-type="bibr" rid="pcbi.1004963.ref027">27</xref>, <xref ref-type="bibr" rid="pcbi.1004963.ref028">28</xref>], was that the lagged cross-covariance of spike trains of different neurons can be analytically computed directly from the matrix of interaction kernels <italic>G</italic>(<italic>t</italic>). More precisely, we can formally define the covariance density matrix, denoted by <italic>C</italic>(<italic>τ</italic>), as
<disp-formula id="pcbi.1004963.e014"><alternatives><graphic id="pcbi.1004963.e014g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e014" xlink:type="simple"/><mml:math display="block" id="M14"><mml:mrow><mml:mi>C</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mi mathvariant="double-struck">E</mml:mi> <mml:mrow><mml:mo>[</mml:mo> <mml:mi>S</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>S</mml:mi> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>T</mml:mi></mml:msup> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:mo>Λ</mml:mo> <mml:msup><mml:mo>Λ</mml:mo> <mml:mi>T</mml:mi></mml:msup> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(5)</label></disp-formula>
As was discussed before, intuitively, the entry (<italic>i</italic>, <italic>j</italic>) in <italic>C</italic>(<italic>τ</italic>) can be thought of as representing the probability that a spike of neuron <italic>j</italic> causes a spike of neuron <italic>i</italic> after time lag <italic>τ</italic>, minus the probability that this happens by chance (which, assuming stationarity, equals ΛΛ<sup><italic>T</italic></sup>). As noted in [<xref ref-type="bibr" rid="pcbi.1004963.ref027">27</xref>, <xref ref-type="bibr" rid="pcbi.1004963.ref028">28</xref>], it is possible to rewrite <italic>C</italic>(<italic>τ</italic>) as
<disp-formula id="pcbi.1004963.e015"><alternatives><graphic id="pcbi.1004963.e015g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e015" xlink:type="simple"/><mml:math display="block" id="M15"><mml:mrow><mml:mi>C</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mi>D</mml:mi> <mml:mi>δ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msub><mml:mi>C</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:mo>Λ</mml:mo> <mml:msup><mml:mo>Λ</mml:mo> <mml:mi>T</mml:mi></mml:msup> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(6)</label></disp-formula>
where <italic>D</italic> ≡ diag(Λ) is a diagonal matrix, with the entries of the rate vector Λ on the diagonal. Furthermore, <italic>C</italic><sub>0</sub>(<italic>τ</italic>) denotes the continuous part of the covariance density matrix, which is the solution to the matrix convolution equation
<disp-formula id="pcbi.1004963.e016"><alternatives><graphic id="pcbi.1004963.e016g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e016" xlink:type="simple"/><mml:math display="block" id="M16"><mml:mrow><mml:msub><mml:mi>C</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mi>G</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>D</mml:mi> <mml:mo>+</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>G</mml:mi> <mml:mo>⋆</mml:mo> <mml:msub><mml:mi>C</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>&gt;</mml:mo> <mml:mn>0</mml:mn> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(7)</label></disp-formula>
where the convolution of two matrix functions <italic>F</italic>(<italic>t</italic>) and <italic>G</italic>(<italic>t</italic>) equals a matrix function <italic>H</italic>(<italic>t</italic>) ≡ (<italic>F</italic> ⋆ <italic>G</italic>)(<italic>t</italic>) with
<disp-formula id="pcbi.1004963.e017"><alternatives><graphic id="pcbi.1004963.e017g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e017" xlink:type="simple"/><mml:math display="block" id="M17"><mml:mrow><mml:msub><mml:mi>H</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>∞</mml:mi></mml:mrow> <mml:mi>t</mml:mi></mml:msubsup> <mml:mi>F</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>·</mml:mo> <mml:mi>G</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>d</mml:mi> <mml:mi>s</mml:mi> <mml:mo>=</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mi>k</mml:mi></mml:munder> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>∞</mml:mi></mml:mrow> <mml:mi>t</mml:mi></mml:msubsup> <mml:msub><mml:mi>F</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msub><mml:mi>G</mml:mi> <mml:mrow><mml:mi>k</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>d</mml:mi> <mml:mi>s</mml:mi> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(8)</label></disp-formula>
where ⋅ denotes the usual product of two numerical matrices. An important result in [<xref ref-type="bibr" rid="pcbi.1004963.ref028">28</xref>] is that the Fourier transform of the covariance density matrix, i.e. <inline-formula id="pcbi.1004963.e018"><alternatives><graphic id="pcbi.1004963.e018g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e018" xlink:type="simple"/><mml:math display="inline" id="M18"><mml:mrow><mml:mover accent="true"><mml:mi>C</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≡</mml:mo> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>∞</mml:mi></mml:mrow> <mml:mrow><mml:mo>+</mml:mo> <mml:mi>∞</mml:mi></mml:mrow></mml:msubsup> <mml:mi>C</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>i</mml:mi> <mml:mi>ω</mml:mi> <mml:mi>τ</mml:mi></mml:mrow></mml:msup> <mml:mi>d</mml:mi> <mml:mi>τ</mml:mi></mml:mrow></mml:math></alternatives></inline-formula> can be expressed in terms of the Fourier transform <inline-formula id="pcbi.1004963.e019"><alternatives><graphic id="pcbi.1004963.e019g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e019" xlink:type="simple"/><mml:math display="inline" id="M19"><mml:mrow><mml:mover accent="true"><mml:mi>G</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> of the matrix of interaction kernels <italic>G</italic>(<italic>t</italic>). More precisely, we have
<disp-formula id="pcbi.1004963.e020"><alternatives><graphic id="pcbi.1004963.e020g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e020" xlink:type="simple"/><mml:math display="block" id="M20"><mml:mrow><mml:mover accent="true"><mml:mi>C</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="double-struck">I</mml:mi> <mml:mo>-</mml:mo> <mml:mover accent="true"><mml:mi>G</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mi>D</mml:mi> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="double-struck">I</mml:mi> <mml:mo>-</mml:mo> <mml:msup><mml:mover accent="true"><mml:mi>G</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>*</mml:mo></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(9)</label></disp-formula>
where * denotes the conjugate transpose of a matrix.</p>
<p>Recently, it has been shown [<xref ref-type="bibr" rid="pcbi.1004963.ref029">29</xref>, <xref ref-type="bibr" rid="pcbi.1004963.ref030">30</xref>] that, component-wise and in the time domain, the previous equation can be written as
<disp-formula id="pcbi.1004963.e021"><alternatives><graphic id="pcbi.1004963.e021g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e021" xlink:type="simple"/><mml:math display="block" id="M21"><mml:mrow><mml:msub><mml:mi>C</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>N</mml:mi></mml:munderover> <mml:msub><mml:mo>Λ</mml:mo> <mml:mi>k</mml:mi></mml:msub> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>∞</mml:mi></mml:mrow> <mml:mrow><mml:mo>+</mml:mo> <mml:mi>∞</mml:mi></mml:mrow></mml:msubsup> <mml:msub><mml:mi>R</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>u</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msub><mml:mi>R</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>u</mml:mi> <mml:mo>+</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="0.166667em"/><mml:mi>d</mml:mi> <mml:mi>u</mml:mi> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(10)</label></disp-formula>
where Λ<sub><italic>k</italic></sub> is the <italic>k</italic>-th component of the previously defined stationary rate vector, and the matrix <italic>R</italic>(<italic>t</italic>) is a function of <italic>G</italic>(<italic>t</italic>). Namely, we have that <italic>R</italic>(<italic>t</italic>) is a “convolution power series” of <italic>G</italic>(<italic>t</italic>) or, more precisely,
<disp-formula id="pcbi.1004963.e022"><alternatives><graphic id="pcbi.1004963.e022g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e022" xlink:type="simple"/><mml:math display="block" id="M22"><mml:mrow><mml:mi>R</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>n</mml:mi> <mml:mo>≥</mml:mo> <mml:mn>0</mml:mn></mml:mrow></mml:munder> <mml:msup><mml:mi>G</mml:mi> <mml:mrow><mml:mo>⋆</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(11)</label></disp-formula>
Here, the matrix <italic>G</italic><sup>⋆<italic>n</italic></sup>(<italic>t</italic>) denotes the <italic>n</italic>-th convolution power of the interaction kernel <italic>G</italic>(<italic>t</italic>), defined recursively by
<disp-formula id="pcbi.1004963.e023"><alternatives><graphic id="pcbi.1004963.e023g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e023" xlink:type="simple"/><mml:math display="block" id="M23"><mml:mrow><mml:msup><mml:mi>G</mml:mi> <mml:mrow><mml:mo>⋆</mml:mo> <mml:mn>0</mml:mn></mml:mrow></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mi mathvariant="double-struck">I</mml:mi> <mml:mi>δ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(12)</label></disp-formula> <disp-formula id="pcbi.1004963.e024"><alternatives><graphic id="pcbi.1004963.e024g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e024" xlink:type="simple"/><mml:math display="block" id="M24"><mml:mrow><mml:msup><mml:mi>G</mml:mi> <mml:mrow><mml:mo>⋆</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>∞</mml:mi></mml:mrow> <mml:mi>t</mml:mi></mml:msubsup> <mml:msup><mml:mi>G</mml:mi> <mml:mrow><mml:mo>⋆</mml:mo> <mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>·</mml:mo> <mml:mi>G</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>d</mml:mi> <mml:mi>s</mml:mi> <mml:mo>,</mml:mo> <mml:mspace width="1pt"/> <mml:mi>n</mml:mi> <mml:mo>≥</mml:mo> <mml:mn>1</mml:mn> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(13)</label></disp-formula>
where ⋅ again denotes a matrix product. We have the following heuristic interpretation of the matrix elements <italic>R</italic><sub><italic>ij</italic></sub>(<italic>t</italic>):
<disp-formula id="pcbi.1004963.e025"><alternatives><graphic id="pcbi.1004963.e025g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e025" xlink:type="simple"/><mml:math display="block" id="M25"><mml:mrow><mml:msub><mml:mi>R</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="0.166667em"/><mml:mi>d</mml:mi> <mml:mi>t</mml:mi> <mml:mo>≡</mml:mo> <mml:mi>P</mml:mi> <mml:mrow><mml:mo>{</mml:mo> <mml:mtext>spike of neuron </mml:mtext> <mml:mi>j</mml:mi> <mml:mtext> at </mml:mtext> <mml:mn>0</mml:mn> <mml:mtext> causes neuron </mml:mtext> <mml:mi>i</mml:mi> <mml:mtext> to spike at </mml:mtext> <mml:mi>t</mml:mi> <mml:mo>}</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(14)</label></disp-formula></p>
<p>This heuristic offer an interesting interpretation of <xref ref-type="disp-formula" rid="pcbi.1004963.e021">Eq 10</xref>. Indeed, we can see the product Λ<sub><italic>k</italic></sub> <italic>R</italic><sub><italic>ik</italic></sub>(<italic>u</italic>)<italic>R</italic><sub><italic>jk</italic></sub>(<italic>u</italic> + <italic>τ</italic>)<italic>du</italic> as representing the probability that neuron <italic>k</italic>, spiking at its stationary rate Λ<sub><italic>k</italic></sub>, causes neuron <italic>i</italic> to spike at <italic>u</italic> and neuron <italic>j</italic> at <italic>u</italic> + <italic>τ</italic>. The covariance density <italic>C</italic><sub><italic>ij</italic></sub>(<italic>τ</italic>) of neurons <italic>i</italic> and <italic>j</italic> at lag <italic>τ</italic> is then nothing more than this probability, summed over all possible spikes times of neuron <italic>i</italic> (hence the integral w.r.t. <italic>u</italic>) and over all possible “presynaptic” neurons <italic>k</italic>. Thus, <italic>C</italic><sub><italic>ij</italic></sub>(<italic>τ</italic>) can be seen as a sum of all possible ways in which a neuron <italic>k</italic> can induce activity in neurons <italic>i</italic> and <italic>j</italic>, with spikes that are <italic>τ</italic> apart.</p>
<p>Moreover, a simple graphical representation of <italic>C</italic><sub><italic>ij</italic></sub>(<italic>τ</italic>) is now available. As was first shown in [<xref ref-type="bibr" rid="pcbi.1004963.ref003">3</xref>], the product Λ<sub><italic>k</italic></sub> <italic>R</italic><sub><italic>ik</italic></sub>(<italic>u</italic>)<italic>R</italic><sub><italic>jk</italic></sub>(<italic>u</italic> + <italic>τ</italic>) <italic>du</italic> can be represented as a rooted tree with leaves <italic>i</italic> and <italic>j</italic> (see <xref ref-type="fig" rid="pcbi.1004963.g002">Fig 2</xref>). Then, it can be shown that the lagged cross-covariance of spiking activity between neurons <italic>i</italic> and <italic>j</italic> is a sum of integral terms, each corresponding to a rooted tree with leaves <italic>i</italic> and <italic>j</italic> in the underlying network (for more details, see [<xref ref-type="bibr" rid="pcbi.1004963.ref003">3</xref>] and [<xref ref-type="bibr" rid="pcbi.1004963.ref029">29</xref>]).</p>
<fig id="pcbi.1004963.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004963.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Pictorial representation of terms contributing to the pairwise covariance density.</title>
<p>Each entry of <italic>C</italic>(<italic>τ</italic>) is a weighted sum of integral terms, corresponding to rooted trees with 2 leaves, <italic>i</italic> and <italic>j</italic>.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004963.g002" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec005">
<title>Higher order cumulants in analysis of network dynamics</title>
<p>We now move on to the problem of analyzing cumulants of higher order in networks of spiking neurons and introduce the tools necessary to do so. In statistics, a quantifier of third order correlations, analogous to the well-known covariance operator, is the third order joint cumulant, often denoted as <italic>κ</italic><sub>3</sub>[<italic>X</italic>, <italic>Y</italic>, <italic>Z</italic>]. It measures above-chance level third order dependence in the same way that covariance does for second order. It is defined, for random variables <italic>X</italic>, <italic>Y</italic> and <italic>Z</italic>, as (see <xref ref-type="supplementary-material" rid="pcbi.1004963.s003">S3 Appendix</xref>. for a full derivation of the formula)
<disp-formula id="pcbi.1004963.e026"><alternatives><graphic id="pcbi.1004963.e026g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e026" xlink:type="simple"/><mml:math display="block" id="M26"><mml:mrow><mml:msub><mml:mi>κ</mml:mi> <mml:mn>3</mml:mn></mml:msub> <mml:mrow><mml:mo>[</mml:mo> <mml:mi>X</mml:mi> <mml:mo>,</mml:mo> <mml:mi>Y</mml:mi> <mml:mo>,</mml:mo> <mml:mi>Z</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mi mathvariant="double-struck">E</mml:mi> <mml:mrow><mml:mo>[</mml:mo> <mml:mi>X</mml:mi> <mml:mi>Y</mml:mi> <mml:mi>Z</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:mi mathvariant="double-struck">E</mml:mi> <mml:mrow><mml:mo>[</mml:mo> <mml:mi>X</mml:mi> <mml:mi>Y</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mi mathvariant="double-struck">E</mml:mi> <mml:mrow><mml:mo>[</mml:mo> <mml:mi>Z</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:mi mathvariant="double-struck">E</mml:mi> <mml:mrow><mml:mo>[</mml:mo> <mml:mi>X</mml:mi> <mml:mi>Z</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mi mathvariant="double-struck">E</mml:mi> <mml:mrow><mml:mo>[</mml:mo> <mml:mi>Y</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:mi mathvariant="double-struck">E</mml:mi> <mml:mrow><mml:mo>[</mml:mo> <mml:mi>Y</mml:mi> <mml:mi>Z</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mi mathvariant="double-struck">E</mml:mi> <mml:mrow><mml:mo>[</mml:mo> <mml:mi>X</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mn>2</mml:mn> <mml:mi mathvariant="double-struck">E</mml:mi> <mml:mrow><mml:mo>[</mml:mo> <mml:mi>X</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mi mathvariant="double-struck">E</mml:mi> <mml:mrow><mml:mo>[</mml:mo> <mml:mi>Y</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mi mathvariant="double-struck">E</mml:mi> <mml:mrow><mml:mo>[</mml:mo> <mml:mi>Z</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(15)</label></disp-formula>
Let <italic>i</italic>, <italic>j</italic> and <italic>k</italic> be three distinct neurons in a recurrent neuronal network. Let further <italic>A</italic> = {(<italic>i</italic>, <italic>t</italic><sub>1</sub>), (<italic>j</italic>, <italic>t</italic><sub>2</sub>), (<italic>k</italic>, <italic>t</italic><sub>3</sub>)} denote a spike pattern, where neuron <italic>i</italic> spikes at time <italic>t</italic><sub>1</sub>, neuron <italic>j</italic> at <italic>t</italic><sub>2</sub> and neuron <italic>k</italic> at <italic>t</italic><sub>3</sub>. If we now plug in the variables <italic>S</italic><sub><italic>i</italic></sub>(<italic>t</italic><sub>1</sub>), <italic>S</italic><sub><italic>j</italic></sub>(<italic>t</italic><sub>2</sub>) and <italic>S</italic><sub><italic>k</italic></sub>(<italic>t</italic><sub>3</sub>) into <xref ref-type="disp-formula" rid="pcbi.1004963.e026">Eq 15</xref> and denote
<disp-formula id="pcbi.1004963.e027"><alternatives><graphic id="pcbi.1004963.e027g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e027" xlink:type="simple"/><mml:math display="block" id="M27"><mml:mrow><mml:msup><mml:mi>κ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>t</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>t</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>t</mml:mi> <mml:mn>3</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≡</mml:mo> <mml:msub><mml:mi>κ</mml:mi> <mml:mn>3</mml:mn></mml:msub> <mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>S</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>t</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>S</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>t</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>S</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>t</mml:mi> <mml:mn>3</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(16)</label></disp-formula>
we see that the newly introduced function <italic>κ</italic><sup><italic>ijk</italic></sup>(<italic>t</italic><sub>1</sub>, <italic>t</italic><sub>2</sub>, <italic>t</italic><sub>3</sub>) measures the likelihood of the pattern <italic>A</italic> occurring not due to chance and not due to pairwise correlations.</p>
<p>Next, let <italic>N</italic><sub><italic>i</italic></sub>(<italic>T</italic>) represent the number of spikes of neuron <italic>i</italic> in a time bin of size <italic>T</italic>. Then, clearly,
<disp-formula id="pcbi.1004963.e028"><alternatives><graphic id="pcbi.1004963.e028g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e028" xlink:type="simple"/><mml:math display="block" id="M28"><mml:mrow><mml:msub><mml:mi>N</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>T</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mrow><mml:mn>0</mml:mn></mml:mrow> <mml:mi>T</mml:mi></mml:msubsup> <mml:msub><mml:mi>S</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="0.166667em"/><mml:mi>d</mml:mi> <mml:mi>t</mml:mi> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(17)</label></disp-formula>
Now, using Fubini’s theorem, we find that
<disp-formula id="pcbi.1004963.e029"><alternatives><graphic id="pcbi.1004963.e029g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e029" xlink:type="simple"/><mml:math display="block" id="M29"><mml:mrow><mml:msup><mml:mi>κ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>T</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≡</mml:mo> <mml:msub><mml:mi>κ</mml:mi> <mml:mn>3</mml:mn></mml:msub> <mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>N</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>T</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>N</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>T</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>N</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>T</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mrow><mml:mn>0</mml:mn></mml:mrow> <mml:mi>T</mml:mi></mml:msubsup> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mrow><mml:mn>0</mml:mn></mml:mrow> <mml:mi>T</mml:mi></mml:msubsup> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mrow><mml:mn>0</mml:mn></mml:mrow> <mml:mi>T</mml:mi></mml:msubsup> <mml:msup><mml:mi>κ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>t</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>t</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>t</mml:mi> <mml:mn>3</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="0.166667em"/><mml:mi>d</mml:mi> <mml:msub><mml:mi>t</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mi>d</mml:mi> <mml:msub><mml:mi>t</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mi>d</mml:mi> <mml:msub><mml:mi>t</mml:mi> <mml:mn>3</mml:mn></mml:msub> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(18)</label></disp-formula>
In other words, while the function <italic>κ</italic><sup><italic>ijk</italic></sup>(<italic>t</italic><sub>1</sub>, <italic>t</italic><sub>2</sub>, <italic>t</italic><sub>3</sub>) encodes the probability of occurrence of a single pattern <italic>A</italic>, the “integrated cumulant” <italic>κ</italic><sup><italic>ijk</italic></sup>(<italic>T</italic>) (that is, the joint third cumulant of spike counts) measures the probability of the non-chance occurrence of any pattern of neurons <italic>i</italic>, <italic>j</italic> and <italic>k</italic> in a time bin of duration <italic>T</italic>. We will call the function <italic>κ</italic><sup><italic>ijk</italic></sup>(<italic>t</italic><sub>1</sub>, <italic>t</italic><sub>2</sub>, <italic>t</italic><sub>3</sub>) the <italic>(3rd order) cumulant density</italic>, as one needs to integrate it in order to obtain the 3rd cumulant of spike counts, i.e. <italic>κ</italic><sup><italic>ijk</italic></sup>(<italic>T</italic>).</p>
<p>Assuming stationarity, the density <italic>κ</italic><sup><italic>ijk</italic></sup>(<italic>t</italic><sub>1</sub>, <italic>t</italic><sub>2</sub>, <italic>t</italic><sub>3</sub>) can be written (with slight abuse of notation) as a function of only the (two) time lags between spike events at <italic>t</italic><sub>1</sub>, <italic>t</italic><sub>2</sub> and <italic>t</italic><sub>3</sub> <disp-formula id="pcbi.1004963.e030"><alternatives><graphic id="pcbi.1004963.e030g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e030" xlink:type="simple"/><mml:math display="block" id="M30"><mml:mrow><mml:msup><mml:mi>κ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>t</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>t</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>t</mml:mi> <mml:mn>3</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msup><mml:mi>κ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>t</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>t</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>t</mml:mi> <mml:mn>3</mml:mn></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>t</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≡</mml:mo> <mml:msup><mml:mi>κ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>τ</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>τ</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(19)</label></disp-formula>
where we have defined <italic>τ</italic><sub>1</sub> = <italic>t</italic><sub>2</sub> − <italic>t</italic><sub>1</sub> and <italic>τ</italic><sub>2</sub> = <italic>t</italic><sub>3</sub> − <italic>t</italic><sub>1</sub>. In that case, we get (see <xref ref-type="supplementary-material" rid="pcbi.1004963.s001">S1 Appendix</xref>)
<disp-formula id="pcbi.1004963.e031"><alternatives><graphic id="pcbi.1004963.e031g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e031" xlink:type="simple"/><mml:math display="block" id="M31"><mml:mrow><mml:msup><mml:mi>κ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>T</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:msub><mml:mi>κ</mml:mi> <mml:mn>3</mml:mn></mml:msub> <mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>N</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>T</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>N</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>T</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>N</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>T</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow> <mml:mi>T</mml:mi></mml:mfrac> <mml:mo>=</mml:mo> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>T</mml:mi></mml:mrow> <mml:mi>T</mml:mi></mml:msubsup> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>T</mml:mi></mml:mrow> <mml:mi>T</mml:mi></mml:msubsup> <mml:msup><mml:mi>κ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>τ</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>τ</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>d</mml:mi> <mml:msub><mml:mi>τ</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mspace width="0.166667em"/><mml:mi>d</mml:mi> <mml:msub><mml:mi>τ</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(20)</label></disp-formula>
Thus, we obtain an alternative interpretation of <italic>κ</italic><sup><italic>ijk</italic></sup>(<italic>T</italic>): It represents the third joint cumulant of spike counts of neurons <italic>i</italic>, <italic>j</italic> and <italic>k</italic> in a bin of size <italic>T</italic>, normalized by the bin size. As such, it is a quantity that can be easily computed from data, using unbiased estimators of higher-order cumulants, called <italic>k</italic>-statistics [<xref ref-type="bibr" rid="pcbi.1004963.ref031">31</xref>].</p>
</sec>
<sec id="sec006">
<title>Joint third cumulants in the Hawkes process framework</title>
<p>A recent result in the theory of Hawkes processes [<xref ref-type="bibr" rid="pcbi.1004963.ref029">29</xref>] shows that all 3rd order cumulant densities <italic>κ</italic><sup><italic>ijk</italic></sup>(<italic>t</italic><sub>1</sub>, <italic>t</italic><sub>2</sub>, <italic>t</italic><sub>3</sub>) can be computed, just as in the pairwise case, as sums of integral terms, each corresponding to a relevant topological motif (a subtree of the graph on which the process evolves), present in the underlying network. However, in the case of triplet correlations, the relevant rooted trees are somewhat more complicated (see <xref ref-type="fig" rid="pcbi.1004963.g003">Fig 3</xref>). Algebraically, we have
<disp-formula id="pcbi.1004963.e032"><alternatives><graphic id="pcbi.1004963.e032g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e032" xlink:type="simple"/><mml:math display="block" id="M32"><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msup><mml:mi>κ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munderover><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msub><mml:mo>Λ</mml:mo><mml:mi>m</mml:mi></mml:msub><mml:msubsup><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>∫</mml:mo></mml:mstyle><mml:mrow><mml:mo>−</mml:mo><mml:mi>∞</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mi>u</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mspace width="2em"/><mml:mrow><mml:mo>+</mml:mo><mml:munderover><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msub><mml:mo>Λ</mml:mo><mml:mi>n</mml:mi></mml:msub><mml:msubsup><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>∫</mml:mo></mml:mstyle><mml:mrow><mml:mo>−</mml:mo><mml:mi>∞</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>∫</mml:mo></mml:mstyle><mml:mrow><mml:mo>−</mml:mo><mml:mi>∞</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mo>Ψ</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>−</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mi>v</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>u</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mspace width="2em"/><mml:mrow><mml:mo>+</mml:mo><mml:munderover><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msub><mml:mo>Λ</mml:mo><mml:mi>n</mml:mi></mml:msub><mml:msubsup><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>∫</mml:mo></mml:mstyle><mml:mrow><mml:mo>−</mml:mo><mml:mi>∞</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>∫</mml:mo></mml:mstyle><mml:mrow><mml:mo>−</mml:mo><mml:mi>∞</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mo>Ψ</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>−</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mi>v</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>u</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mspace width="2em"/><mml:mrow><mml:mo>+</mml:mo><mml:munderover><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msub><mml:mo>Λ</mml:mo><mml:mi>n</mml:mi></mml:msub><mml:msubsup><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>∫</mml:mo></mml:mstyle><mml:mrow><mml:mo>−</mml:mo><mml:mi>∞</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>∫</mml:mo></mml:mstyle><mml:mrow><mml:mo>−</mml:mo><mml:mi>∞</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mo>Ψ</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>−</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mi>v</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>u</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math>
</alternatives> <label>(21)</label></disp-formula>
where Λ<sub><italic>n</italic></sub> (the stationary rate of neuron <italic>n</italic>) and <italic>R</italic><sub><italic>ij</italic></sub>(<italic>t</italic>) (the rate change at time <italic>t</italic> in neuron <italic>i</italic> caused by a spike of neuron <italic>j</italic> at 0) have been defined previously, and
<disp-formula id="pcbi.1004963.e033"><alternatives><graphic id="pcbi.1004963.e033g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e033" xlink:type="simple"/><mml:math display="block" id="M33"><mml:mrow><mml:mo>Ψ</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mi>R</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:mi mathvariant="double-struck">I</mml:mi> <mml:mi>δ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>n</mml:mi> <mml:mo>≥</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:munder> <mml:msup><mml:mi>G</mml:mi> <mml:mrow><mml:mo>⋆</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(22)</label></disp-formula>
which, heuristically, simply means that
<disp-formula id="pcbi.1004963.e034"><alternatives><graphic id="pcbi.1004963.e034g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e034" xlink:type="simple"/><mml:math display="block" id="M34"><mml:mrow><mml:msub><mml:mo>Ψ</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="0.166667em"/><mml:mi>d</mml:mi> <mml:mi>t</mml:mi> <mml:mo>≡</mml:mo> <mml:mi>P</mml:mi> <mml:mrow><mml:mo>{</mml:mo> <mml:mtext>spike of neuron </mml:mtext> <mml:mi>j</mml:mi> <mml:mtext> at </mml:mtext> <mml:mn>0</mml:mn> <mml:mtext> causes neuron </mml:mtext> <mml:mi>i</mml:mi> <mml:mtext> </mml:mtext> <mml:mo>≠</mml:mo> <mml:mtext> </mml:mtext> <mml:mi>j</mml:mi> <mml:mtext> to spike at </mml:mtext> <mml:mi>t</mml:mi> <mml:mtext> </mml:mtext> <mml:mo>≠</mml:mo> <mml:mtext> </mml:mtext> <mml:mn>0</mml:mn> <mml:mo>}</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(23)</label></disp-formula></p>
<fig id="pcbi.1004963.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004963.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Pictorial representation of terms contributing to <italic>κ</italic><sup>ijk</sup>(t<sub>1</sub>, t<sub>2</sub>, t<sub>3</sub>).</title>
<p>Each <italic>κ</italic><sup><italic>ijk</italic></sup>(<italic>t</italic><sub>1</sub>, <italic>t</italic><sub>2</sub>, <italic>t</italic><sub>3</sub>) is a weighted sum of integral terms, corresponding to rooted trees with leaves <italic>i</italic>, <italic>j</italic> and <italic>k</italic> (see <xref ref-type="disp-formula" rid="pcbi.1004963.e032">Eq 21</xref>). The first term maps to the left tree, while the three remaining terms correspond to three possible ways in which three labeled leaves can be arranged into two groups to form the tree on the right. The first group would represent the daughter nodes of vertex <italic>m</italic>, and the second group would be a single child of the root node <italic>n</italic>.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004963.g003" xlink:type="simple"/>
</fig>
<p>Unfortunately, this formula is cumbersome, impractical and difficult to work with. However, a much more elegant expression is obtained if one considers the previously defined joint cumulants of spike counts, <italic>κ</italic><sup><italic>ijk</italic></sup>(<italic>T</italic>). Formally, considering infinitely large time bins
<disp-formula id="pcbi.1004963.e035"><alternatives><graphic id="pcbi.1004963.e035g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e035" xlink:type="simple"/><mml:math display="block" id="M35"><mml:mrow><mml:msup><mml:mi>κ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msup> <mml:mo>≡</mml:mo> <mml:munder><mml:mo form="prefix" movablelimits="true">lim</mml:mo> <mml:mrow><mml:mi>T</mml:mi> <mml:mo>→</mml:mo> <mml:mo>+</mml:mo> <mml:mi>∞</mml:mi></mml:mrow></mml:munder> <mml:msup><mml:mi>κ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>T</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>∞</mml:mi></mml:mrow> <mml:mrow><mml:mo>+</mml:mo> <mml:mi>∞</mml:mi></mml:mrow></mml:msubsup> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>∞</mml:mi></mml:mrow> <mml:mrow><mml:mo>+</mml:mo> <mml:mi>∞</mml:mi></mml:mrow></mml:msubsup> <mml:msup><mml:mi>κ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>τ</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>τ</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="0.166667em"/><mml:mi>d</mml:mi> <mml:msub><mml:mi>τ</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mi>d</mml:mi> <mml:msub><mml:mi>τ</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(24)</label></disp-formula>
and letting <inline-formula id="pcbi.1004963.e036"><alternatives><graphic id="pcbi.1004963.e036g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e036" xlink:type="simple"/><mml:math display="inline" id="M36"><mml:mrow><mml:mi>B</mml:mi> <mml:mo>≡</mml:mo> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="double-struck">I</mml:mi> <mml:mo>-</mml:mo> <mml:mi>G</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>, where <italic>G</italic> is the previously defined integrated matrix of interaction kernels, we have [<xref ref-type="bibr" rid="pcbi.1004963.ref029">29</xref>]
<disp-formula id="pcbi.1004963.e037"><alternatives><graphic id="pcbi.1004963.e037g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e037" xlink:type="simple"/><mml:math display="block" id="M37"><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msup><mml:mi>κ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:munder><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>∑</mml:mo></mml:mstyle> <mml:mi>m</mml:mi></mml:munder> <mml:msub><mml:mo>Λ</mml:mo> <mml:mi>m</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>m</mml:mi></mml:mrow></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>m</mml:mi></mml:mrow></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mrow><mml:mi>k</mml:mi> <mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr> <mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow/></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>+</mml:mo> <mml:munder><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>∑</mml:mo></mml:mstyle> <mml:mrow><mml:mi>m</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:munder> <mml:msub><mml:mo>Λ</mml:mo> <mml:mi>n</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>m</mml:mi></mml:mrow></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>m</mml:mi></mml:mrow></mml:msub> <mml:mo stretchy="false">(</mml:mo> <mml:msub><mml:mi>B</mml:mi> <mml:mrow><mml:mi>m</mml:mi> <mml:mi>n</mml:mi></mml:mrow></mml:msub> <mml:mo>−</mml:mo> <mml:msub><mml:mi>δ</mml:mi> <mml:mrow><mml:mi>m</mml:mi> <mml:mi>n</mml:mi></mml:mrow></mml:msub> <mml:mo stretchy="false">)</mml:mo> <mml:msub><mml:mi>B</mml:mi> <mml:mrow><mml:mi>k</mml:mi> <mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr> <mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow/></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>+</mml:mo> <mml:munder><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>∑</mml:mo></mml:mstyle> <mml:mrow><mml:mi>m</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:munder> <mml:msub><mml:mo>Λ</mml:mo> <mml:mi>n</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>m</mml:mi></mml:mrow></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mrow><mml:mi>k</mml:mi> <mml:mi>m</mml:mi></mml:mrow></mml:msub> <mml:mo stretchy="false">(</mml:mo> <mml:msub><mml:mi>B</mml:mi> <mml:mrow><mml:mi>m</mml:mi> <mml:mi>n</mml:mi></mml:mrow></mml:msub> <mml:mo>−</mml:mo> <mml:msub><mml:mi>δ</mml:mi> <mml:mrow><mml:mi>m</mml:mi> <mml:mi>n</mml:mi></mml:mrow></mml:msub> <mml:mo stretchy="false">)</mml:mo> <mml:msub><mml:mi>B</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr> <mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow/></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>+</mml:mo> <mml:munder><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>∑</mml:mo></mml:mstyle> <mml:mrow><mml:mi>m</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:munder> <mml:msub><mml:mo>Λ</mml:mo> <mml:mi>n</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>m</mml:mi></mml:mrow></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mrow><mml:mi>k</mml:mi> <mml:mi>m</mml:mi></mml:mrow></mml:msub> <mml:mo stretchy="false">(</mml:mo> <mml:msub><mml:mi>B</mml:mi> <mml:mrow><mml:mi>m</mml:mi> <mml:mi>n</mml:mi></mml:mrow></mml:msub> <mml:mo>−</mml:mo> <mml:msub><mml:mi>δ</mml:mi> <mml:mrow><mml:mi>m</mml:mi> <mml:mi>n</mml:mi></mml:mrow></mml:msub> <mml:mo stretchy="false">)</mml:mo> <mml:msub><mml:mi>B</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>n</mml:mi></mml:mrow></mml:msub> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(25)</label></disp-formula>
This can be considered as a generalization of the pairwise correlation result from [<xref ref-type="bibr" rid="pcbi.1004963.ref003">3</xref>]. Indeed, if we let <italic>ω</italic> = 0 in <xref ref-type="disp-formula" rid="pcbi.1004963.e020">Eq 9</xref> and set <inline-formula id="pcbi.1004963.e038"><alternatives><graphic id="pcbi.1004963.e038g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e038" xlink:type="simple"/><mml:math display="inline" id="M38"><mml:mrow><mml:mi>C</mml:mi> <mml:mo>≡</mml:mo> <mml:mover accent="true"><mml:mi>C</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>0</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mo>∫</mml:mo> <mml:mi>C</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="0.166667em"/><mml:mi>d</mml:mi> <mml:mi>τ</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>, we have
<disp-formula id="pcbi.1004963.e039"><alternatives><graphic id="pcbi.1004963.e039g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e039" xlink:type="simple"/><mml:math display="block" id="M39"><mml:mrow><mml:msub><mml:mi>C</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:mi>B</mml:mi> <mml:mi>D</mml:mi> <mml:msup><mml:mi>B</mml:mi> <mml:mo>*</mml:mo></mml:msup> <mml:mo>=</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>m</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>N</mml:mi></mml:munderover> <mml:msub><mml:mo>Λ</mml:mo> <mml:mi>m</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>m</mml:mi></mml:mrow></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>m</mml:mi></mml:mrow></mml:msub> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(26)</label></disp-formula>
The problem, of course, is that the collection of all integrated cumulants {<italic>κ</italic><sup><italic>ijk</italic></sup>}<sub><italic>i</italic>, <italic>j</italic>, <italic>k</italic></sub> represents a three-dimensional tensor, and as such cannot be represented in terms of a common matrix multiplication. For this reason, we must express <italic>κ</italic><sup><italic>ijk</italic></sup> as weighted sums and double sums of entries of the matrix <italic>B</italic> in <xref ref-type="disp-formula" rid="pcbi.1004963.e037">formula 25</xref>.</p>
</sec>
<sec id="sec007">
<title>Populations cumulants as sums of joint cumulants of spike counts</title>
<p>Finally, let us touch upon the link between integrated covariances <italic>C</italic><sub><italic>ij</italic></sub>, cumulants <italic>κ</italic><sup><italic>ijk</italic></sup>, and moments of the population count distribution <italic>N</italic><sub>pop</sub>(<italic>T</italic>) which we define as the sum of activity of all neurons in the network
<disp-formula id="pcbi.1004963.e040"><alternatives><graphic id="pcbi.1004963.e040g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e040" xlink:type="simple"/><mml:math display="block" id="M40"><mml:mrow><mml:msub><mml:mi>N</mml:mi> <mml:mrow><mml:mtext>pop</mml:mtext></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>T</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≡</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>m</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>N</mml:mi></mml:munderover> <mml:msub><mml:mi>N</mml:mi> <mml:mi>m</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>T</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(27)</label></disp-formula>
From the general properties of cumulants [<xref ref-type="bibr" rid="pcbi.1004963.ref032">32</xref>], one can prove that
<disp-formula id="pcbi.1004963.e041"><alternatives><graphic id="pcbi.1004963.e041g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e041" xlink:type="simple"/><mml:math display="block" id="M41"><mml:mrow><mml:munder><mml:mo form="prefix" movablelimits="true">lim</mml:mo> <mml:mrow><mml:mi>T</mml:mi> <mml:mo>→</mml:mo> <mml:mo>+</mml:mo> <mml:mi>∞</mml:mi></mml:mrow></mml:munder> <mml:mfrac><mml:mrow><mml:mtext>Var</mml:mtext> <mml:mo>[</mml:mo> <mml:msub><mml:mi>N</mml:mi> <mml:mrow><mml:mtext>pop</mml:mtext></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>T</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo></mml:mrow> <mml:mi>T</mml:mi></mml:mfrac> <mml:mo>=</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>,</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:munder> <mml:msub><mml:mi>C</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(28)</label></disp-formula>
In other words, the variance of the population activity is equal to the sum of all integrated covariances, normalized by bin size. Of course, this is only strictly true for infinitely large time bins, but we have found that <xref ref-type="disp-formula" rid="pcbi.1004963.e041">Eq 28</xref> is still a very good approximation whenever the size of bin <italic>T</italic> is much bigger than the temporal width of any entry in the matrix of interaction kernels <italic>G</italic>(<italic>t</italic>).</p>
<p>Likewise, one can prove that
<disp-formula id="pcbi.1004963.e042"><alternatives><graphic id="pcbi.1004963.e042g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e042" xlink:type="simple"/><mml:math display="block" id="M42"><mml:mrow><mml:munder><mml:mo form="prefix" movablelimits="true">lim</mml:mo> <mml:mrow><mml:mi>T</mml:mi> <mml:mo>→</mml:mo> <mml:mo>+</mml:mo> <mml:mi>∞</mml:mi></mml:mrow></mml:munder> <mml:mfrac><mml:mrow><mml:msub><mml:mi>κ</mml:mi> <mml:mn>3</mml:mn></mml:msub> <mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>N</mml:mi> <mml:mrow><mml:mtext>pop</mml:mtext></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>T</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow> <mml:mi>T</mml:mi></mml:mfrac> <mml:mo>=</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>,</mml:mo> <mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi></mml:mrow></mml:munder> <mml:msup><mml:mi>κ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msup> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(29)</label></disp-formula>
Thus, the sums of all integrated cumulants of order 3 is equal to the third cumulant of population activity, normalized by bin size [<xref ref-type="bibr" rid="pcbi.1004963.ref031">31</xref>]. To understand why it is important to know the third cumulant <italic>κ</italic><sub>3</sub>[<italic>N</italic><sub>pop</sub>(<italic>T</italic>)] consider that, for a normally distributed random variable <italic>X</italic>, all cumulants of order 3 and higher are zero
<disp-formula id="pcbi.1004963.e043"><alternatives><graphic id="pcbi.1004963.e043g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e043" xlink:type="simple"/><mml:math display="block" id="M43"><mml:mrow><mml:mi>X</mml:mi> <mml:mo>∼</mml:mo> <mml:mi mathvariant="script">N</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>0</mml:mn> <mml:mo>,</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>⇒</mml:mo> <mml:msub><mml:mi>κ</mml:mi> <mml:mi>n</mml:mi></mml:msub> <mml:mrow><mml:mo>[</mml:mo> <mml:mi>X</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>,</mml:mo> <mml:mtext> for all </mml:mtext> <mml:mi>n</mml:mi> <mml:mtext> </mml:mtext> <mml:mo>≥</mml:mo> <mml:mtext> </mml:mtext> <mml:mn>3</mml:mn> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(30)</label></disp-formula>
Therefore, in a sense, non-zero cumulants of order 3 and higher measure the departure from normality of the variable <italic>N</italic><sub>pop</sub>(<italic>T</italic>). Furthermore, in statistics, a measure of skewness of the distribution of a random variable <italic>X</italic> is defined as the (scaled) third cumulant <italic>κ</italic><sub>3</sub>[<italic>X</italic>]. As the Gaussian distribution is symmetric about 0 (and thus <italic>κ</italic><sub>3</sub>[<italic>X</italic>] = 0), any significant deviation of <italic>κ</italic><sub>3</sub>[<italic>N</italic><sub>pop</sub>(<italic>T</italic>)] indicates right (negative) or left (positive) skewness.</p>
</sec>
<sec id="sec008">
<title>Simulation and data analysis details</title>
<p>The simulation of linearly interacting point processes was conducted using the NEST simulator [<xref ref-type="bibr" rid="pcbi.1004963.ref033">33</xref>]. We simulated a network of 1000 neurons, of which 800 were excitatory and 200 inhibitory. The spikes of each neuron were generated according to a time-dependent rate function Λ(<italic>t</italic>), defined by <xref ref-type="disp-formula" rid="pcbi.1004963.e004">Eq 2</xref>. Negative values of Λ(<italic>t</italic>) were rectified to zero, resulting in no spike output. Neurons received external Poissonian drive with constant rate of 10 Hz. Incoming spikes induced an increment of amplitude 1.5 Hz and −7.5 Hz for excitatory and inhibitory spikes, respectively, which decayed with a time constant of 10 ms. In the Hawkes process framework, this corresponds to an exponential interaction kernel with total integral <italic>g</italic><sub><italic>E</italic></sub> = 0.015 and <italic>g</italic><sub><italic>I</italic></sub> = −0.075, respectively. The synaptic delay was set to 2 ms. The simulation time step was 0.1 ms. The total simulation time was 5000 s = 5 ⋅ 10<sup>6</sup> ms.</p>
<p>Spike data from simulations were sampled in time bins of duration <italic>T</italic> = 100 ms, producing 5 ⋅ 10<sup>4</sup> bins. We found that the theoretical results concerning infinite sized bins are still largely valid when the bin size <italic>T</italic> is at least one order of magnitude larger than the interaction kernel time constant. The rates, pairwise covariances and joint third cumulants were estimated from a data matrix with 1000 rows (representing individual neurons) and 50000 columns (representing time bins) using <italic>k</italic>-statistics [<xref ref-type="bibr" rid="pcbi.1004963.ref031">31</xref>], which are known to be unbiased estimators of cumulants of any order. Note that pairwise covariances are nothing more that joint cumulants of second order.</p>
</sec>
</sec>
<sec id="sec009" sec-type="results">
<title>Results</title>
<sec id="sec010">
<title>Weights of subtrees in the network determine the strength of triplet correlations</title>
<p>In this section we explain how recurrent connectivity affects joint third cumulants of triplets of neurons in a spiking neuronal network. As was mentioned before, the matrix of integrated interaction kernels <italic>G</italic> can be interpreted as an effective connectivity matrix, as each entry (<italic>i</italic>, <italic>j</italic>) represents the excess number of spikes in neuron <italic>i</italic>, caused by an individual spike in neuron <italic>j</italic>. With this in mind, let us now take a moment to develop a topological interpretation of <xref ref-type="disp-formula" rid="pcbi.1004963.e037">Eq 25</xref>. Firstly, as <italic>ρ</italic>(<italic>G</italic>)&lt;1 has been assumed, we have a power series expansion for the matrix <inline-formula id="pcbi.1004963.e044"><alternatives><graphic id="pcbi.1004963.e044g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e044" xlink:type="simple"/><mml:math display="inline" id="M44"><mml:mrow><mml:mi>B</mml:mi> <mml:mo>=</mml:mo> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="double-struck">I</mml:mi> <mml:mo>-</mml:mo> <mml:mi>G</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>, namely <italic>B</italic> = ∑<sub><italic>n</italic></sub> <italic>G</italic><sup><italic>n</italic></sup>. In order to develop intuition, we first consider what happens to <xref ref-type="disp-formula" rid="pcbi.1004963.e039">Eq 26</xref> when we plug the power series expansion of <italic>B</italic> into it (as was done in [<xref ref-type="bibr" rid="pcbi.1004963.ref003">3</xref>]). The formula for <italic>C</italic><sub><italic>ij</italic></sub> reads
<disp-formula id="pcbi.1004963.e045"><alternatives><graphic id="pcbi.1004963.e045g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e045" xlink:type="simple"/><mml:math display="block" id="M45"><mml:mrow><mml:msub><mml:mi>C</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>m</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>N</mml:mi></mml:munderover> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>r</mml:mi> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn></mml:mrow> <mml:mrow><mml:mo>+</mml:mo> <mml:mi>∞</mml:mi></mml:mrow></mml:munderover> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>s</mml:mi> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn></mml:mrow> <mml:mrow><mml:mo>+</mml:mo> <mml:mi>∞</mml:mi></mml:mrow></mml:munderover> <mml:msub><mml:mo>Λ</mml:mo> <mml:mi>m</mml:mi></mml:msub> <mml:msubsup><mml:mi>G</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>m</mml:mi></mml:mrow> <mml:mi>r</mml:mi></mml:msubsup> <mml:msubsup><mml:mi>G</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>m</mml:mi></mml:mrow> <mml:mi>s</mml:mi></mml:msubsup> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(31)</label></disp-formula>
We now interpret the matrix <italic>G</italic><sup><italic>r</italic></sup> in the sense of graph theory, i.e. as a matrix whose entry (<italic>i</italic>, <italic>j</italic>) corresponds to the sum of compound weights of all paths from node <italic>j</italic> to node <italic>i</italic> in exactly <italic>r</italic> steps. Indeed, a typical entry of matrix <italic>G</italic><sup><italic>r</italic></sup> equals
<disp-formula id="pcbi.1004963.e046"><alternatives><graphic id="pcbi.1004963.e046g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e046" xlink:type="simple"/><mml:math display="block" id="M46"><mml:mrow><mml:msubsup><mml:mi>G</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mi>r</mml:mi></mml:msubsup> <mml:mo>=</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:msub><mml:mi>k</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>k</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:mo>⋯</mml:mo> <mml:mo>,</mml:mo> <mml:msub><mml:mi>k</mml:mi> <mml:mrow><mml:mi>r</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:munder> <mml:msub><mml:mi>G</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:msub><mml:mi>k</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msub> <mml:msub><mml:mi>G</mml:mi> <mml:mrow><mml:msub><mml:mi>k</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:msub><mml:mi>k</mml:mi> <mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msub> <mml:mo>⋯</mml:mo> <mml:msub><mml:mi>G</mml:mi> <mml:mrow><mml:msub><mml:mi>k</mml:mi> <mml:mrow><mml:mi>r</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(32)</label></disp-formula>
We observe that each of the summands in the above equation is the average number of excess spikes, caused by an individual length <italic>r</italic> chain of spiking events, originating in neuron <italic>j</italic>. The entry <inline-formula id="pcbi.1004963.e047"><alternatives><graphic id="pcbi.1004963.e047g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e047" xlink:type="simple"/><mml:math display="inline" id="M47"><mml:msubsup><mml:mi>G</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mi>r</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>
is then the sum over all such chains, i.e. over all possible intermediary neurons <italic>k</italic><sub>1</sub>, <italic>k</italic><sub>2</sub>, ⋯<italic>k</italic><sub><italic>r</italic>−1</sub>. Thus, a procedure for computing <italic>C</italic><sub><italic>ij</italic></sub> would go as follows:</p>
<list list-type="order">
<list-item>
<p>Pick a “root neuron” <italic>m</italic></p>
</list-item>
<list-item>
<p>Create a “spiking chain” from neuron <italic>m</italic> to neuron <italic>i</italic> that is <italic>r</italic> synaptic steps long</p>
</list-item>
<list-item>
<p>Create a “spiking chain” from neuron <italic>m</italic> to neuron <italic>j</italic> that is <italic>s</italic> neurons long</p>
</list-item>
<list-item>
<p>Compute the weight of the subtree defined in this way by multiplying together the weights of the branches (given by <inline-formula id="pcbi.1004963.e048"><alternatives><graphic id="pcbi.1004963.e048g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e048" xlink:type="simple"/><mml:math display="inline" id="M48"><mml:msubsup><mml:mi>G</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>m</mml:mi></mml:mrow> <mml:mi>r</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1004963.e049"><alternatives><graphic id="pcbi.1004963.e049g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e049" xlink:type="simple"/><mml:math display="inline" id="M49"><mml:msubsup><mml:mi>G</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>m</mml:mi></mml:mrow> <mml:mi>s</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>)</p>
</list-item>
<list-item>
<p>Multiply everything by the “weight of the root node”, which we can formally define to be Λ<sub><italic>m</italic></sub></p>
</list-item>
</list>
<p>Note that <italic>r</italic> = 0 (<italic>s</italic> = 0) is a distinct possibility (as the first term in the power series expansion of <italic>B</italic> is <italic>G</italic><sup>0</sup> ≡ <italic>I</italic>). In that case, we identify neurons <italic>m</italic> and <italic>i</italic> (<italic>m</italic> and <italic>j</italic>) and our “two-pronged tree” becomes a single branch with neuron <italic>i</italic> (<italic>j</italic>) on top and neuron <italic>j</italic> (<italic>i</italic>) on the bottom.</p>
<p>Our previous discussion shows that the integrated covariance density <italic>C</italic><sub><italic>ij</italic></sub> can be equivalently expressed as
<disp-formula id="pcbi.1004963.e050"><alternatives><graphic id="pcbi.1004963.e050g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e050" xlink:type="simple"/><mml:math display="block" id="M50"><mml:mrow><mml:msub><mml:mi>C</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>T</mml:mi> <mml:mo>∈</mml:mo> <mml:msubsup><mml:mi mathvariant="script">T</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mi>m</mml:mi></mml:msubsup></mml:mrow></mml:munder> <mml:mi>w</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>T</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(33)</label></disp-formula>
where the sum goes over the set <inline-formula id="pcbi.1004963.e051"><alternatives><graphic id="pcbi.1004963.e051g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e051" xlink:type="simple"/><mml:math display="inline" id="M51"><mml:msubsup><mml:mi mathvariant="script">T</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mi>m</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> of all rooted trees <italic>T</italic> with root <italic>m</italic>, containing nodes <italic>i</italic> and <italic>j</italic>. Here, <italic>w</italic>(<italic>T</italic>) denotes the weight of tree <italic>T</italic>, defined as the product of weights of all edges, contained in <italic>T</italic>, times the weight of the root <italic>m</italic>, defined as being equal to Λ<sub><italic>m</italic></sub>.</p>
<p>Now, since, in the stationary case (see <xref ref-type="supplementary-material" rid="pcbi.1004963.s001">S1 Appendix</xref>)
<disp-formula id="pcbi.1004963.e052"><alternatives><graphic id="pcbi.1004963.e052g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e052" xlink:type="simple"/><mml:math display="block" id="M52"><mml:mrow><mml:msub><mml:mi>C</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:munder><mml:mo form="prefix" movablelimits="true">lim</mml:mo> <mml:mrow><mml:mi>T</mml:mi> <mml:mo>→</mml:mo> <mml:mo>+</mml:mo> <mml:mi>∞</mml:mi></mml:mrow></mml:munder> <mml:mfrac><mml:mrow><mml:mtext>cov</mml:mtext> <mml:mo>[</mml:mo> <mml:msub><mml:mi>N</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>T</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>N</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>T</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo></mml:mrow> <mml:mi>T</mml:mi></mml:mfrac> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(34)</label></disp-formula>
we have that, for infinitely large time bins, the probability (normalized by bin size) of the non-chance occurrence of ANY pattern of neurons <italic>i</italic> and <italic>j</italic> in a bin of size <italic>T</italic> can simply be computed as the sum of weights of ALL possible rooted trees with leaves <italic>i</italic> and <italic>j</italic>. Thus, in a nutshell, the only way pairwise interaction can arise between neurons <italic>i</italic> and <italic>j</italic> is through shared input by a neuron <italic>k</italic>, that can be arbitrarily far upstream from both <italic>i</italic> and <italic>j</italic>. This is the main result of [<xref ref-type="bibr" rid="pcbi.1004963.ref003">3</xref>].</p>
<p>With our intuition primed by consideration of the simpler, pairwise correlation case, we are ready to tackle the computation of <italic>κ</italic><sup><italic>ijk</italic></sup>. Once again, plugging the power series expansion of matrix <italic>B</italic> into <xref ref-type="disp-formula" rid="pcbi.1004963.e037">Eq 25</xref> yields
<disp-formula id="pcbi.1004963.e053"><alternatives><graphic id="pcbi.1004963.e053g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e053" xlink:type="simple"/><mml:math display="block" id="M53"><mml:mrow><mml:msup><mml:mi>κ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msup> <mml:mo>=</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>T</mml:mi> <mml:mo>∈</mml:mo> <mml:msubsup><mml:mi mathvariant="script">T</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow> <mml:mi>m</mml:mi></mml:msubsup></mml:mrow></mml:munder> <mml:mi>w</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>T</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(35)</label></disp-formula>
where <inline-formula id="pcbi.1004963.e054"><alternatives><graphic id="pcbi.1004963.e054g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e054" xlink:type="simple"/><mml:math display="inline" id="M54"><mml:msubsup><mml:mi mathvariant="script">T</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow> <mml:mi>m</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> is the set of all rooted trees with root <italic>m</italic> containing nodes <italic>i</italic>, <italic>j</italic>, <italic>k</italic>, and <italic>w</italic>(⋅) is the already defined weight function. As we have that (see <xref ref-type="supplementary-material" rid="pcbi.1004963.s001">S1 Appendix</xref>)
<disp-formula id="pcbi.1004963.e055"><alternatives><graphic id="pcbi.1004963.e055g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e055" xlink:type="simple"/><mml:math display="block" id="M55"><mml:mrow><mml:msup><mml:mi>κ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msup> <mml:mo>=</mml:mo> <mml:munder><mml:mo form="prefix" movablelimits="true">lim</mml:mo> <mml:mrow><mml:mi>T</mml:mi> <mml:mo>→</mml:mo> <mml:mo>+</mml:mo> <mml:mi>∞</mml:mi></mml:mrow></mml:munder> <mml:mfrac><mml:mrow><mml:msub><mml:mi>κ</mml:mi> <mml:mn>3</mml:mn></mml:msub> <mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>N</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>T</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>N</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>T</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>N</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>T</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow> <mml:mi>T</mml:mi></mml:mfrac> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(36)</label></disp-formula>
the interpretation of the “sum over trees” formula is analogous. In other words, for infinitely large time bins, the probability (normalized by bin size) of the non-chance occurrence of ANY pattern of neurons <italic>i</italic>, <italic>j</italic> and <italic>k</italic> in a bin of size <italic>T</italic> can simply be computed as the sum of weights of ALL possible rooted trees, containing nodes <italic>i</italic>, <italic>j</italic> and <italic>k</italic>. The only difference from the pairwise correlation case is that the topological motifs contributing to triplet correlations are different and more numerous.</p>
<p>What are the subtrees, contributing to <italic>κ</italic><sup><italic>ijk</italic></sup>? We can get our first hint by comparing the <xref ref-type="disp-formula" rid="pcbi.1004963.e037">formula 25</xref> and the trees in <xref ref-type="fig" rid="pcbi.1004963.g003">Fig 3</xref>. Indeed, the first term in <xref ref-type="disp-formula" rid="pcbi.1004963.e037">Eq 25</xref> corresponds to the left, “three-pronged” tree in <xref ref-type="fig" rid="pcbi.1004963.g003">Fig 3</xref>—in fact, it is the combined weight of all such structures found in the graph with adjacency matrix <italic>G</italic>, summed over all possible identities of the root node <italic>m</italic> and over all possible lengths of the tree branches terminating at <italic>i</italic>, <italic>j</italic> and <italic>k</italic>. However, as any of the three branches can also be of length 0, the left tree in <xref ref-type="fig" rid="pcbi.1004963.g003">Fig 3</xref> actually represents 4 different contributions to <italic>κ</italic><sup><italic>ijk</italic></sup>, one corresponding to the tree depicted, in which case all of the branches are of length at least 1, and three other “two-pronged” trees obtained by collapsing one of the three branches and identifying the node <italic>m</italic> with node <italic>i</italic>, <italic>j</italic> or <italic>k</italic> (see first row of <xref ref-type="fig" rid="pcbi.1004963.g004">Fig 4</xref>). Algebraically, this can also be seen by replacing one of the <italic>B</italic> matrices in the first row of <xref ref-type="disp-formula" rid="pcbi.1004963.e037">formula 25</xref> by the identity matrix <inline-formula id="pcbi.1004963.e056"><alternatives><graphic id="pcbi.1004963.e056g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e056" xlink:type="simple"/><mml:math display="inline" id="M56"><mml:mi mathvariant="double-struck">I</mml:mi></mml:math></alternatives></inline-formula>. Indeed, placing <inline-formula id="pcbi.1004963.e057"><alternatives><graphic id="pcbi.1004963.e057g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e057" xlink:type="simple"/><mml:math display="inline" id="M57"><mml:mi mathvariant="double-struck">I</mml:mi></mml:math></alternatives></inline-formula> instead of <italic>B</italic> in any of the tree slots yields three possible contractions.</p>
<fig id="pcbi.1004963.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004963.g004</object-id>
<label>Fig 4</label>
<caption>
<title>The pictorial representation of all terms, contributing to <italic>κ</italic><sup>ijk</sup>.</title>
<p>The tree shapes depicted in this figure were obtained from those in <xref ref-type="fig" rid="pcbi.1004963.g003">Fig 3</xref> by performing all possible contractions of branches (see text).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004963.g004" xlink:type="simple"/>
</fig>
<p>In the right tree in <xref ref-type="fig" rid="pcbi.1004963.g003">Fig 3</xref>, each of the last three terms in <xref ref-type="disp-formula" rid="pcbi.1004963.e037">Eq 25</xref> corresponds to one copy of it, the only difference among them being the label of the rightmost node. Indeed, the second term represents a tree in which the rightmost node is labeled <italic>k</italic>, for the third term the rightmost node is <italic>i</italic>, and for the last one it is <italic>j</italic>. Each of these terms contains three <italic>B</italic> matrices, and thus, each of these three terms will yield three additional trees whose weight will contribute to the overall sum, defining <italic>κ</italic><sup><italic>ijk</italic></sup> (see the second row of <xref ref-type="fig" rid="pcbi.1004963.g004">Fig 4</xref>). Like before, all of these are obtained by replacing one of the <italic>B</italic> matrices with the identity matrix <inline-formula id="pcbi.1004963.e058"><alternatives><graphic id="pcbi.1004963.e058g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e058" xlink:type="simple"/><mml:math display="inline" id="M58"><mml:mi mathvariant="double-struck">I</mml:mi></mml:math></alternatives></inline-formula> and performing the corresponding summation.</p>
<p>Notice that the last three terms in <xref ref-type="disp-formula" rid="pcbi.1004963.e037">Eq 25</xref> also depend on entries of the matrix <inline-formula id="pcbi.1004963.e059"><alternatives><graphic id="pcbi.1004963.e059g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e059" xlink:type="simple"/><mml:math display="inline" id="M59"><mml:mrow><mml:mi>B</mml:mi> <mml:mo>-</mml:mo> <mml:mi mathvariant="double-struck">I</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>. This signifies the fact that the link between nodes <italic>n</italic> and <italic>m</italic> in <xref ref-type="fig" rid="pcbi.1004963.g003">Fig 3</xref> can only “telescope out”, i.e. it cannot be contracted to 0 (indeed, it corresponds to the power series ∑<sub><italic>n</italic> ≥ 1</sub> <italic>G</italic><sup><italic>n</italic></sup> in which the term of order 0 is not present). For reasons as to why this branch does not allow contractions, see [<xref ref-type="bibr" rid="pcbi.1004963.ref029">29</xref>].</p>
<p>To summarize, the six different tree shapes depicted in <xref ref-type="fig" rid="pcbi.1004963.g004">Fig 4</xref> all contribute terms that, when summed up, yield <italic>κ</italic><sup><italic>ijk</italic></sup>. Likewise, as was mentioned previously, each branch, incident to each of the trees pictured, can have arbitrarily many intermediate nodes in between the two vertices shown.</p>
</sec>
<sec id="sec011">
<title>Average third cumulants in large random networks depend on the presence of a particular subtree</title>
<p>We are interested in computing the average third cumulant in the network, defined as
<disp-formula id="pcbi.1004963.e060"><alternatives><graphic id="pcbi.1004963.e060g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e060" xlink:type="simple"/><mml:math display="block" id="M60"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn> <mml:msup><mml:mi>N</mml:mi> <mml:mn>3</mml:mn></mml:msup></mml:mfrac> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>,</mml:mo> <mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi></mml:mrow></mml:munder> <mml:msup><mml:mi>κ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msup> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(37)</label></disp-formula>
where <italic>κ</italic><sup><italic>ijk</italic></sup> represent the integrated joint third cumulants of neurons <italic>i</italic>, <italic>j</italic> and <italic>k</italic>, considered previously. From <xref ref-type="disp-formula" rid="pcbi.1004963.e042">Eq 29</xref>, we have that the previous sum equals
<disp-formula id="pcbi.1004963.e061"><alternatives><graphic id="pcbi.1004963.e061g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e061" xlink:type="simple"/><mml:math display="block" id="M61"><mml:mrow><mml:munder><mml:mo form="prefix" movablelimits="true">lim</mml:mo> <mml:mrow><mml:mi>T</mml:mi> <mml:mo>→</mml:mo> <mml:mo>+</mml:mo> <mml:mi>∞</mml:mi></mml:mrow></mml:munder> <mml:mfrac><mml:mrow><mml:msub><mml:mi>κ</mml:mi> <mml:mn>3</mml:mn></mml:msub> <mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>N</mml:mi> <mml:mrow><mml:mtext>pop</mml:mtext></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>T</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow> <mml:mrow><mml:mi>T</mml:mi> <mml:msup><mml:mi>N</mml:mi> <mml:mn>3</mml:mn></mml:msup></mml:mrow></mml:mfrac> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(38)</label></disp-formula>
the third cumulant of population activity for an infinitely large time bin <italic>T</italic>, normalized by network size and bin width.</p>
<p>Note that the sum in <xref ref-type="disp-formula" rid="pcbi.1004963.e060">Eq 37</xref> goes over ALL indices <italic>i</italic>, <italic>j</italic> and <italic>k</italic>. Thus, we have three distinct cases:</p>
<list list-type="order">
<list-item>
<p>The three indices are all distinct (<italic>i</italic> ≠ <italic>j</italic>, <italic>j</italic> ≠ <italic>k</italic>, <italic>k</italic> ≠ <italic>i</italic>);</p>
</list-item>
<list-item>
<p>the three indices are all equal (<italic>i</italic> = <italic>j</italic> = <italic>k</italic>);</p>
</list-item>
<list-item>
<p>two of three indices are equal, with the third being distinct (<italic>i</italic> = <italic>j</italic> and <italic>j</italic> ≠ <italic>k</italic>, or a permutation thereof).</p>
</list-item>
</list>
<p>The number of summands in the first case is equal to <italic>N</italic>(<italic>N</italic> − 1)(<italic>N</italic> − 2), in the second case it is simply <italic>N</italic>, and in the third one it equals 3<italic>N</italic>(<italic>N</italic> − 1). Thus, we have
<disp-formula id="pcbi.1004963.e062"><alternatives><graphic id="pcbi.1004963.e062g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e062" xlink:type="simple"/><mml:math display="block" id="M62"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>κ</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mn>3</mml:mn></mml:msub> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:msup><mml:mi>N</mml:mi> <mml:mn>3</mml:mn></mml:msup></mml:mfrac> <mml:mfenced close="]" open="[" separators=""><mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>,</mml:mo> <mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi></mml:mrow></mml:munder> <mml:msup><mml:mi>κ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msup> <mml:mo>+</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>,</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:munder> <mml:msup><mml:mi>κ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msup> <mml:mo>+</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mi>i</mml:mi></mml:munder> <mml:msup><mml:mi>κ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>i</mml:mi> <mml:mi>i</mml:mi></mml:mrow></mml:msup></mml:mfenced> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(39)</label></disp-formula></p>
<p>In the limit of large networks, the first term becomes dominant, as
<disp-formula id="pcbi.1004963.e063"><alternatives><graphic id="pcbi.1004963.e063g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e063" xlink:type="simple"/><mml:math display="block" id="M63"><mml:mrow><mml:munder><mml:mo form="prefix" movablelimits="true">lim</mml:mo> <mml:mrow><mml:mi>N</mml:mi> <mml:mo>→</mml:mo> <mml:mo>+</mml:mo> <mml:mi>∞</mml:mi></mml:mrow></mml:munder> <mml:mfrac><mml:mrow><mml:mn>3</mml:mn> <mml:mi>N</mml:mi> <mml:mo>(</mml:mo> <mml:mi>N</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:msup><mml:mi>N</mml:mi> <mml:mn>3</mml:mn></mml:msup></mml:mfrac> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>,</mml:mo> <mml:munder><mml:mo form="prefix" movablelimits="true">lim</mml:mo> <mml:mrow><mml:mi>N</mml:mi> <mml:mo>→</mml:mo> <mml:mo>+</mml:mo> <mml:mi>∞</mml:mi></mml:mrow></mml:munder> <mml:mfrac><mml:mi>N</mml:mi> <mml:msup><mml:mi>N</mml:mi> <mml:mn>3</mml:mn></mml:msup></mml:mfrac> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>,</mml:mo> <mml:mspace width="1pt"/> <mml:mtext>but</mml:mtext> <mml:munder><mml:mo form="prefix" movablelimits="true">lim</mml:mo> <mml:mrow><mml:mi>N</mml:mi> <mml:mo>→</mml:mo> <mml:mo>+</mml:mo> <mml:mi>∞</mml:mi></mml:mrow></mml:munder> <mml:mfrac><mml:mrow><mml:mi>N</mml:mi> <mml:mo>(</mml:mo> <mml:mi>N</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo> <mml:mo>(</mml:mo> <mml:mi>N</mml:mi> <mml:mo>-</mml:mo> <mml:mn>2</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:msup><mml:mi>N</mml:mi> <mml:mn>3</mml:mn></mml:msup></mml:mfrac> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(40)</label></disp-formula>
Therefore, in all calculations that follow, we will assume that <italic>i</italic>, <italic>j</italic> and <italic>k</italic> are all different
<disp-formula id="pcbi.1004963.e064"><alternatives><graphic id="pcbi.1004963.e064g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e064" xlink:type="simple"/><mml:math display="block" id="M64"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>κ</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mn>3</mml:mn></mml:msub> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:msup><mml:mi>N</mml:mi> <mml:mn>3</mml:mn></mml:msup></mml:mfrac> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>≠</mml:mo> <mml:mi>j</mml:mi> <mml:mo>≠</mml:mo> <mml:mi>k</mml:mi></mml:mrow></mml:munder> <mml:msup><mml:mi>κ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msup> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(41)</label></disp-formula>
Furthermore, we assume the following about the underlying network topology:</p>
<list list-type="order">
<list-item>
<p>(Random network condition) Every node <italic>j</italic> has probability <italic>p</italic> of forming a connection with any of the other <italic>N</italic> − 1 nodes.</p>
</list-item>
<list-item>
<p>(Generalized Dale’s law) To each node <italic>j</italic> we assign a <italic>type</italic> <italic>l</italic> ∈ <italic>L</italic> such that, for a fixed <italic>j</italic> we have ∀<italic>i</italic>, <italic>g</italic><sub><italic>ij</italic></sub> = <italic>g</italic><sub><italic>l</italic></sub>.</p>
</list-item>
</list>
<p>In other words, the probability of a directed connection between any pair of nodes is equal to <italic>p</italic>, and each node is of a <italic>single type</italic> <italic>l</italic> and as such, only makes outgoing connections of type <italic>l</italic>. Here, <italic>L</italic> denotes the set of <italic>type labels</italic>.</p>
<p>The derivations that follow can still be done under these general assumptions. Also, note that, even though the first assumption allows for random topologies, the results obtained in this section hold true for regular networks as well, as very large random networks are approximately regular. However, in the interest of concreteness, we will assume that <italic>L</italic> = {<italic>E</italic>, <italic>I</italic>}. In short, each node <italic>j</italic> can either be of type <italic>E</italic> (excitatory) or type <italic>I</italic> (inhibitory). Thus, for a given “excitatory” node <italic>j</italic>, <italic>g</italic><sub><italic>ij</italic></sub> is either 0 (with probability 1 − <italic>p</italic>) or <italic>g</italic><sub><italic>E</italic></sub> (with probability <italic>p</italic>), for every neuron <italic>i</italic>. Likewise if the neuron is inhibitory (in that case, <italic>g</italic><sub><italic>ij</italic></sub> equals <italic>g</italic><sub><italic>I</italic></sub>).</p>
<p>We now compute the average input to a neuron, embedded in the network. First, we note that, mathematically, the total input to node <italic>i</italic> can be computed as ∑<sub><italic>j</italic></sub> <italic>G</italic><sub><italic>ij</italic></sub>. Given our previous considerations, we have that the total input equals
<disp-formula id="pcbi.1004963.e065"><alternatives><graphic id="pcbi.1004963.e065g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e065" xlink:type="simple"/><mml:math display="block" id="M65"><mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>N</mml:mi> <mml:mi>E</mml:mi></mml:msub> <mml:msub><mml:mi>g</mml:mi> <mml:mi>E</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>N</mml:mi> <mml:mi>I</mml:mi></mml:msub> <mml:msub><mml:mi>g</mml:mi> <mml:mi>I</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mi>N</mml:mi> <mml:mi>p</mml:mi> <mml:mfenced close=")" open="(" separators=""><mml:mfrac><mml:msub><mml:mi>N</mml:mi> <mml:mi>E</mml:mi></mml:msub> <mml:mi>N</mml:mi></mml:mfrac> <mml:msub><mml:mi>g</mml:mi> <mml:mi>E</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:mfrac><mml:msub><mml:mi>N</mml:mi> <mml:mi>I</mml:mi></mml:msub> <mml:mi>N</mml:mi></mml:mfrac> <mml:msub><mml:mi>g</mml:mi> <mml:mi>I</mml:mi></mml:msub></mml:mfenced> <mml:mo>≡</mml:mo> <mml:mi>N</mml:mi> <mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>n</mml:mi></mml:mrow></mml:msup> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(42)</label></disp-formula>
where <italic>N</italic><sub><italic>E</italic></sub> and <italic>N</italic><sub><italic>I</italic></sub> are the numbers of excitatory and inhibitory neurons in the network, respectively. We have also <italic>μ</italic><sup><italic>in</italic></sup> as <inline-formula id="pcbi.1004963.e066"><alternatives><graphic id="pcbi.1004963.e066g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e066" xlink:type="simple"/><mml:math display="inline" id="M66"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mfrac><mml:msub><mml:mi>N</mml:mi> <mml:mi>E</mml:mi></mml:msub> <mml:mi>N</mml:mi></mml:mfrac> <mml:msub><mml:mi>g</mml:mi> <mml:mi>E</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:mfrac><mml:msub><mml:mi>N</mml:mi> <mml:mi>I</mml:mi></mml:msub> <mml:mi>N</mml:mi></mml:mfrac> <mml:msub><mml:mi>g</mml:mi> <mml:mi>I</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, the average strength of the total input to a neuron. Now, if we set the external input <italic>μ</italic> to 1, the stationary rate of neuron <italic>i</italic> can be seen to equal
<disp-formula id="pcbi.1004963.e067"><alternatives><graphic id="pcbi.1004963.e067g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e067" xlink:type="simple"/><mml:math display="block" id="M67"><mml:mrow><mml:msub><mml:mo>Λ</mml:mo> <mml:mi>i</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mi>j</mml:mi></mml:munder> <mml:msub><mml:mfenced close="]" open="[" separators=""><mml:munder><mml:mo>∑</mml:mo> <mml:mi>n</mml:mi></mml:munder> <mml:msup><mml:mi>G</mml:mi> <mml:mi>n</mml:mi></mml:msup></mml:mfenced> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mi>j</mml:mi></mml:munder> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>δ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>G</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>G</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>+</mml:mo> <mml:mo>⋯</mml:mo> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>N</mml:mi> <mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>n</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac> <mml:mo>≡</mml:mo> <mml:mover accent="true"><mml:mo>Λ</mml:mo> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(43)</label></disp-formula>
Unsurprisingly, since the external input to all neurons is the same, the stationary rates are all equal (<inline-formula id="pcbi.1004963.e068"><alternatives><graphic id="pcbi.1004963.e068g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e068" xlink:type="simple"/><mml:math display="inline" id="M68"><mml:mrow><mml:msub><mml:mo>Λ</mml:mo> <mml:mi>i</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mover accent="true"><mml:mo>Λ</mml:mo> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>,</mml:mo> <mml:mo>∀</mml:mo> <mml:mi>i</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>). The computation of the average cumulant <inline-formula id="pcbi.1004963.e069"><alternatives><graphic id="pcbi.1004963.e069g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e069" xlink:type="simple"/><mml:math display="inline" id="M69"><mml:msub><mml:mover accent="true"><mml:mi>κ</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mn>3</mml:mn></mml:msub></mml:math></alternatives></inline-formula> can be done in much the same way (for details, see <xref ref-type="supplementary-material" rid="pcbi.1004963.s002">S2 Appendix</xref>). Note that, to simplify derivation, we assume that all neurons (irrespective of their type) have the same in-degree and out-degree. The final formula then reads
<disp-formula id="pcbi.1004963.e070"><alternatives><graphic id="pcbi.1004963.e070g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e070" xlink:type="simple"/><mml:math display="block" id="M70"><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>κ</mml:mi> <mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow> <mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:mo>−</mml:mo> <mml:mfrac><mml:mrow><mml:mover accent="true"><mml:mo>Λ</mml:mo> <mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow> <mml:mrow><mml:msup><mml:mi>N</mml:mi> <mml:mn>3</mml:mn></mml:msup></mml:mrow></mml:mfrac> <mml:mfrac><mml:mrow><mml:msup><mml:mi>N</mml:mi> <mml:mn>4</mml:mn></mml:msup> <mml:msup><mml:mi>p</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mn>3</mml:mn> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow> <mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>−</mml:mo> <mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mn>1</mml:mn> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup> <mml:mi>N</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow> <mml:mn>3</mml:mn></mml:msup></mml:mrow></mml:mfrac> <mml:mo>+</mml:mo> <mml:mfrac><mml:mrow><mml:mn>3</mml:mn> <mml:mover accent="true"><mml:mo>Λ</mml:mo> <mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow> <mml:mrow><mml:msup><mml:mi>N</mml:mi> <mml:mn>3</mml:mn></mml:msup></mml:mrow></mml:mfrac> <mml:mfrac><mml:mrow><mml:msup><mml:mi>N</mml:mi> <mml:mn>3</mml:mn></mml:msup> <mml:mi>p</mml:mi> <mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mn>2</mml:mn> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow> <mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>−</mml:mo> <mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mn>1</mml:mn> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup> <mml:mi>N</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac> <mml:mo>−</mml:mo> <mml:mfrac><mml:mrow><mml:mn>3</mml:mn> <mml:mover accent="true"><mml:mo>Λ</mml:mo> <mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow> <mml:mrow><mml:msup><mml:mi>N</mml:mi> <mml:mn>3</mml:mn></mml:msup></mml:mrow></mml:mfrac> <mml:mfrac><mml:mrow><mml:msup><mml:mi>N</mml:mi> <mml:mn>4</mml:mn></mml:msup> <mml:mi>p</mml:mi> <mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mn>1</mml:mn> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup> <mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mn>2</mml:mn> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow> <mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>−</mml:mo> <mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mn>1</mml:mn> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup> <mml:mi>N</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow> <mml:mn>3</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr> <mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow/></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>−</mml:mo> <mml:mfrac><mml:mrow><mml:mn>6</mml:mn> <mml:mover accent="true"><mml:mo>Λ</mml:mo> <mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow> <mml:mrow><mml:msup><mml:mi>N</mml:mi> <mml:mn>3</mml:mn></mml:msup></mml:mrow></mml:mfrac> <mml:mfrac><mml:mrow><mml:msup><mml:mi>N</mml:mi> <mml:mn>4</mml:mn></mml:msup> <mml:mi>p</mml:mi> <mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mn>1</mml:mn> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup> <mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mn>2</mml:mn> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow> <mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>−</mml:mo> <mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mn>1</mml:mn> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup> <mml:mi>N</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow> <mml:mn>3</mml:mn></mml:msup></mml:mrow></mml:mfrac> <mml:mo>+</mml:mo> <mml:mfrac><mml:mrow><mml:mn>6</mml:mn> <mml:mover accent="true"><mml:mo>Λ</mml:mo> <mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow> <mml:mrow><mml:msup><mml:mi>N</mml:mi> <mml:mn>3</mml:mn></mml:msup></mml:mrow></mml:mfrac> <mml:mfrac><mml:mrow><mml:msup><mml:mi>N</mml:mi> <mml:mn>3</mml:mn></mml:msup> <mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mn>1</mml:mn> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow> <mml:mn>2</mml:mn></mml:msup></mml:mrow> <mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>−</mml:mo> <mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mn>1</mml:mn> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup> <mml:mi>N</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac> <mml:mo>+</mml:mo> <mml:mfrac><mml:mrow><mml:mn>3</mml:mn> <mml:mover accent="true"><mml:mo>Λ</mml:mo> <mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow> <mml:mrow><mml:msup><mml:mi>N</mml:mi> <mml:mn>3</mml:mn></mml:msup></mml:mrow></mml:mfrac> <mml:mfrac><mml:mrow><mml:msup><mml:mi>N</mml:mi> <mml:mn>5</mml:mn></mml:msup> <mml:msup><mml:mi>p</mml:mi> <mml:mn>3</mml:mn></mml:msup> <mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mn>2</mml:mn> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow> <mml:mn>2</mml:mn></mml:msup></mml:mrow> <mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>−</mml:mo> <mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mn>1</mml:mn> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup> <mml:mi>N</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow> <mml:mn>4</mml:mn></mml:msup></mml:mrow></mml:mfrac> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(44)</label></disp-formula>
where each term in the equation corresponds to one of the tree shapes in <xref ref-type="fig" rid="pcbi.1004963.g004">Fig 4</xref>. We have chosen not to perform any simplifications in the formula, as we feel that this would obscure the correspondence each term has to its tree counterpart. Here, we have defined <italic>μ</italic><sup>(<italic>k</italic>)</sup> as the average common input, shared by <italic>k</italic> neurons, equaling
<disp-formula id="pcbi.1004963.e071"><alternatives><graphic id="pcbi.1004963.e071g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e071" xlink:type="simple"/><mml:math display="block" id="M71"><mml:mrow><mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mo>=</mml:mo> <mml:mi>p</mml:mi> <mml:mfenced close=")" open="(" separators=""><mml:mfrac><mml:msub><mml:mi>N</mml:mi> <mml:mi>E</mml:mi></mml:msub> <mml:mi>N</mml:mi></mml:mfrac> <mml:msubsup><mml:mi>g</mml:mi> <mml:mrow><mml:mi>E</mml:mi></mml:mrow> <mml:mi>k</mml:mi></mml:msubsup> <mml:mo>+</mml:mo> <mml:mfrac><mml:msub><mml:mi>N</mml:mi> <mml:mi>I</mml:mi></mml:msub> <mml:mi>N</mml:mi></mml:mfrac> <mml:msubsup><mml:mi>g</mml:mi> <mml:mrow><mml:mi>I</mml:mi></mml:mrow> <mml:mi>k</mml:mi></mml:msubsup></mml:mfenced> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(45)</label></disp-formula>
Note that in this formalism, <italic>μ</italic><sup>(1)</sup> is the “average common input shared by one neuron”, equal to <italic>μ</italic><sup><italic>in</italic></sup>, the average total input to a neuron. The precise nature of this relation between <xref ref-type="disp-formula" rid="pcbi.1004963.e070">formula 44</xref> and the topology of specific trees is covered in <xref ref-type="supplementary-material" rid="pcbi.1004963.s002">S2 Appendix</xref>. However, heuristically, the relationship is as follows</p>
<list list-type="bullet">
<list-item>
<p>The exponent of <italic>N</italic> in the formula counts the number of nodes of a particular tree</p>
</list-item>
<list-item>
<p>The exponent of <italic>p</italic> is one less than the number of leaves of the tree</p>
</list-item>
<list-item>
<p>The <italic>μ</italic><sup>(⋅)</sup> terms each correspond to an internal node of the tree (that is, a node that is not a leaf). The number in parenthesis in the superscript denotes the out-degree of that particular internal node. Thus, for example, <italic>μ</italic><sup>(3)</sup> indicates that the particular tree has an internal node with out-degree 3.</p>
</list-item>
<list-item>
<p>The power <italic>k</italic> of the normalization factor <inline-formula id="pcbi.1004963.e072"><alternatives><graphic id="pcbi.1004963.e072g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e072" xlink:type="simple"/><mml:math display="inline" id="M72"><mml:mfrac><mml:mn>1</mml:mn> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mi>N</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>k</mml:mi></mml:msup></mml:mfrac></mml:math></alternatives></inline-formula> encodes the number of edges in the tree</p>
</list-item>
</list>
<p>
<xref ref-type="disp-formula" rid="pcbi.1004963.e070">Eq 44</xref> can be used as an approximation whenever the degree distribution of the network in question is narrow–formally, it is only exactly true for a regular
network, in which all neuron have the same in- and out-degrees. For large random networks of the Erdős-Rényi type, this is true as the resulting Binomial distributions have a standard deviation that vanishes with increasing network size. The numerical efficacy of such an approximation can be found in the following section.</p>
<p>A final thing to note about <xref ref-type="disp-formula" rid="pcbi.1004963.e070">Eq 44</xref> is what happens when <italic>N</italic> → +∞. Firstly, note that, once we perform all possible cancellations of terms in <xref ref-type="disp-formula" rid="pcbi.1004963.e070">eq 44</xref>, we find, after rearranging
<disp-formula id="pcbi.1004963.e073"><alternatives><graphic id="pcbi.1004963.e073g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e073" xlink:type="simple"/><mml:math display="block" id="M73"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>κ</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mn>3</mml:mn></mml:msub> <mml:mo>=</mml:mo> <mml:mn>3</mml:mn> <mml:msup><mml:mi>p</mml:mi> <mml:mn>3</mml:mn></mml:msup> <mml:msup><mml:mfenced close="]" open="[" separators=""><mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>2</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mfenced> <mml:mn>2</mml:mn></mml:msup> <mml:msup><mml:mi>N</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:msup><mml:mover accent="true"><mml:mo>Λ</mml:mo> <mml:mo>¯</mml:mo></mml:mover> <mml:mn>5</mml:mn></mml:msup> <mml:mo>-</mml:mo> <mml:mfenced close=")" open="(" separators=""><mml:mn>9</mml:mn> <mml:mi>p</mml:mi> <mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>2</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mo>+</mml:mo> <mml:msup><mml:mi>p</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>3</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mfenced> <mml:mi>N</mml:mi> <mml:msup><mml:mover accent="true"><mml:mo>Λ</mml:mo> <mml:mo>¯</mml:mo></mml:mover> <mml:mn>4</mml:mn></mml:msup> <mml:mo>+</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>3</mml:mn> <mml:mi>p</mml:mi> <mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>2</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mo>+</mml:mo> <mml:mn>6</mml:mn> <mml:msup><mml:mrow><mml:mo>[</mml:mo> <mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mo>]</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:msup><mml:mover accent="true"><mml:mo>Λ</mml:mo> <mml:mo>¯</mml:mo></mml:mover> <mml:mn>3</mml:mn></mml:msup> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(46)</label></disp-formula>
Thus, in the limit of large networks, the most important term is the one corresponding to tree <italic>T</italic><sub>6</sub> in <xref ref-type="fig" rid="pcbi.1004963.g004">Fig 4</xref> <disp-formula id="pcbi.1004963.e074"><alternatives><graphic id="pcbi.1004963.e074g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e074" xlink:type="simple"/><mml:math display="block" id="M74"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>κ</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>3</mml:mn></mml:msub> <mml:mo>≡</mml:mo> <mml:mfrac><mml:mrow><mml:mn>3</mml:mn> <mml:mover accent="true"><mml:mo>Λ</mml:mo> <mml:mo>¯</mml:mo></mml:mover></mml:mrow> <mml:msup><mml:mi>N</mml:mi> <mml:mn>3</mml:mn></mml:msup></mml:mfrac> <mml:mfrac><mml:mrow><mml:msup><mml:mi>N</mml:mi> <mml:mn>5</mml:mn></mml:msup> <mml:msup><mml:mi>p</mml:mi> <mml:mn>3</mml:mn></mml:msup> <mml:msup><mml:mfenced close="]" open="[" separators=""><mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>2</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mfenced> <mml:mn>2</mml:mn></mml:msup></mml:mrow> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mi>N</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mn>4</mml:mn></mml:msup></mml:mfrac> <mml:mo>=</mml:mo> <mml:mn>3</mml:mn> <mml:msup><mml:mi>p</mml:mi> <mml:mn>3</mml:mn></mml:msup> <mml:msup><mml:mfenced close="]" open="[" separators=""><mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>2</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mfenced> <mml:mn>2</mml:mn></mml:msup> <mml:msup><mml:mi>N</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:msup><mml:mover accent="true"><mml:mo>Λ</mml:mo> <mml:mo>¯</mml:mo></mml:mover> <mml:mn>5</mml:mn></mml:msup> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(47)</label></disp-formula>
since we have <inline-formula id="pcbi.1004963.e075"><alternatives><graphic id="pcbi.1004963.e075g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e075" xlink:type="simple"/><mml:math display="inline" id="M75"><mml:mrow><mml:mn>1</mml:mn> <mml:mo>/</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mi>N</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mover accent="true"><mml:mo>Λ</mml:mo> <mml:mo>¯</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula>. More precisely, we obtain the relation
<disp-formula id="pcbi.1004963.e076"><alternatives><graphic id="pcbi.1004963.e076g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e076" xlink:type="simple"/><mml:math display="block" id="M76"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>κ</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mn>3</mml:mn></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>κ</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>3</mml:mn></mml:msub> <mml:mo>+</mml:mo> <mml:mi>O</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>N</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mi>O</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(48)</label></disp-formula>
As is now evident, the contributions from all trees of this shape to <inline-formula id="pcbi.1004963.e077"><alternatives><graphic id="pcbi.1004963.e077g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e077" xlink:type="simple"/><mml:math display="inline" id="M77"><mml:msub><mml:mover accent="true"><mml:mi>κ</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mn>3</mml:mn></mml:msub></mml:math></alternatives></inline-formula> grows as a quadratic function of <italic>N</italic>. The reason for this is that, in large networks, the number of “more complicated” subgraphs grows faster than the number of simpler ones. To see why this is true, consider counting all possible trees with <italic>k</italic> nodes and <italic>k</italic> − 1 edges in a random graph. Since each edge is generated independently, the number of such trees equals
<disp-formula id="pcbi.1004963.e078"><alternatives><graphic id="pcbi.1004963.e078g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e078" xlink:type="simple"/><mml:math display="block" id="M78"><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mi>N</mml:mi></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mi>k</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:msup><mml:mi>p</mml:mi> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>−</mml:mo> <mml:mi>p</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow> <mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mi>k</mml:mi></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mn>2</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>−</mml:mo> <mml:mi>k</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>,</mml:mo></mml:math></alternatives> <label>(49)</label></disp-formula>
Thus, as long as <italic>k</italic> ≤ ⌊<italic>N</italic>/2⌋, the number of tree structures with <italic>k</italic> nodes in a random graph of size <italic>N</italic> will increase with increasing <italic>k</italic>. This is, in a nutshell, why the most relevant contribution to <inline-formula id="pcbi.1004963.e079"><alternatives><graphic id="pcbi.1004963.e079g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e079" xlink:type="simple"/><mml:math display="inline" id="M79"><mml:msub><mml:mover accent="true"><mml:mi>κ</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mn>3</mml:mn></mml:msub></mml:math></alternatives></inline-formula> comes from the “most complicated” tree, i.e. <italic>T</italic><sub>6</sub>.</p>
<p>With the previous discussion in mind, one may expect that, for <italic>N</italic> → +∞, the quadratic term <inline-formula id="pcbi.1004963.e080"><alternatives><graphic id="pcbi.1004963.e080g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e080" xlink:type="simple"/><mml:math display="inline" id="M80"><mml:msub><mml:mover accent="true"><mml:mi>κ</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>3</mml:mn></mml:msub></mml:math></alternatives></inline-formula> is a good approximation for <inline-formula id="pcbi.1004963.e081"><alternatives><graphic id="pcbi.1004963.e081g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e081" xlink:type="simple"/><mml:math display="inline" id="M81"><mml:msub><mml:mover accent="true"><mml:mi>κ</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mn>3</mml:mn></mml:msub></mml:math></alternatives></inline-formula>. Indeed, <xref ref-type="fig" rid="pcbi.1004963.g005">Fig 5</xref> illustrates this. Thus, we are able to conclude that, in the limit of large networks, the dominating contribution to the average joint third cumulant <inline-formula id="pcbi.1004963.e082"><alternatives><graphic id="pcbi.1004963.e082g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e082" xlink:type="simple"/><mml:math display="inline" id="M82"><mml:msub><mml:mover accent="true"><mml:mi>κ</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mn>3</mml:mn></mml:msub></mml:math></alternatives></inline-formula> comes from the trees of topology <italic>T</italic><sub>6</sub> present in the network. One more thing to note is that the leading term <inline-formula id="pcbi.1004963.e083"><alternatives><graphic id="pcbi.1004963.e083g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e083" xlink:type="simple"/><mml:math display="inline" id="M83"><mml:msub><mml:mover accent="true"><mml:mi>κ</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>3</mml:mn></mml:msub></mml:math></alternatives></inline-formula> is proportional to a power of the stationary rate <inline-formula id="pcbi.1004963.e084"><alternatives><graphic id="pcbi.1004963.e084g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e084" xlink:type="simple"/><mml:math display="inline" id="M84"><mml:mover accent="true"><mml:mo>Λ</mml:mo> <mml:mo>¯</mml:mo></mml:mover></mml:math></alternatives></inline-formula>. Let us briefly consider what happens to <inline-formula id="pcbi.1004963.e085"><alternatives><graphic id="pcbi.1004963.e085g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e085" xlink:type="simple"/><mml:math display="inline" id="M85"><mml:mover accent="true"><mml:mo>Λ</mml:mo> <mml:mo>¯</mml:mo></mml:mover></mml:math></alternatives></inline-formula> in very large networks, for <italic>N</italic> → +∞. We have
<disp-formula id="pcbi.1004963.e086"><alternatives><graphic id="pcbi.1004963.e086g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e086" xlink:type="simple"/><mml:math display="block" id="M86"><mml:mrow><mml:mover accent="true"><mml:mo>Λ</mml:mo> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>N</mml:mi> <mml:mi>p</mml:mi> <mml:mfenced close=")" open="(" separators=""><mml:mfrac><mml:msub><mml:mi>N</mml:mi> <mml:mi>E</mml:mi></mml:msub> <mml:mi>N</mml:mi></mml:mfrac> <mml:msub><mml:mi>g</mml:mi> <mml:mi>E</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:mfrac><mml:msub><mml:mi>N</mml:mi> <mml:mi>I</mml:mi></mml:msub> <mml:mi>N</mml:mi></mml:mfrac> <mml:msub><mml:mi>g</mml:mi> <mml:mi>I</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:mfrac> <mml:mo>→</mml:mo> <mml:mn>0</mml:mn> <mml:mtext>,</mml:mtext> <mml:mspace width="4.pt"/><mml:mi>N</mml:mi> <mml:mo>→</mml:mo> <mml:mo>+</mml:mo> <mml:mi>∞</mml:mi> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(50)</label></disp-formula>
assuming we keep all other parameters fixed. As a result of this, the product <inline-formula id="pcbi.1004963.e087"><alternatives><graphic id="pcbi.1004963.e087g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e087" xlink:type="simple"/><mml:math display="inline" id="M87"><mml:mrow><mml:msup><mml:mi>N</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:msup><mml:mover accent="true"><mml:mo>Λ</mml:mo> <mml:mo>¯</mml:mo></mml:mover> <mml:mn>5</mml:mn></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> in <inline-formula id="pcbi.1004963.e088"><alternatives><graphic id="pcbi.1004963.e088g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e088" xlink:type="simple"/><mml:math display="inline" id="M88"><mml:msub><mml:mover accent="true"><mml:mi>κ</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>3</mml:mn></mml:msub></mml:math></alternatives></inline-formula>, will decay to zero with increasing network size. Thus, when the size of the network considered grows without bounds, two things happen:</p>
<list list-type="bullet">
<list-item>
<p>The leading term <inline-formula id="pcbi.1004963.e089"><alternatives><graphic id="pcbi.1004963.e089g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e089" xlink:type="simple"/><mml:math display="inline" id="M89"><mml:msub><mml:mover accent="true"><mml:mi>κ</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>3</mml:mn></mml:msub></mml:math></alternatives></inline-formula> becomes a better approximation of the average third cumulant <inline-formula id="pcbi.1004963.e090"><alternatives><graphic id="pcbi.1004963.e090g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e090" xlink:type="simple"/><mml:math display="inline" id="M90"><mml:msub><mml:mover accent="true"><mml:mi>κ</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mn>3</mml:mn></mml:msub></mml:math></alternatives></inline-formula> but, at the same time,</p>
</list-item>
<list-item>
<p>The average third cumulant <inline-formula id="pcbi.1004963.e091"><alternatives><graphic id="pcbi.1004963.e091g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e091" xlink:type="simple"/><mml:math display="inline" id="M91"><mml:msub><mml:mover accent="true"><mml:mi>κ</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mn>3</mml:mn></mml:msub></mml:math></alternatives></inline-formula> itself goes to 0.</p>
</list-item>
</list>
<fig id="pcbi.1004963.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004963.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Efficacy of the quadratic approximation to <inline-formula id="pcbi.1004963.e092"><alternatives><graphic id="pcbi.1004963.e092g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e092" xlink:type="simple"/><mml:math display="inline" id="M92"><mml:msub><mml:mover accent="true"><mml:mi>κ</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mn mathvariant="bold">3</mml:mn></mml:msub></mml:math></alternatives></inline-formula> (<xref ref-type="disp-formula" rid="pcbi.1004963.e074">Eq 47</xref>) for different network sizes <italic>N</italic>.</title>
<p>All four panels: <inline-formula id="pcbi.1004963.e093"><alternatives><graphic id="pcbi.1004963.e093g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e093" xlink:type="simple"/><mml:math display="inline" id="M93"><mml:msub><mml:mover accent="true"><mml:mi>κ</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mn>3</mml:mn></mml:msub></mml:math></alternatives></inline-formula> and its quadratic approximation, <inline-formula id="pcbi.1004963.e094"><alternatives><graphic id="pcbi.1004963.e094g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e094" xlink:type="simple"/><mml:math display="inline" id="M94"><mml:msub><mml:mover accent="true"><mml:mi>κ</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>3</mml:mn></mml:msub></mml:math></alternatives></inline-formula>, plotted for different values of the connection probability <italic>p</italic>. Each panel corresponds to a network of a given size.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004963.g005" xlink:type="simple"/>
</fig>
<p>The second point shouldn’t be too surprising. Indeed, once we remember that <inline-formula id="pcbi.1004963.e095"><alternatives><graphic id="pcbi.1004963.e095g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e095" xlink:type="simple"/><mml:math display="inline" id="M95"><mml:msub><mml:mover accent="true"><mml:mi>κ</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mn>3</mml:mn></mml:msub></mml:math></alternatives></inline-formula> is proportional to the skewness of the population activity (defined as the sum of spike counts of all neurons
in the network, in a bin of size <italic>T</italic>), its asymptotic vanishing is a straightforward consequence of the Central Limit Theorem. As <italic>N</italic> increases, the population activity is behaving more and more like a Gaussian random variable and, as a consequence, its skewness inevitably decays to zero. This effect is reflected by the horizontal asymptote in <xref ref-type="fig" rid="pcbi.1004963.g005">Fig 5</xref>.</p>
</sec>
<sec id="sec012">
<title>The signs of tree motif contributions to the third cumulant in regular networks depend on their topological structure</title>
<p>In this section, we will analyze the contributions of terms, corresponding to tree shapes in <xref ref-type="fig" rid="pcbi.1004963.g004">Fig 4</xref> with fixed branch length. More precisely, let us consider once again <xref ref-type="disp-formula" rid="pcbi.1004963.e037">Eq 25</xref>, plugging in the power series expansion of matrix <italic>B</italic> and exchanging the order of summation over “branch length” (i.e. summation over powers of the <italic>G</italic> matrix) and summation “over nodes” (i.e. summation over <italic>i</italic>, <italic>j</italic> and <italic>k</italic>, used to define <inline-formula id="pcbi.1004963.e096"><alternatives><graphic id="pcbi.1004963.e096g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e096" xlink:type="simple"/><mml:math display="inline" id="M96"><mml:msub><mml:mover accent="true"><mml:mi>κ</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mn>3</mml:mn></mml:msub></mml:math></alternatives></inline-formula>), we get
<disp-formula id="pcbi.1004963.e097"><alternatives><graphic id="pcbi.1004963.e097g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e097" xlink:type="simple"/><mml:math display="block" id="M97"><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>κ</mml:mi> <mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow> <mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mover accent="true"><mml:mo>Λ</mml:mo> <mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow> <mml:mrow><mml:msup><mml:mi>N</mml:mi> <mml:mn>3</mml:mn></mml:msup></mml:mrow></mml:mfrac> <mml:munder><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>∑</mml:mo></mml:mstyle> <mml:mrow><mml:msub><mml:mi>l</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>l</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>l</mml:mi> <mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:munder> <mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:munder><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>∑</mml:mo></mml:mstyle> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>,</mml:mo> <mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi> <mml:mo>,</mml:mo> <mml:mi>m</mml:mi></mml:mrow></mml:munder> <mml:msubsup><mml:mi>G</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>m</mml:mi></mml:mrow> <mml:mrow><mml:msub><mml:mi>l</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msubsup> <mml:msubsup><mml:mi>G</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>m</mml:mi></mml:mrow> <mml:mrow><mml:msub><mml:mi>l</mml:mi> <mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msubsup> <mml:msubsup><mml:mi>G</mml:mi> <mml:mrow><mml:mi>k</mml:mi> <mml:mi>m</mml:mi></mml:mrow> <mml:mrow><mml:msub><mml:mi>l</mml:mi> <mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:msubsup></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow/></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>+</mml:mo> <mml:mfrac><mml:mrow><mml:mn>3</mml:mn> <mml:mover accent="true"><mml:mo>Λ</mml:mo> <mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow> <mml:mrow><mml:msup><mml:mi>N</mml:mi> <mml:mn>3</mml:mn></mml:msup></mml:mrow></mml:mfrac> <mml:munder><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>∑</mml:mo></mml:mstyle> <mml:mrow><mml:msub><mml:mi>l</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>l</mml:mi> <mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:munder> <mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:munder><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>∑</mml:mo></mml:mstyle> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>,</mml:mo> <mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi></mml:mrow></mml:munder> <mml:msubsup><mml:mi>G</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>k</mml:mi></mml:mrow> <mml:mrow><mml:msub><mml:mi>l</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msubsup> <mml:msubsup><mml:mi>G</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow> <mml:mrow><mml:msub><mml:mi>l</mml:mi> <mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msubsup></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow/></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>+</mml:mo> <mml:mfrac><mml:mrow><mml:mn>3</mml:mn> <mml:mover accent="true"><mml:mo>Λ</mml:mo> <mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow> <mml:mrow><mml:msup><mml:mi>N</mml:mi> <mml:mn>3</mml:mn></mml:msup></mml:mrow></mml:mfrac> <mml:munder><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>∑</mml:mo></mml:mstyle> <mml:mrow><mml:msub><mml:mi>l</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>l</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>l</mml:mi> <mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:munder> <mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:munder><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>∑</mml:mo></mml:mstyle> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>,</mml:mo> <mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi> <mml:mo>,</mml:mo> <mml:mi>m</mml:mi></mml:mrow></mml:munder> <mml:msubsup><mml:mi>G</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>m</mml:mi></mml:mrow> <mml:mrow><mml:msub><mml:mi>l</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msubsup> <mml:msubsup><mml:mi>G</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>m</mml:mi></mml:mrow> <mml:mrow><mml:msub><mml:mi>l</mml:mi> <mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msubsup> <mml:msubsup><mml:mi>G</mml:mi> <mml:mrow><mml:mi>m</mml:mi> <mml:mi>k</mml:mi></mml:mrow> <mml:mrow><mml:msub><mml:mi>l</mml:mi> <mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:msubsup></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow/></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mfrac><mml:mrow><mml:mn>6</mml:mn> <mml:mover accent="true"><mml:mo>Λ</mml:mo> <mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow> <mml:mrow><mml:msup><mml:mi>N</mml:mi> <mml:mn>3</mml:mn></mml:msup></mml:mrow></mml:mfrac> <mml:munder><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>∑</mml:mo></mml:mstyle> <mml:mrow><mml:msub><mml:mi>l</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>l</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>l</mml:mi> <mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:munder> <mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:munder><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>∑</mml:mo></mml:mstyle> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>,</mml:mo> <mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:munder> <mml:msubsup><mml:mi>G</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mrow><mml:msub><mml:mi>l</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msubsup> <mml:msubsup><mml:mi>G</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>n</mml:mi></mml:mrow> <mml:mrow><mml:msub><mml:mi>l</mml:mi> <mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msubsup> <mml:msubsup><mml:mi>G</mml:mi> <mml:mrow><mml:mi>k</mml:mi> <mml:mi>n</mml:mi></mml:mrow> <mml:mrow><mml:msub><mml:mi>l</mml:mi> <mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:msubsup></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow/></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>+</mml:mo> <mml:mfrac><mml:mrow><mml:mn>6</mml:mn> <mml:mover accent="true"><mml:mo>Λ</mml:mo> <mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow> <mml:mrow><mml:msup><mml:mi>N</mml:mi> <mml:mn>3</mml:mn></mml:msup></mml:mrow></mml:mfrac> <mml:munder><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>∑</mml:mo></mml:mstyle> <mml:mrow><mml:msub><mml:mi>l</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>l</mml:mi> <mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:munder> <mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:munder><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>∑</mml:mo></mml:mstyle> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>,</mml:mo> <mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi></mml:mrow></mml:munder> <mml:msubsup><mml:mi>G</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mrow><mml:msub><mml:mi>l</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msubsup> <mml:msubsup><mml:mi>G</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow> <mml:mrow><mml:msub><mml:mi>l</mml:mi> <mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msubsup></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow/></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>+</mml:mo> <mml:mfrac><mml:mrow><mml:mn>3</mml:mn> <mml:mover accent="true"><mml:mo>Λ</mml:mo> <mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow> <mml:mrow><mml:msup><mml:mi>N</mml:mi> <mml:mn>3</mml:mn></mml:msup></mml:mrow></mml:mfrac> <mml:munder><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>∑</mml:mo></mml:mstyle> <mml:mrow><mml:msub><mml:mi>l</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>l</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>l</mml:mi> <mml:mn>3</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>l</mml:mi> <mml:mn>4</mml:mn></mml:msub></mml:mrow></mml:munder> <mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:munder><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>∑</mml:mo></mml:mstyle> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>,</mml:mo> <mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi> <mml:mo>,</mml:mo> <mml:mi>m</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:munder> <mml:msubsup><mml:mi>G</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>m</mml:mi></mml:mrow> <mml:mrow><mml:msub><mml:mi>l</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msubsup> <mml:msubsup><mml:mi>G</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>m</mml:mi></mml:mrow> <mml:mrow><mml:msub><mml:mi>l</mml:mi> <mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msubsup> <mml:msubsup><mml:mi>G</mml:mi> <mml:mrow><mml:mi>m</mml:mi> <mml:mi>n</mml:mi></mml:mrow> <mml:mrow><mml:msub><mml:mi>l</mml:mi> <mml:mn>4</mml:mn></mml:msub></mml:mrow></mml:msubsup> <mml:msubsup><mml:mi>G</mml:mi> <mml:mrow><mml:mi>k</mml:mi> <mml:mi>n</mml:mi></mml:mrow> <mml:mrow><mml:msub><mml:mi>l</mml:mi> <mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:msubsup></mml:mrow> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(51)</label></disp-formula>
The terms in the square brackets can be interpreted as the total weight of all relevant trees (see <xref ref-type="fig" rid="pcbi.1004963.g004">Fig 4</xref>) present in the network, with lengths of all branches fixed. Under the regularity assumption, i.e. if all neurons have the same in-degree and out-degree, it is straightforward to conclude that the “square bracket term” of a tree <inline-formula id="pcbi.1004963.e098"><alternatives><graphic id="pcbi.1004963.e098g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e098" xlink:type="simple"/><mml:math display="inline" id="M98"><mml:mi mathvariant="script">T</mml:mi></mml:math></alternatives></inline-formula> with <italic>n</italic> nodes and <italic>l</italic> leaves, embedded in a network of size <italic>N</italic>, can be computed as (see <xref ref-type="supplementary-material" rid="pcbi.1004963.s002">S2 Appendix</xref>)
<disp-formula id="pcbi.1004963.e099"><alternatives><graphic id="pcbi.1004963.e099g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e099" xlink:type="simple"/><mml:math display="block" id="M99"><mml:mrow><mml:msup><mml:mi>N</mml:mi> <mml:mi>n</mml:mi></mml:msup> <mml:msup><mml:mi>p</mml:mi> <mml:mrow><mml:mi>l</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:munder><mml:mo>∏</mml:mo> <mml:mi>v</mml:mi></mml:munder> <mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>k</mml:mi> <mml:mi>v</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:msup><mml:mfenced close="]" open="[" separators=""><mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mi>N</mml:mi></mml:mfenced> <mml:mrow><mml:msub><mml:mi>l</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>+</mml:mo> <mml:mo>⋯</mml:mo> <mml:mo>+</mml:mo> <mml:msub><mml:mi>l</mml:mi> <mml:mrow><mml:mi>n</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>-</mml:mo> <mml:mi>n</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(52)</label></disp-formula>
where the product is over all internal nodes (i.e. nodes that are not leaves) of <inline-formula id="pcbi.1004963.e100"><alternatives><graphic id="pcbi.1004963.e100g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e100" xlink:type="simple"/><mml:math display="inline" id="M100"><mml:mi mathvariant="script">T</mml:mi></mml:math></alternatives></inline-formula> and <italic>k</italic><sub><italic>v</italic></sub> is the out-degree of node <italic>v</italic>. The numbers <italic>l</italic><sub>1</sub>, …, <italic>l</italic><sub><italic>n</italic>−1</sub> encode the lengths of branches of <inline-formula id="pcbi.1004963.e101"><alternatives><graphic id="pcbi.1004963.e101g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e101" xlink:type="simple"/><mml:math display="inline" id="M101"><mml:mi mathvariant="script">T</mml:mi></mml:math></alternatives></inline-formula>, of which there are exactly <italic>n</italic> − 1 in a tree with <italic>n</italic> nodes. In fact, it is this result that greatly simplifies the “summation over branch lengths” one needs to perform in order to obtain <xref ref-type="disp-formula" rid="pcbi.1004963.e070">Eq 44</xref>.</p>
<p>Furthermore, from <xref ref-type="disp-formula" rid="pcbi.1004963.e099">formula 52</xref> we see that the only relevant characteristics of a tree <inline-formula id="pcbi.1004963.e102"><alternatives><graphic id="pcbi.1004963.e102g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e102" xlink:type="simple"/><mml:math display="inline" id="M102"><mml:mi mathvariant="script">T</mml:mi></mml:math></alternatives></inline-formula> that determine the weight of the contribution are the number of its nodes <italic>n</italic>, the number of its leaves <italic>l</italic> and the out-degrees of its internal nodes. Note that the root counts as an internal node here. Trees with a large total branch length contribute relatively little to <inline-formula id="pcbi.1004963.e103"><alternatives><graphic id="pcbi.1004963.e103g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e103" xlink:type="simple"/><mml:math display="inline" id="M103"><mml:msub><mml:mover accent="true"><mml:mi>κ</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mn>3</mml:mn></mml:msub></mml:math></alternatives></inline-formula>. Indeed, as
<disp-formula id="pcbi.1004963.e104"><alternatives><graphic id="pcbi.1004963.e104g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e104" xlink:type="simple"/><mml:math display="block" id="M104"><mml:mrow><mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mrow><mml:mi>N</mml:mi> <mml:mo>|</mml:mo> <mml:mo>=</mml:mo> <mml:mo>|</mml:mo> <mml:mi>p</mml:mi></mml:mrow> <mml:mfenced close=")" open="(" separators=""><mml:msub><mml:mi>N</mml:mi> <mml:mi>E</mml:mi></mml:msub> <mml:msub><mml:mi>g</mml:mi> <mml:mi>e</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>N</mml:mi> <mml:mi>I</mml:mi></mml:msub> <mml:msub><mml:mi>g</mml:mi> <mml:mi>I</mml:mi></mml:msub></mml:mfenced> <mml:mrow><mml:mo>|</mml:mo> <mml:mo>&lt;</mml:mo> <mml:mn>1</mml:mn> <mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives> <label>(53)</label></disp-formula>
we have that, when the total length of all branches tends to infinity (i.e. when the sum <italic>s</italic><sub><italic>n</italic></sub> ≡ <italic>l</italic><sub>1</sub> + ⋯ + <italic>l</italic><sub><italic>n</italic>−1</sub> grows beyond all bounds), the corresponding term <inline-formula id="pcbi.1004963.e105"><alternatives><graphic id="pcbi.1004963.e105g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e105" xlink:type="simple"/><mml:math display="inline" id="M105"><mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mi>N</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msub><mml:mi>s</mml:mi> <mml:mi>n</mml:mi></mml:msub></mml:msup></mml:math></alternatives></inline-formula> decays to zero.</p>
<p>Lastly, we consider the issue of determining the signs of various contributions to <inline-formula id="pcbi.1004963.e106"><alternatives><graphic id="pcbi.1004963.e106g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e106" xlink:type="simple"/><mml:math display="inline" id="M106"><mml:msub><mml:mover accent="true"><mml:mi>κ</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mn>3</mml:mn></mml:msub></mml:math></alternatives></inline-formula>. This can be done by once again closely analyzing <xref ref-type="disp-formula" rid="pcbi.1004963.e099">formula 52</xref>. First, note that the common input terms <italic>μ</italic><sup>(<italic>k</italic>)</sup> are positive for even and negative for odd <italic>k</italic>. Indeed, as we assume that underlying network in inhibition-dominated (that is, if we assume that the total input to a neuron is negative) we have, in mathematical terms that
<disp-formula id="pcbi.1004963.e107"><alternatives><graphic id="pcbi.1004963.e107g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e107" xlink:type="simple"/><mml:math display="block" id="M107"><mml:mrow><mml:msub><mml:mi>N</mml:mi> <mml:mi>E</mml:mi></mml:msub> <mml:msub><mml:mi>g</mml:mi> <mml:mi>E</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>N</mml:mi> <mml:mi>I</mml:mi></mml:msub> <mml:msub><mml:mi>g</mml:mi> <mml:mi>I</mml:mi></mml:msub> <mml:mo>&lt;</mml:mo> <mml:mn>0</mml:mn> <mml:mspace width="2.em"/><mml:mo>⇔</mml:mo> <mml:mspace width="2.em"/><mml:msub><mml:mi>g</mml:mi> <mml:mi>I</mml:mi></mml:msub> <mml:mo>&lt;</mml:mo> <mml:mo>-</mml:mo> <mml:mfrac><mml:msub><mml:mi>N</mml:mi> <mml:mi>E</mml:mi></mml:msub> <mml:msub><mml:mi>N</mml:mi> <mml:mi>I</mml:mi></mml:msub></mml:mfrac> <mml:msub><mml:mi>g</mml:mi> <mml:mi>E</mml:mi></mml:msub> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(54)</label></disp-formula>
Thus,
<disp-formula id="pcbi.1004963.e108"><alternatives><graphic id="pcbi.1004963.e108g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e108" xlink:type="simple"/><mml:math display="block" id="M108"><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mn>2</mml:mn> <mml:mi>r</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>N</mml:mi> <mml:mi>E</mml:mi></mml:msub></mml:mrow> <mml:mi>N</mml:mi></mml:mfrac> <mml:msubsup><mml:mi>g</mml:mi> <mml:mi>E</mml:mi> <mml:mrow><mml:mn>2</mml:mn> <mml:mi>r</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:mo>+</mml:mo> <mml:mfrac><mml:mrow><mml:msub><mml:mi>N</mml:mi> <mml:mi>I</mml:mi></mml:msub></mml:mrow> <mml:mi>N</mml:mi></mml:mfrac> <mml:msubsup><mml:mi>g</mml:mi> <mml:mi>I</mml:mi> <mml:mrow><mml:mn>2</mml:mn> <mml:mi>r</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow/></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>&lt;</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>N</mml:mi> <mml:mi>E</mml:mi></mml:msub></mml:mrow> <mml:mi>N</mml:mi></mml:mfrac> <mml:msubsup><mml:mi>g</mml:mi> <mml:mi>E</mml:mi> <mml:mrow><mml:mn>2</mml:mn> <mml:mi>r</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:mo>+</mml:mo> <mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mo>−</mml:mo> <mml:mn>1</mml:mn> <mml:mo stretchy="false">)</mml:mo></mml:mrow> <mml:mrow><mml:mn>2</mml:mn> <mml:mi>r</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mfrac><mml:mrow><mml:msub><mml:mi>N</mml:mi> <mml:mi>E</mml:mi></mml:msub></mml:mrow> <mml:mi>N</mml:mi></mml:mfrac> <mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>N</mml:mi> <mml:mi>E</mml:mi></mml:msub></mml:mrow> <mml:mrow><mml:msub><mml:mi>N</mml:mi> <mml:mi>I</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mrow><mml:mn>2</mml:mn> <mml:mi>r</mml:mi></mml:mrow></mml:msup> <mml:msubsup><mml:mi>g</mml:mi> <mml:mi>E</mml:mi> <mml:mrow><mml:mn>2</mml:mn> <mml:mi>r</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
Therefore,
<disp-formula id="pcbi.1004963.e109"><alternatives><graphic id="pcbi.1004963.e109g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e109" xlink:type="simple"/><mml:math display="block" id="M109"><mml:mrow><mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>2</mml:mn> <mml:mi>r</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mo>&lt;</mml:mo> <mml:mi>p</mml:mi> <mml:mfrac><mml:msub><mml:mi>N</mml:mi> <mml:mi>E</mml:mi></mml:msub> <mml:mi>N</mml:mi></mml:mfrac> <mml:mfenced close="]" open="[" separators=""><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msup><mml:mfenced close=")" open="(" separators=""><mml:mfrac><mml:msub><mml:mi>N</mml:mi> <mml:mi>E</mml:mi></mml:msub> <mml:msub><mml:mi>N</mml:mi> <mml:mi>I</mml:mi></mml:msub></mml:mfrac></mml:mfenced> <mml:mrow><mml:mn>2</mml:mn> <mml:mi>r</mml:mi></mml:mrow></mml:msup></mml:mfenced> <mml:msubsup><mml:mi>g</mml:mi> <mml:mrow><mml:mi>E</mml:mi></mml:mrow> <mml:mrow><mml:mn>2</mml:mn> <mml:mi>r</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:mo>&lt;</mml:mo> <mml:mi>p</mml:mi> <mml:mfenced close="]" open="[" separators=""><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msup><mml:mfenced close=")" open="(" separators=""><mml:mfrac><mml:msub><mml:mi>N</mml:mi> <mml:mi>E</mml:mi></mml:msub> <mml:msub><mml:mi>N</mml:mi> <mml:mi>I</mml:mi></mml:msub></mml:mfrac></mml:mfenced> <mml:mrow><mml:mn>2</mml:mn> <mml:mi>r</mml:mi></mml:mrow></mml:msup></mml:mfenced> <mml:msubsup><mml:mi>g</mml:mi> <mml:mi>E</mml:mi> <mml:mrow><mml:mn>2</mml:mn> <mml:mi>r</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:mo>&lt;</mml:mo> <mml:mn>0</mml:mn> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(55)</label></disp-formula>
since <italic>g</italic><sub><italic>E</italic></sub> &gt; 0, <italic>N</italic><sub><italic>E</italic></sub> &gt; <italic>N</italic><sub><italic>I</italic></sub> and 0 ≤ <italic>p</italic> ≤ 1. In the same way, one can show that <italic>μ</italic><sup>(2<italic>r</italic>)</sup> &gt; 0. Therefore, the out-degree sequence of the internal nodes of the tree affects the sign of the corresponding contribution. If, for example, the tree has two internal nodes, with out-degrees 1 and 2, respectively, this will contribute an overall negative sign to the term. However, the out-degree sequence alone does not completely determine the sign of the contribution. Another factor is the parity of the total length of all branches, i.e. the sum <italic>s</italic><sub><italic>n</italic></sub> ≡ <italic>l</italic><sub>1</sub> + … + <italic>l</italic><sub><italic>n</italic>−1</sub>. To see why, note that <italic>Nμ</italic><sup>(1)</sup> &lt; 0, by our previous discussion, and likewise
<disp-formula id="pcbi.1004963.e110"><alternatives><graphic id="pcbi.1004963.e110g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e110" xlink:type="simple"/><mml:math display="block" id="M110"><mml:mrow><mml:msup><mml:mfenced close="]" open="[" separators=""><mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mi>N</mml:mi></mml:mfenced> <mml:mrow><mml:msub><mml:mi>s</mml:mi> <mml:mi>n</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:mi>n</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mspace width="4pt"/></mml:mrow></mml:math></alternatives> <label>(56)</label></disp-formula>
is either negative or positive, depending on whether <italic>s</italic><sub><italic>n</italic></sub> = 2<italic>r</italic> + 1 or <italic>s</italic><sub><italic>n</italic></sub> = 2<italic>r</italic>. (Note that <italic>s</italic><sub><italic>n</italic></sub> ≥ <italic>n</italic> − 1.)</p>
<p>To summarize, the resulting sign of the total contribution to the average third cumulant, of a specific tree with <italic>n</italic> nodes, <italic>l</italic> leaves, a given out-degree sequence and branch lengths depends on both the parity of the product of the internal node out-degrees and the parity of the total branch length. What this means in practice is that the presence of certain trees increases the overall level of third order correlation, while the existence of others can actually have the opposite effect. Whether the latter or the former is the case depends solely on the tree’s topological structure, i.e. how the internal nodes branch and how many edges it contains. As an illustration, the signs and sizes of contributions of two sample trees in a recurrent random network are depicted in <xref ref-type="fig" rid="pcbi.1004963.g006">Fig 6</xref>. One can clearly see which trees increase third-order correlations in the network, and which trees actually decrease them.</p>
<fig id="pcbi.1004963.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004963.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Contributions of some tree structures to the average third cumulant in a random network.</title>
<p>Top: Theoretical (narrow out-degree distribution approximation) and sample contributions to the average third cumulant of <italic>T</italic><sub>6</sub> (see <xref ref-type="fig" rid="pcbi.1004963.g004">Fig 4</xref>) tree topologies with fixed branch lengths. Ticks on the x-axis code for the lengths of the four branches of the tree. The ordering of the indices in the tick labels is done in a top-to-bottom and left-to-right fashion. More precisely, the first number corresponds to the length of the “leftmost” branch emanating from the root node, and so forth. The sample contributions were computed as averages of 3 independent realizations of a random network. Bottom: Theoretical and sample contributions to the average third cumulant of <italic>T</italic><sub>1</sub> tree topologies with fixed branch lengths.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004963.g006" xlink:type="simple"/>
</fig>
<p>One last thing to note is how quickly the contributions, involving higher matrix powers of <italic>G</italic> (i.e. those trees with higher total branch length) decay to zero as the total branch length increases. This behavior is essentially governed by the spectral radius <italic>ρ</italic>(<italic>G</italic>) of the connectivity matrix. For example, in a large random network of both excitatory and inhibitory neurons, the spectrum consists of a single eigenvalue of size <inline-formula id="pcbi.1004963.e111"><alternatives><graphic id="pcbi.1004963.e111g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e111" xlink:type="simple"/><mml:math display="inline" id="M111"><mml:mrow><mml:mi>N</mml:mi> <mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mo>=</mml:mo> <mml:mi>N</mml:mi> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mfrac><mml:msub><mml:mi>N</mml:mi> <mml:mi>E</mml:mi></mml:msub> <mml:mi>N</mml:mi></mml:mfrac> <mml:msub><mml:mi>g</mml:mi> <mml:mi>E</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:mfrac><mml:msub><mml:mi>N</mml:mi> <mml:mi>I</mml:mi></mml:msub> <mml:mi>N</mml:mi></mml:mfrac> <mml:msub><mml:mi>g</mml:mi> <mml:mi>I</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> and a bulk spectrum, contained within a circle in the complex plane [<xref ref-type="bibr" rid="pcbi.1004963.ref034">34</xref>]. Its radius <italic>r</italic> is asympotically given by
<disp-formula id="pcbi.1004963.e112"><alternatives><graphic id="pcbi.1004963.e112g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e112" xlink:type="simple"/><mml:math display="block" id="M112"><mml:mrow><mml:msup><mml:mi>r</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mo>=</mml:mo> <mml:mi>N</mml:mi> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>p</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mfenced close=")" open="(" separators=""><mml:mfrac><mml:msub><mml:mi>N</mml:mi> <mml:mi>E</mml:mi></mml:msub> <mml:mi>N</mml:mi></mml:mfrac> <mml:msubsup><mml:mi>g</mml:mi> <mml:mi>E</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>+</mml:mo> <mml:mfrac><mml:msub><mml:mi>N</mml:mi> <mml:mi>I</mml:mi></mml:msub> <mml:mi>N</mml:mi></mml:mfrac> <mml:msubsup><mml:mi>g</mml:mi> <mml:mi>I</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mfenced> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(57)</label></disp-formula>
While, as was already mentioned, the quantity <italic>Nμ</italic><sup>(1)</sup> corresponds to the total average input to a neuron, the radius <italic>r</italic> of the circle encompassing the bulk spectrum corresponds to the variance of this input. Thus, if the variance of the total input to a neuron in a random network is not too big (<italic>r</italic> &lt; 1), it will exhibit the aforementioned decay of contributions from trees with higher total branch lengths.</p>
</sec>
<sec id="sec013">
<title>Excitatory hubs in the network increase third-order cumulants</title>
<p>In the previous sections, we have demonstrated that the average third cumulant in networks with narrow degree distributions is determined by global parameters such as the number of neurons <italic>N</italic>, the connection probability <italic>p</italic>, and the average strength of input shared by <italic>k</italic> neurons, <italic>μ</italic><sup>(<italic>k</italic>)</sup>. Of course, in networks with a wide degree distribution, the regular network approximation (which we used to derive the equation in <xref ref-type="supplementary-material" rid="pcbi.1004963.s002">S2 Appendix</xref>) is no longer valid. To demonstrate some of the new phenomena by simulation, we consider a network model with a geometric degree distribution, originally introduced in [<xref ref-type="bibr" rid="pcbi.1004963.ref003">3</xref>]. In short, the out-degrees <italic>k</italic> of excitatory and inhibitory neurons are chosen from a geometric distribution with parameter <italic>k</italic><sub>0</sub> (representing the mean out-degree) according to
<disp-formula id="pcbi.1004963.e113"><alternatives><graphic id="pcbi.1004963.e113g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e113" xlink:type="simple"/><mml:math display="block" id="M113"><mml:mrow><mml:mi>P</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msup><mml:mfenced close=")" open="(" separators=""><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:msub><mml:mi>k</mml:mi> <mml:mn>0</mml:mn></mml:msub></mml:mfrac></mml:mfenced> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mfrac><mml:mn>1</mml:mn> <mml:msub><mml:mi>k</mml:mi> <mml:mn>0</mml:mn></mml:msub></mml:mfrac> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(58)</label></disp-formula>
This distribution exhibits a mean connection probability of 1/<italic>k</italic><sub>0</sub> and a long tail. After the sampling of out-degrees, excitatory neurons are divided into “hubs” (out-degree <italic>k</italic> &gt; <italic>k</italic><sub>0</sub>) and “non-hubs” (<italic>k</italic> ≤ <italic>k</italic><sub>0</sub>). Postsynaptic neurons for non-hubs and inhibitory neurons are chosen randomly from the population consisting of all other neurons. However, for hub neurons, a fixed fraction <italic>f</italic> of all outgoing connections goes to other hubs. By varying <italic>f</italic> between 0 and 1, one can choose how densely connected the subnetwork of hubs will be. The “critical value” to keep in mind here is <italic>f</italic><sub>0</sub> = 0.35. If <italic>f</italic> &gt; <italic>f</italic><sub>0</sub>, hub neurons have a preference to connect to other hubs. Such a network is called “assortative”, otherwise it is called “disassortative”, see [<xref ref-type="bibr" rid="pcbi.1004963.ref003">3</xref>] for details. Similar networks have been studied in [<xref ref-type="bibr" rid="pcbi.1004963.ref035">35</xref>, <xref ref-type="bibr" rid="pcbi.1004963.ref036">36</xref>]. The effect of the geometric out-degree distribution on the distribution of network motifs is depicted in <xref ref-type="fig" rid="pcbi.1004963.g007">Fig 7</xref>.</p>
<fig id="pcbi.1004963.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004963.g007</object-id>
<label>Fig 7</label>
<caption>
<title>Contribution of tree motifs with longer total branch length increases in networks with excitatory hubs.</title>
<p>Top: Theoretical (narrow out-degree distribution approximation for random networks) and sample contributions (in non-regular networks) of the average third cumulant of <italic>T</italic><sub>6</sub> (see <xref ref-type="fig" rid="pcbi.1004963.g004">Fig 4</xref>) tree topologies with fixed branch lengths. Ticks on the x-axis code for the lengths of the branches of the tree. The ordering of the indices in the tick labels is done in a top-to-bottom and left-to-right fashion. The sample contributions were computed as averages of 3 independent realizations of an assortative network with a geometric out-degree distribution. Bottom: Theoretical and sample contributions to the average third cumulant of <italic>T</italic><sub>1</sub> tree topologies with fixed branch lengths.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004963.g007" xlink:type="simple"/>
</fig>
<p>If excitatory hubs preferentially connect to other hubs (for assortative networks), the number of relevant tree motifs with high total branch length grows in the network, and so does their combined strength. This is one major difference between assortative and random networks, and a reason why the contributions of longer trees in networks with hubs tend to be much larger than in Erdős-Rényi topologies. Of course, along the same lines, the number of “short” motifs (i.e. those with small total branch length) decreases (in comparison to their “longer” counterparts). This phenomenon is illustrated in <xref ref-type="fig" rid="pcbi.1004963.g007">Fig 7</xref>.</p>
<p>This discrepancy can also be used to say something about the topology of the network that generated a given set of recorded spike data. Indeed, once the connection probability and third order correlations have been estimated (e.g. with the help of k-statistics), one could compare the regular network theory predictions with the third order cumulants obtained from data. A large disparity between the two could imply, for example, the presence of hubs and a wide in- and out-degree distribution in the network that generated the data.</p>
</sec>
</sec>
<sec id="sec014" sec-type="conclusions">
<title>Discussion</title>
<p>In this work, we have studied connections between topology and measures of average third-order correlations in networks of spiking neurons. We have compared different connectivity rules with respect to their effect on the average joint third cumulant, <inline-formula id="pcbi.1004963.e114"><alternatives><graphic id="pcbi.1004963.e114g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e114" xlink:type="simple"/><mml:math display="inline" id="M114"><mml:msub><mml:mover accent="true"><mml:mi>κ</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mn>3</mml:mn></mml:msub></mml:math></alternatives></inline-formula>. Furthermore, we showed which topological motifs in the network contribute to the overall strength of third-order correlations. While our focus was on network models arising in neuroscience, we feel that the results presented here could as well be relevant in other fields, where correlations of higher-order play an important role.</p>
<p>As a handy computational model of spiking neuronal activity, we have used the Hawkes point process [<xref ref-type="bibr" rid="pcbi.1004963.ref027">27</xref>, <xref ref-type="bibr" rid="pcbi.1004963.ref028">28</xref>], which was originally introduced as a model of earthquake activity. It is sufficiently rich in order to model interesting dependencies between various types of events (in our case, spikes of different neurons), but still simple enough to be tractable. Indeed, these are the exact properties that make Hawkes processes quite useful models in neuroscience. They have been employed in the analysis of pairwise correlations between spike trains [<xref ref-type="bibr" rid="pcbi.1004963.ref003">3</xref>, <xref ref-type="bibr" rid="pcbi.1004963.ref037">37</xref>], modeling spike-timing dependent plasticity [<xref ref-type="bibr" rid="pcbi.1004963.ref038">38</xref>, <xref ref-type="bibr" rid="pcbi.1004963.ref039">39</xref>], and, very recently, to model single unit activity recorded on a monkey during a sensory-motor task [<xref ref-type="bibr" rid="pcbi.1004963.ref040">40</xref>].</p>
<p>Using the Hawkes process theory, we have shown that a linear stochastic point process model can reproduce not only the event rates and pairwise correlations in networks (as was already shown in [<xref ref-type="bibr" rid="pcbi.1004963.ref003">3</xref>]), but also its third-order joint cumulants, which are statistical measures of correlations between groups of three nodes. These cumulants can be seen as a quantification of “non-Gaussian” properties of the total population activity observed in time bins of a given size.</p>
<p>The problem of quantifying higher-order correlations is of some importance in computational neuroscience. It has been suggested a long time ago [<xref ref-type="bibr" rid="pcbi.1004963.ref041">41</xref>, <xref ref-type="bibr" rid="pcbi.1004963.ref042">42</xref>] that understanding the cooperative dynamics of populations of neurons would provide much needed insight into the neuron-level mechanisms of brain function. Indeed, there is now a large body of experimental evidence that supports the idea of computationally relevant correlations between neurons in a network [<xref ref-type="bibr" rid="pcbi.1004963.ref007">7</xref>, <xref ref-type="bibr" rid="pcbi.1004963.ref043">43</xref>–<xref ref-type="bibr" rid="pcbi.1004963.ref045">45</xref>]. The evidence for coordinated activity of neuronal spike trains, however, mostly relies on the correlations between pairs of nerve cells [<xref ref-type="bibr" rid="pcbi.1004963.ref046">46</xref>–<xref ref-type="bibr" rid="pcbi.1004963.ref050">50</xref>]. Unfortunately, it is becoming increasingly clear that pairwise correlations cannot explain the intricate dynamics of neuronal populations [<xref ref-type="bibr" rid="pcbi.1004963.ref009">9</xref>, <xref ref-type="bibr" rid="pcbi.1004963.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1004963.ref051">51</xref>, <xref ref-type="bibr" rid="pcbi.1004963.ref052">52</xref>] and that higher-order moments of spiking activity need to be taken into account.</p>
<p>Traditionally in neuroscience, higher-order synchrony has been almost exclusively investigated with the help of classical tools borrowed from statistical physics such as maximum entropy models [<xref ref-type="bibr" rid="pcbi.1004963.ref013">13</xref>–<xref ref-type="bibr" rid="pcbi.1004963.ref018">18</xref>, <xref ref-type="bibr" rid="pcbi.1004963.ref053">53</xref>]. In this approach, the quantifiers of higher-order coordination are the so-called “interaction parameters” of the binary exponential family. However, an alternative measure, commonly used in statistical literature, also exists—it is the joint cumulant. As already mentioned in [<xref ref-type="bibr" rid="pcbi.1004963.ref054">54</xref>, <xref ref-type="bibr" rid="pcbi.1004963.ref055">55</xref>], cumulant correlations are not identical to the higher order exponential family parameters (for details, see [<xref ref-type="bibr" rid="pcbi.1004963.ref054">54</xref>]). In a sense, it can be said that non-zero cumulants indicate the presence of additive common input (a well-known model for correlated stochastic signals, see [<xref ref-type="bibr" rid="pcbi.1004963.ref056">56</xref>–<xref ref-type="bibr" rid="pcbi.1004963.ref058">58</xref>]), while the interaction parameters of maximum entropy models measure multiplicative interactions. The mathematical differences between the two types of dependence are currently under investigation [<xref ref-type="bibr" rid="pcbi.1004963.ref059">59</xref>–<xref ref-type="bibr" rid="pcbi.1004963.ref061">61</xref>]. As our neuronal network model each neuron “feels” only the linear sum of spiking activity of its presynaptic partners, in this work we have opted for quantifying synchrony using joint cumulants. Finally, it may be worthwhile to note that there are other ways of generating time structured correlations of higher order in computational models (see, for example, [<xref ref-type="bibr" rid="pcbi.1004963.ref009">9</xref>], but also [<xref ref-type="bibr" rid="pcbi.1004963.ref062">62</xref>]).</p>
<p>In addition, by generalizing the result in [<xref ref-type="bibr" rid="pcbi.1004963.ref003">3</xref>], we have found that integrated third-order correlations (<italic>κ</italic><sup><italic>ijk</italic></sup>) also admit a representation in terms of sums of weights of certain topological sub-motifs in the network. While in the case of pairwise correlations between neurons these motifs were simple binary trees (see <xref ref-type="fig" rid="pcbi.1004963.g002">Fig 2</xref>), when dealing with third-order interactions the motifs become more complex (<xref ref-type="fig" rid="pcbi.1004963.g003">Fig 3</xref>) “trees with three leaves”, which are still manageable computationally. More precisely, it is the combined “strength” of all such trees containing a triplet of neurons that determine how often, on average, the activity of such a triplet exhibits coordinated spiking. Sadly, no concise matrix product formula is available for the whole third cumulant tensor {<italic>κ</italic><sup><italic>ijk</italic></sup>}<sub><italic>i</italic>, <italic>j</italic>, <italic>k</italic></sub> and one has to resort to writing down equations for individual components, which still offer the possibility of efficient estimation. Indeed, computing the theoretical cumulants <italic>κ</italic><sup><italic>ijk</italic></sup> for (close to) regular networks is much less computationally intensive than estimating them from data via <italic>k</italic>-statistics and only relies on simple algebraic manipulations of the connectivity matrix <italic>G</italic>.</p>
<p>We have also studied analytically the average third-order cumulant <inline-formula id="pcbi.1004963.e115"><alternatives><graphic id="pcbi.1004963.e115g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e115" xlink:type="simple"/><mml:math display="inline" id="M115"><mml:msub><mml:mover accent="true"><mml:mi>κ</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mn>3</mml:mn></mml:msub></mml:math></alternatives></inline-formula>, derived from the sum of joint cumulants of all possible triplets of neurons in the network. We have shown that the value of <inline-formula id="pcbi.1004963.e116"><alternatives><graphic id="pcbi.1004963.e116g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e116" xlink:type="simple"/><mml:math display="inline" id="M116"><mml:msub><mml:mover accent="true"><mml:mi>κ</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mn>3</mml:mn></mml:msub></mml:math></alternatives></inline-formula> in random networks of Erdős-Rényi type does not depend on fine-scale topological structure and is instead a function of global network parameters, such as the network size <italic>N</italic>, the connection probability <italic>p</italic> and total common input to groups of neurons. Furthermore, we have shown that, in the limit of very large networks, the dominating contribution to <inline-formula id="pcbi.1004963.e117"><alternatives><graphic id="pcbi.1004963.e117g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e117" xlink:type="simple"/><mml:math display="inline" id="M117"><mml:msub><mml:mover accent="true"><mml:mi>κ</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mn>3</mml:mn></mml:msub></mml:math></alternatives></inline-formula> comes from the combined weight of all trees with a specific topology (which we denoted <italic>T</italic><sub>6</sub>, see <xref ref-type="fig" rid="pcbi.1004963.g004">Fig 4</xref>) present in the network. Thus, for large, random networks, it is tree-like connectivity motifs of this topology that affects the average third cumulant most.</p>
<p>We were able to show that the contributions of individual subtrees to the average joint cumulant depend on specific topological properties of the tree, such as its number of branches, number of nodes and, interestingly, the out-degrees of its internal nodes (nodes that are not leaves as they have a nonzero out-degree). Not surprisingly, in a stable network (whose connectivity matrix <italic>G</italic> has a spectral radius less than 1), the absolute contributions of trees with a large number of branches decays to 0 as the number of branches increases. However, the sign of the total contribution turns out to depend both on the parity of the sum of all internal node out-degrees and the parity of the total branch length. This, in principle, allows one to determine whether the presence of a particular sub-tree in a network will increase or decrease the third cumulant, and thus allow to compute the total size of third-order interactions.</p>
<p>Finally, we considered a case in which our regular network approximation fails, networks with interconnected hub neurons. Similar networks were already considered in [<xref ref-type="bibr" rid="pcbi.1004963.ref003">3</xref>]. Their main characteristic is a heavy-tailed out-degree distribution (in the case we considered, it was geometric). Such networks are, in a sense, the opposite of an Erdős-Rényi type random network. The presence of interconnected hubs increases the number of subtrees in the network with large total branch length and, consequently, their overall contribution to the average joint third cumulant. Thus, such networks illustrate nicely how “higher-order” motifs can, for certain networks, influence the overall third-order cumulant structure, which is not possible in networks with narrow out-degree distributions.</p>
<p>As far as the limitations of our approach are concerned, it is important to note that the linear theory of Hawkes processes which we resorted to [<xref ref-type="bibr" rid="pcbi.1004963.ref029">29</xref>] is strictly valid only for purely excitatory networks, as the instantaneous rate function is not allowed to become negative. For the case discussed here, this may happen, as the networks are inhibition-dominated. However, in accordance with what was already mentioned in [<xref ref-type="bibr" rid="pcbi.1004963.ref027">27</xref>], the theoretical results remain approximately valid for networks with negative interactions, as long as the probability of the rate being negative is small. Still, an interesting generalization of our model, and the results achieved with it, would be the case of multiplicative interaction [<xref ref-type="bibr" rid="pcbi.1004963.ref063">63</xref>]. More generally, a point process model in which an non-negative nonlinearity is applied to <xref ref-type="disp-formula" rid="pcbi.1004963.e006">Eq 3</xref> yields a necessarily positive rate for any choice of interaction kernels. The computational approach one would have to use in this case in order to study the effect of topology on higher-order correlations would be quite different, though, as almost no analytical results exist for such models [<xref ref-type="bibr" rid="pcbi.1004963.ref064">64</xref>, <xref ref-type="bibr" rid="pcbi.1004963.ref065">65</xref>].</p>
</sec>
<sec id="sec015">
<title>Supporting Information</title>
<supplementary-material id="pcbi.1004963.s001" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004963.s001" xlink:type="simple">
<label>S1 Appendix</label>
<caption>
<title>Integrated covariances and joint third cumulants.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004963.s002" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004963.s002" xlink:type="simple">
<label>S2 Appendix</label>
<caption>
<title>Computation of <inline-formula id="pcbi.1004963.e118"><alternatives><graphic id="pcbi.1004963.e118g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004963.e118" xlink:type="simple"/><mml:math display="inline" id="M118"><mml:msub><mml:mover accent="true"><mml:mi>κ</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mn>3</mml:mn></mml:msub></mml:math></alternatives></inline-formula>.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004963.s003" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004963.s003" xlink:type="simple">
<label>S3 Appendix</label>
<caption>
<title>Derivation of the third-order joint cumulant formula.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>The authors thank the reviewers, as well as John Hertz for their comments on this paper. S. J. acknowledges the hospitality of NORDITA.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1004963.ref001">
<label>1</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bascompte</surname> <given-names>J</given-names></name>, <etal>et al</etal>. <article-title>Disentangling the web of life</article-title>. <source>Science</source>. <year>2009</year>;<volume>325</volume>(<issue>5939</issue>):<fpage>416</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.1170749" xlink:type="simple">10.1126/science.1170749</ext-link></comment> <object-id pub-id-type="pmid">19628856</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref002">
<label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Reynaud-Bouret</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Schbath</surname> <given-names>S</given-names></name>, <etal>et al</etal>. <article-title>Adaptive estimation for Hawkes processes; application to genome analysis</article-title>. <source>The Annals of Statistics</source>. <year>2010</year>;<volume>38</volume>(<issue>5</issue>):<fpage>2781</fpage>–<lpage>2822</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1214/10-AOS806" xlink:type="simple">10.1214/10-AOS806</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref003">
<label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Pernice</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Staude</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Cardanobile</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Rotter</surname> <given-names>S</given-names></name>. <article-title>How structure determines correlations in neuronal networks</article-title>. <source>PLoS Comput Biol</source>. <year>2011</year>;<volume>7</volume>(<issue>5</issue>):<fpage>e1002059</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1002059" xlink:type="simple">10.1371/journal.pcbi.1002059</ext-link></comment> <object-id pub-id-type="pmid">21625580</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref004">
<label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Strogatz</surname> <given-names>SH</given-names></name>. <article-title>Exploring complex networks</article-title>. <source>Nature</source>. <year>2001</year>;<volume>410</volume>(<issue>6825</issue>):<fpage>268</fpage>–<lpage>276</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/35065725" xlink:type="simple">10.1038/35065725</ext-link></comment> <object-id pub-id-type="pmid">11258382</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref005">
<label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Shadlen</surname> <given-names>MN</given-names></name>, <name name-style="western"><surname>Newsome</surname> <given-names>WT</given-names></name>. <article-title>The variable discharge of cortical neurons: implications for connectivity, computation, and information coding</article-title>. <source>The Journal of neuroscience</source>. <year>1998</year>;<volume>18</volume>(<issue>10</issue>):<fpage>3870</fpage>–<lpage>3896</lpage>. <object-id pub-id-type="pmid">9570816</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref006">
<label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Averbeck</surname> <given-names>BB</given-names></name>, <name name-style="western"><surname>Latham</surname> <given-names>PE</given-names></name>, <name name-style="western"><surname>Pouget</surname> <given-names>A</given-names></name>. <article-title>Neural correlations, population coding and computation</article-title>. <source>Nature Reviews Neuroscience</source>. <year>2006</year>;<volume>7</volume>(<issue>5</issue>):<fpage>358</fpage>–<lpage>366</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nrn1888" xlink:type="simple">10.1038/nrn1888</ext-link></comment> <object-id pub-id-type="pmid">16760916</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref007">
<label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Salinas</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Sejnowski</surname> <given-names>TJ</given-names></name>. <article-title>Correlated neuronal activity and the flow of neural information</article-title>. <source>Nature reviews neuroscience</source>. <year>2001</year>;<volume>2</volume>(<issue>8</issue>):<fpage>539</fpage>–<lpage>550</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/35086012" xlink:type="simple">10.1038/35086012</ext-link></comment> <object-id pub-id-type="pmid">11483997</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref008">
<label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Rossant</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Leijon</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Magnusson</surname> <given-names>AK</given-names></name>, <name name-style="western"><surname>Brette</surname> <given-names>R</given-names></name>. <article-title>Sensitivity of noisy neurons to coincident inputs</article-title>. <source>The Journal of Neuroscience</source>. <year>2011</year>;<volume>31</volume>(<issue>47</issue>):<fpage>17193</fpage>–<lpage>17206</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.2482-11.2011" xlink:type="simple">10.1523/JNEUROSCI.2482-11.2011</ext-link></comment> <object-id pub-id-type="pmid">22114286</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref009">
<label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kuhn</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Aertsen</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Rotter</surname> <given-names>S</given-names></name>. <article-title>Higher-order statistics of input ensembles and the response of simple model neurons</article-title>. <source>Neural Computation</source>. <year>2003</year>;<volume>15</volume>(<issue>1</issue>):<fpage>67</fpage>–<lpage>101</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/089976603321043702" xlink:type="simple">10.1162/089976603321043702</ext-link></comment> <object-id pub-id-type="pmid">12590820</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref010">
<label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Martignon</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Deco</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Laskey</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Diamond</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Freiwald</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Vaadia</surname> <given-names>E</given-names></name>. <article-title>Neural coding: higher-order temporal patterns in the neurostatistics of cell assemblies</article-title>. <source>Neural Computation</source>. <year>2000</year>;<volume>12</volume>(<issue>11</issue>):<fpage>2621</fpage>–<lpage>2653</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/089976600300014872" xlink:type="simple">10.1162/089976600300014872</ext-link></comment> <object-id pub-id-type="pmid">11110130</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref011">
<label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Yu</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Yang</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Nakahara</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Santos</surname> <given-names>GS</given-names></name>, <name name-style="western"><surname>Nikolić</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Plenz</surname> <given-names>D</given-names></name>. <article-title>Higher-order interactions characterized in cortical activity</article-title>. <source>The Journal of Neuroscience</source>. <year>2011</year>;<volume>31</volume>(<issue>48</issue>):<fpage>17514</fpage>–<lpage>17526</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.3127-11.2011" xlink:type="simple">10.1523/JNEUROSCI.3127-11.2011</ext-link></comment> <object-id pub-id-type="pmid">22131413</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref012">
<label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ohiorhenuan</surname> <given-names>IE</given-names></name>, <name name-style="western"><surname>Mechler</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Purpura</surname> <given-names>KP</given-names></name>, <name name-style="western"><surname>Schmid</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Hu</surname> <given-names>Q</given-names></name>, <name name-style="western"><surname>Victor</surname> <given-names>JD</given-names></name>. <article-title>Sparse coding and high-order correlations in fine-scale cortical networks</article-title>. <source>Nature</source>. <year>2010</year>;<volume>466</volume>(<issue>7306</issue>):<fpage>617</fpage>–<lpage>621</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature09178" xlink:type="simple">10.1038/nature09178</ext-link></comment> <object-id pub-id-type="pmid">20601940</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref013">
<label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Tkačik</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Marre</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Amodei</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Schneidman</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Bialek</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Berry</surname> <given-names>MJ</given-names> <suffix>II</suffix></name>. <article-title>Searching for collective behavior in a large network of sensory neurons</article-title>. <source>PLoS Comput Biol</source>. <year>2014</year>;<volume>10</volume>(<issue>1</issue>):<fpage>e1003408</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1003408" xlink:type="simple">10.1371/journal.pcbi.1003408</ext-link></comment> <object-id pub-id-type="pmid">24391485</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref014">
<label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Montani</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Ince</surname> <given-names>RA</given-names></name>, <name name-style="western"><surname>Senatore</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Arabzadeh</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Diamond</surname> <given-names>ME</given-names></name>, <name name-style="western"><surname>Panzeri</surname> <given-names>S</given-names></name>. <article-title>The impact of high-order interactions on the rate of synchronous discharge and information transmission in somatosensory cortex</article-title>. <source>Philosophical Transactions of the Royal Society of London A: Mathematical, Physical and Engineering Sciences</source>. <year>2009</year>;<volume>367</volume>(<issue>1901</issue>):<fpage>3297</fpage>–<lpage>3310</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1098/rsta.2009.0082" xlink:type="simple">10.1098/rsta.2009.0082</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref015">
<label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Köster</surname> <given-names>U</given-names></name>, <name name-style="western"><surname>Sohl-Dickstein</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Gray</surname> <given-names>CM</given-names></name>, <name name-style="western"><surname>Olshausen</surname> <given-names>BA</given-names></name>. <article-title>Modeling higher-order correlations within cortical microcolumns</article-title>. <source>PLoS Comput Biol</source>. <year>2014</year>;<volume>10</volume>(<issue>7</issue>):<fpage>e1003684</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1003684" xlink:type="simple">10.1371/journal.pcbi.1003684</ext-link></comment> <object-id pub-id-type="pmid">24991969</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref016">
<label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schneidman</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Berry</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Segev</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Bialek</surname> <given-names>W</given-names></name>. <article-title>Weak pairwise correlations imply strongly correlated network states in a neural population</article-title>. <source>Nature</source>. <year>2006</year>;<volume>440</volume>(<issue>7087</issue>):<fpage>1007</fpage>–<lpage>1012</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature04701" xlink:type="simple">10.1038/nature04701</ext-link></comment> <object-id pub-id-type="pmid">16625187</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref017">
<label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Shlens</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Field</surname> <given-names>GD</given-names></name>, <name name-style="western"><surname>Gauthier</surname> <given-names>JL</given-names></name>, <name name-style="western"><surname>Grivich</surname> <given-names>MI</given-names></name>, <name name-style="western"><surname>Petrusca</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Sher</surname> <given-names>A</given-names></name>, <etal>et al</etal>. <article-title>The structure of multi-neuron firing patterns in primate retina</article-title>. <source>The Journal of neuroscience</source>. <year>2006</year>;<volume>26</volume>(<issue>32</issue>):<fpage>8254</fpage>–<lpage>8266</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.1282-06.2006" xlink:type="simple">10.1523/JNEUROSCI.1282-06.2006</ext-link></comment> <object-id pub-id-type="pmid">16899720</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref018">
<label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Pillow</surname> <given-names>JW</given-names></name>, <name name-style="western"><surname>Shlens</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Paninski</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Sher</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Litke</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Chichilnisky</surname> <given-names>E</given-names></name>, <etal>et al</etal>. <article-title>Spatio-temporal correlations and visual signalling in a complete neuronal population</article-title>. <source>Nature</source>. <year>2008</year>;<volume>454</volume>(<issue>7207</issue>):<fpage>995</fpage>–<lpage>999</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature07140" xlink:type="simple">10.1038/nature07140</ext-link></comment> <object-id pub-id-type="pmid">18650810</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref019">
<label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Shimazaki</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Amari</surname> <given-names>Si</given-names></name>, <name name-style="western"><surname>Brown</surname> <given-names>EN</given-names></name>, <name name-style="western"><surname>Grün</surname> <given-names>S</given-names></name>. <article-title>State-space analysis of time-varying higher-order spike correlation for multiple neural spike train data</article-title>. <source>PLoS computational biology</source>. <year>2012</year>;<volume>8</volume>(<issue>3</issue>):<fpage>e1002385</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1002385" xlink:type="simple">10.1371/journal.pcbi.1002385</ext-link></comment> <object-id pub-id-type="pmid">22412358</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref020">
<label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hu</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Trousdale</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Josić</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Shea-Brown</surname> <given-names>E</given-names></name>. <article-title>Local paths to global coherence: cutting networks down to size</article-title>. <source>Physical Review E</source>. <year>2014</year>;<volume>89</volume>(<issue>3</issue>):<fpage>032802</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevE.89.032802" xlink:type="simple">10.1103/PhysRevE.89.032802</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref021">
<label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Cayco-Gajic</surname> <given-names>NA</given-names></name>, <name name-style="western"><surname>Zylberberg</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Shea-Brown</surname> <given-names>E</given-names></name>. <article-title>Triplet correlations among similarly tuned cells impact population coding</article-title>. <source>Frontiers in Computational Neuroscience</source>. <year>2015</year>;<volume>9</volume>:<fpage>57</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fncom.2015.00057" xlink:type="simple">10.3389/fncom.2015.00057</ext-link></comment> <object-id pub-id-type="pmid">26042024</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref022">
<label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Pernice</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Staude</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Cardanobile</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Rotter</surname> <given-names>S</given-names></name>. <article-title>Recurrent interactions in spiking networks with arbitrary topology</article-title>. <source>Physical review E</source>. <year>2012</year>;<volume>85</volume>(<issue>3</issue>):<fpage>031916</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevE.85.031916" xlink:type="simple">10.1103/PhysRevE.85.031916</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref023">
<label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Pernice</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Rotter</surname> <given-names>S</given-names></name>. <article-title>Reconstruction of sparse connectivity in neural networks from spike train covariances</article-title>. <source>Journal of Statistical Mechanics: Theory and Experiment</source>. <year>2013</year>(<issue>03</issue>):<fpage>P03008</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004963.ref024">
<label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Rangan</surname> <given-names>AV</given-names></name>. <article-title>Diagrammatic expansion of pulse-coupled network dynamics</article-title>. <source>Physical review letters</source>. <year>2009</year>;<volume>102</volume>(<issue>15</issue>):<fpage>158101</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevLett.102.158101" xlink:type="simple">10.1103/PhysRevLett.102.158101</ext-link></comment> <object-id pub-id-type="pmid">19518674</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref025">
<label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Rangan</surname> <given-names>AV</given-names></name>. <article-title>Diagrammatic expansion of pulse-coupled network dynamics in terms of subnetworks</article-title>. <source>Physical Review E</source>. <year>2009</year>;<volume>80</volume>(<issue>3</issue>):<fpage>036101</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevE.80.036101" xlink:type="simple">10.1103/PhysRevE.80.036101</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref026">
<label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Trousdale</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Hu</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Shea-Brown</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Josic</surname> <given-names>K</given-names></name>. <article-title>Impact of network structure and cellular response on spike time correlations</article-title>. <source>PLoS Comput Biol</source>. <year>2012</year>;<volume>8</volume>(<issue>3</issue>):<fpage>e1002408</fpage>–<lpage>e1002408</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1002408" xlink:type="simple">10.1371/journal.pcbi.1002408</ext-link></comment> <object-id pub-id-type="pmid">22457608</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref027">
<label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hawkes</surname> <given-names>AG</given-names></name>. <article-title>Spectra of some self-exciting and mutually exciting point processes</article-title>. <source>Biometrika</source>. <year>1971</year>;<volume>58</volume>(<issue>1</issue>):<fpage>83</fpage>–<lpage>90</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/biomet/58.1.83" xlink:type="simple">10.1093/biomet/58.1.83</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref028">
<label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hawkes</surname> <given-names>AG</given-names></name>. <article-title>Point Spectra of Some Mutually Exciting Point Processes</article-title>. <source>Journal of the Royal Statistical Society Series B (Methodological)</source>. <volume>33</volume>(<issue>3</issue>):pp. <fpage>438</fpage>–<lpage>443</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004963.ref029">
<label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Jovanović</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Hertz</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Rotter</surname> <given-names>S</given-names></name>. <article-title>Cumulants of Hawkes point processes</article-title>. <source>Phys Rev E</source>. <year>2015</year> <month>Apr</month>;<volume>91</volume>:<fpage>042802</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevE.91.042802" xlink:type="simple">10.1103/PhysRevE.91.042802</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref030">
<label>30</label>
<mixed-citation publication-type="other" xlink:type="simple">Bacry E, Muzy JF. Second order statistics characterization of Hawkes processes and non-parametric estimation. arXiv preprint arXiv:14010903. 2014;.</mixed-citation>
</ref>
<ref id="pcbi.1004963.ref031">
<label>31</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>McCullagh</surname> <given-names>P</given-names></name>. <source>Tensor methods in statistics</source>. <volume>vol. 161</volume>. <publisher-name>Chapman and Hall</publisher-name> <publisher-loc>London</publisher-loc>; <year>1987</year>.</mixed-citation>
</ref>
<ref id="pcbi.1004963.ref032">
<label>32</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Lukacs</surname> <given-names>E</given-names></name>. <source>Characteristics functions</source>. <publisher-name>Griffin</publisher-name>, <publisher-loc>London</publisher-loc>. <year>1970</year>;.</mixed-citation>
</ref>
<ref id="pcbi.1004963.ref033">
<label>33</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Diesmann</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Gewaltig</surname> <given-names>MO</given-names></name>. <article-title>NEST: An environment for neural systems simulations</article-title>. <source>Forschung und wisschenschaftliches Rechnen, Beiträge zum Heinz-Billing-Preis</source>. <year>2001</year>;<volume>58</volume>:<fpage>43</fpage>–<lpage>70</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004963.ref034">
<label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Rajan</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Abbott</surname> <given-names>L</given-names></name>. <article-title>Eigenvalue spectra of random matrices for neural networks</article-title>. <source>Physical review letters</source>. <year>2006</year>;<volume>97</volume>(<issue>18</issue>):<fpage>188104</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevLett.97.188104" xlink:type="simple">10.1103/PhysRevLett.97.188104</ext-link></comment> <object-id pub-id-type="pmid">17155583</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref035">
<label>35</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Roxin</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Hakim</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Brunel</surname> <given-names>N</given-names></name>. <article-title>The statistics of repeating patterns of cortical activity can be reproduced by a model network of stochastic binary neurons</article-title>. <source>The Journal of neuroscience</source>. <year>2008</year>;<volume>28</volume>(<issue>42</issue>):<fpage>10734</fpage>–<lpage>10745</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.1016-08.2008" xlink:type="simple">10.1523/JNEUROSCI.1016-08.2008</ext-link></comment> <object-id pub-id-type="pmid">18923048</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref036">
<label>36</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Rubinov</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Sporns</surname> <given-names>O</given-names></name>. <article-title>Complex network measures of brain connectivity: uses and interpretations</article-title>. <source>Neuroimage</source>. <year>2010</year>;<volume>52</volume>(<issue>3</issue>):<fpage>1059</fpage>–<lpage>1069</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuroimage.2009.10.003" xlink:type="simple">10.1016/j.neuroimage.2009.10.003</ext-link></comment> <object-id pub-id-type="pmid">19819337</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref037">
<label>37</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Krumin</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Reutsky</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Shoham</surname> <given-names>S</given-names></name>. <article-title>Correlation-based analysis and generation of multiple spike trains using Hawkes models with an exogenous input</article-title>. <source>Frontiers in Computational Neuroscience</source>. <year>2010</year>;<volume>4</volume>(<issue>147</issue>). Available from: <ext-link ext-link-type="uri" xlink:href="http://www.frontiersin.org/computational_neuroscience/10.3389/fncom.2010.00147/abstract" xlink:type="simple">http://www.frontiersin.org/computational_neuroscience/10.3389/fncom.2010.00147/abstract</ext-link>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fncom.2010.00147" xlink:type="simple">10.3389/fncom.2010.00147</ext-link></comment> <object-id pub-id-type="pmid">21151360</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref038">
<label>38</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gilson</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Burkitt</surname> <given-names>AN</given-names></name>, <name name-style="western"><surname>Grayden</surname> <given-names>DB</given-names></name>, <name name-style="western"><surname>Thomas</surname> <given-names>DA</given-names></name>, <name name-style="western"><surname>van Hemmen</surname> <given-names>JL</given-names></name>. <article-title>Emergence of network structure due to spike-timing-dependent plasticity in recurrent neuronal networks. I. Input selectivity–strengthening correlated input pathways</article-title>. <source>Biological cybernetics</source>. <year>2009</year>;<volume>101</volume>(<issue>2</issue>):<fpage>81</fpage>–<lpage>102</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s00422-009-0319-4" xlink:type="simple">10.1007/s00422-009-0319-4</ext-link></comment> <object-id pub-id-type="pmid">19536560</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref039">
<label>39</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kempter</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Gerstner</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Van Hemmen</surname> <given-names>JL</given-names></name>. <article-title>Hebbian learning and spiking neurons</article-title>. <source>Physical Review E</source>. <year>1999</year>;<volume>59</volume>(<issue>4</issue>):<fpage>4498</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevE.59.4498" xlink:type="simple">10.1103/PhysRevE.59.4498</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref040">
<label>40</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Reynaud-Bouret</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Rivoirard</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Grammont</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Tuleau-Malot</surname> <given-names>C</given-names></name>. <article-title>Goodness-of-fit tests and nonparametric adaptive estimation for spike train analysis</article-title>. <source>Journal of mathematical neuroscience</source>. <year>2014</year>;<volume>4</volume>(<issue>3</issue>). <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1186/2190-8567-4-3" xlink:type="simple">10.1186/2190-8567-4-3</ext-link></comment> <object-id pub-id-type="pmid">24742008</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref041">
<label>41</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Hebb</surname> <given-names>DO</given-names></name>. <source>The Organization of Behavior: A Neuropsychological Theory</source>. <edition>New ed</edition> ed. <publisher-loc>New York</publisher-loc>: <publisher-name>Wiley</publisher-name>;<year>1949</year></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref042">
<label>42</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gerstein</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Bedenbaugh</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Aertsen</surname> <given-names>AM</given-names></name>. <article-title>Neuronal assemblies</article-title>. <source>Biomedical Engineering, IEEE Transactions on</source>. <year>1989</year>;<volume>36</volume>(<issue>1</issue>):<fpage>4</fpage>–<lpage>14</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1109/10.16444" xlink:type="simple">10.1109/10.16444</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref043">
<label>43</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Lestienne</surname> <given-names>R</given-names></name>. <article-title>Spike timing, synchronization and information processing on the sensory side of the central nervous system</article-title>. <source>Progress in neurobiology</source>. <year>2001</year>;<volume>65</volume>(<issue>6</issue>):<fpage>545</fpage>–<lpage>591</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0301-0082(01)00019-3" xlink:type="simple">10.1016/S0301-0082(01)00019-3</ext-link></comment> <object-id pub-id-type="pmid">11728644</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref044">
<label>44</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Womelsdorf</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Fries</surname> <given-names>P</given-names></name>.benton toner <article-title>The role of neuronal synchronization in selective attention</article-title>. <source>Current opinion in neurobiology</source>. <year>2007</year>;<volume>17</volume>(<issue>2</issue>):<fpage>154</fpage>–<lpage>160</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.conb.2007.02.002" xlink:type="simple">10.1016/j.conb.2007.02.002</ext-link></comment> <object-id pub-id-type="pmid">17306527</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref045">
<label>45</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kohn</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Zandvakili</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Smith</surname> <given-names>MA</given-names></name>. <article-title>Correlations and brain states: from electrophysiology to functional imaging</article-title>. <source>Current opinion in neurobiology</source>. <year>2009</year>;<volume>19</volume>(<issue>4</issue>):<fpage>434</fpage>–<lpage>438</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.conb.2009.06.007" xlink:type="simple">10.1016/j.conb.2009.06.007</ext-link></comment> <object-id pub-id-type="pmid">19608406</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref046">
<label>46</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gray</surname> <given-names>CM</given-names></name>, <name name-style="western"><surname>Singer</surname> <given-names>W</given-names></name>. <article-title>Stimulus-specific neuronal oscillations in orientation columns of cat visual cortex</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>1989</year> <month>Mar</month>;<volume>86</volume>(<issue>5</issue>):<fpage>1698</fpage>–<lpage>1702</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.86.5.1698" xlink:type="simple">10.1073/pnas.86.5.1698</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref047">
<label>47</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Vaadia</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Haalman</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Abeles</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Bergman</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Prut</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Slovin</surname> <given-names>H</given-names></name>, <etal>et al</etal>. <article-title>Dynamics of neuronal interactions in monkey cortex in relation to behavioural events</article-title>. <source>Nature</source>. <year>1995</year>;<volume>373</volume>(<issue>6514</issue>):<fpage>515</fpage>–<lpage>518</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/373515a0" xlink:type="simple">10.1038/373515a0</ext-link></comment> <object-id pub-id-type="pmid">7845462</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref048">
<label>48</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Riehle</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Grün</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Diesmann</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Aertsen</surname> <given-names>A</given-names></name>. <article-title>Spike synchronization and rate modulation differentially involved in motor cortical function</article-title>. <source>Science</source>. <year>1997</year>;<volume>278</volume>(<issue>5345</issue>):<fpage>1950</fpage>–<lpage>1953</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.278.5345.1950" xlink:type="simple">10.1126/science.278.5345.1950</ext-link></comment> <object-id pub-id-type="pmid">9395398</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref049">
<label>49</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bair</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Zohary</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Newsome</surname> <given-names>WT</given-names></name>. <article-title>Correlated firing in macaque visual area MT: time scales and relationship to behavior</article-title>. <source>The journal of Neuroscience</source>. <year>2001</year>;<volume>21</volume>(<issue>5</issue>):<fpage>1676</fpage>–<lpage>1697</lpage>. <object-id pub-id-type="pmid">11222658</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref050">
<label>50</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kohn</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Smith</surname> <given-names>MA</given-names></name>. <article-title>Stimulus dependence of neuronal correlation in primary visual cortex of the macaque</article-title>. <source>The Journal of neuroscience</source>. <year>2005</year>;<volume>25</volume>(<issue>14</issue>):<fpage>3661</fpage>–<lpage>3673</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.5106-04.2005" xlink:type="simple">10.1523/JNEUROSCI.5106-04.2005</ext-link></comment> <object-id pub-id-type="pmid">15814797</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref051">
<label>51</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Martignon</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Von Hassein</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Grün</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Aertsen</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Palm</surname> <given-names>G</given-names></name>. <article-title>Detecting higher-order interactions among the spiking events in a group of neurons</article-title>. <source>Biological cybernetics</source>. <year>1995</year>;<volume>73</volume>(<issue>1</issue>):<fpage>69</fpage>–<lpage>81</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/BF00199057" xlink:type="simple">10.1007/BF00199057</ext-link></comment> <object-id pub-id-type="pmid">7654851</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref052">
<label>52</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bohté</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Spekreijse</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Roelfsema</surname> <given-names>PR</given-names></name>. <article-title>The effects of pair-wise and higher-order correlations on the firing rate of a postsynaptic neuron</article-title>. <source>Neural Computation</source>. <year>2000</year>;<volume>12</volume>(<issue>1</issue>):<fpage>153</fpage>–<lpage>179</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/089976600300015934" xlink:type="simple">10.1162/089976600300015934</ext-link></comment> <object-id pub-id-type="pmid">10636937</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref053">
<label>53</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Nakahara</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Amari</surname> <given-names>Si</given-names></name>. <article-title>Information-geometric measure for neural spikes</article-title>. <source>Neural Computation</source>. <year>2002</year>;<volume>14</volume>(<issue>10</issue>):<fpage>2269</fpage>–<lpage>2316</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/08997660260293238" xlink:type="simple">10.1162/08997660260293238</ext-link></comment> <object-id pub-id-type="pmid">12396564</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref054">
<label>54</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Staude</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Grün</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Rotter</surname> <given-names>S</given-names></name>. <chapter-title>Higher-order correlations and cumulants</chapter-title>. In: <source>Analysis of parallel spike trains</source>. <publisher-name>Springer</publisher-name>; <year>2010</year>. p. <fpage>253</fpage>–<lpage>280</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004963.ref055">
<label>55</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Staude</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Rotter</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Grün</surname> <given-names>S</given-names></name>. <article-title>CuBIC: cumulant based inference of higher-order correlations in massively parallel spike trains</article-title>. <source>Journal of Computational Neuroscience</source>. <year>2010</year>;<volume>29</volume>(<issue>1–2</issue>):<fpage>327</fpage>–<lpage>350</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s10827-009-0195-x" xlink:type="simple">10.1007/s10827-009-0195-x</ext-link></comment> <object-id pub-id-type="pmid">19862611</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref056">
<label>56</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>De La Rocha</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Doiron</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Shea-Brown</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Josić</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Reyes</surname> <given-names>A</given-names></name>. <article-title>Correlation between neural spike trains increases with firing rate</article-title>. <source>Nature</source>. <year>2007</year>;<volume>448</volume>(<issue>7155</issue>):<fpage>802</fpage>–<lpage>806</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature06028" xlink:type="simple">10.1038/nature06028</ext-link></comment> <object-id pub-id-type="pmid">17700699</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref057">
<label>57</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Staude</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Rotter</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Grün</surname> <given-names>S</given-names></name>. <article-title>Can spike coordination be differentiated from rate covariation?</article-title> <source>Neural Computation</source>. <year>2008</year>;<volume>20</volume>(<issue>8</issue>):<fpage>1973</fpage>–<lpage>1999</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/neco.2008.06-07-550" xlink:type="simple">10.1162/neco.2008.06-07-550</ext-link></comment> <object-id pub-id-type="pmid">18336077</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref058">
<label>58</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Tetzlaff</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Rotter</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Stark</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Abeles</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Aertsen</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Diesmann</surname> <given-names>M</given-names></name>. <article-title>Dependence of neuronal correlations on filter characteristics and marginal spike train statistics</article-title>. <source>Neural computation</source>. <year>2008</year>;<volume>20</volume>(<issue>9</issue>):<fpage>2133</fpage>–<lpage>2184</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/neco.2008.05-07-525" xlink:type="simple">10.1162/neco.2008.05-07-525</ext-link></comment> <object-id pub-id-type="pmid">18439140</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref059">
<label>59</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Darroch</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Speed</surname> <given-names>T</given-names></name>. <article-title>Additive and multiplicative models and interactions</article-title>. <source>The Annals of Statistics</source>. <year>1983</year>;p. <fpage>724</fpage>–<lpage>738</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1214/aos/1176346240" xlink:type="simple">10.1214/aos/1176346240</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref060">
<label>60</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Streitberg</surname> <given-names>B</given-names></name>. <article-title>Lancaster interactions revisited</article-title>. <source>The Annals of Statistics</source>. <year>1990</year>;p. <fpage>1878</fpage>–<lpage>1885</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1214/aos/1176347885" xlink:type="simple">10.1214/aos/1176347885</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref061">
<label>61</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ip</surname> <given-names>EH</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>YJ</given-names></name>, <name name-style="western"><surname>Yeh</surname> <given-names>Yn</given-names></name>. <article-title>Structural decompositions of multivariate distributions with applications in moment and cumulant</article-title>. <source>Journal of multivariate analysis</source>. <year>2004</year>;<volume>89</volume>(<issue>1</issue>):<fpage>119</fpage>–<lpage>134</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.jmva.2003.09.001" xlink:type="simple">10.1016/j.jmva.2003.09.001</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref062">
<label>62</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Trousdale</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Hu</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Shea-Brown</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Josic</surname> <given-names>K</given-names></name>. <article-title>A generative spike train model with time-structured higher order correlations</article-title>. <source>Frontiers in Computational Neuroscience</source>. <year>2013</year>;<volume>7</volume>(<issue>84</issue>). Available from: <ext-link ext-link-type="uri" xlink:href="http://www.frontiersin.org/computational_neuroscience/10.3389/fncom.2013.00084/abstract" xlink:type="simple">http://www.frontiersin.org/computational_neuroscience/10.3389/fncom.2013.00084/abstract</ext-link>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fncom.2013.00084" xlink:type="simple">10.3389/fncom.2013.00084</ext-link></comment> <object-id pub-id-type="pmid">23908626</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref063">
<label>63</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Cardanobile</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Rotter</surname> <given-names>S</given-names></name>. <article-title>Multiplicatively interacting point processes and applications to neural modeling</article-title>. <source>Journal of computational neuroscience</source>. <year>2010</year>;<volume>28</volume>(<issue>2</issue>):<fpage>267</fpage>–<lpage>284</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s10827-009-0204-0" xlink:type="simple">10.1007/s10827-009-0204-0</ext-link></comment> <object-id pub-id-type="pmid">20052525</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref064">
<label>64</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bremaud</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Massoulie</surname> <given-names>L</given-names></name>. <article-title>Stability of Nonlinear Hawkes Processes</article-title>. <source>The Annals of Probability</source>. <year>1996</year>;<volume>24</volume>(<issue>3</issue>):pp. <fpage>1563</fpage>–<lpage>1588</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1214/aop/1065725193" xlink:type="simple">10.1214/aop/1065725193</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004963.ref065">
<label>65</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Zhu</surname> <given-names>L</given-names></name>. <article-title>Central Limit Theorem for Nonlinear Hawkes Processes</article-title>. <source>Journal of Applied Probability</source>. <year>2013</year>;(<issue>50</issue>):<fpage>760</fpage>–<lpage>771</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1239/jap/1378401234" xlink:type="simple">10.1239/jap/1378401234</ext-link></comment></mixed-citation>
</ref>
</ref-list>
</back>
</article>
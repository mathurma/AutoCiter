<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-14-02017</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1004288</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Encoder-Decoder Optimization for Brain-Computer Interfaces</article-title>
<alt-title alt-title-type="running-head">BCI Optimization</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<name name-style="western">
<surname>Merel</surname> <given-names>Josh</given-names></name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Pianto</surname> <given-names>Donald M.</given-names></name>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Cunningham</surname> <given-names>John P.</given-names></name>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Paninski</surname> <given-names>Liam</given-names></name>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
</contrib>
</contrib-group>
<aff id="aff001">
<label>1</label>
<addr-line>Neurobiology and Behavior Program, Columbia University, New York, New York, United States of America</addr-line>
</aff>
<aff id="aff002">
<label>2</label>
<addr-line>Statistics Department, Columbia University, New York, New York, United States of America</addr-line>
</aff>
<aff id="aff003">
<label>3</label>
<addr-line>Statistics Department, University of Bras√≠lia, Bras√≠lia, Distrito Federal, Brazil</addr-line>
</aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Stevenson</surname> <given-names>Ian H.</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>University of Connecticut, UNITED STATES</addr-line>
</aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<fn fn-type="con" id="contrib001">
<p>Conceived and designed the experiments: JM JPC LP. Performed the experiments: JM. Analyzed the data: JM. Contributed reagents/materials/analysis tools: JM DMP JPC LP. Wrote the paper: JM DMP JPC LP.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">jsmerel@gmail.com</email></corresp>
</author-notes>
<pub-date pub-type="collection">
<month>6</month>
<year>2015</year>
</pub-date>
<pub-date pub-type="epub">
<day>1</day>
<month>6</month>
<year>2015</year>
</pub-date>
<volume>11</volume>
<issue>6</issue>
<elocation-id>e1004288</elocation-id>
<history>
<date date-type="received">
<day>5</day>
<month>11</month>
<year>2014</year>
</date>
<date date-type="accepted">
<day>14</day>
<month>4</month>
<year>2015</year>
</date>
</history>
<permissions>
<copyright-year>2015</copyright-year>
<copyright-holder>Merel et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1004288" xlink:type="simple"/>
<abstract>
<p>Neuroprosthetic brain-computer interfaces are systems that decode neural activity into useful control signals for effectors, such as a cursor on a computer screen. It has long been recognized that both the user and decoding system can adapt to increase the accuracy of the end effector. Co-adaptation is the process whereby a user learns to control the system in conjunction with the decoder adapting to learn the user's neural patterns. We provide a mathematical framework for co-adaptation and relate co-adaptation to the joint optimization of the user's control scheme ("encoding model") and the decoding algorithm's parameters. When the assumptions of that framework are respected, co-adaptation cannot yield better performance than that obtainable by an optimal initial choice of fixed decoder, coupled with optimal user learning. For a specific case, we provide numerical methods to obtain such an optimized decoder. We demonstrate our approach in a model brain-computer interface system using an online prosthesis simulator, a simple human-in-the-loop pyschophysics setup which provides a non-invasive simulation of the BCI setting. These experiments support two claims: that users can learn encoders matched to fixed, optimal decoders and that, once learned, our approach yields expected performance advantages.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author Summary</title>
<p>Brain-computer interfaces are systems which allow a user to control a device in their environment via their neural activity. The system consists of hardware used to acquire signals from the brain of the user, algorithms to decode the signals, and some effector in the world that the user will be able to control, such as a cursor on a computer screen. When the user can see the effector under control, the system is closed-loop, such that the user can learn based on discrepancies between intended and actual kinematic outcomes. During training sessions where the user has specified objectives, the decoding algorithm can be updated as well based on discrepancies between what the user is supposed to be doing and what was decoded. When both the user and the decoding algorithm are simultaneously co-adapting, performance can improve. We propose a mathematical framework which contextualizes co-adaptation as a joint optimization of the user‚Äôs control scheme and the decoding algorithm, and we relate co-adaptation to optimal, fixed (non-adaptive) choices of decoder. We use simulation and human psychophysics experiments intended to model the BCI setting to demonstrate the utility of this approach.</p>
</abstract>
<funding-group>
<funding-statement>DMP recieved funding from Coordination for the Improvement of Higher Education Personnel (CAPES) for the research grant he received during the execution of this project (BEX 2353/13-0, <ext-link ext-link-type="uri" xlink:type="simple" xlink:href="http://capes.gov.br">http://capes.gov.br</ext-link>). JPC and LP were supported by the Simons Foundation (SCGB#325171 and SCGB#325233, <ext-link ext-link-type="uri" xlink:type="simple" xlink:href="http://www.simonsfoundation.org/">http://www.simonsfoundation.org/</ext-link>), the Grossman Center at Columbia University (<ext-link ext-link-type="uri" xlink:type="simple" xlink:href="http://grossmancenter.columbia.edu/">http://grossmancenter.columbia.edu/</ext-link>), and the Gatsby Charitable Trust (<ext-link ext-link-type="uri" xlink:type="simple" xlink:href="http://www.gatsby.org.uk/">http://www.gatsby.org.uk/</ext-link>). LP was also supported by an National Science Foundation CAREER award (<ext-link ext-link-type="uri" xlink:type="simple" xlink:href="http://www.nsf.gov/index.jsp">http://www.nsf.gov/index.jsp</ext-link>). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="8"/>
<table-count count="0"/>
<page-count count="25"/>
</counts>
<custom-meta-group>
<custom-meta id="data-availability" xlink:type="simple">
<meta-name>Data Availability</meta-name>
<meta-value>All relevant data are within the paper and its Supporting Information files.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Brain-computer interfaces (BCI) allow for a user to control effectors, such as a cursor on a computer screen, by the modulation of neural activity. For this approach to be practical for clinical settings, performance optimization through user learning and decoder tuning is a critical issue (see [<xref ref-type="bibr" rid="pcbi.1004288.ref001">1</xref>] for review). While it is clear that closed-loop control (i.e. control with user feedback) differs from open-loop, off-line decoding [<xref ref-type="bibr" rid="pcbi.1004288.ref002">2</xref>], there is much uncertainty as to the benefit of co-adaptation, namely using adaptive decoding algorithms in a setting where the user is also learning. There is optimism that co-adaptation should yield performance better than the simpler scheme of presenting a fixed decoder in closed-loop and user learning, but a rigorous framework for clarifying these issues has been lacking. Here we offer such a theoretical framework. According to this theory, for arbitrary, fixed decoders, performance after the user has learned should differ, but for a correct choice of fixed decoder, only the user needs to learn in order to obtain optimal performance. While this result may initially seem surprising, it becomes apparent when the problem is cast as a joint optimization over encoders and decoders. We begin by reviewing co-adaptation and then motivate our approach.</p>
<sec id="sec002">
<title>Co-adaptation</title>
<p>When the BCI system is closed-loop such that both the user can learn and the decoding algorithm can adapt, we have a setting which permits co-adaptation [<xref ref-type="bibr" rid="pcbi.1004288.ref003">3</xref>, <xref ref-type="bibr" rid="pcbi.1004288.ref004">4</xref>]. Changes in system performance may be driven by distinct types of adaptation: (1) All of the adaptation may occur due to the decoder and the user might not learn on relevant timescales [<xref ref-type="bibr" rid="pcbi.1004288.ref005">5</xref>]. (2) The user may learn in response to a fixed decoder [<xref ref-type="bibr" rid="pcbi.1004288.ref006">6</xref>, <xref ref-type="bibr" rid="pcbi.1004288.ref007">7</xref>]. (3) Both the user and the decoder might change, but the end result might perform no better than if only either the decoder or the user had learned. (4) In the most fortunate case, co-adaptation might be able to permit some synergistic result where both the user and the decoder learn in a collaborative fashion which yields high performance. Results in the literature hint suggestively at possibility (4), yet it is difficult to distinguish this from possibility (3) because even if both decoder and user adapt, it may not be clear which drove the performance improvements [<xref ref-type="bibr" rid="pcbi.1004288.ref004">4</xref>]. Here we investigate this open question.</p>
<p>While previous work has examined how decoder parameters should adapt in closed-loop settings in order to improve over static decoders [<xref ref-type="bibr" rid="pcbi.1004288.ref005">5</xref>, <xref ref-type="bibr" rid="pcbi.1004288.ref008">8</xref>, <xref ref-type="bibr" rid="pcbi.1004288.ref009">9</xref>], there has not been an emphasis on doing so while explicitly considering how the user adapts. We define the decoder as the external system which decodes neural activity into end effector (BCI) control signals. The encoder then is the user‚Äôs internal encoding of intention into neural activity. As a clarifying example, neurons with simple tuning curves imply a linear encoding model in some cases, and a user‚Äôs adaptation of the encoder could correspond directly to tuning curve shifts [<xref ref-type="bibr" rid="pcbi.1004288.ref004">4</xref>, <xref ref-type="bibr" rid="pcbi.1004288.ref006">6</xref>, <xref ref-type="bibr" rid="pcbi.1004288.ref007">7</xref>, <xref ref-type="bibr" rid="pcbi.1004288.ref010">10</xref>]. For a given, fixed decoder, different encoding models will perform differently and better encoders will be those that, in some sense, match the decoder well. We will show that it is possible to compute the ‚Äúbest‚Äù encoding model for a given decoder‚Äîthat is, some encoding model exists that minimizes the mean squared error (MSE) performance for a given decoder subject to signal-to-noise ratio (SNR) constraints. Similarly, for a given encoding model, there exists a best decoder in the MSE sense [<xref ref-type="bibr" rid="pcbi.1004288.ref011">11</xref>]. When a given decoder is presented to a user, optimal performance will be obtained if the user adapts such that encoding is optimally matched to the decoder. With this knowledge, one might imagine it useful to attempt to shape the user‚Äôs neural tuning properties [<xref ref-type="bibr" rid="pcbi.1004288.ref012">12</xref>] or otherwise attempt to guide the user to a certain encoding scheme which has been determined will optimize performance.</p>
</sec>
<sec id="sec003">
<title>Motivation for our approach</title>
<p>Conceptually motivated by co-adaptation and BCI-user learning, we propose a framework for jointly optimizing the encoding model and decoder of a BCI under a minimum mean square error (MMSE) objective. The central premise of this work is that closed-loop co-adaptation is a special case of this joint encoder-decoder optimization problem, so an optimal decoder can be computed in advance, effectively circumventing the co-adaptation process. The core of our approach amounts to ‚Äúpre-computing‚Äù the limit of an idealized co-adaptation process in which the user (hypothetically) optimally learns in order to obtain an optimized encoder-decoder pair. Instead of focusing on the temporal dynamics of learning in closed-loop [<xref ref-type="bibr" rid="pcbi.1004288.ref011">11</xref>], we abstract to the space of encoder-decoder pairs and characterize how well different encoder-decoder pairs perform relative to one another. We pre-compute an optimal decoder which we can present as a fixed decoder to the user; given our modeling assumptions, the performance of this decoder by definition should not be surpassed by one obtained through co-adaptation. We emphasize that closed-loop learning by the user will still be critical to learn to control the fixed decoder, but that the decoder will not also need to be adapted.</p>
<p>In a very general sense, learning by both the user and the decoder is equivalent to an optimization of performance with respect to these components. This perspective is essential, as it allows us to critically investigate co-adaptation as a mathematical optimization procedure, rather than an ill-defined ‚Äúsynergistic‚Äù training process. Co-adaptation then amounts to a specific approach to optimizing this objective over time‚Äîa coordinate descent approach where the user updates the encoder, and then the BCI system updates the decoder, iteratively. Seen from this perspective, it becomes clear that this objective function over encoder-decoder pairs could instead be descended using some other optimization strategy, and then a fixed, pre-optimized decoder could be presented to the user and learned. Such a setting would obviate co-adaptation. This approach could break down in a few key places: (1) The optimization could be intractable. (2) We may not be able to characterize the user objective. (3) We may not be able to characterize the constraints on user learning.</p>
<p>It is worth emphasizing that these issues are present for co-adaptation as much as any generic optimization approach. Co-adaptation may not do a good job of obtaining optima of the objective function, and without knowing the user‚Äôs objective or constraints on user learning, co-adaptive decoder updates may be very difficult to tune or suboptimal.</p>
<p>In the remainder of this work, we specify a MSE objective, and we work through the joint encoder-decoder optimization framework for the case when encoding is linear and the decoder is a steady state Kalman Filter (SSKF). We assume that the SNR of the neurons is constrained and that it is difficult for the user to learn encoding models in which the correlation structure of the neural activity must change too much. We also assume that the user is aware of the MSE objective and is motivated to optimize this objective. Our model form is broadly consistent with other Kalman Filter decoding schemes employed in contemporary BCI. However, in particular settings, the objective function and the constraints on learning of the encoding model could be specialized. We return to the opportunity for specialization in the discussion after presenting our results.</p>
<p>Finally, we validate the pre-computed decoder in computer simulations as well as in an online prosthesis simulator (OPS) [<xref ref-type="bibr" rid="pcbi.1004288.ref013">13</xref>], a psychophysics platform which can serve as a test-bed for BCI. The OPS demonstrations are fully transparent (e.g. allowing us to specify neural signal and noise characteristics) so they allow us to gain insights into how the approaches we are studying work, and we show that our approach provides decoders which are both plausibly learnable and permit performance improvements on point-to-point reaching tasks.</p>
</sec>
</sec>
<sec id="sec004" sec-type="results">
<title>Results</title>
<sec id="sec005">
<title>Encoder-Decoder system framework</title>
<p>Allowing for changes to both the decoder and encoder, we here show how to obtain encoder-decoder pairs which theoretically yield better performance than would be obtained either by learning an arbitrary, fixed decoder or adapting the decoder when the user is not learning. Although conceptually applicable generally, we apply our framework to the conventional Kalman filter (KF), which serves as a reasonable choice of decoder for BCI system. KF decoding approaches have been made to have adaptive parameters in various ways [<xref ref-type="bibr" rid="pcbi.1004288.ref004">4</xref>, <xref ref-type="bibr" rid="pcbi.1004288.ref005">5</xref>, <xref ref-type="bibr" rid="pcbi.1004288.ref008">8</xref>, <xref ref-type="bibr" rid="pcbi.1004288.ref014">14</xref>]. However, no previous work has directly considered the co-adaptation problem as a joint optimization problem over pairs of encoders and decoders. Here we review the KF and then show how to derive optimal encoder-decoder pairs.</p>
<sec id="sec006">
<title>Review of Kalman Filter for neuroprosthetics</title>
<p>To build a Bayesian decoder, we will need both an ‚Äúencoding model‚Äù (or encoder), mapping user intention to neural activity, as well as a ‚Äúprior model‚Äù, which relates the variables capturing user intention across time (<xref ref-type="fig" rid="pcbi.1004288.g001">Fig 1</xref>). In the simple case of controlling a cursor on a screen, the encoding model relates user intention about kinematic variables (such as cursor position and velocity) to neural activity. The prior relates these kinematic variables across time, effectively serving to smooth them. The Bayesian decoding algorithm combines the prior and encoding model using Bayes rule to infer the user‚Äôs intended kinematics from neural activity [<xref ref-type="bibr" rid="pcbi.1004288.ref015">15</xref>]. The Kalman filter (KF) is a simple Bayesian decoder and is widely used as a decoder for cursor control neuroprosthetic applications [<xref ref-type="bibr" rid="pcbi.1004288.ref004">4</xref>, <xref ref-type="bibr" rid="pcbi.1004288.ref008">8</xref>, <xref ref-type="bibr" rid="pcbi.1004288.ref014">14</xref>‚Äì<xref ref-type="bibr" rid="pcbi.1004288.ref016">16</xref>].</p>
<fig id="pcbi.1004288.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004288.g001</object-id>
<label>Fig 1</label>
<caption>
<title>BCI decoding framework.</title>
<p>Top figure depicts the general setting where neural activity is taken together with prior information to decode an estimate of the underlying intention. When in closed loop, sensory (visual) feedback is provided which can allow the user to modify intention and also permit changes to the encoding model. Bottom figure depicts the steady state Kalman filter (SSKF), a simple exemplar of the general setting in which <italic>A</italic>, <italic>F</italic>, &amp; <italic>G</italic> are matrices which multiply the vectors <italic>x</italic><sub><italic>t</italic></sub>, <italic>y</italic><sub><italic>t</italic></sub>, or <inline-formula id="pcbi.1004288.e001"><mml:math id="M1" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>‚àí</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. Contributions from <italic>Fy</italic><sub><italic>t</italic></sub> and <inline-formula id="pcbi.1004288.e002"><mml:math id="M2" display="inline" overflow="scroll"><mml:mrow><mml:mi>G</mml:mi> <mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>‚àí</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> combine additively.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004288.g001"/>
</fig>
<p>For the KF, the kinematic variables are related by a first order autoregressive process (AR(1)), which serves as a prior model over cursor trajectories.
<disp-formula id="pcbi.1004288.e003"><alternatives><graphic id="pcbi.1004288.e003g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004288.e003"/><mml:math id="M3" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>x</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mi>P</mml:mi> <mml:msub><mml:mi>x</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mspace width="4.pt"/><mml:mtext>(with</mml:mtext> <mml:mspace width="4.pt"/><mml:mrow><mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>‚àº</mml:mo> <mml:mo>ùí©</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>0</mml:mn> <mml:mo>,</mml:mo> <mml:mi>Q</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mtext>)</mml:mtext> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(1)</label></disp-formula>
Here <italic>x</italic><sub><italic>t</italic></sub> is a vector of size <italic>n</italic>, corresponding to the number of dimensions to be controlled (i.e. the kinematic variables corresponding to user intention). <italic>P</italic> is therefore an <italic>n</italic> by <italic>n</italic> transition matrix which characterizes the physical dependencies between variables across timesteps. This prior equation encourages posterior estimates of consecutive time points to be nearby if the noise covariance, <italic>Q</italic>, is small.</p>
<p>We then specify an observation model, which in our case will be the linear encoding of the kinematic variable in the neural activity with additive Gaussian noise.
<disp-formula id="pcbi.1004288.e004"><alternatives><graphic id="pcbi.1004288.e004g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004288.e004"/><mml:math id="M4" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>y</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mi>A</mml:mi> <mml:msub><mml:mi>x</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>œµ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mspace width="4.pt"/><mml:mtext>(with</mml:mtext> <mml:mspace width="4.pt"/><mml:mrow><mml:msub><mml:mi>œµ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>‚àº</mml:mo> <mml:mo>ùí©</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>0</mml:mn> <mml:mo>,</mml:mo> <mml:mi>C</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mtext>)</mml:mtext> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(2)</label></disp-formula>
Here <italic>y</italic><sub><italic>t</italic></sub> is a vector of size <italic>k</italic>, the number of observed neural signals. This observation could be any observation of user intent such as binned spiking activity, electrocorticography, electroencephalography, peripheral electromyography, or other methods. Conceptually the observation matrix <italic>A</italic> (size <italic>k</italic> by <italic>n</italic>) corresponds to the encoding model parameters. For this model, the Kalman filter is known to be the optimal Bayesian decoder and it also minimizes the squared error of the decoded variables with respect to the actual value [<xref ref-type="bibr" rid="pcbi.1004288.ref017">17</xref>, <xref ref-type="bibr" rid="pcbi.1004288.ref018">18</xref>].</p>
<p>The Kalman filter has transients due to initial conditions, but we are interested in the performance of the user and decoder on long timescales, so we will prefer the simplification that the system is in steady state. It has been shown that very little performance is lost in BCI settings using steady state approaches [<xref ref-type="bibr" rid="pcbi.1004288.ref019">19</xref>]. It is well known that a decoder of the following form corresponds to a steady-state Kalman Filter (SSKF) [<xref ref-type="bibr" rid="pcbi.1004288.ref020">20</xref>]:
<disp-formula id="pcbi.1004288.e005"><alternatives><graphic id="pcbi.1004288.e005g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004288.e005"/><mml:math id="M5" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mi>F</mml:mi> <mml:msub><mml:mi>y</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:mi>G</mml:mi> <mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(3)</label></disp-formula>
Matrices <italic>F</italic> and <italic>G</italic> correspond to decoding model parameters, and <inline-formula id="pcbi.1004288.e006"><mml:math id="M6" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is a vector of size <italic>n</italic>. <italic>F</italic> and <italic>G</italic> depend on the Kalman model parameters <italic>A</italic>, <italic>C</italic>, <italic>P</italic>, and <italic>Q</italic>, and solving for the SSKF parameters is standard [<xref ref-type="bibr" rid="pcbi.1004288.ref020">20</xref>]. The solution is:
<disp-formula id="pcbi.1004288.e007"><alternatives><graphic id="pcbi.1004288.e007g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004288.e007"/><mml:math id="M7" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>F</mml:mi> <mml:mo>=</mml:mo> <mml:msub><mml:mo>Œ£</mml:mo> <mml:mrow><mml:mi>S</mml:mi> <mml:mi>S</mml:mi></mml:mrow></mml:msub> <mml:msup><mml:mi>A</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>A</mml:mi> <mml:msub><mml:mo>Œ£</mml:mo> <mml:mrow><mml:mi>S</mml:mi> <mml:mi>S</mml:mi></mml:mrow></mml:msub> <mml:msup><mml:mi>A</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mo>+</mml:mo> <mml:mi>C</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(4)</label></disp-formula>
<disp-formula id="pcbi.1004288.e008"><alternatives><graphic id="pcbi.1004288.e008g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004288.e008"/><mml:math id="M8" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>G</mml:mi> <mml:mo>=</mml:mo> <mml:mi>P</mml:mi> <mml:mo>-</mml:mo> <mml:mi>F</mml:mi> <mml:mi>A</mml:mi> <mml:mi>P</mml:mi> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(5)</label></disp-formula>
where Œ£<sub><italic>SS</italic></sub> is the fixed point solution to the Riccati equation:
<disp-formula id="pcbi.1004288.e009"><alternatives><graphic id="pcbi.1004288.e009g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004288.e009"/><mml:math id="M9" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mo>Œ£</mml:mo> <mml:mtext>SS</mml:mtext></mml:msub> <mml:mo>=</mml:mo> <mml:mi>P</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mo>Œ£</mml:mo> <mml:mtext>SS</mml:mtext></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mo>Œ£</mml:mo> <mml:mtext>SS</mml:mtext></mml:msub> <mml:msup><mml:mi>A</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>A</mml:mi> <mml:msub><mml:mo>Œ£</mml:mo> <mml:mtext>SS</mml:mtext></mml:msub> <mml:msup><mml:mi>A</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mo>+</mml:mo> <mml:mi>C</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mi>A</mml:mi> <mml:msub><mml:mo>Œ£</mml:mo> <mml:mtext>SS</mml:mtext></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:msup><mml:mi>P</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mo>+</mml:mo> <mml:mi>Q</mml:mi> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(6)</label></disp-formula></p>
</sec>
<sec id="sec007">
<title>Joint optimization of the encoder and decoder</title>
<p><italic>F</italic> and <italic>G</italic> are parameters of the decoder, so they are free to be selected by the decoding algorithm. <italic>A</italic> corresponds to the user‚Äôs encoding model and is not directly selectable by the experimenter. However, assuming the user can learn and is motivated to perform well, presenting a fixed decoder should cause the user to attempt to match the decoder with the corresponding optimal encoding model. Learning here corresponds to exploring the space of mappings between intention and neural activity (captured by <italic>A</italic>), and the user can change <italic>A</italic> by modulating how their intention corresponds to desired control in the kinematic space (i.e. the mapping from ‚Äúwhat the user thinks‚Äù to ‚Äúwhat the end effector does‚Äù).</p>
<p>The problem we want to solve then is the joint optimization of the encoder and decoder. In the general Kalman filter decoder setting, we solve for parameters <italic>F</italic> and <italic>G</italic>, but <italic>A</italic> is specified. By solving for <italic>A</italic> also, we are finding the KF solution for an optimal encoder. This joint optimization space is equivalent to that covered by co-adaptive settings in which the KF parameters can adapt and the user can learn‚Äîthat is, any setting in which the user learns and the decoder is a Kalman filter variant is subsumed by our approach of looking at the whole space of user encoders and KF decoders.</p>
<p>For the problems we consider, we are provided with a source distribution for the kinematic intention variables <italic>x</italic><sub><italic>t</italic></sub>, given by the AR(1) model parameters <italic>P</italic> and <italic>Q</italic> which are assumed known (these can be engineered for the task). We optimize over encoding model parameters <italic>A</italic> and the decoder parameters <italic>F</italic> and <italic>G</italic> with respect to a minimum mean square error (MMSE) objective. The solution depends on the statistics of the neural signal <italic>y</italic><sub><italic>t</italic></sub>, predominantly given by the observation noise (<italic>C</italic>). For the following derivations, we assume the noise covariance (<italic>C</italic>) is known, although it would be estimated in practice. Also, in practice the neural activity would be pre-processed‚Äîwe assume zero-mean signals.</p>
</sec>
<sec id="sec008">
<title>Optimal solution for AR(1) kinematics</title>
<p>In trying to determine the optimal encoder-decoder pair, we consider the objective function to be MMSE, so the objective is (see equations (15)‚Äì(18) of <xref ref-type="supplementary-material" rid="pcbi.1004288.s001">S1 Text</xref> for more details):
<disp-formula id="pcbi.1004288.e010"><alternatives><graphic id="pcbi.1004288.e010g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004288.e010"/><mml:math id="M10" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mo>‚Ñ∞</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>A</mml:mi> <mml:mo>,</mml:mo> <mml:mi>F</mml:mi> <mml:mo>,</mml:mo> <mml:mi>G</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mo>ùîº</mml:mo> <mml:mrow><mml:mo>[</mml:mo> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>T</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mi>t</mml:mi> <mml:mi>r</mml:mi> <mml:mrow><mml:mo>[</mml:mo> <mml:mo>ùîº</mml:mo> <mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub> <mml:msubsup><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>t</mml:mi> <mml:mi>T</mml:mi></mml:msubsup> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:mn>2</mml:mn> <mml:mo>ùîº</mml:mo> <mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:msubsup><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>t</mml:mi> <mml:mi>T</mml:mi></mml:msubsup> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mo>ùîº</mml:mo> <mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:msubsup><mml:mi>x</mml:mi> <mml:mi>t</mml:mi> <mml:mi>T</mml:mi></mml:msubsup> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(7)</label></disp-formula>
<disp-formula id="pcbi.1004288.e011"><alternatives><graphic id="pcbi.1004288.e011g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004288.e011"/><mml:math id="M11" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mo>=</mml:mo> <mml:mi>t</mml:mi> <mml:mi>r</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>F</mml:mi> <mml:mi>A</mml:mi> <mml:mo>-</mml:mo> <mml:mi>I</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msub><mml:mo>Œ£</mml:mo> <mml:mi>x</mml:mi></mml:msub> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>F</mml:mi> <mml:mi>A</mml:mi> <mml:mo>-</mml:mo> <mml:mi>I</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>T</mml:mi></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mi>t</mml:mi> <mml:mi>r</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>2</mml:mn> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>F</mml:mi> <mml:mi>A</mml:mi> <mml:mo>-</mml:mo> <mml:mi>I</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>ùîº</mml:mo> <mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:msubsup><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>T</mml:mi></mml:msubsup> <mml:mo>]</mml:mo></mml:mrow> <mml:msup><mml:mi>G</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mi>t</mml:mi> <mml:mi>r</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>F</mml:mi> <mml:mi>C</mml:mi> <mml:msup><mml:mi>F</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mi>t</mml:mi> <mml:mi>r</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>G</mml:mi> <mml:mo>ùîº</mml:mo> <mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:msubsup><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>T</mml:mi></mml:msubsup> <mml:mo>]</mml:mo></mml:mrow> <mml:msup><mml:mi>G</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(8)</label></disp-formula>
where Œ£<sub><italic>x</italic></sub> is the marginal covariance for <italic>x</italic><sub><italic>t</italic></sub> given by the (zero-mean) process distribution in <xref ref-type="disp-formula" rid="pcbi.1004288.e003">Eq 1</xref>:
<disp-formula id="pcbi.1004288.e012"><alternatives><graphic id="pcbi.1004288.e012g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004288.e012"/><mml:math id="M12" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mo>Œ£</mml:mo> <mml:mi>x</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mo>ùîº</mml:mo> <mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:msubsup><mml:mi>x</mml:mi> <mml:mi>t</mml:mi> <mml:mi>T</mml:mi></mml:msubsup> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mi>P</mml:mi> <mml:mo>ùîº</mml:mo> <mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:msubsup><mml:mi>x</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>T</mml:mi></mml:msubsup> <mml:mo>]</mml:mo></mml:mrow> <mml:msup><mml:mi>P</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mo>+</mml:mo> <mml:mo>ùîº</mml:mo> <mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:msubsup><mml:mi>z</mml:mi> <mml:mi>t</mml:mi> <mml:mi>T</mml:mi></mml:msubsup> <mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(9)</label></disp-formula>
<disp-formula id="pcbi.1004288.e013"><alternatives><graphic id="pcbi.1004288.e013g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004288.e013"/><mml:math id="M13" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mo>=</mml:mo> <mml:mi>P</mml:mi> <mml:msub><mml:mo>Œ£</mml:mo> <mml:mi>x</mml:mi></mml:msub> <mml:msup><mml:mi>P</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mo>+</mml:mo> <mml:mi>Q</mml:mi> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(10)</label></disp-formula>
This is a Lyapunov equation and the solution is standard, as <italic>P</italic> and <italic>Q</italic> are assumed known. We can solve for Œ£<sub><italic>x</italic></sub> (and thereby the marginal distribution <italic>x</italic><sub><italic>t</italic></sub> ‚àº ùí©(0, Œ£<sub><italic>x</italic></sub>)) by iterating the matrix recursion to convergence or by vectorizing and solving for the covariance in closed form [<xref ref-type="bibr" rid="pcbi.1004288.ref021">21</xref>].</p>
<p>The choice of encoding <italic>A</italic> determines the signal strength in the observed neural data <italic>y</italic><sub><italic>t</italic></sub>, which also carries an additive noise component with covariance <italic>C</italic>, as shown in <xref ref-type="disp-formula" rid="pcbi.1004288.e004">Eq 2</xref>. If we simply attempt to optimize encoding and decoding for the MMSE objective in an unconstrained fashion, we will obtain the trivial solution of <italic>A</italic> ‚Üí ‚àû. Such a solution corresponds to arbitrarily high firing rates of neurons.</p>
<p>To capture the physiological requirement that neurons cannot be active with arbitrary magnitude and/or arbitrarily low noise, we must penalize the signal power while encouraging it to be as distinct as possible from the noise power. Additionally, when considering the optimal encoder-decoder pair, we want to constrain the optimal encoding model to a set which is feasible for the user to learn. Several studies suggest that BCI users can only adjust neural activity such that it does not violate certain features of the neural activity structure [<xref ref-type="bibr" rid="pcbi.1004288.ref022">22</xref>‚Äì<xref ref-type="bibr" rid="pcbi.1004288.ref024">24</xref>]. To capture the basic structure of some of these limitations, we can place a simple phenomenological constraint on the encoder which prohibits the covariance of the neural activity from deviating too much from an initial, native setting. Specifically, a standard approach for multivariate signals is to use a trace-of-quotient penalty‚Äîthis is also used in linear discriminant analysis and other methods that share this motivation [<xref ref-type="bibr" rid="pcbi.1004288.ref025">25</xref>].
<disp-formula id="pcbi.1004288.e014"><alternatives><graphic id="pcbi.1004288.e014g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004288.e014"/><mml:math id="M14" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mo>ùí¢</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>o</mml:mi> <mml:mi>i</mml:mi> <mml:mi>n</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>A</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mi>t</mml:mi> <mml:mi>r</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mo>ùîº</mml:mo> <mml:msup><mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>y</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:msubsup><mml:mi>y</mml:mi> <mml:mi>t</mml:mi> <mml:mi>T</mml:mi></mml:msubsup> <mml:mo>]</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>ùîº</mml:mo> <mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>A</mml:mi> <mml:msub><mml:mi>x</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>A</mml:mi> <mml:msub><mml:mi>x</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>T</mml:mi></mml:msup> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(11)</label></disp-formula>
<disp-formula id="pcbi.1004288.e015"><alternatives><graphic id="pcbi.1004288.e015g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004288.e015"/><mml:math id="M15" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mo>=</mml:mo> <mml:mi>t</mml:mi> <mml:mi>r</mml:mi> <mml:mo>(</mml:mo> <mml:msubsup><mml:mover accent="true"><mml:mo>Œ£</mml:mo> <mml:mo>^</mml:mo></mml:mover> <mml:mi>y</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:mi>A</mml:mi> <mml:msub><mml:mo>Œ£</mml:mo> <mml:mi>x</mml:mi></mml:msub> <mml:msup><mml:mi>A</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(12)</label></disp-formula>
where
<disp-formula id="pcbi.1004288.e016"><alternatives><graphic id="pcbi.1004288.e016g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004288.e016"/><mml:math id="M16" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mo>Œ£</mml:mo> <mml:mi>y</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mo>ùîº</mml:mo> <mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>y</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:msubsup><mml:mi>y</mml:mi> <mml:mi>t</mml:mi> <mml:mi>T</mml:mi></mml:msubsup> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:munder><mml:munder accentunder="true"><mml:mrow><mml:mi>A</mml:mi> <mml:msub><mml:mo>Œ£</mml:mo> <mml:mi>x</mml:mi></mml:msub> <mml:msup><mml:mi>A</mml:mi> <mml:mi>T</mml:mi></mml:msup></mml:mrow> <mml:mo>Ô∏∏</mml:mo></mml:munder> <mml:msub><mml:mo>Œ£</mml:mo> <mml:mrow><mml:mi>s</mml:mi> <mml:mi>i</mml:mi> <mml:mi>g</mml:mi></mml:mrow></mml:msub></mml:munder> <mml:mo>+</mml:mo> <mml:mi>C</mml:mi> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(13)</label></disp-formula></p>
<p>For our class of models, this joint activity constraint ensures that both signal and noise correlations in neural activity are appropriately respected. If future experiments reveal additional constraints that restrict the set of encoding models learnable by the user, it would be straightforward to model them and incorporate them into an updated penalty. In the simpler case where neural signal constraints are unknown and we only wish to focus on noise constraints, we can replace Œ£<sub><italic>y</italic></sub> with <italic>C</italic> yielding ùí¢<sub><italic>SNR</italic></sub>(<italic>A</italic>) = <italic>tr</italic>(<italic>C</italic><sup>‚àí1</sup> <italic>A</italic>Œ£<sub><italic>x</italic></sub> <italic>A</italic><sup><italic>T</italic></sup>).</p>
<p>We add the ùí¢<sub><italic>joint</italic></sub>(<italic>A</italic>) penalizer to our objective and arrive at the main optimization problem we are trying to solve. The full objective for the minimum MSE encoder-decoder pair subject to this penalty on the encoding scheme is:
<disp-formula id="pcbi.1004288.e017"><alternatives><graphic id="pcbi.1004288.e017g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004288.e017"/><mml:math id="M17" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mo>‚Ñí</mml:mo> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>A</mml:mi> <mml:mo>,</mml:mo> <mml:mi>F</mml:mi> <mml:mo>,</mml:mo> <mml:mi>G</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>*</mml:mo></mml:msup> <mml:mo>=</mml:mo> <mml:mo>‚Ñ∞</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>A</mml:mi> <mml:mo>,</mml:mo> <mml:mi>F</mml:mi> <mml:mo>,</mml:mo> <mml:mi>G</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mi>Œª</mml:mi> <mml:msub><mml:mo>ùí¢</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>o</mml:mi> <mml:mi>i</mml:mi> <mml:mi>n</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>A</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(14)</label></disp-formula>
The <italic>Œª</italic> parameter enforces a specific magnitude of the constraint (which can be tuned as a Lagrange multiplier to match the SNR of the actual system). This objective function serves as a key theoretical statement of this paper insofar as it describes a well-defined optimization problem that summarizes optimal co-adaptation.</p>
<p>We optimize the full objective (<xref ref-type="disp-formula" rid="pcbi.1004288.e017">Eq 14</xref>) with respect to <italic>F</italic>, <italic>G</italic>, and <italic>A</italic>. For <italic>A</italic> held fixed, the optimal <italic>F</italic> and <italic>G</italic> follow from standard methods for solving for the optimal SSKF (i.e. linear-quadratic estimator). For <italic>F</italic> and <italic>G</italic> held fixed, we can take explicitly the gradients of this objective with respect to encoding model parameters <italic>A</italic>. We alternate between gradient-based optimization of <italic>A</italic> given <italic>F</italic>, <italic>G</italic> and optimization of <italic>F</italic>, <italic>G</italic> given <italic>A</italic>‚Äîthis is a coordinate-wise optimization of the full objective to obtain a joint local optimum (see <xref ref-type="supplementary-material" rid="pcbi.1004288.s001">S1 Text</xref> for full derivation).</p>
</sec>
<sec id="sec009">
<title>Characterization of solutions</title>
<p>Conceptually, we compare the optimal coding solutions of the form described in the previous section with those that follow from using a static, linear decoder instead of a Kalman filter:
<disp-formula id="pcbi.1004288.e018"><alternatives><graphic id="pcbi.1004288.e018g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004288.e018"/><mml:math id="M18" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mi>F</mml:mi> <mml:msub><mml:mi>y</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(15)</label></disp-formula></p>
<p>Such a decoder corresponds to the setting where each timestep of the process <italic>x</italic><sub>1‚Ä¶<italic>T</italic></sub> is sampled independently and identically distributed (i.i.d.) from a Gaussian, rather than from an AR(1) process. Work on ‚Äúrobust coding‚Äù has solved the optimal encoder-decoder problem for i.i.d. input without temporal correlations‚Äîversions of this problem are explored in the context of neuroscience in [<xref ref-type="bibr" rid="pcbi.1004288.ref026">26</xref>‚Äì<xref ref-type="bibr" rid="pcbi.1004288.ref028">28</xref>], and an abstract variant of this problems was solved much earlier in the control literature [<xref ref-type="bibr" rid="pcbi.1004288.ref029">29</xref>]. If we consider only the marginal statistics of our kinematic variables (which are Gaussian), the solution of our problem aligns with the classical robust coding solutions (see <xref ref-type="supplementary-material" rid="pcbi.1004288.s001">S1 Text</xref> for details). The solution to the full problem from the preceding section appropriately generalizes this marginal solution. In the limit of <italic>P</italic> ‚Üí 0 which eliminates the temporal dependencies, the KF-decoder solution turns into this marginal solution (see <xref ref-type="supplementary-material" rid="pcbi.1004288.s001">S1 Text</xref>).</p>
<p>For the AR(1) case, we have empirically studied the objective function using both penalties with up to k = 200 neural channels to control n = 3 dimensions. As long as parameters are initialized to the correct order of magnitude (for numerical stability), optimized encoders and decoders obtained from different, random initializations converge to the same value of the objective function. The parameters (<italic>A</italic>, <italic>F</italic>, <italic>G</italic>) obtained are different but the invariant objective function value suggests that most local optima may comprise a set of solutions which obtain the same error. The observation of multiple equivalent optimal solutions is consistent with the various indeterminacies in our problem‚Äîthat is, ‚Ñí(<italic>A</italic>, <italic>F</italic>, <italic>G</italic>)* does not change if the encoder <italic>A</italic> and the decoder <italic>F</italic> are both operated on in ways which preserve the quantities in the objective function. In this work, we only focus on situations where the kinematic variables correspond to position, so <italic>P</italic> ‚àù <italic>I</italic><sub><italic>n</italic> √ó <italic>n</italic></sub> and Œ£<sub><italic>x</italic></sub> ‚àù <italic>I</italic><sub><italic>n</italic> √ó <italic>n</italic></sub>. In general, if there are other variables such as velocities, then <italic>P</italic> will have a block which is ‚àù <italic>I</italic><sub><italic>n</italic> √ó <italic>n</italic></sub> and other blocks which relate the variables to position according to physical relationships (see [<xref ref-type="bibr" rid="pcbi.1004288.ref030">30</xref>] for an explicit presentation of this). Choices of parameters (such as a structured <italic>P</italic> and a full rank signal covariance with the ùí¢<sub><italic>joint</italic></sub>(<italic>A</italic>) penalty) can break most of the indeterminacies, in some cases leaving only a sign indeterminacy (i.e. <italic>F</italic> and <italic>A</italic> may both have signs of parameters inverted with no affect on the objective). Overall, it is clear that our algorithm obtains optima for which performance is not dominated by other encoder-decoder pairs.</p>
</sec>
</sec>
<sec id="sec010">
<title>Validation of framework</title>
<p>Having provided the framework and described the encoder-decoder optimization methods, we validate our approach in two settings. We first examine the coding schemes arising from simulations and verify that our approach yields interpretable solutions. Following the simulation results, we show the results of psychophysics experiments implementing our approach on an online prosthesis simulator (OPS), a system which tracks overt human body movements and generates synthetic, closed-loop data.</p>
<sec id="sec011">
<title>Finding good encoder-decoder pairs (simulation)</title>
<p>In this section, we wish to build intuition for the optimized encoder-decoder pairs we obtain. Consider a generic case in which there are <italic>k</italic> ‚Äúelectrodes,‚Äù each having independent signal and noise, and we wish to design a decoder having only a single output degree of freedom (DOF), a 1D <inline-formula id="pcbi.1004288.e019"><mml:math id="M19" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. In this case, the encoder is a <italic>k</italic> √ó 1 matrix mapping intention <italic>x</italic><sub><italic>t</italic></sub> to the <italic>k</italic>-dimensional neural observation <italic>y</italic><sub><italic>t</italic></sub>. The decoder is a 1 √ó <italic>k</italic> matrix mapping from <italic>y</italic><sub><italic>t</italic></sub> to an estimate <inline-formula id="pcbi.1004288.e020"><mml:math id="M20" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>.</p>
<p>We can simulate this setting by constructing signal and noise covariance matrices, and we can numerically compute the optimal decoder parameters. The optimization procedure finds encoders which have good signal subject to constraints on the magnitude of the encoded variables (i.e. for fixed SNR level). The encoder corresponds to the <italic>A</italic> matrix, visualized as the encoder in <xref ref-type="fig" rid="pcbi.1004288.g002">Fig 2</xref>. The corresponding decoder parameters <italic>F</italic> should rely on the more strongly encoded dimensions, with more decoder weight on those dimensions which are less noisy. The decoder parameters <italic>G</italic> are also important, but they largely reflect the prior dynamics parameters <italic>P</italic> which in this case are proportional to the identity matrix.</p>
<fig id="pcbi.1004288.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004288.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Two simulated examples of signal and noise covariances which give easily interpretable encoder-decoder optima.</title>
<p>In (a) &amp; (c) we generate a signal covariance (Œ£<sub><italic>sig</italic></sub>) and noise covariance (<italic>C</italic>) which sum to the empirical covariance (Œ£<sub><italic>y</italic></sub>). These covariances are sufficient statistics for the optimization procedure and allow us to determine the optimal encoder-decoder pair for these channels. In (b) &amp; (d) we visualize the corresponding optimal encoder and decoder. For example 1 (a) &amp; (b), the optimized encoder-decoder pair transmits information along dimensions 2 &amp; 5 which have the highest SNR (i.e. signal magnitude is same for all dimensions and noise is lowest for dimensions 2 &amp; 5). For example 2 (c) &amp; (d), the signal is a rank 1 matrix and the encoder parameters preferentially encode higher signal dimensions. The obtained decoder parameters again reflect preferential decoding of dimensions with high signal and low noise.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004288.g002"/>
</fig>
<p>Indeed, in simple example simulations here, we see that signal is coded along dimensions with less noise. In example 1 (top row of <xref ref-type="fig" rid="pcbi.1004288.g002">Fig 2</xref>), signal is present and equally strong for all dimensions, and noise is lowest for dimensions 2 and 5. We optimized the encoder and decoder for the specified covariances, and we see that, consistent with intuitions, optimal encoding and decoding relies primarily on the two, high-SNR dimensions. An optimal decoder may ignore noisy channels in favor of not mixing less reliable channels with the more reliable channels if this is best for the objective function. In example 2 (bottom row of <xref ref-type="fig" rid="pcbi.1004288.g002">Fig 2</xref>), signal covariance reflects decreasing signal on higher numbered dimensions. The noise is the same as in example 1. The optimized encoder encodes the high signal dimensions preferentially and the decoder reads out the dimensions which both have high signal and low noise (e.g. dimension 2 is decoded more strongly than dimension 1 since it is considerably less noisy). In 1D control, the only indeterminacy is of the sign of both the encoder and decoder. Both of these examples validate that our optimization yields encoder-decoder pairs which conform to our intuition of what constitutes a good encoding scheme. If it is believed that the representations available in a specific setting should be subject to additional constraints, these should be included in the objective.</p>
<p>The key point is that the encoder and decoder are matched. Recall that in the prosthetic setting, the user‚Äôs initial encoding will be arbitrary, but users who change their encoding (i.e. adapt their control scheme) to match the optimized encoder, will potentially be able to obtain optimal performance when using the corresponding decoder. The feature of our framework, that neurons not relevant for the decoder will have decreased encoding weight, has experimental corroboration in BCI settings from work showing that neurons not used by a decoder have decreased modulation [<xref ref-type="bibr" rid="pcbi.1004288.ref031">31</xref>, <xref ref-type="bibr" rid="pcbi.1004288.ref032">32</xref>].</p>
</sec>
<sec id="sec012">
<title>Online prosthesis simulation for 1D control</title>
<p>In order to thoroughly examine our approach when we know how neural activity is generated, we tested our framework with human subjects in a general setting where all features of the system are observed and controlled. To this end, we used an online prosthesis simulator (OPS) to validate our approach in experimental demonstrations [<xref ref-type="bibr" rid="pcbi.1004288.ref013">13</xref>]. In this system, an able-bodied user made overt movements which were detected and used to drive an artificial population of neurons (see <xref ref-type="sec" rid="sec019">methods</xref> for full details of our OPS). The simulated neurons were decoded in real time, enabling the user to control a cursor (via overt movements) in closed-loop, where the overall system performs analogously to a BCI. We present an example pipeline of the experiment in <xref ref-type="fig" rid="pcbi.1004288.g003">Fig 3</xref>‚Äîthe user sees a static target and makes overt movements reflecting intention, the overt movements drive synthetic neural activity, and a cursor position is decoded from the synthetic activity. Here, the encoding model is considered the mapping from user intention (i.e. where the user wants the cursor to move) to noisy neural activity, and decoding goes from neural activity to cursor position.</p>
<fig id="pcbi.1004288.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004288.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Pipeline for OPS experiments with a single-trial trace for the ‚Äúpinball‚Äù (point-to-point reaching) task (subject 2, SNR-case 3, using the pre-computed decoder).</title>
<p>The top-most plot depicts target position observed by user, in response to which the user makes overt movements reflecting their intention. The second plot depicts these overt user movements captured by the motion-capture sensor and pose tracking software. The third plot depicts simulated neural activity which was synthesized by reweighting, mixing and adding noise to the raw movement data. The bottom-most plot depicts decoded cursor positions (1D) during the task. Target remains fixed until acquired by the cursor, noted by black markings around target transition times. Trajectories are smooth and under/overshoots are common, visual feedback being crucial to performance.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004288.g003"/>
</fig>
<p>If the appropriate signals are available, it is natural for a neuroprosthesis to use biomimetic control‚Äîfor example, using the neurons which correspond to imagined left-right movement of the hands to control left-right movement of a cursor. With the OPS, we set out to explore a relevant regime where the user is inclined to use a biomimetic decoder (e.g. moving their hands naturally to control a cursor), but higher SNR is available in other, non-biomimetic dimensions which might be less likely to be explored. By deciding what body movements generate neural activity and how much noise is present for various neural channels, we can construct cases which require the user to learn in order to achieve optimal performance. Na√Øve motor-imitation control will not suffice because the native movement dimensions are noisier. Closed-loop learning is required in this setting so the user can learn the non-biomimetic scheme.</p>
<p>The purposes of these OPS demonstrations are (1) to examine how much performance might be expected to improve if optimal encoder-decoder pairs are used instead of sub-optimal, initial mappings and (2) to examine the extent to which non-biomimetic schemes are learnable. To this end, we compared the use of a pre-computed, fixed decoder for the cursor task with biomimetic schemes to illustrate the sense in which our approach finds better solutions. Given that we only receive signal from a small number of control dimensions (i.e. overt movement channels) and we wish to make some of these control dimensions noisy, we restricted attention to 1D cursor versions of the task. We compute the optimal decoder according to our framework and use it for the cursor task, expecting that the user should be able to learn it. As described when presenting our framework, this decoder corresponds to a theoretically obtainable end-result of a co-adaptation process having occurred, for which user learning was permitted.</p>
</sec>
<sec id="sec013">
<title>OPS experimental results</title>
<p>After a few minutes of free exploration during which the user could become comfortable controlling the cursor (see <xref ref-type="sec" rid="sec019">methods</xref> for full description), subjects were evaluated on the ‚Äúpinball‚Äù (point-to-point reaching) task. We compared subjects across two decoder conditions: whether the decoder was derived from motor-imitation initialization (described in methods) or using the jointly optimized, pre-computed decoding approach which follows from our framework. Each subject participated in three cases of the experiment, with each case differing in SNR level as well as how the overt movements mapped to neural signals (see <xref ref-type="sec" rid="sec019">methods</xref>). These three cases are different in details but are meant to provide multiple, independent demonstrations of the same effects.</p>
<p>We first consider single-subject comparisons using each of the two classes of decoders. We observe that our method performs visibly better than the motor-imitation decoder (see <xref ref-type="fig" rid="pcbi.1004288.g004">Fig 4</xref> for a representative example trial). In general, during motor-imitation decoder conditions, dynamic range of the cursor was limited (by noise, finite range of movement, and limb constraints) so subjects had difficulty reaching all extremal-located targets (see <xref ref-type="fig" rid="pcbi.1004288.g004">Fig 4</xref>). Weaker encoding leads to limited range of motion on screen and slower responsiveness on screen as a consequence of heavy smoothing/dampening, arising from relying more on the Kalman filter prior than the noisy observation. The level of smoothing is set automatically when optimizing the KF decoder to appropriately balance reliance on the prior and the encoding model. If the decoder places less weight on the prior, it does so because it has a sufficiently informative encoding model. Higher reliance on the prior indicates the use of a less informative encoding model, and less smoothing in this setting would have suboptimal error, permitting more jitter without compensating improvements in control. If encoding were stronger for noisier neural dimensions, the noise in those dimensions would be amplified, thereby undermining decoding. The timescale of smoothing can be empirically characterized by the autocorrelation function (ACF) of the cursor position when the user controls it, with slower autocorrelation falloff corresponding to slower, more sluggish control and heavier smoothing (see rightside panels of <xref ref-type="fig" rid="pcbi.1004288.g004">Fig 4</xref>). The timescale of smoothing in the decoder due to the prior arises in large part from the dominant eigenvalue of the <italic>G</italic> matrix of the decoder (which for a 1D setting is simply the value of <italic>G</italic>). Indeed, we find that <italic>G</italic> is larger for motor-imitation decoder conditions whenever the motor-imitation decoder ACF decays slower than the pre-computed decoder ACF (not shown).</p>
<fig id="pcbi.1004288.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004288.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Comparison of the two decoding conditions for subject 2, SNR-case 3.</title>
<p>The top plot depicts single trial data with a motor-imitation initialized decoder. The cursor moves more smoothly (i.e. oversmoothed) and it is difficult to reach extremally-located targets. This smoothness is reflected in a slow falloff for the autocorrelation function (ACF) of the cursor position. The bottom plot depicts a matched trial with a pre-computed decoder. The user‚Äôs better control derives from a decoder with comparable local smoothness, but more responsiveness. Empirically the ACF has correspondingly sharper falloff.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004288.g004"/>
</fig>
<p>The details of the single-trial data shown in <xref ref-type="fig" rid="pcbi.1004288.g004">Fig 4</xref> generalize to all three task conditions, across multiple subjects. Cursor ACFs across subjects and conditions are presented in <xref ref-type="fig" rid="pcbi.1004288.g005">Fig 5</xref>, with motor-imitation decoder conditions plotted in blue and pre-computed decoder conditions plotted on the same plots in red. The slower falloff in the ACF for motor-imitation decoder conditions indicates less controllability for this class of decoder. Moreover, when encoding uses low-SNR channels, the KF decoder has perceptible lag insofar as optimal decoding will rely more on the prior. This is reduced when using higher-SNR neural activity because the encoding model contributes more reliable information, which in turn requires less smoothing by the optimal decoder. For a given level of noise, there is necessarily a trade-off between responsiveness and posterior variance. Taken together, these features tended to make performance better when using the pre-computed decoder relative to the motor-imitation decoder as the former took better advantage of the available signal along less noisy dimensions (see <xref ref-type="fig" rid="pcbi.1004288.g006">Fig 6</xref>). Significance across decoders is tested with one-sided unpaired t-tests (<italic>p</italic> &lt; .05) on time between acquisitions. In nearly all cases and across subjects, the performance of the pre-computed decoder dominates the performance using the motor-imitation scheme.</p>
<fig id="pcbi.1004288.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004288.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Cursor autocorrelation functions for all subjects and all conditions.</title>
<p>For each SNR case, motor-imitation decoder curves are depicted in blue and the pre-computed decoder overlays it in red. Better controllability would be expected to be reflected in faster ACF falloff. In almost every case, falloff was faster for the cursor control using the pre-computed decoder (SNR-case 2 did not follow this trend as reliably‚Äîsee main text for discussion).</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004288.g005"/>
</fig>
<fig id="pcbi.1004288.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004288.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Each subfigure depicts performance comparisons for the different decoders in various SNR conditions for a particular subject.</title>
<p>The quantity compared is the number of targets per time and and significance is tested with one-sided unpaired t-tests (<italic>p</italic> &lt; .05) on time between acquisitions. In general, subjects tend to perform better on the task using the pre-computed decoders rather than those initialized by motor-imitation.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004288.g006"/>
</fig>
<p>All three SNR cases were designed with the expectation that user ‚Äúmotor-imitation‚Äù behavior would consist of moving both hands together left or right to control a horizontal cursor (i.e. moving both hands rightwards to get the cursor to move rightwards, etc.). However, subjects 2 and 3 predominantly used one hand during SNR-case 2 motor-imitation trials, and this happened to correspond to a good non-biomimetic scheme‚Äîthe distance between hands served as a signal which strongly drove neural activity. Consequently, the motor-imitation decoder had decent signal as these subjects‚Äô motor-imitation preferences coincidentally aligned with high SNR dimensions. This meant that the pre-computed decoder did not have enough room to do meaningfully better. This is reflected both in the insignificant differences in performance (<xref ref-type="fig" rid="pcbi.1004288.g006">Fig 6</xref>) and also in the similar ACFs for case 2 across decoders (<xref ref-type="fig" rid="pcbi.1004288.g005">Fig 5</xref>).</p>
<p>In addition to the performance differences between decoders, we examined how well the subjects learned to control the cursor via the decoders, essentially to verify the learnability of the pre-computed decoder. To demonstrate this, we provide plots comparing the parameters of the optimal encoding models against the estimated actual encoding model of the user (<xref ref-type="fig" rid="pcbi.1004288.g007">Fig 7</xref>‚Äîsee <xref ref-type="sec" rid="sec019">methods</xref> for details of estimation of encoding models). For each subject and decoder type, we compare the estimates of the subject‚Äôs encoding model parameters (how strongly the user relies on each neural channel) of all conditions against the optimal encoding model parameters for the decoder presented. The optimal encoder parameters for the motor-imitation and pre-computed decoders are not related and were in fact found to be quite distinct (data not shown). The purpose of this figure is merely to assess the extent to which each user was able to approximately match their encoder to the optimal encoding strategy. Relatively high correlations for both decoders for all subjects suggest that users have successfully learned an encoding scheme which approximately matches the decoder. This implies that differences in performance are related to the coding scheme and do not have to do with inadequate user learning. Effectively, for these examples using the OPS, the pre-computed decoder seemed to realize the theoretically expected performance improvements and these decoders seemed empirically quite learnable.</p>
<fig id="pcbi.1004288.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004288.g007</object-id>
<label>Fig 7</label>
<caption>
<title>All subjects learned the coding schemes.</title>
<p>Each plot compares, for each decoder, an estimate of the user‚Äôs learned encoder parameters against the optimal encoder parameters for a given subject, aggregated across signal cases. The optimal parameters for the two decoders are unrelated. A reference line is depicted on each plot and correlation coefficients are provided for each decoder (All correlations are significantly different from zero, <italic>p</italic> &lt; &lt; .01). Each point corresponds to a comparison between how much weight the user gave each channel vs how much weight the channel would have been given if optimally learned. Points near zero correspond to channels not heavily used. While perfect match would not be expected, the relatively strong correlations indicate that both decoder classes are learned reasonably well by all subjects.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004288.g007"/>
</fig>
</sec>
</sec>
</sec>
<sec id="sec014" sec-type="conclusions">
<title>Discussion</title>
<p>The key contributions of this paper are to establish co-adaptation methods as joint optimization problems over encoder-decoder pairs and to propose our approach for pre-computing an optimized decoder. For Kalman filter decoders and under our modeling assumptions, we showed that co-adaptation should not be able to do better than our approach in theory. To test the approach empirically, we also presented 1D OPS validation, in which our approach provided significantly better performance than the motor-imitation decoding approach. Instead of devising rules for adapting the decoder, we have presented an approach which characterizes what the user and decoder ought to do to complement one another, and we demonstrated that the user can match the optimal strategy in the 1D setting.</p>
<sec id="sec015">
<title>Revisiting co-adaptation</title>
<p>Our framework points to some qualitative insights into co-adaptation. In presenting our framework, we pointed out a non-obvious property of KF-decoder updates‚Äîupdates to the decoder that are designed to be optimal for the current encoding model can allow for improvement if the user learns further (i.e. adapts the encoding model). This is effectively why co-adaptation can serve as a coordinate descent algorithm. Implicitly, this property, coupled with the recognition that the user encoding can change, has permitted various approaches that attempt to track these changing encoders, using Kalman Filtering (e.g. CLDA [<xref ref-type="bibr" rid="pcbi.1004288.ref004">4</xref>]) as well as reinforcement learning (e.g RLBMI [<xref ref-type="bibr" rid="pcbi.1004288.ref009">9</xref>]). In both settings, the decoder is adapted in a principled fashion which permits tracking as a user adapts, so user and decoder collaboratively improve task performance (via a coordinate-descent-like method). These approaches may adapt the decoder slowly over many days. However, there is an intrinsic trade-off between lag and noise when using adaptive methods‚Äîthe decoder can either adapt slowly when it has enough information to make good steps or adapt quickly but be highly susceptible to noise in the updates [<xref ref-type="bibr" rid="pcbi.1004288.ref033">33</xref>]. Slow updating induces delays in decoder adaptation which may make exploration by the user difficult because the user may attempt to explore on timescales shorter than the lag.</p>
<p>We can contextualize our pre-computation approach relative to standard co-adaptive methods, by viewing pre-computed decoders as an attempt to push towards a certain logical extreme, essentially with the decoder ‚Äúadapting‚Äù entirely before any user learning takes place. Leveraging available information about the statistics of the recorded signals, the decoder can change pro-actively to prompt the user, who may not be learning very efficiently, to move in a direction in which better performance is expected. This is effectively what our algorithm was designed to do. A core intuition in assessing the relationship between these approaches is the observation that if one dimension of neural activity has less noise than another, optimal decoding will rely more heavily on the less noisy dimension. If noisy and non-noisy dimensions initially have non-zero weight, perhaps co-adaptation can be used to tune the relative strengths. However, this tuning can also be computed directly given estimates of signal and noise statistics. We believe our framework helps clarify the performance opportunities available when using fixed or adaptive decoders.</p>
</sec>
<sec id="sec016">
<title>Relationships to other approaches</title>
<p>Our approach is broadly consistent with the literature on joint source-channel coding, but we are not aware of neural modeling being performed using our formulation. In the control literature, others have derived solutions to the related problem of optimizing time-varying observation models for the time-varying Kalman filter, but their result does not extend to the steady state case and concludes with a numerical analysis showing that their solution can be very suboptimal for our setting [<xref ref-type="bibr" rid="pcbi.1004288.ref034">34</xref>].</p>
<p>There also exists other research which has looked into control schemes for ‚Äúbody-machine interfaces‚Äù, for example using a sensor-wired glove with many degrees of freedom (DOF) to control a cursor-on-a-screen [<xref ref-type="bibr" rid="pcbi.1004288.ref035">35</xref>‚Äì<xref ref-type="bibr" rid="pcbi.1004288.ref037">37</xref>]. This research is generally consistent with our approach, and also uses the term co-adaptation in a way which refers to situations where a user learning over time can be complemented by the decoder adapting to the new encoding of the user. The body-machine interface literature discusses various options for selecting the encoder, but they do not model the effects of noise or the relative differences between different encoder choices. One approach uses principal component analysis (PCA) on calibration data and then maps the first <italic>n</italic> principal components to the <italic>n</italic> effector DOFs by an arbitrary mapping which can be relatively straightforward for the user to then learn by exploration [<xref ref-type="bibr" rid="pcbi.1004288.ref038">38</xref>, <xref ref-type="bibr" rid="pcbi.1004288.ref039">39</xref>]. Our approach resembles the PCA approach if noise and temporal correlations are ignored, since we also rely on unsupervised collection of second order statistics. However, neural noise plays a significant role for us. Consider that in our 1D demo the total covariance has high variance in noisy dimensions. A na√Øve application of the PCA-based decoding scheme will result in a decoder which most heavily relies on the noisiest dimensions simply because they have more variance. Alternatively, when an adaptive decoder is used, the adaptation proceeds from a reasonable initialization [<xref ref-type="bibr" rid="pcbi.1004288.ref036">36</xref>, <xref ref-type="bibr" rid="pcbi.1004288.ref037">37</xref>]‚Äîfor the neural case, our approach helps find a reasonable scheme without depending upon any well chosen initialization.</p>
</sec>
<sec id="sec017">
<title>Further considerations</title>
<p>There are a few points to be aware of when interpreting the results of this paper. We optimize encoder-decoder pairs for the target tracing task, and we rely on similarity between tracing and the pinball tasks for the derived optimal solutions to hold in the pinball case. Additionally, we still have a free parameter in our optimization, <italic>Œª</italic>, for tuning the magnitude of the neural activity constraints. For OPS experiments, we did not optimize performance over <italic>Œª</italic>; rather, we tuned it very crudely to the parameters of the synthetic neural activity and held it fixed across subjects.</p>
<p>A limitation of the present study is that learning in an OPS setting may be different from learning in real BCI or across classes of BCI [<xref ref-type="bibr" rid="pcbi.1004288.ref040">40</xref>, <xref ref-type="bibr" rid="pcbi.1004288.ref041">41</xref>]‚Äîfor example, myoelectric interfaces engage later stages of a motor hierarchy, so timescales and constraints of learning may be different [<xref ref-type="bibr" rid="pcbi.1004288.ref040">40</xref>]. Consequently the extent of learnability and timescale of learning of our fixed, optimized decoder may vary by setting (OPS vs BCI type). While the OPS may serve as a relevant proxy of BCI in many respects [<xref ref-type="bibr" rid="pcbi.1004288.ref013">13</xref>], ultimately experiments in specific settings will be required to test the utility of our approach to each.</p>
<p>That said, both the decoding approach and the OPS can be modified to incorporate other features of the neural activity such as neural dynamics. While not conventionally modeled in BCI, recent research has revealed dynamical components to neural activity in motor cortices [<xref ref-type="bibr" rid="pcbi.1004288.ref042">42</xref>]. For such a class of neural activity used for the neuroprosthesis, one could consider the extensions <inline-formula id="pcbi.1004288.e021"><mml:math id="M21" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>y</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mi>A</mml:mi> <mml:msub><mml:mi>x</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:mi>B</mml:mi> <mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>‚àí</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>+</mml:mo> <mml:mi>D</mml:mi> <mml:msub><mml:mi>y</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>‚àí</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>+</mml:mo> <mml:mi>n</mml:mi> <mml:mi>o</mml:mi> <mml:mi>i</mml:mi> <mml:mi>s</mml:mi> <mml:mi>e</mml:mi></mml:mrow></mml:math></inline-formula> as a model of the neural activity. Moreover, although we used kinematic signals as the inputs to our simulated neurons, other user-controllable signals (e.g. muscle activity) could be used as inputs into the encoding model, possibly affecting the results. The inputs to the OPS are merely intended to serve as reflections of user intention and not necessarily what the real neural activity encodes in normal, non-BCI behavior.</p>
<p>We lastly emphasize that our methods require estimation of the neural noise covariance, so a calibration session used to examine neural activity is of crucial importance. For real neural applications, the neural signal and noise components could be estimated using various neural factor analysis methods [<xref ref-type="bibr" rid="pcbi.1004288.ref043">43</xref>, <xref ref-type="bibr" rid="pcbi.1004288.ref044">44</xref>].</p>
</sec>
<sec id="sec018">
<title>Future directions</title>
<p>We have made an initial attempt to build learnable decoders using a new joint optimization framework. We have focused on the linear-Gaussian setting which is implicit when KF decoders are employed. There will certainly be model mismatch, and insofar as this model proves too simple, the way forward is to incorporate additional features of the encoding model and constraints on user learning. While our approach is very clear about the extent to which it relies upon the accuracy of these assumptions, it is worth emphasizing that co-adaptation approaches are equally (if implicitly) dependent on these assumptions. For example, the structure and timescale of decoder updates in co-adaptive approaches directly impact how well users can learn [<xref ref-type="bibr" rid="pcbi.1004288.ref036">36</xref>] or whether the user learns at all [<xref ref-type="bibr" rid="pcbi.1004288.ref005">5</xref>]. By making these assumptions explicit, we hope that we can improve the adaptive decoder engineering process.</p>
<p>Additionally, while KF decoders are still widely used in BCI, future improvements may require nonlinear decoding methods, so we may wish to extend our framework to certain classes of nonlinear encoder-decoder pairs. For example we could consider Poisson-observation encoding with point-process decoders or otherwise parameterize the neural noise covariance to scale with the magnitude of the signal (i.e. signal-dependent noise as in [<xref ref-type="bibr" rid="pcbi.1004288.ref045">45</xref>]). Generally, any processes (even discrete ones) could be specified for <italic>x</italic> and <italic>y</italic>. Following the conceptual approach proposed here, the objective function over encoder and decoder parameters could be specified and optimized subject to constraints. Furthermore, a full decoding system would certainly incorporate additional components such as modifications for increased stopping reliability [<xref ref-type="bibr" rid="pcbi.1004288.ref046">46</xref>] and approaches for longer-timescale nonstationarity tracking as in [<xref ref-type="bibr" rid="pcbi.1004288.ref047">47</xref>, <xref ref-type="bibr" rid="pcbi.1004288.ref048">48</xref>].</p>
<p>In our OPS experiments the modeling assumptions hold by construction, so how significantly results will deviate from those of this paper in physiological experiments is open. Also, we admittedly focused on low dimensional control in order to gain conceptual ground, but this is simpler than high dimensional control. It remains to be explored how much more difficult user learning is in high dimensional settings, and what modifications will be required to assist users in learning optimal encodings. Additionally, more detailed characterization of the learning process may become relevant.</p>
<p>If applying our framework to human BCI, there are a number of practical opportunities. For example, it may be interesting to develop interfaces which indicate to the user how much control is available for some number of DOF and permit the user to select how to map control to the BCI effector. Users may have specific preferences to invert certain dimensions of control or request more precision on a certain effector DOF even at the expense of precision for other DOF. Such user-specific modifications are entirely amenable within our approach.</p>
</sec>
</sec>
<sec id="sec019" sec-type="materials|methods">
<title>Materials and Methods</title>
<p>All simulations, optimizations, and experiments were conducted using custom code in Matlab (<bold>see corresponding author‚Äôs website for code implementing the main algorithm</bold>). As noted when presented in the text, full derivations of our methods are provided in <xref ref-type="supplementary-material" rid="pcbi.1004288.s001">S1 Text</xref>. The remainder of this methods section describes the experimental methods.</p>
<sec id="sec020">
<title>Ethics statement</title>
<p>Human protocols were approved by the Columbia University Morningside Institutional Review Board‚Äîall subjects read an IRB-approved informed consent document and provided verbal consent (Protocol Number: IRB-AAAM6407).</p>
</sec>
<sec id="sec021">
<title>Online prosthesis simulator as a model of BCI</title>
<p>The Online prosthesis simulator (OPS) is an experimental platform that tracks overt movements of the user, uses the movements to simulate noisy neural data, and then decodes the synthetic data by a brain-computer interface (BCI) decoding algorithm [<xref ref-type="bibr" rid="pcbi.1004288.ref005">5</xref>, <xref ref-type="bibr" rid="pcbi.1004288.ref013">13</xref>]. We captured the overt movements of able-bodied users with a Microsoft Kinect. The Kinect interfaces to a standard computer via usb and signals were analyzed in real time in matlab (middleware for Kinect-to-Matlab follows [<xref ref-type="bibr" rid="pcbi.1004288.ref005">5</xref>]). Kinect data for our experiments was collected at approximately 10Hz. Movement data was used to simulate neural signals by an arbitrary scheme, selectable by the experimenter‚Äîwe chose to generate neural activity by de-meaning the movement signals, linearly mixing them, and adding independent Gaussian noise to each neural channel. This simulated neural data was then analyzed by real-time BCI algorithms during experiments. The decoded results of the simulated data were presented as feedback to the user so the user could change their movements. See <xref ref-type="fig" rid="pcbi.1004288.g008">Fig 8</xref> for a visual depiction of this system.</p>
<fig id="pcbi.1004288.g008" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004288.g008</object-id>
<label>Fig 8</label>
<caption>
<title>OPS setup is depicted and related to real BCI.</title>
<p>The cartoon on the left depicts the OPS: (a) Actual overt movements of the user are detected. (b) Synthetic neural activity is generated in some fashion derived from the overt movements. (c) The decoder sees only the simulated activity and provides a decoded estimate of the cursor position. (d) The cursor is placed on the screen along with the target permitting visual feedback. The flow diagrams on the right compare how data is generated in a real BCI versus the OPS and the relationship between the variables. While there is no direct link relating intended kinematics and overt movement (or volition), these variables are conditionally related. If the user desires to produce a certain decoded kinematics and doing so requires some modulations of the neural activity which are controlled by the overt movement, then the user should modulate overt movement in a way that reflects their intended kinematics.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004288.g008"/>
</fig>
<p>The user‚Äôs kinematic intention (<italic>x</italic><sub><italic>t</italic></sub>) should correspond to an attempt to control the cursor towards a target presented on the screen. The overt arm movements of the user are used to simulate a population of synthetic, noisy neural units (<italic>y</italic><sub><italic>t</italic></sub>). The encoding model (<italic>A</italic>) is the estimated linear mapping from <italic>x</italic><sub><italic>t</italic></sub> to <italic>y</italic><sub><italic>t</italic></sub>. During the task, the neural activity is combined with the decoded estimate of the previous timestep (<inline-formula id="pcbi.1004288.e022"><mml:math id="M22" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>‚àí</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>) to determine the current cursor position (<inline-formula id="pcbi.1004288.e023"><mml:math id="M23" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>). The decoded cursor position comes from the use of the optimal steady state Kalman filter (using <italic>F</italic> and <italic>G</italic> via <xref ref-type="disp-formula" rid="pcbi.1004288.e005">Eq 3</xref>).</p>
<p>In some high level sense, the user could explore the space of mappings from their behavior to visible feedback. While the user could not change how their overt movements map to neural activity, the user could change the relationship between ‚Äúkinematic intention‚Äù and simulated neural activity‚Äîthis is the relationship we call the encoding model. That is, changes in how the user made overt movements when intending to obtain certain decoded kinematics will cause changes in the encoding model (estimated parameters <italic>A</italic>).</p>
<p>We emphasize that these overt movements are not supposed to correspond to overt movements in a BCI setting; rather, these overt movements are simply supposed to provide arbitrary volitional signals which the BCI system will exploit to perform a task. BCI permits the use of any neural signals which are correlated with user volition‚Äîfor example, even imagined speech has been used to control a 1D cursor [<xref ref-type="bibr" rid="pcbi.1004288.ref049">49</xref>]. The OPS could be driven with arbitrary control signals, and overt movement signals seem a reasonable model of the class of signals which may in part be used to drive a real BCI.</p>
</sec>
<sec id="sec022">
<title>Experimental procedures</title>
<p>To analyze optimal encoder-decoder pairs, we have been considering the objective function of a ‚Äútracing‚Äù task (a.k.a. pursuit tracking), in which the user has a time-varying kinematic intention and the decoder attempts to optimally estimate the kinematics. This objective is standard, physically meaningful, and the methods developed from it yield smooth priors. We validated our methods using the OPS on a ‚Äúpinball‚Äù task (a.k.a. point-to-point reaching) where the user controls a smoothly moving cursor towards targets, as this is more realistic for applications.</p>
<p>In this work, we present the results of a 1D pinball task. We present data from 4 subjects (none of whom are authors of the study or otherwise directly affiliated with this project). Subjects were explained the rules of the ‚Äúgame‚Äù they were to play but were not described details of simulated neural activity (some had performed prototype versions of the experiment previous to participation in the experiments reported here). Before beginning the task, we collected calibration data for each user‚Äîthe user was instructed to move around freely in an unstructured way. During this time, the user saw real-time video (RGB image frames) of themselves with skeletal tracking superimposed, in order to see how well the Kinect tracking worked. This unstructured phase was to get an estimate of the empirical neural activity covariance (i.e. estimated as the sample covariance of the neural responses).</p>
<p>The subjects participated in one session for each of two decoders (‚Äúmotor-imitation‚Äù and ‚Äúpre-computed‚Äù, described more below) in each of three ‚Äúsignal cases‚Äù. Signal cases consisted of specifications of how strongly the simulated neural channels were driven by different tracked body movements of the user (described more below). Between each of these six conditions, subjects were given a break until they felt ready for the next. For each signal case, the two decoder sessions were presented with the motor-imitation trial first, followed by a trial where the cursor was controlled by the pre-computed decoder. These trials were independent and the decoders were unrelated so the order mattered only so the control strategy the user learned when using the pre-computed decoder would not affect the motor-imitation control scheme. For block-order validation see <xref ref-type="supplementary-material" rid="pcbi.1004288.s003">S1 Fig</xref>.</p>
<p>Each session consisted of two key phases, ‚Äúfree exploration‚Äù and ‚Äútesting.‚Äù During free exploration, the user controlled a cursor on a screen via closed-loop OPS control, and there was no target. During this time, the user was prompted to explore and try to learn as well as possible how to control the cursor‚Äîthis phase gave the subject an opportunity to learn, and nothing about the decoder was changed. Exploration rapidly provided information about how the user‚Äôs intentions relate to the movement of the cursor. The user can adjust their control strategy, in turn, adjusting the tuning of the simulated neurons‚Äîthis process constitutes learning in this task. After a few minutes of exploration, a target appeared and the user was prompted verbally to move to the testing phase when ready by holding the cursor at the target for a few seconds (subject 1 moved directly to the testing phase without having to hold a target first, and this subject reported having had adequate time in free exploration). During testing, a single target at a time was presented, surrounded by a visible halo. The user attempted to control their cursor to the target and attempted to ‚Äúacquire‚Äù the target by holding the cursor in the halo-region (holding is indicated by a color change of the region inside the halo). After a short period of time, if the cursor is held within the halo (‚âà1s), the target is acquired, disappears, and a new target is randomly placed at a new location. Targets that were not acquired after ‚âà15s were treated as misses, and a new target replaced them. The subject was instructed to acquire as many targets as possible in the ‚âà3min duration of the testing phase. Before beginning the task, the entire trial structure was verbally described to each subject, and verbal reminders of trial-stage (at transitions) were provided by the experimenter. A video depicting the experimental procedures is included as <xref ref-type="supplementary-material" rid="pcbi.1004288.s002">S1 Movie</xref>.</p>
</sec>
<sec id="sec023">
<title>Decoders</title>
<p>The two decoders tested were selected either by ‚Äúmotor-imitation‚Äù initialization or by pre-computing the optimal encoder-decoder pair and presenting the optimal decoder. Trials with ‚Äúmotor-imitation‚Äù decoders began with an extra phase (at the beginning of the free exploration phase), during which a target moved smoothly on the screen. The user was instructed to ‚Äútrace‚Äù the target with their hand movements, thereby providing the ‚Äúnative‚Äù control mapping of making rightwards and leftwards movements of their hands to control a cursor along the horizontal axis (without visual feedback, i.e. open-loop). This OPS phase provided supervised data which permitted estimation (by recursive least squares‚Äîan online algorithm for linear regression) of a motor-imitation encoding model, a control scheme which is as close as possible to user default control. The motor-imitation decoder refers to the optimal decoder corresponding to this encoding model, which can be computed directly from the estimated encoding model. Alternatively, for the pre-computed decoder trials, we used covariance information determined from the calibration data to estimate an optimal encoder-decoder pair according to our joint optimization approach presented in this paper, and we presented the pre-computed optimal decoder to the user. This second approach does not require labeled data; rather it merely optimizes the encoder-decoder pair such that good task performance results after the user learns how to use the scheme. Selection of the decoder is unsupervised, and this approach relies on the user to adapt to match the fixed decoder.</p>
<p>We note that <italic>P</italic> and <italic>Q</italic> (i.e. the prior dynamics parameters of <xref ref-type="disp-formula" rid="pcbi.1004288.e003">Eq 1</xref>) are the same for both cases, with <italic>P</italic> selected just under 1 (i.e. .99) to discourage drift and <italic>Q</italic> selected to be small (.01), which was determined by the sample rate and the distances in the task to permit appropriate movement rates for this task. Strictly, <italic>Q</italic> is a free parameter which affects smoothing, but it should be selected in a task-dependent manner matched to the speed of target movement (or distance between targets).</p>
</sec>
<sec id="sec024">
<title>Signal cases</title>
<p>Using the OPS, we are able to arbitrarily specify mappings of user movements to the simulated neural data as well as setting noise levels across channels‚Äîthis corresponds to the blue box of the OPS flow diagram in <xref ref-type="fig" rid="pcbi.1004288.g008">Fig 8</xref>. To compare results across subjects, we selected three pre-defined mappings by which overt movement would drive simulated neural channels (k = 6) along with corresponding neural noise structure. These could be thought of either as a small number of electrodes or pre-processed neural data (e.g. after dimensionality reduction). Noise is the same order of magnitude as the signal‚Äîthis is realistic for single units. For each channel, noise is set to a fixed high or low value, with high noise set to be approximately the same magnitude as the signal of a heavily used channel and low noise set to be less than the signal power of a heavily used channel (per channel). Optimal encoder-decoder pairs necessarily take into account user calibration data so it is not possible to know in advance precisely what the optimal encoder-decoder pair will be. With that said, the optimal coding scheme should leverage the highest SNR dimensions. For comparison, the motor-imitation scheme which the user initializes will consist of rightwards and leftwards movements to control the cursor rightwards and leftwards respectively.</p>
<p><italic>Case 1:</italic> Simulated neural activity is linearly modulated by positions of the right hand in horizontal and vertical dimensions‚Äîone channel driven by horizontal movement, another by vertical movement. Noise is low in the vertical dimension channel and high in the horizontal dimension channel, so the optimal encoder-decoder pair will predominantly encode the movement axis in the y movements of the right hand.</p>
<p><italic>Case 2:</italic> Simulated neural activity is linearly modulated by horizontal position of both hands together as well as distance between hands‚Äîone channel driven by the sum of the two hands‚Äô horizontal position, another channel by their difference. The channel driven by distance between hands has low noise so the optimal encoder-decoder pair will predominantly encode the movement axis in channel corresponding to the distance between hands.</p>
<p><italic>Case 3:</italic> Simulated neural activity is linearly modulated by positions of each hand in horizontal and vertical dimensions independently‚Äîseparate channels are driven by each of these variables. Noise is low on the simulated activity driven by vertical dimension of each hand, so subjects should move both hands together vertically.</p>
<p>We compared all subjects on all three cases of signal-noise structure using both motor-imitation initialized decoders and pre-computed decoders. The above cases were selected with the intent of highlighting differences between na√Øve, motor-imitation schemes and schemes which permit better performance by coding in dimensions that are not natively leveraged. The intention was to see if optimization of the decoder yielded performance differences and how learnable the schemes were.</p>
</sec>
<sec id="sec025">
<title>Estimation of encoding models</title>
<p>In the results, we made use of estimated user encoding models, comparing them with optimal encoding models. To estimate the user encoding models during the pinball task, we simply performed linear regression from target positions to neural activity during the pinball phase. This assumes that the user is attempting to control the cursor such that it moves directly towards the target.</p>
</sec>
</sec>
<sec id="sec026">
<title>Supporting Information</title>
<supplementary-material id="pcbi.1004288.s001" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004288.s001" mimetype="application/pdf" xlink:type="simple">
<label>S1 Text</label>
<caption>
<title>Mathematical appendices including detailed derivations of methods used for joint encoder-decoder optimization.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004288.s002" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004288.s002" mimetype="video/quicktime" xlink:type="simple">
<label>S1 Movie</label>
<caption>
<title>‚ÄúSimple demonstration of experimental procedures‚Äù.</title>
<p>Side-by-side video of tracked user pose along with cursor control task. For high SNR, user initializes the decoder by motor-imitation, freely explores to become comfortable with the scheme, and then proceeds to the testing phase. The data used in the video was collected for demonstration purposes only.</p>
<p>(MOV)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004288.s003" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004288.s003" mimetype="image/tiff" xlink:type="simple">
<label>S1 Fig</label>
<caption>
<title>‚ÄúBlock order validation‚Äù.</title>
<p>Two additional subjects were run for alternating blocks of testing with the motor-imitation and pre-computed decoder on signal case 1 (three tests blocks using each decoder per subject). The initialization for the motor-imitation decoder was run once at the beginning. Between decoder switches, subjects were given short exploration phases to refamiliarize themselves before testing. One subject began with the motor-imitation decoder, and the other began with the pre-computed decoder. Performance across subjects and blocks was significantly better using the pre-computed decoder (using a one-sided t-test on targets/time across repeats and subjects). Across subjects and repeats, no statistically significant linear trend was found for performance with the motor-imitation decoder. A weak trend was found for the pre-computed decoder across repeats (i.e. for these subjects there was some evidence that subjects continued to improve when using the pre-computed decoder <italic>p</italic> &lt; .05)</p>
<p>(TIFF)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>Earlier versions of related experiments were assisted by Antony Qian. Thanks to Hagai Lalazar for comments on a draft of the manuscript. Also, thanks to Conor Dempsey, Lars Buesing, Eftychios Pnevmatikakis, Grace Lindsay as well as other members of the Center for Theoretical Neuroscience at Columbia for helpful discussions.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1004288.ref001">
<label>1</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Shenoy</surname> <given-names>KV</given-names></name>, <name name-style="western"><surname>Carmena</surname> <given-names>JM</given-names></name> (<year>2014</year>) <article-title>Combining decoder design and neural adaptation in brain-machine interfaces</article-title>. <source>Neuron</source> <volume>84</volume>: <fpage>665</fpage>‚Äì<lpage>680</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2014.08.038" xlink:type="simple">10.1016/j.neuron.2014.08.038</ext-link></comment> <object-id pub-id-type="pmid">25459407</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004288.ref002">
<label>2</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Koyama</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Chase</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Whitford</surname> <given-names>AS</given-names></name>, <name name-style="western"><surname>Velliste</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Schwartz</surname> <given-names>AB</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>Comparison of brain-computer interface decoding algorithms in open-loop and closed-loop control</article-title>. <source>Journal of computational neuroscience</source> <volume>29</volume>: <fpage>73</fpage>‚Äì<lpage>87</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s10827-009-0196-9" xlink:type="simple">10.1007/s10827-009-0196-9</ext-link></comment> <object-id pub-id-type="pmid">19904595</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004288.ref003">
<label>3</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Taylor</surname> <given-names>DM</given-names></name>, <name name-style="western"><surname>Helms Tillery</surname> <given-names>SI</given-names></name>, <name name-style="western"><surname>Schwartz</surname> <given-names>AB</given-names></name> (<year>2002</year>) <article-title>Direct cortical control of 3d neuroprosthetic devices</article-title>. <source>Science</source>: <fpage>1829</fpage>‚Äì<lpage>1832</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.1070291" xlink:type="simple">10.1126/science.1070291</ext-link></comment> <object-id pub-id-type="pmid">12052948</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004288.ref004">
<label>4</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Orsborn</surname> <given-names>AL</given-names></name>, <name name-style="western"><surname>Moorman</surname> <given-names>HG</given-names></name>, <name name-style="western"><surname>Overduin</surname> <given-names>SA</given-names></name>, <name name-style="western"><surname>Shanechi</surname> <given-names>MM</given-names></name>, <name name-style="western"><surname>Dimitrov</surname> <given-names>DF</given-names></name>, <etal>et al</etal>. (<year>2014</year>) <article-title>Closed-loop decoder adaptation shapes neural plasticity for skillful neuroprosthetic control</article-title>. <source>Neuron</source> <volume>82</volume>: <fpage>1380</fpage>‚Äì<lpage>1392</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2014.04.048" xlink:type="simple">10.1016/j.neuron.2014.04.048</ext-link></comment> <object-id pub-id-type="pmid">24945777</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004288.ref005">
<label>5</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Kowalski</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>He</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Srinivasan</surname> <given-names>L</given-names></name> (<year>2013</year>) <article-title>Dynamic analysis of naive adaptive brain-machine interfaces</article-title>. <source>Neural Computation</source> <volume>25</volume>: <fpage>2373</fpage>‚Äì<lpage>2420</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/NECO_a_00484" xlink:type="simple">10.1162/NECO_a_00484</ext-link></comment> <object-id pub-id-type="pmid">23777523</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004288.ref006">
<label>6</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Carmena</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Lebedev</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Crist</surname> <given-names>RE</given-names></name>, <name name-style="western"><surname>ODoherty</surname> <given-names>JE</given-names></name>, <name name-style="western"><surname>Santucci</surname> <given-names>DM</given-names></name>, <etal>et al</etal>. (<year>2003</year>) <article-title>Learning to control a brainmachine interface for reaching and grasping by primates</article-title>. <source>PLoS Biology</source> <volume>1</volume>: <fpage>E42</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pbio.0000042" xlink:type="simple">10.1371/journal.pbio.0000042</ext-link></comment> <object-id pub-id-type="pmid">14624244</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004288.ref007">
<label>7</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Ganguly</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Carmena</surname> <given-names>JM</given-names></name> (<year>2009</year>) <article-title>Emergence of a stable cortical map for neuroprosthetic control</article-title>. <source>PLoS Biology</source>: <fpage>e1000153</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pbio.1000153" xlink:type="simple">10.1371/journal.pbio.1000153</ext-link></comment> <object-id pub-id-type="pmid">19621062</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004288.ref008">
<label>8</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Dangi</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Gowda</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Moorman</surname> <given-names>HG</given-names></name>, <name name-style="western"><surname>Orsborn</surname> <given-names>AL</given-names></name>, <name name-style="western"><surname>So</surname> <given-names>K</given-names></name>, <etal>et al</etal>. (<year>2014</year>) <article-title>Continuous closed-loop decoder adaptation with a recursive maximum likelihood algorithm allows for rapid performance acquisition in brain-machine interfaces</article-title>. <source>Neural Computation</source>: <fpage>1</fpage>‚Äì<lpage>29</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004288.ref009">
<label>9</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>DiGiovanna</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Mahmoudi</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Fortes</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Principe</surname> <given-names>JC</given-names></name>, <name name-style="western"><surname>Sanchez</surname> <given-names>JC</given-names></name> (<year>2009</year>) <article-title>Coadaptive brain-machine interface via reinforcement learning</article-title>. <source>Biomedical Engineering, IEEE Transactions on</source> <volume>56</volume>: <fpage>54</fpage>‚Äì<lpage>64</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1109/TBME.2008.926699" xlink:type="simple">10.1109/TBME.2008.926699</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004288.ref010">
<label>10</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Lagang</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Srinivasan</surname> <given-names>L</given-names></name> (<year>2013</year>) <article-title>Stochastic optimal control as a theory of brain-machine interface operation</article-title>. <source>Neural Computation</source> <volume>25</volume>: <fpage>374</fpage>‚Äì<lpage>417</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/NECO_a_00394" xlink:type="simple">10.1162/NECO_a_00394</ext-link></comment> <object-id pub-id-type="pmid">23148413</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004288.ref011">
<label>11</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Merel</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Fox</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Jebara</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Paninski</surname> <given-names>L</given-names></name> (<year>2013</year>) <article-title>A multi-agent control framework for co-adaptation in brain-computer interfaces</article-title>. <source>Advances in Neural Information Processing Systems</source>.</mixed-citation>
</ref>
<ref id="pcbi.1004288.ref012">
<label>12</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>He</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Srinivasan</surname> <given-names>L</given-names></name> (<year>2014</year>) <article-title>Neural shaping with joint optimization of controller and plant under restricted dynamics</article-title>. In: <source>Information Theory and Applications Workshop (ITA)</source>, 2014. pp. <fpage>1</fpage>‚Äì<lpage>6</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004288.ref013">
<label>13</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Cunningham</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Nuyujukian</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Gilja</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Chestek</surname> <given-names>CA</given-names></name>, <name name-style="western"><surname>Ryu</surname> <given-names>SI</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>A closed-loop human simulator for investigating the role of feedback control in brain-machine interfaces</article-title>. <source>Journal of Neurophysiology</source> <volume>105</volume>: <fpage>1932</fpage>‚Äì<lpage>1949</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.00503.2010" xlink:type="simple">10.1152/jn.00503.2010</ext-link></comment> <object-id pub-id-type="pmid">20943945</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004288.ref014">
<label>14</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Gilja</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Nuyujukian</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Chestek</surname> <given-names>CA</given-names></name>, <name name-style="western"><surname>Cunningham</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Byron</surname> <given-names>MY</given-names></name>, <etal>et al</etal>. (<year>2012</year>) <article-title>A high-performance neural prosthesis enabled by control algorithm design</article-title>. <source>Nature Neuroscience</source> <volume>15</volume>: <fpage>1752</fpage>‚Äì<lpage>1757</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.3265" xlink:type="simple">10.1038/nn.3265</ext-link></comment> <object-id pub-id-type="pmid">23160043</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004288.ref015">
<label>15</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Wu</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Gao</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Bienenstock</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Donoghue</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Black</surname> <given-names>MJ</given-names></name> (<year>2006</year>) <article-title>Bayesian population decoding of motor cortical activity using a kalman filter</article-title>. <source>Neural Computation</source> <volume>18</volume>: <fpage>80</fpage>‚Äì<lpage>118</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/089976606774841585" xlink:type="simple">10.1162/089976606774841585</ext-link></comment> <object-id pub-id-type="pmid">16354382</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004288.ref016">
<label>16</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Kim</surname> <given-names>SP</given-names></name>, <name name-style="western"><surname>Simeral</surname> <given-names>JD</given-names></name>, <name name-style="western"><surname>Hochberg</surname> <given-names>LR</given-names></name>, <name name-style="western"><surname>Donoghue</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Black</surname> <given-names>MJ</given-names></name> (<year>2008</year>) <article-title>Neural control of computer cursor velocity by decoding motor cortical spiking activity in humans with tetraplegia</article-title>. <source>Journal of Neural Engineering</source> <volume>5</volume>: <fpage>455</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1088/1741-2560/5/4/010" xlink:type="simple">10.1088/1741-2560/5/4/010</ext-link></comment> <object-id pub-id-type="pmid">19015583</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004288.ref017">
<label>17</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Kalman</surname> <given-names>RE</given-names></name> (<year>1960</year>) <article-title>A new approach to linear filtering and prediction problems</article-title>. <source>Transactions of the ASME Journal of Basic Engineering</source>: <fpage>35</fpage>‚Äì<lpage>45</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1115/1.3662552" xlink:type="simple">10.1115/1.3662552</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004288.ref018">
<label>18</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Ho</surname> <given-names>YC</given-names></name>, <name name-style="western"><surname>Lee</surname> <given-names>R</given-names></name> (<year>1964</year>) <article-title>A bayesian approach to problems in stochastic estimation and control</article-title>. <source>Automatic Control, IEEE Transactions on</source> <volume>9</volume>: <fpage>333</fpage>‚Äì<lpage>339</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1109/TAC.1964.1105763" xlink:type="simple">10.1109/TAC.1964.1105763</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004288.ref019">
<label>19</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Malik</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Truccolo</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Brown</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Hochberg</surname> <given-names>L</given-names></name> (<year>2011</year>) <article-title>Efficient decoding with steady-state kalman filter in neural interface systems</article-title>. <source>Neural Systems and Rehabilitation Engineering, IEEE Transactions on</source> <volume>19</volume>: <fpage>25</fpage>‚Äì<lpage>34</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1109/TNSRE.2010.2092443" xlink:type="simple">10.1109/TNSRE.2010.2092443</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004288.ref020">
<label>20</label>
<mixed-citation xlink:type="simple" publication-type="other">Simon D (2006) Optimal State Estimation: Kalman, H Infinity, and Nonlinear Approaches. Wiley-Interscience.</mixed-citation>
</ref>
<ref id="pcbi.1004288.ref021">
<label>21</label>
<mixed-citation xlink:type="simple" publication-type="other">Laub A (2005) Matrix Analysis for Scientists and Engineers. Society for Industrial and Applied Mathematics. URL <ext-link ext-link-type="uri" xlink:type="simple" xlink:href="http://books.google.com/books?id=0kdukXSX-9AC">http://books.google.com/books?id=0kdukXSX-9AC</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1004288.ref022">
<label>22</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Chase</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Kass</surname> <given-names>RE</given-names></name>, <name name-style="western"><surname>Schwartz</surname> <given-names>AB</given-names></name> (<year>2012</year>) <article-title>Behavioral and neural correlates of visuomotor adaptation observed through a brain-computer interface in primary motor cortex</article-title>. <source>Journal of Neurophysiology</source> <volume>108</volume>: <fpage>624</fpage>‚Äì<lpage>644</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.00371.2011" xlink:type="simple">10.1152/jn.00371.2011</ext-link></comment> <object-id pub-id-type="pmid">22496532</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004288.ref023">
<label>23</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Hwang</surname> <given-names>EJ</given-names></name>, <name name-style="western"><surname>Bailey</surname> <given-names>PM</given-names></name>, <name name-style="western"><surname>Andersen</surname> <given-names>RA</given-names></name> (<year>2013</year>) <article-title>Volitional control of neural activity relies on the natural motor repertoire</article-title>. <source>Current Biology</source> <volume>23</volume>: <fpage>353</fpage>‚Äì<lpage>361</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.cub.2013.01.027" xlink:type="simple">10.1016/j.cub.2013.01.027</ext-link></comment> <object-id pub-id-type="pmid">23416098</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004288.ref024">
<label>24</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Sadtler</surname> <given-names>PT</given-names></name>, <name name-style="western"><surname>Quick</surname> <given-names>KM</given-names></name>, <name name-style="western"><surname>Golub</surname> <given-names>MD</given-names></name>, <name name-style="western"><surname>Chase</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Ryu</surname> <given-names>SI</given-names></name>, <etal>et al</etal>. (<year>2014</year>) <article-title>Neural constraints on learning</article-title>. <source>Nature</source> <volume>512</volume>: <fpage>423</fpage>‚Äì<lpage>426</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature13665" xlink:type="simple">10.1038/nature13665</ext-link></comment> <object-id pub-id-type="pmid">25164754</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004288.ref025">
<label>25</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Cunningham</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Ghahramani</surname> <given-names>Z</given-names></name> (in press) <article-title>Linear dimensionality reduction: Survey, insights, and generalizations</article-title>. <source>Journal of Machine Learning Research</source>.</mixed-citation>
</ref>
<ref id="pcbi.1004288.ref026">
<label>26</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Doi</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Balcan</surname> <given-names>DC</given-names></name>, <name name-style="western"><surname>Lewicki</surname> <given-names>MS</given-names></name> (<year>2007</year>) <article-title>Robust coding over noisy overcomplete channels</article-title>. <source>IEEE Transactions on Image Processing</source> <volume>16</volume>: <fpage>442</fpage>‚Äì<lpage>452</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1109/TIP.2006.888352" xlink:type="simple">10.1109/TIP.2006.888352</ext-link></comment> <object-id pub-id-type="pmid">17269637</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004288.ref027">
<label>27</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Doi</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Lewicki</surname> <given-names>MS</given-names></name> (<year>2011</year>) <article-title>Characterization of minimum error linear coding with sensory and neural noise</article-title>. <source>Neural Computation</source> <volume>23</volume>: <fpage>2498</fpage>‚Äì<lpage>2510</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/NECO_a_00181" xlink:type="simple">10.1162/NECO_a_00181</ext-link></comment> <object-id pub-id-type="pmid">21732860</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004288.ref028">
<label>28</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Doi</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Gauthier</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Field</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Shlens</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Sher</surname> <given-names>A</given-names></name>, <etal>et al</etal>. (<year>2012</year>) <article-title>Efficient coding of spatial information in the primate retina</article-title>. <source>Journal of Neuroscience</source> <volume>32</volume>: <fpage>16256</fpage>‚Äì<lpage>16264</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.4036-12.2012" xlink:type="simple">10.1523/JNEUROSCI.4036-12.2012</ext-link></comment> <object-id pub-id-type="pmid">23152609</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004288.ref029">
<label>29</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Lee</surname> <given-names>KH</given-names></name>, <name name-style="western"><surname>Petersen</surname> <given-names>D</given-names></name> (<year>1976</year>) <article-title>Optimal linear coding for vector channels</article-title>. <source>Communications, IEEE Transactions on</source> <volume>24</volume>: <fpage>1283</fpage>‚Äì<lpage>1290</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1109/TCOM.1976.1093255" xlink:type="simple">10.1109/TCOM.1976.1093255</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004288.ref030">
<label>30</label>
<mixed-citation xlink:type="simple" publication-type="other">Gilja V, Nuyujukian P, Chestek CA, Cunningham JP, Yu BM, et al. (2012) A brain machine interface control algorithm designed from a feedback control perspective. In: Engineering in Medicine and Biology Society (EMBC), 2012 Annual International Conference of the IEEE. IEEE, pp. 1318‚Äì1322.</mixed-citation>
</ref>
<ref id="pcbi.1004288.ref031">
<label>31</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Jarosiewicz</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Chase</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Fraser</surname> <given-names>GW</given-names></name>, <name name-style="western"><surname>Velliste</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Kass</surname> <given-names>RE</given-names></name>, <etal>et al</etal>. (<year>2008</year>) <article-title>Functional network reorganization during learning in a brain-computer interface paradigm</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>105</volume>: <fpage>19486</fpage>‚Äì<lpage>19491</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.0808113105" xlink:type="simple">10.1073/pnas.0808113105</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004288.ref032">
<label>32</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Ganguly</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Dimitrov</surname> <given-names>DF</given-names></name>, <name name-style="western"><surname>Wallis</surname> <given-names>JD</given-names></name>, <name name-style="western"><surname>Carmena</surname> <given-names>JM</given-names></name> (<year>2011</year>) <article-title>Reversible large-scale modification of cortical networks during neuroprosthetic control</article-title>. <source>Nature Neuroscience</source> <volume>14</volume>: <fpage>662</fpage>‚Äì<lpage>667</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.2797" xlink:type="simple">10.1038/nn.2797</ext-link></comment> <object-id pub-id-type="pmid">21499255</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004288.ref033">
<label>33</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Bobrow</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Murray</surname> <given-names>W</given-names></name> (<year>1993</year>) <article-title>An algorithm for rls identification parameters that vary quickly with time</article-title>. <source>Automatic Control, IEEE Transactions on</source> <volume>38</volume>: <fpage>351</fpage>‚Äì<lpage>354</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1109/9.250491" xlink:type="simple">10.1109/9.250491</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004288.ref034">
<label>34</label>
<mixed-citation xlink:type="simple" publication-type="other">Ramabadran T, Sinha D (1989) On the selection of measurements in least-squares estimation. In: Systems Engineering, 1989., IEEE International Conference on. pp. 221‚Äì226.</mixed-citation>
</ref>
<ref id="pcbi.1004288.ref035">
<label>35</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Mosier</surname> <given-names>KM</given-names></name>, <name name-style="western"><surname>Scheidt</surname> <given-names>RA</given-names></name>, <name name-style="western"><surname>Acosta</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Mussa-Ivaldi</surname> <given-names>FA</given-names></name> (<year>2005</year>) <article-title>Remapping hand movements in a novel geometrical environment</article-title>. <source>Journal of Neurophysiology</source> <volume>94</volume>: <fpage>4362</fpage>‚Äì<lpage>4372</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.00380.2005" xlink:type="simple">10.1152/jn.00380.2005</ext-link></comment> <object-id pub-id-type="pmid">16148276</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004288.ref036">
<label>36</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Danziger</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Fishbach</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Mussa-Ivaldi</surname> <given-names>FA</given-names></name> (<year>2009</year>) <article-title>Learning algorithms for human-machine interfaces</article-title>. <source>Biomedical Engineering, IEEE Transactions on</source> <volume>56</volume>: <fpage>1502</fpage>‚Äì<lpage>1511</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1109/TBME.2009.2013822" xlink:type="simple">10.1109/TBME.2009.2013822</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004288.ref037">
<label>37</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Danziger</surname> <given-names>Z</given-names></name> (<year>2014</year>) <article-title>A reductionist approach to the analysis of learning in brain-computer interfaces</article-title>. <source>Biological Cybernetics</source> <volume>108</volume>: <fpage>183</fpage>‚Äì<lpage>201</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s00422-014-0589-3" xlink:type="simple">10.1007/s00422-014-0589-3</ext-link></comment> <object-id pub-id-type="pmid">24531644</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004288.ref038">
<label>38</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Casadio</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Ranganathan</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Mussa-Ivaldi</surname> <given-names>FA</given-names></name> (<year>2012</year>) <article-title>The body-machine interface: a new perspective on an old theme</article-title>. <source>Journal of Motor Behavior</source> <volume>44</volume>: <fpage>419</fpage>‚Äì<lpage>33</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1080/00222895.2012.700968" xlink:type="simple">10.1080/00222895.2012.700968</ext-link></comment> <object-id pub-id-type="pmid">23237465</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004288.ref039">
<label>39</label>
<mixed-citation xlink:type="simple" publication-type="other">Casadio M, Pressman A, Acosta S, Danzinger Z, Fishbach A, et al. (2011) Body machine interface: remapping motor skills after spinal cord injury. Proceedings of 2011 International Conference On Rehabilitation Robotics.</mixed-citation>
</ref>
<ref id="pcbi.1004288.ref040">
<label>40</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Jackson</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Fetz</surname> <given-names>EE</given-names></name> (<year>2011</year>) <article-title>Interfacing with the computational brain</article-title>. <source>Neural Systems and Rehabilitation Engineering, IEEE Transactions on</source> <volume>19</volume>: <fpage>534</fpage>‚Äì<lpage>541</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1109/TNSRE.2011.2158586" xlink:type="simple">10.1109/TNSRE.2011.2158586</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004288.ref041">
<label>41</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Green</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Kalaska</surname> <given-names>JF</given-names></name> (<year>2011</year>) <article-title>Learning to move machines with the mind</article-title>. <source>Trends in Neurosciences</source> <volume>34</volume>: <fpage>61</fpage>‚Äì<lpage>75</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.tins.2010.11.003" xlink:type="simple">10.1016/j.tins.2010.11.003</ext-link></comment> <object-id pub-id-type="pmid">21176975</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004288.ref042">
<label>42</label>
<mixed-citation xlink:type="simple" publication-type="other">Churchland MM, Cunningham JP, Kaufman MT, Foster JD, Nuyujukian P, et al. (2012) Neural population dynamics during reaching. Nature.</mixed-citation>
</ref>
<ref id="pcbi.1004288.ref043">
<label>43</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Byron</surname> <given-names>MY</given-names></name>, <name name-style="western"><surname>Cunningham</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Santhanam</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Ryu</surname> <given-names>SI</given-names></name>, <name name-style="western"><surname>Shenoy</surname> <given-names>KV</given-names></name>, <etal>et al</etal>. (<year>2009</year>) <article-title>Gaussian-process factor analysis for low-dimensional single-trial analysis of neural population activity</article-title>. In: <source>Advances in Neural Information Processing Systems</source>. pp. <fpage>1881</fpage>‚Äì<lpage>1888</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004288.ref044">
<label>44</label>
<mixed-citation xlink:type="simple" publication-type="book">
<name name-style="western"><surname>Macke</surname> <given-names>JH</given-names></name>, <name name-style="western"><surname>Buesing</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Cunningham</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Yu</surname> <given-names>BM</given-names></name>, <name name-style="western"><surname>Shenoy</surname> <given-names>KV</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <chapter-title>Empirical models of spiking in neural populations</chapter-title>. In: <source>Advances in Neural Information Processing Systems</source>. <publisher-name>Curran Associates, Inc</publisher-name>., <volume>volume 24</volume>.</mixed-citation>
</ref>
<ref id="pcbi.1004288.ref045">
<label>45</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Harris</surname> <given-names>CM</given-names></name>, <name name-style="western"><surname>Wolpert</surname> <given-names>DM</given-names></name> (<year>1998</year>) <article-title>Signal-dependent noise determines motor planning</article-title>. <source>Nature</source> <volume>394</volume>: <fpage>780</fpage>‚Äì<lpage>784</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/29528" xlink:type="simple">10.1038/29528</ext-link></comment> <object-id pub-id-type="pmid">9723616</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004288.ref046">
<label>46</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Golub</surname> <given-names>MD</given-names></name>, <name name-style="western"><surname>Yu</surname> <given-names>BM</given-names></name>, <name name-style="western"><surname>Schwartz</surname> <given-names>AB</given-names></name>, <name name-style="western"><surname>Chase</surname> <given-names>SM</given-names></name> (<year>2014</year>) <article-title>Motor cortical control of movement speed with implications for brain-machine interface control</article-title>. <source>Journal of Neurophysiology</source>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.00391.2013" xlink:type="simple">10.1152/jn.00391.2013</ext-link></comment> <object-id pub-id-type="pmid">24717350</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004288.ref047">
<label>47</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Li</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>ODoherty</surname> <given-names>JE</given-names></name>, <name name-style="western"><surname>Lebedev</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Nicolelis</surname> <given-names>MAL</given-names></name> (<year>2011</year>) <article-title>Adaptive decoding for brain-machine interfaces through bayesian parameter updates</article-title>. <source>Neural Computation</source> <volume>23</volume>: <fpage>3162</fpage>‚Äì<lpage>204</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/NECO_a_00207" xlink:type="simple">10.1162/NECO_a_00207</ext-link></comment> <object-id pub-id-type="pmid">21919788</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004288.ref048">
<label>48</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Bishop</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Chestek</surname> <given-names>CC</given-names></name>, <name name-style="western"><surname>Gilja</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Nuyujukian</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Foster</surname> <given-names>JD</given-names></name>, <etal>et al</etal>. (<year>2014</year>) <article-title>Self-recalibrating classifiers for intracortical braincomputer interfaces</article-title>. <source>Journal of Neural Engineering</source> <volume>11</volume>: <fpage>026001</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1088/1741-2560/11/2/026001" xlink:type="simple">10.1088/1741-2560/11/2/026001</ext-link></comment> <object-id pub-id-type="pmid">24503597</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004288.ref049">
<label>49</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Leuthardt</surname> <given-names>EC</given-names></name>, <name name-style="western"><surname>Gaona</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Sharma</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Szrama</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Roland</surname> <given-names>J</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <article-title>Using the electrocorticographic speech network to control a brain-computer interface in humans</article-title>. <source>Journal of Neural Engineering</source> <volume>8</volume>: <fpage>036004</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1088/1741-2560/8/3/036004" xlink:type="simple">10.1088/1741-2560/8/3/036004</ext-link></comment> <object-id pub-id-type="pmid">21471638</object-id></mixed-citation>
</ref>
</ref-list>
</back>
</article>
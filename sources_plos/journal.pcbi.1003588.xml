<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id><journal-title-group>
<journal-title>PLoS Computational Biology</journal-title></journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-13-02024</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1003588</article-id>
<article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Biology and life sciences</subject><subj-group><subject>Computational biology</subject><subj-group><subject>Computational neuroscience</subject><subj-group><subject>Coding mechanisms</subject></subj-group></subj-group></subj-group><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive neuroscience</subject><subj-group><subject>Consciousness</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Computer and information sciences</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group></article-categories>
<title-group>
<article-title>From the Phenomenology to the Mechanisms of Consciousness: Integrated Information Theory 3.0</article-title>
<alt-title alt-title-type="running-head">Integrated Information Theory 3.0</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" equal-contrib="yes" xlink:type="simple"><name name-style="western"><surname>Oizumi</surname><given-names>Masafumi</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib>
<contrib contrib-type="author" equal-contrib="yes" xlink:type="simple"><name name-style="western"><surname>Albantakis</surname><given-names>Larissa</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Tononi</surname><given-names>Giulio</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
</contrib-group>
<aff id="aff1"><label>1</label><addr-line>Department of Psychiatry, University of Wisconsin, Madison, Wisconsin, United States of America</addr-line></aff>
<aff id="aff2"><label>2</label><addr-line>RIKEN Brain Science Institute, Wako-shi, Saitama, Japan</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Sporns</surname><given-names>Olaf</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group>
<aff id="edit1"><addr-line>Indiana University, United States of America</addr-line></aff>
<author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">gtononi@wisc.edu</email></corresp>
<fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn>
<fn fn-type="con"><p>Conceived and designed the experiments: GT MO LA. Performed the experiments: MO LA. Analyzed the data: MO LA. Wrote the paper: MO LA GT.</p></fn>
</author-notes>
<pub-date pub-type="collection"><month>5</month><year>2014</year></pub-date>
<pub-date pub-type="epub"><day>8</day><month>5</month><year>2014</year></pub-date>
<volume>10</volume>
<issue>5</issue>
<elocation-id>e1003588</elocation-id>
<history>
<date date-type="received"><day>18</day><month>11</month><year>2013</year></date>
<date date-type="accepted"><day>11</day><month>3</month><year>2014</year></date>
</history>
<permissions>
<copyright-year>2014</copyright-year>
<copyright-holder>Oizumi et al</copyright-holder><license xlink:type="simple"><license-p>This is an open-access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions>
<abstract>
<p>This paper presents Integrated Information Theory (IIT) of consciousness 3.0, which incorporates several advances over previous formulations. IIT starts from phenomenological axioms: information says that each experience is specific – it is what it is by how it differs from alternative experiences; integration says that it is unified – irreducible to non-interdependent components; exclusion says that it has unique borders and a particular spatio-temporal grain. These axioms are formalized into postulates that prescribe how physical mechanisms, such as neurons or logic gates, must be configured to generate experience (phenomenology). The postulates are used to define intrinsic information as “differences that make a difference” within a system, and integrated information as information specified by a whole that cannot be reduced to that specified by its parts. By applying the postulates both at the level of individual mechanisms and at the level of systems of mechanisms, IIT arrives at an identity: an experience is a maximally irreducible conceptual structure (<italic>MICS</italic>, a constellation of concepts in qualia space), and the set of elements that generates it constitutes a <italic>complex</italic>. According to IIT, a MICS specifies the quality of an experience and integrated information Φ<sup>Max</sup> its quantity. From the theory follow several results, including: a system of mechanisms may condense into a major complex and non-overlapping minor complexes; the concepts that specify the quality of an experience are always about the complex itself and relate only indirectly to the external environment; anatomical connectivity influences complexes and associated MICS; a complex can generate a MICS even if its elements are inactive; simple systems can be minimally conscious; complicated systems can be unconscious; there can be true “zombies” – unconscious feed-forward systems that are functionally equivalent to conscious complexes.</p>
</abstract>
<abstract abstract-type="summary"><title>Author Summary</title>
<p>Integrated information theory (IIT) approaches the relationship between consciousness and its physical substrate by first identifying the fundamental properties of experience itself: existence, composition, information, integration, and exclusion. IIT then postulates that the physical substrate of consciousness must satisfy these very properties. We develop a detailed mathematical framework in which composition, information, integration, and exclusion are defined precisely and made operational. This allows us to establish to what extent simple systems of mechanisms, such as logic gates or neuron-like elements, can form complexes that can account for the fundamental properties of consciousness. Based on this principled approach, we show that IIT can explain many known facts about consciousness and the brain, leads to specific predictions, and allows us to infer, at least in principle, both the quantity and quality of consciousness for systems whose causal structure is known. For example, we show that some simple systems can be minimally conscious, some complicated systems can be unconscious, and two different systems can be functionally equivalent, yet one is conscious and the other one is not.</p>
</abstract>
<funding-group><funding-statement>This work was supported by a Paul G. Allen Family Foundation grant, by the McDonnell Foundation, and by the Templeton World Charities Foundation (Grant #TWCF 0067/AB41). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="25"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>Understanding consciousness requires not only empirical studies of its neural correlates, but also a principled theoretical approach that can provide explanatory, inferential, and predictive power. For example, why is consciousness generated by the corticothalamic system – or at least some parts of it, but not by the cerebellum, despite the latter having even more neurons? Why does consciousness fade early in sleep, although the brain remains active? Why is it lost during generalized seizures, when neural activity is intense and synchronous? And why is there no direct contribution to consciousness from neural activity within sensory and motor pathways, or within neural circuits looping out of the cortex into subcortical structures and back, despite their manifest ability to influence the content of experience? Explaining these facts in a parsimonious manner calls for a theory of consciousness. (Below, consciousness, experience, and phenomenology are taken as being synonymous).</p>
<p>A theory is also needed for making inferences in difficult or ambiguous cases. For example, is a newborn baby conscious, how much, and of what? Or an animal like a bat, a lizard, a fruit fly? In such cases, one cannot resort to verbal reports to establish the presence and nature of consciousness, or to the neural correlates of consciousness as established in healthy adults. The inadequacy of behavioral assessments of consciousness is also evident in many brain-damaged patients, who cannot communicate, and whose brain may be working in ways that are hard to interpret. Is a clinically vegetative patient showing an island of residual, near-normal brain activity in just one region of the cortex conscious, how much, and of what? Or is nobody home? Or again, consider machines, which are becoming more and more sophisticated at reproducing human cognitive abilities and at interacting profitably with us. Some machines can learn to categorize objects such as faces, places, animals, and so on, as well if not better than humans <xref ref-type="bibr" rid="pcbi.1003588-Le1">[1]</xref>, or can answer difficult questions better than humans <xref ref-type="bibr" rid="pcbi.1003588-The1">[2]</xref>, <xref ref-type="bibr" rid="pcbi.1003588-Thompson1">[3]</xref>. Are such machines approaching our level of consciousness? If not, what are they missing, and what does it take to build a machine that is actually conscious? Clearly, only a theory - one that says what consciousness is and how it can be generated - can hope to offer a combination of explanatory, inferential, and predictive power starting from a few basic principles, and provide a way to quantify both the level of consciousness and its content.</p>
<p>Integrated information theory (IIT) is an attempt to characterize consciousness mathematically both in quantity and in quality <xref ref-type="bibr" rid="pcbi.1003588-Tononi1">[4]</xref>–<xref ref-type="bibr" rid="pcbi.1003588-Tononi3">[6]</xref>. IIT starts from the fundamental properties of the phenomenology of consciousness, which are identified as <italic>axioms</italic> of consciousness. Then, IIT translates these axioms into <italic>postulates</italic>, which specify which conditions must be satisfied by physical mechanisms, such as neurons and their connections, to account for the phenomenology of consciousness. It must be emphasized that taking the phenomenology of consciousness as primary, and asking how it can be implemented by physical mechanisms, is the opposite of the approach usually taken in neuroscience: start from neural mechanisms in the brain, and ask under what conditions they give rise to consciousness, as assessed by behavioral reports <xref ref-type="bibr" rid="pcbi.1003588-Baars1">[7]</xref>–<xref ref-type="bibr" rid="pcbi.1003588-Dehaene1">[10]</xref>. While identifying the “neural correlates of consciousness” is undoubtedly important <xref ref-type="bibr" rid="pcbi.1003588-Crick1">[8]</xref>, it is hard to see how it could ever lead to a satisfactory explanation of what consciousness is and how it comes about <xref ref-type="bibr" rid="pcbi.1003588-Chalmers1">[11]</xref>.</p>
<p>As will be illustrated below, IIT offers a way to analyze systems of mechanisms to determine if they are properly structured to give rise to consciousness, how much of it, and of which kind. As reviewed previously <xref ref-type="bibr" rid="pcbi.1003588-Tononi1">[4]</xref>, <xref ref-type="bibr" rid="pcbi.1003588-Tononi2">[5]</xref>, <xref ref-type="bibr" rid="pcbi.1003588-Tononi4">[12]</xref>, <xref ref-type="bibr" rid="pcbi.1003588-Tononi5">[13]</xref>, the fundamental principles of IIT, such as integration and differentiation, can provide a parsimonious explanation for many neuroanatomical, neurophysiological, and neuropsychological findings concerning the neural substrate of consciousness. Moreover, IIT leads to experimental predictions, for instance that the loss and recovery of consciousness should be associated with the breakdown and recovery of information integration. This prediction has been confirmed using transcranial magnetic stimulation in combination with high-density electroencephalography in several different conditions characterized by loss of consciousness, such as deep sleep, general anesthesia obtained with several different agents, and in brain damaged patients (vegetative, minimally conscious, emerging from minimal consciousness, locked-in <xref ref-type="bibr" rid="pcbi.1003588-Casali1">[14]</xref>). Furthermore, IIT has inspired theoretically motivated measures of the level of consciousness that have been applied to human and animal data (e.g. <xref ref-type="bibr" rid="pcbi.1003588-Casali1">[14]</xref>, see also <xref ref-type="bibr" rid="pcbi.1003588-King1">[15]</xref> for a related attempt to measure the level of consciousness based on symbolic mutual information).</p>
<p>While the central assumptions of IIT have remained the same, its theoretical apparatus has undergone various developments over the years. The original formulation, which may be called IIT 1.0, introduced the essential notions including causal measures of the quantity and quality of consciousness. However, to simplify the analysis, IIT 1.0 dealt exclusively with stationary systems <xref ref-type="bibr" rid="pcbi.1003588-Tononi1">[4]</xref> (see also <xref ref-type="bibr" rid="pcbi.1003588-Tononi6">[16]</xref>). The next formulation, which will be called IIT 2.0 <xref ref-type="bibr" rid="pcbi.1003588-Tononi2">[5]</xref>, <xref ref-type="bibr" rid="pcbi.1003588-Balduzzi1">[17]</xref>, <xref ref-type="bibr" rid="pcbi.1003588-Balduzzi2">[18]</xref> applied the same notions on a state-dependent basis: it showed how integrated information could be calculated in a top-down manner for a system of mechanisms in a state <xref ref-type="bibr" rid="pcbi.1003588-Balduzzi1">[17]</xref> and suggested a way to characterize the quality of an experience by considering its sub-mechanisms <xref ref-type="bibr" rid="pcbi.1003588-Balduzzi2">[18]</xref>. The formulation presented below, and the new results that follow from it, represent a substantial advance at several different levels, hence IIT 3.0 (see also <xref ref-type="bibr" rid="pcbi.1003588-Tononi3">[6]</xref>). Nevertheless, this article is presented independently of previous “releases” for readers new to IIT. For those readers who may have followed the evolution of IIT, the main advances are summarized in the Supplementary Material (<xref ref-type="supplementary-material" rid="pcbi.1003588.s002">Text S1</xref>).</p>
<p>In what follows, we first present the axioms and the postulates of IIT. We then provide the mathematical formalism and motivating examples for each of the postulates. The key constructs of IIT are introduced first at the level of individual mechanisms, which can be taken to represent physical objects such as logic gates or neurons, then at the level of systems of mechanisms, such as computers or neural architectures. The <xref ref-type="sec" rid="s2">Models</xref> section ends by presenting the central identity proposed by IIT, according to which the quality and quantity of an experience is completely specified by a maximally irreducible conceptual structure (MICS) and the associated value of integrated information Φ<sup>Max</sup>. The <xref ref-type="sec" rid="s3">Results/Discussion</xref> section presents several new results that follow directly from IIT, including the condensation of systems of mechanisms into main complexes and minor complexes; examples of simple systems that are minimally conscious and of complicated systems that are not; an example of an unconscious feed-forward system that is functionally equivalent to a conscious complex; and finally, an example showing that concepts within a complex are self-referential and relate only indirectly to the external environment.</p>
</sec><sec id="s2" sec-type="methods">
<title>Models</title>
<sec id="s2a">
<title>Axioms, postulates, and identities</title>
<p>The main tenets of IIT can be presented as a set of phenomenological axioms, ontological postulates, and identities. While the terms “axioms” and “postulates” are often used interchangeably, we follow the classical tradition according to which an “axiom” is a self-evident truth, whereas a “postulate” is an unproven assumption that can serve as the basis for logic or heuristics. Here the distinction takes on an even stronger meaning: axioms are self-evident truths about consciousness – the only truths that, with Descartes, cannot be doubted and do not need proof (experience exists, it is irreducible etc.). Postulates instead are assumptions about the physical world and specifically about the physical substrates of consciousness (mechanisms must exist, be irreducible, etc.), which can be formalized and form the basis of the mathematical framework of IIT.</p>
<sec id="s2a1">
<title>Axioms</title>
<p>The central axioms, which are taken to be immediately evident, are as follows:</p>
<list list-type="bullet"><list-item>
<p>E<sc>xistence</sc>: Consciousness exists – it is an undeniable aspect of reality. Paraphrasing Descartes, “I experience therefore I am”.</p>
</list-item><list-item>
<p>C<sc>omposition</sc>: Consciousness is compositional (structured): each experience consists of multiple aspects in various combinations. Within the same experience, one can see, for example, left and right, red and blue, a triangle and a square, a red triangle on the left, a blue square on the right, and so on.</p>
</list-item><list-item>
<p>I<sc>nformation</sc>: Consciousness is informative: each experience differs in its particular way from other possible experiences. Thus, an experience of pure darkness is what it is by differing, in its particular way, from an immense number of other possible experiences. A small subset of these possible experiences includes, for example, all the frames of all possible movies.</p>
</list-item><list-item>
<p>I<sc>ntegration</sc>: Consciousness is integrated: each experience is (strongly) irreducible to non-interdependent components. Thus, experiencing the word “SONO” written in the middle of a blank page is irreducible to an experience of the word “SO” at the right border of a half-page, plus an experience of the word “NO” on the left border of another half page – the experience is whole. Similarly, seeing a red triangle is irreducible to seeing a triangle but no red color, plus a red patch but no triangle.</p>
</list-item><list-item>
<p>E<sc>xclusion</sc>: Consciousness is exclusive: each experience excludes all others – at any given time there is only one experience having its full content, rather than a superposition of multiple partial experiences; each experience has definite borders – certain things can be experienced and others cannot; each experience has a particular spatial and temporal grain – it flows at a particular speed, and it has a certain resolution such that some distinctions are possible and finer or coarser distinctions are not.</p>
</list-item></list>
</sec><sec id="s2a2">
<title>Postulates</title>
<p>To parallel the phenomenological axioms, IIT posits a set of postulates. These list the properties physical systems must satisfy in order to generate experience.</p>
<list list-type="bullet"><list-item>
<p>E<sc>xistence</sc>: Mechanisms in a state exist. A system is a set of mechanisms.</p>
</list-item><list-item>
<p>C<sc>omposition</sc>: Elementary mechanisms can be combined into higher order ones.</p>
</list-item></list>
<p>The next three postulates, information, integration, and exclusion, apply both to individual mechanisms and to systems of mechanisms.</p>
</sec><sec id="s2a3">
<title>Mechanisms</title>
<list list-type="bullet"><list-item>
<p>I<sc>nformation</sc>: A mechanism can contribute to consciousness only if it specifies “differences that make a difference” within a system. That is, a mechanism in a state generates information only if it constrains the states of a system that can be its possible causes and effects – its <italic>cause-effect repertoire</italic>. The more selective the possible causes and effects, the higher the <italic>cause-effect information cei</italic> specified by the mechanism.</p>
</list-item><list-item>
<p>I<sc>ntegration</sc>: A mechanism can contribute to consciousness only if it specifies a cause-effect repertoire (information) that is <italic>irreducible</italic> to independent components. <italic>Integration/irreducibility φ</italic> is assessed by partitioning the mechanism and measuring what difference this makes to its cause-effect repertoire.</p>
</list-item><list-item>
<p>E<sc>xclusion</sc>: A mechanism can contribute to consciousness at most one cause-effect repertoire, the one having the maximum value of <italic>integration/irreducibility φ</italic><sup>Max</sup>. This is its <italic>maximally irreducible</italic> cause-effect repertoire (MICE, or <italic>quale sensu stricto</italic> (in the narrow sense of the word, <xref ref-type="bibr" rid="pcbi.1003588-Tononi2">[5]</xref>)). If the MICE exists, the mechanism constitutes a <italic>concept</italic>.</p>
</list-item></list>
</sec><sec id="s2a4">
<title>Systems of mechanisms</title>
<list list-type="bullet"><list-item>
<p>I<sc>nformation</sc>: A set of elements can be conscious only if its mechanisms specify a set of “differences that make a difference” to the set – i.e. a <italic>conceptual structure</italic>. A conceptual structure is a <italic>constellation</italic> of points in concept space, where each axis is a possible past/future state of the set of elements, and each point is a concept specifying differences that make a difference within the set. The higher the number of different concepts and their <italic>φ</italic><sup>Max</sup> value, the higher the <italic>conceptual information CI</italic> that specifies a particular constellation and distinguishes it from other possible constellations.</p>
</list-item><list-item>
<p>I<sc>ntegration</sc>: A set of elements can be conscious only if its mechanisms specify a conceptual structure that is <italic>irreducible</italic> to non-interdependent components (strong integration). <italic>Strong integration/irreducibility</italic> Φ is assessed by partitioning the set of elements into subsets with unidirectional cuts.</p>
</list-item><list-item>
<p>E<sc>xclusion</sc>: Of all overlapping sets of elements, only one set can be conscious – the one whose mechanisms specify a conceptual structure that is <italic>maximally irreducible (MICS)</italic> to independent components. A local maximum of integrated information Φ<sup>Max</sup> (over elements, space, and time) is called a <italic>complex</italic>.</p>
</list-item></list>
</sec><sec id="s2a5">
<title>Identities</title>
<p>Finally, according to IIT, there is an identity between phenomenological properties of experience and informational/causal properties of physical systems (see <xref ref-type="bibr" rid="pcbi.1003588-Chalmers1">[11]</xref> and <xref ref-type="bibr" rid="pcbi.1003588-Ascoli1">[19]</xref> for the importance of identities for the mind-body problem). The central identity is the following:</p>
<p>The maximally irreducible conceptual structure (<italic>MICS</italic>) generated by a complex of elements is identical to its experience. The constellation of concepts of the MICS completely specifies the quality of the experience (its <italic>quale “sensu lato”</italic> (in the broad sense of the term <xref ref-type="bibr" rid="pcbi.1003588-Tononi2">[5]</xref>)). Its irreducibility Φ<sup>Max</sup> specifies its quantity. The maximally irreducible cause-effect repertoire (MICE) of each concept within a MICS specifies what the concept is about (what it contributes to the quality of the experience, i.e. its <italic>quale sensu stricto</italic> (in the narrow sense of the term)), while its value of irreducibility <italic>φ</italic><sup>Max</sup> specifies how much the concept is present in the experience. An experience is thus an <italic>intrinsic property</italic> of a complex of mechanisms in a state. In other words, the maximally irreducible conceptual structure specified by a complex exists intrinsically (from its own intrinsic perspective), without the need for an external observer.</p>
</sec></sec><sec id="s2b">
<title>Mechanisms</title>
<p>In what follows, we consider simple systems that can be used to illustrate the postulates of IIT. In the first part, we apply the postulates of IIT at the level of <italic>individual mechanisms</italic>. We show that an individual mechanism generates information by specifying both selective causes and effects (information), that it needs to be irreducible to independent components (integration), and that only the most irreducible cause-effect repertoire of each mechanism should be considered (exclusion). This allows us to introduce the notion of a <italic>concept</italic>: the maximally irreducible cause-effect repertoire of a mechanism.</p>
<p>In the next part, we consider the postulates of IIT at the level of <italic>systems of mechanisms</italic>, and show how the requirements for information, integration, and exclusion can be satisfied at the system level. This allows us to introduce the notion of a <italic>complex</italic> – a maximally integrated set of elements – and of a <italic>quale</italic> – the maximally irreducible conceptual structure (MICS) it generates. Altogether, these two sections show how to assess in a step-by-step, bottom up manner, whether a system generates a maximally integrated conceptual structure and how the latter can be characterized in full. A summary of the key concepts and associated measures is provided as a reference in <xref ref-type="table" rid="pcbi-1003588-t001">Table 1</xref> and <xref ref-type="sec" rid="pcbi-1003588-box001">Box 1</xref>.</p>
<table-wrap id="pcbi-1003588-t001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003588.t001</object-id><label>Table 1</label><caption>
<title>Key concepts and measures of IIT.</title>
</caption><alternatives><graphic id="pcbi-1003588-t001-1" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003588.t001" xlink:type="simple"/>
<table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" rowspan="1" colspan="1">MECHANISM</td>
<td align="left" rowspan="1" colspan="1">SYSTEM OF MECHANISMS</td>
</tr>
</thead>
<tbody>
<tr>
<td colspan="2" align="left" rowspan="1"><bold>Information</bold></td>
</tr>
<tr>
<td colspan="2" align="left" rowspan="1">Only mechanisms that specify differences that make a difference within a system count</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>Cause-effect information</bold> (<italic>cei</italic>): How a mechanism in a state specifies the probability of past and future states of a set of elements (cause-effect repertoires)</td>
<td align="left" rowspan="1" colspan="1"><bold>Conceptual information</bold> (<italic>CI</italic>): How a set of mechanisms specifies the probability of past and future states of the set (conceptual structure)</td>
</tr>
<tr>
<td colspan="2" align="left" rowspan="1"><bold>Integration</bold></td>
</tr>
<tr>
<td colspan="2" align="left" rowspan="1">Only information that is irreducible to independent components counts</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>Integrated information (</bold><bold><italic>φ</italic></bold><bold>, “small phi”):</bold> How irreducible the cause-effect repertoire specified by a mechanism is compared to its minimum information partition (MIP)</td>
<td align="left" rowspan="1" colspan="1"><bold>Integrated conceptual information (Φ, “big phi”):</bold> How irreducible the conceptual structure specified by a set of mechanism is compared to its minimum information partition (MIP)</td>
</tr>
<tr>
<td colspan="2" align="left" rowspan="1"><bold>Exclusion</bold></td>
</tr>
<tr>
<td colspan="2" align="left" rowspan="1">Only maxima of integrated information count (over elements, space, time)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>Concept (</bold><bold><italic>φ</italic></bold><italic><sup>Max</sup></italic><bold>):</bold> A mechanism that specifies a maximally irreducible cause-effect repertoire (MICE or quale “sensu stricto”)</td>
<td align="left" rowspan="1" colspan="1"><bold>Complex (Φ</bold><bold><italic><sup>Max</sup></italic></bold><bold>):</bold> A set of elements whose mechanisms specify a maximally irreducible conceptual structure (MICS or quale “sensu lato”)</td>
</tr>
</tbody>
</table>
</alternatives></table-wrap><boxed-text id="pcbi-1003588-box001" position="float"><sec id="s2b1a">
<title>Box 1. Glossary</title>
<p><bold>Axiom:</bold> Self-evident truth about consciousness (experience exists, it is irreducible etc.). The only truths that, with Descartes, cannot be doubted and do not need proof. They are existence, composition, information, integration, and exclusion (see text).</p>
<p><bold>Background conditions:</bold> Fixed external constrains on a candidate set of elements. Past and current state of the elements outside the candidate set are fixed to their actual values.</p>
<p><bold>Candidate set:</bold> The set of elements under consideration. Elements inside the candidate set are perturbed into all their possible states to obtain the TPM of the candidate set.</p>
<p><bold>Cause-effect repertoire:</bold> The probability distribution of potential past and future states of a system as constrained by a mechanism in its current state.</p>
<p><bold>Cause-effect information (</bold><bold><italic>cei</italic></bold><bold>):</bold> The amount of information specified by a mechanism in a state, measured as the minimum of cause information (<italic>ci</italic>) and effect information (<italic>ei</italic>).</p>
<p><bold>Cause information (</bold><bold><italic>ci</italic></bold><bold>) and effect information (</bold><bold><italic>ei</italic></bold><bold>):</bold> Information about the past and the future, which is measured as the distance between the cause repertoire and the unconstrained cause repertoire (same on the effect side).</p>
<p><bold>Complex:</bold> A set of elements within a system that generates a local maximum of integrated conceptual information Φ<sup>Max</sup>. Only a complex exists as an entity from its own intrinsic perspective.</p>
<p><bold>Concept:</bold> A set of elements within a system and the maximally irreducible cause-effect repertoire it specifies, with its associated value of integrated information <italic>φ</italic><sup>Max</sup>. The concept expresses the causal role of a mechanism within a complex.</p>
<p><bold>Conceptual structure, constellation of concepts (</bold><bold><italic>C</italic></bold><bold>):</bold> A conceptual structure is the set of all concepts specified by a candidate set with their respective <italic>φ</italic><sup>Max</sup> values, which can be plotted as a constellation in concept space.</p>
<p><bold>Conceptual information (</bold><bold><italic>CI</italic></bold><bold>):</bold> A measure of how many different concepts are generated by a system of elements. <italic>CI</italic> is quantified by the distance D between the constellation of concepts and the “null” concept, the unconstrained cause-effect repertoire <italic>p<sup>uc</sup></italic>.</p>
<p><bold>Concept space:</bold> Concept space is a high dimensional space with one axis for each possible past and future state of the system in which a conceptual structure can be represented.</p>
<p><bold>Distance (D):</bold> In IIT 3.0, the Wasserstein distance, also known as earth mover's distance (EMD). It specifies the metric of concept space and thus the distance between probability distributions (<italic>φ</italic>) and between constellations of concepts (Φ).</p>
<p><bold>Integrated conceptual information (Φ):</bold> Conceptual information that is generated by a system above and beyond the conceptual information generated by its (minimal) parts. Φ measures the integration or irreducibility of a constellation of concepts (integration at the system level).</p>
<p><bold>Integrated information (</bold><bold><italic>φ</italic></bold><bold>):</bold> Information that is generated by a mechanism above and beyond the information generated by its (minimal) parts. <italic>φ</italic> measures the integration or irreducibility of mechanisms (integration at the mechanism level).</p>
<p><bold>Intrinsic information:</bold> Differences that make a difference within a system.</p>
<p><bold>Mechanism:</bold> Any subsystem of a system, including the system itself, that has a causal role within the system, for example, a neuron in the brain, or a logic gate in a computer.</p>
<p><bold>MICE (maximally irreducible cause-effect repertoire):</bold> The cause-effect repertoire of a concept, i.e., the cause-effect repertoire that generates a maximum of integrated information <italic>φ</italic> among all possible purviews.</p>
<p><bold>MICS (maximally irreducible conceptual structure):</bold> The conceptual structure generated by a complex in a state that corresponds to a local maximum of integrated conceptual information Φ<sup>Max</sup> (synonymous with “quale” or “constellation” in “qualia space”).</p>
<p><bold>MIP (minimum information partition):</bold> The partition that makes the least difference (in other words, the minimum “difference” partition).</p>
<p><bold>Null concept:</bold> The unconstrained cause-effect repertoire <italic>p<sup>uc</sup></italic> of the candidate set, with <italic>φ</italic> = 0.</p>
<p><bold>Partition:</bold> Division of a set of elements into causally/informationally independent parts, performed by noising the connections between the parts.</p>
<p><bold>Power set:</bold> The set of all subsets of a candidate set of elements.</p>
<p><bold>Postulates:</bold> Assumptions, derived from axioms, about the physical substrates of consciousness (mechanisms must have causal power, be irreducible, etc.), which can be formalized and form the basis of the mathematical framework of IIT. They are existence, composition, information, integration, and exclusion (see text).</p>
<p><bold>Purview:</bold> Any set of elements of a candidate set over which the cause and effect repertoires of a mechanism in a state are calculated.</p>
<p><bold>Quale:</bold> The conceptual structure generated by a complex in a state that corresponds to a local maximum of integrated conceptual information Φ<sup>Max</sup> (synonymous with “MICS” or “constellation” in “qualia space”).</p>
<p><bold>Qualia space:</bold> If a set of elements forms a complex, its concept space is called qualia space.</p>
<p><bold>System:</bold> A set of elements/mechanisms.</p>
<p><bold>TPM (transition probability matrix):</bold> A matrix that specifies the probability with which any state of a system transitions to any other system state. The TPM is determined by the mechanisms of a system and obtained by perturbing the system into all its possible states.</p>
<p><bold>Unconstrained repertoire (</bold><bold><italic>p<sup>uc</sup></italic></bold><bold>)</bold>: The probability distribution of potential past and future system states without constraints due to any mechanism in a state. The unconstrained cause repertoire is the uniform distribution of system states. The unconstrained effect repertoire is obtained by assuming unconstrained inputs to all system elements.</p>
</sec></boxed-text><sec id="s2b2">
<title>Existence</title>
<p>The existence postulate, the “zeroth” postulate of IIT, claims that mechanisms in a state exist. Within the present framework, “mechanism” simply denotes anything having a causal role within a system, for example, a neuron in the brain, or a logic gate in a computer. In principle, mechanisms might be characterized at various spatio-temporal scales, down to the micro-physical level, although for any given system there will be a scale at which causal interactions are strongest <xref ref-type="bibr" rid="pcbi.1003588-Hoel1">[20]</xref>. In what follows, we consider systems in which the elementary mechanisms are discrete logic gates or linear threshold units (<xref ref-type="supplementary-material" rid="pcbi.1003588.s003">Text S2</xref>) and assume that these mechanisms are the ones mediating the strongest causal interactions.</p>
<p><xref ref-type="fig" rid="pcbi-1003588-g001">Figure 1A</xref> shows the example system <italic>ABCDEF</italic>, which includes three logic gate mechanisms, OR, AND, XOR, which will be used to illustrate the postulates of IIT throughout the Model section. The dotted circle indicates that the particular set of elements <italic>ABC</italic> is going to be considered as a “candidate set” for IIT analysis, whereas the remaining elements <italic>D</italic>,<italic>E</italic>,<italic>F</italic> are considered external and treated as background conditions (<xref ref-type="supplementary-material" rid="pcbi.1003588.s003">Text S2</xref>).</p>
<fig id="pcbi-1003588-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003588.g001</object-id><label>Figure 1</label><caption>
<title>Existence: Mechanisms in a state having causal power.</title>
<p>(A) The dotted circle indicates elements <italic>ABC</italic> as the candidate set of mechanisms. Elements outside the candidate set (<italic>D</italic>, <italic>E</italic>, <italic>F</italic>) are taken as background conditions (external constraints). The logic gates <italic>A</italic>, <italic>B</italic>, and <italic>C</italic> are represented as is customary in neural circuits rather than electronic circuits. The arrows indicate directed connections between the elements. (B) The set's mechanisms <italic>ABC</italic> determine the transition probability matrix (TPM) of the set under the background conditions of <italic>DEF</italic> (here <italic>DEF</italic>(<italic>t</italic><sub>−1</sub>) = <italic>DEF</italic>(<italic>t</italic><sub>0</sub>) = 010). With element <italic>D</italic> fixed to <italic>D</italic> = 0, element <italic>A</italic>, for instance, receives inputs from <italic>B</italic> and <italic>C</italic> and outputs to <italic>B</italic> and <italic>C</italic>. The OR gate <italic>A</italic> is on (1) if either <italic>B</italic>, or <italic>C</italic>, or both were on at the last time step, and off (0) if <italic>BC</italic> was 00. Filled circles denote that the state of an element is ‘1’, open circles indicate that the state of an element is ‘0’. The current state of <italic>ABC</italic> is 100.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003588.g001" position="float" xlink:type="simple"/></fig>
<p>The mechanisms of <italic>ABC</italic> determine the transition probability matrix (TPM) of the candidate set, which specifies the probability with which any state of the set <italic>ABC</italic> transitions into any other state under the background conditions of elements DEF, here <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e001" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pcbi-1003588-g001">Figure 1B</xref>). In this case, since the system is deterministic, the values in the TPM are 0 or 1, but non-deterministic systems can also be considered. In this example, at the current time step <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e002" xlink:type="simple"/></inline-formula>, the mechanisms are in state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e003" xlink:type="simple"/></inline-formula>. The TPM specifies which past states could have led to the current state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e004" xlink:type="simple"/></inline-formula> (the shaded column in <xref ref-type="fig" rid="pcbi-1003588-g001">Figure 1B</xref>) and which future states it could go to (shaded row in <xref ref-type="fig" rid="pcbi-1003588-g001">Figure 1B</xref>), out of all possible states of the set.</p>
</sec><sec id="s2b3">
<title>Composition</title>
<p>The composition postulate states that elementary mechanisms can be structured, forming higher order mechanisms in various combinations. In <xref ref-type="fig" rid="pcbi-1003588-g002">Figure 2</xref>, <italic>A</italic>, <italic>B</italic>, and <italic>C</italic> are the elementary (first-order) mechanisms. By combining them, higher order mechanisms can be constructed. Pairs of elements form second-order mechanisms (<italic>AB</italic>, <italic>AC</italic>, <italic>BC</italic>), and all elements together form the third-order mechanism <italic>ABC</italic>. A red area highlights the respective mechanisms in <xref ref-type="fig" rid="pcbi-1003588-g002">Figure 2</xref>. The elements inside the candidate set, but outside the mechanism under consideration, are treated as independent noise sources (<xref ref-type="supplementary-material" rid="pcbi.1003588.s003">Text S2</xref>). Altogether, the elementary mechanisms and their combinations form the <italic>power set</italic> of possible mechanisms.</p>
<fig id="pcbi-1003588-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003588.g002</object-id><label>Figure 2</label><caption>
<title>Composition: Higher order mechanisms can be composed by combining elementary mechanisms.</title>
<p>The set <italic>ABC</italic> has 3 elementary mechanisms <italic>A</italic>, <italic>B</italic>, and <italic>C</italic> (at the bottom). Second-order mechanisms <italic>AB</italic>, <italic>AC</italic>, and <italic>BC</italic> are shown in the middle row and the third-order mechanism <italic>ABC</italic> (corresponding to the full set) is shown at the top. Altogether, the figure indicates the <italic>power set</italic> of possible mechanisms in set <italic>ABC</italic>. In the figure, each mechanism is highlighted by a red shaded area. The current state of the elements inside the candidate set but outside of a mechanism is undetermined for the mechanism under consideration.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003588.g002" position="float" xlink:type="simple"/></fig></sec><sec id="s2b4">
<title>Information: Cause-effect repertoires and cause-effect information (<italic>cei</italic>)</title>
<p>In IIT, information is meant to capture the “differences that make a difference” from the perspective of the system itself – and is therefore both causal and intrinsic. These and other features distinguish this “intrinsic” notion of information from the “extrinsic”, Shannon notion (see <xref ref-type="supplementary-material" rid="pcbi.1003588.s004">Text S3</xref>; cf. <xref ref-type="bibr" rid="pcbi.1003588-Ay1">[21]</xref>–<xref ref-type="bibr" rid="pcbi.1003588-Griffith1">[23]</xref> for related approaches to information and causation in networks).</p>
<p>Information as “differences that make a difference” to a system from its intrinsic perspective can be quantified by considering how a mechanism in its current state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e005" xlink:type="simple"/></inline-formula> constrains the system's potential past and future states. <xref ref-type="fig" rid="pcbi-1003588-g003">Figure 3</xref> illustrates how a mechanism <italic>A</italic> constrains the past states of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e006" xlink:type="simple"/></inline-formula> more or less <italic>selectively</italic> depending on its input/output function and state. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e007" xlink:type="simple"/></inline-formula> is an AND gate of the inputs from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e008" xlink:type="simple"/></inline-formula>. The constrained distribution of past states is called <italic>A</italic>'s <italic>cause repertoire</italic>. In <xref ref-type="fig" rid="pcbi-1003588-g003">Figure 3A</xref> the connections between <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e009" xlink:type="simple"/></inline-formula> and <italic>BCD</italic> are substituted by noise. Therefore, the current state of <italic>A</italic> cannot specify anything about the past state of <italic>BCD</italic>, the cause repertoire is identical to the unconstrained distribution (unselective), and <italic>A</italic> generates no information. By contrast, when the connections between <italic>A</italic> and <italic>BCD</italic> are deterministic and <italic>A</italic> is on (<italic>A</italic> = 1), the past state of <italic>BCD</italic> is fully constrained, since the only compatible past state is <italic>BCD</italic> = 111 (<xref ref-type="fig" rid="pcbi-1003588-g003">Figure 3B</xref>). In this case, the cause repertoire is maximally selective, corresponding to high information. On the other hand, when <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e010" xlink:type="simple"/></inline-formula> is off (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e011" xlink:type="simple"/></inline-formula>, <xref ref-type="fig" rid="pcbi-1003588-g003">Figure 3C</xref>), the cause repertoire is less selective, because only <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e012" xlink:type="simple"/></inline-formula> is ruled out, corresponding to less information.</p>
<fig id="pcbi-1003588-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003588.g003</object-id><label>Figure 3</label><caption>
<title>Information requires selectivity.</title>
<p>A mechanism generates information to the extent that it selectively constrains a system's past states. Element <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e013" xlink:type="simple"/></inline-formula> constrains the past states of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e014" xlink:type="simple"/></inline-formula> depending on its mechanism (AND gate) and its current state. The constrained distribution of past states is called <italic>A</italic>'s <italic>cause repertoire</italic>. (A) The connections between <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e015" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e016" xlink:type="simple"/></inline-formula> are noisy. <italic>A</italic>'s cause repertoire is thus unselective, since <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e017" xlink:type="simple"/></inline-formula> could have followed from any state of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e018" xlink:type="simple"/></inline-formula> with equal probability. (B) In the case of deterministic connections and current state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e019" xlink:type="simple"/></inline-formula>, <italic>A</italic>'s cause repertoire is maximally selective, because all states except <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e020" xlink:type="simple"/></inline-formula> are ruled out as possible causes of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e021" xlink:type="simple"/></inline-formula>. (C) In the case of deterministic connections and current state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e022" xlink:type="simple"/></inline-formula>, <italic>A</italic>'s cause repertoire is much less selective than for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e023" xlink:type="simple"/></inline-formula>, because only state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e024" xlink:type="simple"/></inline-formula> is ruled out as a possible cause of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e025" xlink:type="simple"/></inline-formula>.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003588.g003" position="float" xlink:type="simple"/></fig>
<p><xref ref-type="fig" rid="pcbi-1003588-g004">Figure 4</xref> illustrates how element <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e026" xlink:type="simple"/></inline-formula> in state 1 constrains the past states (left) and future states (right) of the candidate set <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e027" xlink:type="simple"/></inline-formula>. The probability distribution of past states that could have been potential causes of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e028" xlink:type="simple"/></inline-formula> is its cause repertoire <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e029" xlink:type="simple"/></inline-formula>. The probability distribution of future states that could be potential effects of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e030" xlink:type="simple"/></inline-formula> is called <italic>effect repertoire</italic> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e031" xlink:type="simple"/></inline-formula>. Here, the superscripts <sup>p</sup>, <sup>c</sup>, and <sup>f</sup> stand for past, current, and future, respectively. The set of elements over which the cause and effect repertoires of a mechanism are calculated is called its <italic>purview</italic>. <xref ref-type="fig" rid="pcbi-1003588-g004">Figure 4</xref> shows the cause and effect repertoire of mechanism <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e032" xlink:type="simple"/></inline-formula> over its purview <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e033" xlink:type="simple"/></inline-formula> (the full set) in the past and future, labeled <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e034" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e035" xlink:type="simple"/></inline-formula>. If the purview is not over the full set, the elements outside of the purview are unconstrained (see <xref ref-type="supplementary-material" rid="pcbi.1003588.s003">Text S2</xref> for details on the calculation).</p>
<fig id="pcbi-1003588-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003588.g004</object-id><label>Figure 4</label><caption>
<title>Information: “Differences that make a difference to a system from its own intrinsic perspective.”</title>
<p>A mechanism generates information by constraining the system's past and future states. (Top) The candidate set <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e036" xlink:type="simple"/></inline-formula> consisting of OR, AND, and XOR gates is shown in its current state 100. We consider the purview of mechanism <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e037" xlink:type="simple"/></inline-formula>, highlighted in red, over the set <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e038" xlink:type="simple"/></inline-formula> in the past (blue) and in the future (green). (Bottom center) The same network is displayed unfolded over three time steps, from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e039" xlink:type="simple"/></inline-formula> (past), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e040" xlink:type="simple"/></inline-formula> (current) to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e041" xlink:type="simple"/></inline-formula> (future). Gray-filled circles are undetermined states. The current state of mechanism <italic>A</italic> constrains the possible past and future system states compared to the unconstrained past and future distributions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e042" xlink:type="simple"/></inline-formula>. For example, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e043" xlink:type="simple"/></inline-formula> rules out the two states where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e044" xlink:type="simple"/></inline-formula> as potential causes. The constrained distribution of past states is <italic>A</italic>'s cause repertoire (left). The constrained distribution of future states is <italic>A</italic>'s effect repertoire (right). Cause information (<italic>ci</italic>) is quantified by measuring the distance <italic>D</italic> between the cause repertoire and the unconstrained past repertoire <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e045" xlink:type="simple"/></inline-formula>; effect information (<italic>ei</italic>) is quantified by measuring the distance <italic>D</italic> between the effect repertoire and the unconstrained future repertoire <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e046" xlink:type="simple"/></inline-formula>. Note that the unconstrained future repertoire <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e047" xlink:type="simple"/></inline-formula> is not simply the uniform distribution, but corresponds to the distribution of future system states with unconstrained inputs to each element. Cause-effect information (<italic>cei</italic>) is then defined as the minimum of <italic>ci</italic> and <italic>ei</italic>.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003588.g004" position="float" xlink:type="simple"/></fig>
<p>The amount of information that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e048" xlink:type="simple"/></inline-formula> specifies about the past, its cause information (<italic>ci</italic>), is measured as the distance <italic>D</italic> between the cause repertoire <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e049" xlink:type="simple"/></inline-formula> and the unconstrained past repertoire <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e050" xlink:type="simple"/></inline-formula>. For the purview <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e051" xlink:type="simple"/></inline-formula>:<disp-formula id="pcbi.1003588.e052"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003588.e052" xlink:type="simple"/><label>(1)</label></disp-formula><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e053" xlink:type="simple"/></inline-formula> corresponds to the cause repertoire in the absence of any constraints on the set's output states due to its mechanisms, which is the uniform distribution.</p>
<p>Just like cause information (<italic>ci</italic>), effect information (<italic>ei</italic>) of <italic>A</italic> = 1 is quantified as the distance between the effect repertoire of <italic>A</italic> and the unconstrained future repertoire <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e054" xlink:type="simple"/></inline-formula>:<disp-formula id="pcbi.1003588.e055"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003588.e055" xlink:type="simple"/><label>(2)</label></disp-formula></p>
<p>As can be seen in <xref ref-type="fig" rid="pcbi-1003588-g004">Figure 4</xref> (right), the unconstrained future repertoire <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e056" xlink:type="simple"/></inline-formula> is not simply the uniform distribution of future system states. While <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e057" xlink:type="simple"/></inline-formula> corresponds to the distribution of past system states with unconstrained outputs, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e058" xlink:type="simple"/></inline-formula> corresponds to the distribution of future system states with unconstrained inputs. Therefore, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e059" xlink:type="simple"/></inline-formula> is obtained by perturbing the inputs to each element into all possible states. As an example, the unconstrained future repertoire of element <italic>A</italic>, being an OR gate, is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e060" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e061" xlink:type="simple"/></inline-formula>, which is obtained by perturbing the inputs of <italic>A</italic> into all possible states <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e062" xlink:type="simple"/></inline-formula>.</p>
<p>To quantify differences that make a difference, the distance <italic>D</italic> between two probability distributions is evaluated using the earth mover's distance (EMD) <xref ref-type="bibr" rid="pcbi.1003588-Rubner1">[24]</xref>, which quantifies how much two distributions differ by taking into account the distance between system states. This is important because, from the intrinsic perspective of the system, it should make a difference if two system elements, rather than just one, differ in their state (see <xref ref-type="supplementary-material" rid="pcbi.1003588.s003">Text S2</xref> for details on the EMD and a discussion of EMD as the current distance measure of choice).</p>
<p>Finally, having calculated <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e063" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e064" xlink:type="simple"/></inline-formula>, the total amount of <italic>cause-effect information</italic> (<italic>cei</italic>) specified by <italic>A</italic> = 1 over the purview <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e065" xlink:type="simple"/></inline-formula> is the minimum of its <italic>ci</italic> and <italic>ei</italic>:<disp-formula id="pcbi.1003588.e066"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003588.e066" xlink:type="simple"/><label>(3)</label></disp-formula></p>
<p>The motivation for choosing the minimum is illustrated in <xref ref-type="fig" rid="pcbi-1003588-g005">Figure 5</xref>. First, consider an element that receives inputs from the system but sends no output to it (element <italic>A</italic> in <xref ref-type="fig" rid="pcbi-1003588-g005">Figure 5A</xref>). In this case, the state of element <italic>A</italic> constrains the past states of the system – <italic>A</italic> has selective causes within the system (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e067" xlink:type="simple"/></inline-formula>), but not the future states of the system – <italic>A</italic> has no selective effects on the system (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e068" xlink:type="simple"/></inline-formula>, what <italic>A</italic> does makes no difference to the system). Put differently, while the state of element <italic>A</italic> does convey information about the system's past states from the perspective of an external observer, it does not do so from the intrinsic perspective of the system itself, because the system is not affected by <italic>A</italic> (the system cannot “observe” <italic>A</italic> and thus has no access to <italic>A</italic>'s cause information).</p>
<fig id="pcbi-1003588-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003588.g005</object-id><label>Figure 5</label><caption>
<title>A mechanism generates information only if it has both selective causes and selective effects within the system.</title>
<p>(A) Element <italic>A</italic> receives input from the system and specifies a selective cause repertoire. However, since it has no outputs to the system it does not specify a selective effect repertoire. (B) Element <italic>A</italic> receives no input from the system and therefore it does not specify a selective cause repertoire. In both cases the cause-effect information <italic>cei</italic> generated by mechanism <italic>A</italic> is zero (the minimum between cause and effect information).</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003588.g005" position="float" xlink:type="simple"/></fig>
<p>Similarly, consider an element that only outputs to the system but does not receive inputs from it, being controlled exclusively by external causes (element <italic>A</italic> in <xref ref-type="fig" rid="pcbi-1003588-g005">Figure 5B</xref>). In this case, the state of element <italic>A</italic> constrains the future states of the system – <italic>A</italic> has selective effects on the system (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e069" xlink:type="simple"/></inline-formula>), but not the past states of the system – <italic>A</italic> has no selective causes within the system (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e070" xlink:type="simple"/></inline-formula>, what the system might have done makes no difference to <italic>A</italic>). Put differently, while the state of element <italic>A</italic> does convey information about the system's future states from the perspective of an external observer, it does not do so from the intrinsic perspective of the system, because the system cannot affect the state of <italic>A</italic> (the system cannot “control” <italic>A</italic> and thus has no access to <italic>A</italic>'s effect information).</p>
<p>As illustrated by these two limiting cases, each mechanism in the system acts as an information bottleneck from the intrinsic perspective: its cause information only exists for the system to the extent that it also specifies effect information and vice versa. While other ways of measuring a mechanism's <italic>cei</italic> may also be compatible with the examples shown in <xref ref-type="fig" rid="pcbi-1003588-g005">Figure 5</xref>, the “intrinsic information bottleneck principle” is best captured by defining a mechanism's <italic>cei</italic> as the minimum between its cause and effect information.</p>
</sec><sec id="s2b5">
<title>Integration: Irreducible cause-effect repertoires and integrated information (<italic>φ</italic>)</title>
<p>At the level of an individual mechanism, the integration postulate says that only mechanisms that specify integrated information can contribute to consciousness. Integrated information is information that is generated by the whole mechanism above and beyond the information generated by its parts. This means that, with respect to information, the mechanism is irreducible. Similar to cause-effect information, integrated information <italic>φ</italic> (“small phi”) is calculated as the distance <italic>D</italic> between two probability distributions: the cause-effect repertoire specified by the whole mechanism is compared against the cause-effect repertoire of the partitioned mechanism. Of the many possible ways to partition a mechanism, integrated information is evaluated across the minimum information partition (MIP), the partition that makes the least difference to the cause and effect repertoires (in other words, the minimum “difference” partition). In <xref ref-type="fig" rid="pcbi-1003588-g006">Figure 6</xref> this is demonstrated for the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e071" xlink:type="simple"/></inline-formula> order mechanism <italic>ABC</italic>. The MIP for the purview <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e072" xlink:type="simple"/></inline-formula> is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e073" xlink:type="simple"/></inline-formula> in the past and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e074" xlink:type="simple"/></inline-formula> in the future, where [] denotes the empty set. The cause and effect repertoire specified by the partitioned mechanisms can be calculated as:<disp-formula id="pcbi.1003588.e075"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003588.e075" xlink:type="simple"/><label>(4)</label></disp-formula>and<disp-formula id="pcbi.1003588.e076"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003588.e076" xlink:type="simple"/><label>(5)</label></disp-formula>where the connections between the parts are “injected” with independent noise (<xref ref-type="supplementary-material" rid="pcbi.1003588.s003">Text S2</xref>).</p>
<fig id="pcbi-1003588-g006" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003588.g006</object-id><label>Figure 6</label><caption>
<title>Integrated information: The information generated by the whole that is irreducible to the information generated by its parts.</title>
<p>Integrated information is quantified by measuring the distance between the cause repertoire specified by the whole mechanism and the partitioned mechanism (the same for the effect repertoire). MIP is the minimum information partition – the partition of the mechanism that makes the least difference to the cause and effect repertoires (indicated by dashed lines in the unfolded system). Partitions are performed by noising connections between the parts (those that cross the dashed lines, see <xref ref-type="supplementary-material" rid="pcbi.1003588.s003">Text S2</xref>).</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003588.g006" position="float" xlink:type="simple"/></fig>
<p>The distance <italic>D</italic> between the cause-effect repertoire specified by the whole mechanism and its MIP is quantified again using the EMD, taken separately for the past and the future (cause and effect repertoires):<disp-formula id="pcbi.1003588.e077"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003588.e077" xlink:type="simple"/><label>(6)</label></disp-formula><disp-formula id="pcbi.1003588.e078"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003588.e078" xlink:type="simple"/><label>(7)</label></disp-formula></p>
<p>As with information, the total amount of integrated information of mechanism <italic>ABC</italic> in its current state 100 over the purview <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e079" xlink:type="simple"/></inline-formula> is the minimum of its past and future integrated information:<disp-formula id="pcbi.1003588.e080"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003588.e080" xlink:type="simple"/><label>(8)</label></disp-formula>In what follows, integrated information <italic>φ</italic> is always evaluated for the MIP, so the MIP superscript is dropped for readability.</p>
<p>According to IIT, mechanisms that do not generate integrated information do not exist from the intrinsic perspective of a system, as illustrated in <xref ref-type="fig" rid="pcbi-1003588-g007">Figure 7</xref>. Suppose that <italic>A</italic> is a non-parity gate (<italic>A</italic> turns on when the inputs are even) and <italic>B</italic> is a majority gate (<italic>B</italic> turns on when the majority of its inputs are on). If <italic>A</italic> and <italic>B</italic> have independent causes and independent effects as shown in <xref ref-type="fig" rid="pcbi-1003588-g007">Figure 7A</xref>, a higher order mechanism <italic>AB</italic> cannot generate integrated information, since it is possible to partition <italic>AB</italic>'s causes and effects without any loss of information. In this case, <italic>AB</italic> does not exist intrinsically.</p>
<fig id="pcbi-1003588-g007" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003588.g007</object-id><label>Figure 7</label><caption>
<title>A mechanism generates integrated information only if it has both integrated causes and integrated effects.</title>
<p>(A) The mechanisms of element <italic>A</italic> and <italic>B</italic> are independent, having separate causes and effects. From the intrinsic perspective of the system, the joint mechanism <italic>AB</italic> does not exist, since it can be partitioned (red dashed line) without making any difference to the system. (B) The mechanism <italic>AB</italic> generates integrated information both in the past and in the future. Since it cannot be partitioned without loss, it exists intrinsically. (C) The mechanism <italic>AB</italic> generates integrated information in the past but not in the future. (D) The mechanism <italic>AB</italic> generates integrated information in the future but not in the past. In both cases, the joint mechanism does not exist intrinsically.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003588.g007" position="float" xlink:type="simple"/></fig>
<p>Consider instead <xref ref-type="fig" rid="pcbi-1003588-g007">Figure 7B</xref>. Here, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e081" xlink:type="simple"/></inline-formula> specifies that all inputs had to be on in the past (‘All ON’), which goes above and beyond what is specified separately by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e082" xlink:type="simple"/></inline-formula> (an even number of inputs was on) and by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e083" xlink:type="simple"/></inline-formula> (the majority of inputs was on). On the effect side, there is an AND gate that takes inputs from both <italic>A</italic> and <italic>B</italic>, so the effect of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e084" xlink:type="simple"/></inline-formula> goes above and beyond the separate effects of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e085" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e086" xlink:type="simple"/></inline-formula>. Therefore, mechanism <italic>AB</italic> exists from the intrinsic perspective of the system, in the sense that it plays an irreducible causal role: it picks up a difference that makes a difference to the system in a way that cannot be accounted for by its parts.</p>
<p>By contrast, in <xref ref-type="fig" rid="pcbi-1003588-g007">Figure 7C</xref> mechanism <italic>AB</italic> does not exist from the intrinsic perspective of the system, because the information ‘All ON’ as such does not make any difference to the future state of the system. Similarly, in <xref ref-type="fig" rid="pcbi-1003588-g007">Figure 7D</xref>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e087" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e088" xlink:type="simple"/></inline-formula> do not specify an irreducible past cause for the irreducible future effect that the AND gate will be ON.</p>
</sec><sec id="s2b6">
<title>Exclusion: A maximally irreducible cause-effect repertoire (MICE) specified by a subset of elements (a concept)</title>
<p>The exclusion postulate at the level of a mechanism says that a mechanism can have only one cause and one effect, those that are maximally irreducible; other causes and effects are excluded. The <italic>core cause</italic> of a mechanism from the intrinsic perspective is its maximally irreducible cause repertoire (<italic>one</italic> cause thus means a probability distribution over the past states of <italic>one</italic> particular set of inputs of the mechanism). Consider for example mechanism <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e089" xlink:type="simple"/></inline-formula> in <xref ref-type="fig" rid="pcbi-1003588-g008">Figure 8</xref>. To find the core cause of <italic>BC</italic>, one needs to evaluate <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e090" xlink:type="simple"/></inline-formula> for all past purviews of the power set <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e091" xlink:type="simple"/></inline-formula>. In this case, the purview <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e092" xlink:type="simple"/></inline-formula> has the highest value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e093" xlink:type="simple"/></inline-formula>. The corresponding maximally irreducible cause repertoire is thus the core cause of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e094" xlink:type="simple"/></inline-formula>. The <italic>core effect</italic> is assessed in the same way: it is the maximally irreducible effect repertoire of a mechanism with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e095" xlink:type="simple"/></inline-formula>, where <italic>F</italic> denotes the power set of future purviews. A mechanism that specifies a <italic>maximally irreducible cause and effect (MICE)</italic> constitutes a <italic>concept</italic> or, for emphasis, a <italic>core concept</italic>.</p>
<fig id="pcbi-1003588-g008" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003588.g008</object-id><label>Figure 8</label><caption>
<title>The maximally integrated cause repertoire over the power set of purviews is the “core cause” specified by a mechanism.</title>
<p>All purviews of mechanism <italic>BC</italic> for the past are considered. Only the purview that generates the maximal value of integrated information, <italic>φ</italic><sup>Max</sup>, exists intrinsically as the core cause of the mechanism (or effect when considering the future). In this case, the core cause is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e096" xlink:type="simple"/></inline-formula>.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003588.g008" position="float" xlink:type="simple"/></fig>
<p>To understand the motivation behind the exclusion postulate as applied to a mechanism, consider a neuron with several strong synapses and many weak synapses (<xref ref-type="supplementary-material" rid="pcbi.1003588.s001">Figure S1</xref>). From the intrinsic perspective of the neuron, any combination of synapses could be a potential cause of firing, including “strong synapses”, “strong synapses plus some weak synapses”, and so on, eventually including the potential cause “all synapses”, “all synapses plus stray glutamate receptors”, “all synapses plus stray glutamate receptors plus cosmic rays affecting membrane channels”, and so on, rapidly escalating to infinite regress. The exclusion postulate requires, first, that only one cause exists. This requirement represents a causal version of Occam's razor, saying in essence that “causes should not be multiplied beyond necessity”, i.e. that causal superposition is not allowed <xref ref-type="bibr" rid="pcbi.1003588-Tononi3">[6]</xref>. In the present context this means that <italic>only one</italic> set of synapses can be the cause for the neuron's firing and not, for example, <italic>both</italic> “strong synapses S1,S2” <italic>and</italic> “all synapses”, or an average or integral over all possible causes. Second, the exclusion postulate requires that, from the intrinsic perspective of a mechanism in a system, the only cause be the maximally irreducible one. Recall that IIT's information postulate is based on the intuition that, for something to exist, it must make a difference. By extension, something exists all the more, the more of a difference it makes. The integration postulate further requires that, for a whole to exist, it must make a difference above and beyond its partition, i.e. it must be irreducible. Since, according to the exclusion postulate, only one cause can exist, it must be the cause that makes the most difference to the neuron's output if it is eliminated by a partition – that is, the cause that is maximally irreducible. In <xref ref-type="supplementary-material" rid="pcbi.1003588.s001">Figure S1</xref>, for example, the maximally irreducible cause turns out to be “the strong synapses S1,S2”. Note that the exclusion postulate appears to fit with phenomenology also at the level of mechanisms. Thus, invariant concepts such as “chair”, or “apple” seem to exclude the accidental details of particular apples and chairs, but only reflect the “core” concept. In neural terms, this would imply that the maximally irreducible cause-effect repertoire of the neurons underlying such invariant concepts is similarly restricted to their core causes and effects.</p>
<p>The notion of a concept is illustrated in <xref ref-type="fig" rid="pcbi-1003588-g009">Figure 9</xref> for mechanism <italic>A</italic> of the candidate set <italic>ABC</italic>. The core cause of <italic>A</italic> is the cause repertoire of purview <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e097" xlink:type="simple"/></inline-formula>; the core effect is the effect repertoire of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e098" xlink:type="simple"/></inline-formula>. These purviews generate the maximal amount of integrated information over the whole power set of purviews in the past (<italic>P</italic>) and future (<italic>F</italic>), respectively. The amount of integrated information generated by concept <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e099" xlink:type="simple"/></inline-formula> is again the minimum between past and future:<disp-formula id="pcbi.1003588.e100"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003588.e100" xlink:type="simple"/><label>(9)</label></disp-formula>Each concept of a mechanism in a state is thus endowed with a maximally irreducible cause-effect repertoire (MICE), which specifies what the concept is about (its <italic>quale “sensu stricto”</italic>), and its particular <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e101" xlink:type="simple"/></inline-formula> value, which quantifies its amount of integration or irreducibility. Finally note that the exclusion postulate is applied to the possible cause-effect repertoires of a single mechanism (elementary or higher order). Exclusion does not apply across mechanisms within a set of elements, since elementary and higher order mechanisms can have different causal roles (concepts) in the set, as emphasized by the composition postulate.</p>
<fig id="pcbi-1003588-g009" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003588.g009</object-id><label>Figure 9</label><caption>
<title>A concept: A mechanism that specifies a maximally irreducible cause-effect repertoire.</title>
<p>The core cause and effect of mechanism <italic>A</italic> are <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e102" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e103" xlink:type="simple"/></inline-formula>, respectively. Together, they specify “what” the concept of <italic>A</italic> is about. The <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e104" xlink:type="simple"/></inline-formula> value of the concept specifies “how much” the concept exists intrinsically.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003588.g009" position="float" xlink:type="simple"/></fig></sec></sec><sec id="s2c">
<title>Systems of mechanisms</title>
<p>We now turn from the level of mechanisms to the level of a system of mechanisms, and apply the postulates of IIT with the objective of deriving the experience or <italic>quale</italic> generated by a system in a bottom up manner, from the set of all its concepts.</p>
<sec id="s2c1">
<title>Information: Conceptual structure (constellation of concepts in concept space) and conceptual information (<italic>CI</italic>)</title>
<p>At the system level, the information postulate says that only sets of “differences that make a difference” (i.e. a constellations of concepts) matter for consciousness. <xref ref-type="fig" rid="pcbi-1003588-g010">Figure 10</xref> shows all the concepts specified by the candidate set <italic>ABC</italic> (<xref ref-type="fig" rid="pcbi-1003588-g010">Figure 10A,B</xref>). Of all the possible mechanisms of the power set of <italic>ABC</italic>, only <italic>AC</italic> does not give rise to a concept, since its integrated information <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e105" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pcbi-1003588-g010">Figure 10B</xref>). All other mechanisms generate non-zero integrated information and thus specify concepts (<xref ref-type="fig" rid="pcbi-1003588-g010">Figure 10C</xref>). The set of all concepts of a candidate set constitutes its <italic>conceptual structure</italic>, which can be represented in <italic>concept space</italic>.</p>
<fig id="pcbi-1003588-g010" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003588.g010</object-id><label>Figure 10</label><caption>
<title>Information: A conceptual structure <italic>C</italic> (constellation of concepts) is the set of all concepts generated by a set of elements in a state.</title>
<p>(A) The candidate set <italic>ABC</italic> – a system composed of mechanisms in a state. (B) The power set of <italic>ABC</italic>'s mechanisms. (C) The concepts generated by the candidate set. Core causes are plotted on the left, core effects on the right. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e106" xlink:type="simple"/></inline-formula> values are shown in blue fonts in the middle of the cause and effect repertoires of each mechanism. Note that all mechanisms in the power set are concepts, with the exception of mechanism <italic>AC</italic>, which can be fully reduced <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e107" xlink:type="simple"/></inline-formula>. (D) The concepts generated by the candidate set plotted in concept space, where each axis corresponds to a possible state of <italic>ABC</italic>. For ease of representation past and future subspaces are plotted separately, with only three axes each. The “null” concept <italic>p<sup>uc</sup></italic> is indicated by the small black crosses in concept space.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003588.g010" position="float" xlink:type="simple"/></fig>
<p>Concept space is a high dimensional space, with one axis for each possible past and future state of the system. In this space, each concept is symbolized as a point, or “star”: its coordinates are given by the probability of past and future states in its cause-effect repertoire, and its size is given by its <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e108" xlink:type="simple"/></inline-formula> value. If <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e109" xlink:type="simple"/></inline-formula> is zero, the concept simply does not exist, and if its <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e110" xlink:type="simple"/></inline-formula> is small, it exists to a minimal amount.</p>
<p>In the case of the candidate set <italic>ABC</italic>, the dimension of concept space is 16 (8 axes for the past states and 8 for the future states). For ease of representation, in the figures past and future subspaces are plotted separately, with only three axes each (corresponding to the states at which the concepts have the highest variance in probability). Therefore the 6 concepts in <xref ref-type="fig" rid="pcbi-1003588-g010">Figure 10D</xref> are displayed twice, once in the past subspace and once in the future subspace. In the full 16-dimensional concept space, however, each concept is a single star.</p>
<p>At the system level, the equivalent of the cause-effect information (<italic>cei</italic>) at the level of mechanisms is called conceptual information (<italic>CI</italic>). Just like <italic>cei</italic>, <italic>CI</italic> is quantified by the distance <italic>D</italic> from the unconstrained repertoire of past and future states <italic>p<sup>uc</sup></italic>, which corresponds to the “null” concept (a concept that specifies nothing):<disp-formula id="pcbi.1003588.e111"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003588.e111" xlink:type="simple"/><label>(10)</label></disp-formula>The distance <italic>D</italic> from a constellation <italic>C</italic> to the “null” concept can be measured using an extension of the EMD (see <xref ref-type="supplementary-material" rid="pcbi.1003588.s003">Text S2</xref>), which can be understood as the cost of transporting the amount of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e112" xlink:type="simple"/></inline-formula> of each concept from its location in concept space to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e113" xlink:type="simple"/></inline-formula>. <italic>CI</italic> is thus the sum of the distances between the cause-effect repertoire of each concept and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e114" xlink:type="simple"/></inline-formula>, multiplied by the concept's <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e115" xlink:type="simple"/></inline-formula> value (<xref ref-type="fig" rid="pcbi-1003588-g011">Figure 11</xref>). Thus, a rich constellation with many different elementary and higher order concepts generates a high amount of conceptual information <italic>CI</italic> (<xref ref-type="fig" rid="pcbi-1003588-g011">Figure 11A</xref>). By contrast, a system comprised of a single elementary mechanism generates a minimal amount of conceptual information (<xref ref-type="fig" rid="pcbi-1003588-g011">Figure 11B</xref>).</p>
<fig id="pcbi-1003588-g011" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003588.g011</object-id><label>Figure 11</label><caption>
<title>Assessing the conceptual information <italic>CI</italic> of a conceptual structure (constellation of concepts).</title>
<p><italic>CI</italic> is quantified by measuring the distance in concept space between <italic>C</italic>, the constellation of concepts generated by a set of elements, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e116" xlink:type="simple"/></inline-formula>, the unconstrained past and future repertoire, which can be termed the “null” concept (in the absence of a mechanism, every state is equally likely). This can be done using an extended version of the earth mover's distance (EMD) that corresponds to the sum of the standard EMD for distributions between the cause-effect repertoires of all concepts and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e117" xlink:type="simple"/></inline-formula>, weighted by their <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e118" xlink:type="simple"/></inline-formula> values. (A) Therefore, a system with many different elementary and higher order concepts has high <italic>CI</italic>, as shown here for the candidate set <italic>ABC</italic>. (B) By contrast, a system comprised of a single mechanism can only have one concept and thus has low <italic>CI</italic>.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003588.g011" position="float" xlink:type="simple"/></fig>
<p>In sum, concepts are considered (metaphorically) as stars in concept space. The conceptual structure <italic>C</italic> generated by a set of mechanisms is thus a constellation of concepts – a particular shape in concept space spanned by the set's concepts. The more stars, the further away they are from the “null” concept, and the larger their size, the greater the conceptual information <italic>CI</italic> generated by the constellation <italic>C</italic>.</p>
</sec><sec id="s2c2">
<title>Integration: Irreducible conceptual structure and integrated conceptual information (Φ)</title>
<p>At the system level, the integration postulate says that only conceptual structures that are integrated can give rise to consciousness. As for mechanisms, the integration or irreducibility of the constellation of concepts <italic>C</italic> specified by a set of mechanisms can be assessed by partitioning a set of elements and measuring <italic>integrated conceptual information</italic> Φ as the difference made by the partition (“big phi”, as opposed to “small phi” <italic>φ</italic> at the level of mechanisms).</p>
<p>Partitioning at the system level amounts to noising the connections from one subset <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e119" xlink:type="simple"/></inline-formula> of <italic>S</italic> to its complement <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e120" xlink:type="simple"/></inline-formula>. As for mechanisms, whether and how much the constellation of concepts generated by a set of mechanisms is irreducible can be assessed with respect to the minimum information partition (MIP) of the set of elements <italic>S</italic>. This corresponds to the unidirectional partition that makes the least difference to the constellation of concepts (in other words, the minimum “difference” partition; <xref ref-type="fig" rid="pcbi-1003588-g012">Figure 12</xref>). To find the unidirectional MIP, for each subset <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e121" xlink:type="simple"/></inline-formula> one must evaluate both the connections from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e122" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e123" xlink:type="simple"/></inline-formula> <italic>and</italic> the connections from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e124" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e125" xlink:type="simple"/></inline-formula> and take the minimum MIP. This corresponds, at the level of mechanisms, to finding the minimum of the MIPs with respect to the cause <italic>and</italic> the effect repertoires. Therefore a set of elements <italic>S</italic> and its associated constellation is integrated if and only if each subset of elements specifies both selective causes and selective effects about its complement in <italic>S</italic>. Similar to integrated information <italic>φ</italic> for a mechanism, integrated conceptual information Φ for a set of elements is defined as the distance <italic>D</italic> between the constellation of the whole set and that of the partitioned set:<disp-formula id="pcbi.1003588.e126"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003588.e126" xlink:type="simple"/><label>(11)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e127" xlink:type="simple"/></inline-formula> denotes the constellation of the unidirectionally partitioned set of elements.</p>
<fig id="pcbi-1003588-g012" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003588.g012</object-id><label>Figure 12</label><caption>
<title>Assessing the integrated conceptual information Φ of a constellation <italic>C</italic>.</title>
<p>Φ (“big phi”) is quantified by measuring the distance <italic>C</italic> between the constellation of concepts of the whole set of elements <italic>C</italic> and that of the partitioned set <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e128" xlink:type="simple"/></inline-formula>, using an extended version of the earth mover's distance (EMD). The set is partitioned unidirectionally (see text for the motivation) until the partition is found that yields the least difference between the constellations (MIP, the minimum information i.e. minimum difference partition). In this case, the MIP corresponds to “noising” the connections from <italic>AB</italic> to <italic>C</italic>. This partition leaves 2 concepts intact (<italic>A</italic> and <italic>B</italic>, with zero distance to <italic>A</italic> and <italic>B</italic> from constellation <italic>C</italic>, indicated by the red stars), while the other concepts are destroyed by the partition (gray stars). The distance between the whole and partitioned constellations thus amounts to the sum of the EMD between the cause-effect repertoires of the destroyed concepts and the “null” concept <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e129" xlink:type="simple"/></inline-formula>, weighted by their <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e130" xlink:type="simple"/></inline-formula> values (see <xref ref-type="supplementary-material" rid="pcbi.1003588.s003">Text S2</xref>).</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003588.g012" position="float" xlink:type="simple"/></fig>
<p>The extended EMD between the whole and the partitioned constellation corresponds to the minimal cost of transforming <italic>C</italic> into <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e131" xlink:type="simple"/></inline-formula> in concept space. Through the partition, concepts of <italic>C</italic> may change location, lose <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e132" xlink:type="simple"/></inline-formula>, or disappear. Their <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e133" xlink:type="simple"/></inline-formula> has to be allocated to fill the concepts in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e134" xlink:type="simple"/></inline-formula> with an associated cost of transportation that is proportional to the distance in concept space and the amount of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e135" xlink:type="simple"/></inline-formula> that is moved. Any residual <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e136" xlink:type="simple"/></inline-formula> is transported to the “null” concept (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e137" xlink:type="simple"/></inline-formula>) under the same cost of transportation.</p>
<p><xref ref-type="fig" rid="pcbi-1003588-g012">Figure 12</xref> shows the conceptual structure for the candidate system <italic>ABC</italic> and its MIP (see <xref ref-type="supplementary-material" rid="pcbi.1003588.s003">Text S2</xref> for a calculation of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e138" xlink:type="simple"/></inline-formula>). In this case, 4 of the 6 concepts of <italic>ABC</italic> are lost through the partition; their <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e139" xlink:type="simple"/></inline-formula> is thus transported to the location of the “null” concept (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e140" xlink:type="simple"/></inline-formula>). Since Φ is always evaluated over the MIP, in what follows the superscript MIP is dropped, as it was for <italic>φ</italic>.</p>
<p>The motivation for integration at the system level is illustrated in <xref ref-type="fig" rid="pcbi-1003588-g013">Figure 13</xref> (as was done for mechanisms in <xref ref-type="fig" rid="pcbi-1003588-g006">Figure 6</xref>). The set of 6 elements shown in <xref ref-type="fig" rid="pcbi-1003588-g013">Figure 13A</xref> can be subdivided into two independent subsets of 3 elements, each with its independent set of concepts. Therefore, a minimum partition between the two subsets makes no difference and integrated conceptual information <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e141" xlink:type="simple"/></inline-formula>. Since the set is reducible without any loss, it does not exist intrinsically – it can only be treated as “one” system from the extrinsic perspective of an observer. By contrast, the set in <xref ref-type="fig" rid="pcbi-1003588-g013">Figure 13B</xref> is irreducible because each part specifies both causes and effects in the other part. Two other possibilities are that a subset specifies causes, but not effects, in the rest of the set (<xref ref-type="fig" rid="pcbi-1003588-g013">Figure 13C</xref>), or only effects, but not causes (<xref ref-type="fig" rid="pcbi-1003588-g013">Figure 13D</xref>). In the case of unidirectional connections the subset is integrated “weakly” rather than “strongly” (in analogy with weak and strong connectedness in graph theory, e.g. <xref ref-type="bibr" rid="pcbi.1003588-Wilson1">[25]</xref>), which means that the subset is not really an “integral” part of the set, but merely an “appendix”. As an analogy, take the executive board of a company. An employee who transcribes the recording of a board meeting is obviously affected by the board, but if he has no way to provide any feed-back, he should not be considered an “integral” part of the board, which has no way of knowing that he exists and what he does. The same obtains for an employee who prints the agenda for the board meeting, if the board has no way of giving him feedback about the agenda.</p>
<fig id="pcbi-1003588-g013" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003588.g013</object-id><label>Figure 13</label><caption>
<title>A set of elements generates integrated conceptual information Φ only if each subset has both causes and effects in the rest of the set.</title>
<p>(A) A set of 6 elements is composed of two subsets that are not interconnected. The set reduces to 2 independent subsets of 3 elements each that can be partitioned without loss (dashed red line). The 6 element set does not exist intrinsically (dashed black oval). (B) All subsets of the 6 node set have causes and effects in the rest of the set. The 6 node set generates an integrated conceptual structure since it cannot be unidirectionally partitioned without loss of conceptual information. (C,D) A set of 6 elements divides into 2 subsets of 3 elements that are connected unidirectionally. (C) The left subset has causes in the rest of the set, but no effects. (D) The left subset has effects on the rest of the set, but no causes. In both cases, the set reduces to 2 subsystems of 3 elements each that can be unidirectionally partitioned without loss (dashed red line with directional arrow). The 6 element set does not exist intrinsically.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003588.g013" position="float" xlink:type="simple"/></fig></sec><sec id="s2c3">
<title>Exclusion: A maximally irreducible conceptual structure (MICS) specified by a set of elements (a complex)</title>
<p>The exclusion postulate at the level of systems of mechanisms says that only a conceptual structure that is <italic>maximally</italic> irreducible can give rise to consciousness – other constellations generated by overlapping elements are excluded. A <italic>complex</italic> is thus defined as a set of elements within a system that generates a local maximum of integrated conceptual information Φ<sup>Max</sup> (meaning that it has maximal Φ as compared to all overlapping sets of elements). Only a complex exists as an entity from the intrinsic perspective. Because of exclusion, complexes cannot overlap and at each point in time, an element/mechanism can belong to one complex only (complexes should be evaluated as maxima of integrated information not only over elements, but also over spatial and temporal grains <xref ref-type="bibr" rid="pcbi.1003588-Hoel1">[20]</xref>, but here it is assumed that the binary elements and time intervals considered in the examples are optimal). Once a complex has been identified, concept space can be called “<italic>qualia space</italic>,” and the constellation of concepts can be called a “<italic>quale ‘sensu lato’</italic>”. A quale in the broad sense of the word is therefore a <italic>maximally irreducible conceptual structure (MICS)</italic> or, alternatively, an <italic>integrated information structure</italic>.</p>
<p>To determine whether an integrated set of elements is a complex, Φ must be evaluated for all possible candidate sets (subsets of the system) (<xref ref-type="fig" rid="pcbi-1003588-g014">Figure 14</xref>). As mentioned above, when a set of elements within the system is assessed, the other elements are treated as background conditions (see <xref ref-type="supplementary-material" rid="pcbi.1003588.s003">Text S2</xref>). <xref ref-type="fig" rid="pcbi-1003588-g014">Figure 14</xref> shows the values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e142" xlink:type="simple"/></inline-formula> for all possible candidate sets that are subsets of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e143" xlink:type="simple"/></inline-formula> (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e144" xlink:type="simple"/></inline-formula>,<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e145" xlink:type="simple"/></inline-formula>,<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e146" xlink:type="simple"/></inline-formula>,<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e147" xlink:type="simple"/></inline-formula>) and for one superset (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e148" xlink:type="simple"/></inline-formula>). The latter, and all other sets that include elements <italic>D</italic>, <italic>E</italic>, or <italic>F</italic>, have Φ = 0. This is because <italic>D</italic>, <italic>E</italic>, and <italic>F</italic> are not strongly integrated with the rest of the system. Single elements are not taken into account as candidate sets since they cannot be partitioned and thus cannot be complexes by definition. In this example, the set of elements <italic>ABC</italic> generates the highest value of Φ<sup>Max</sup> and is therefore the complex. By the exclusion postulate (“of all overlapping sets of elements, only one set can be conscious”), only <italic>ABC</italic> “exists” intrinsically, and other overlapping sets of elements within the system cannot “exist” intrinsically at the same time (they are excluded).</p>
<fig id="pcbi-1003588-g014" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003588.g014</object-id><label>Figure 14</label><caption>
<title>A complex: A local maximum of integrated conceptual information Φ.</title>
<p>Integrated conceptual information Φ is computed for the power set of elements of system <italic>ABCDEF</italic> (all possible candidate sets). By the exclusion postulate, among overlapping candidate sets, only one set of elements forms a complex, the one that generates the maximum amount of integrated conceptual information Φ<sup>Max</sup>. In the example system the set of elements <italic>ABC</italic> form the complex. Therefore, no subset or superset of <italic>ABC</italic> can form another complex. Note that all candidate sets that include <italic>D</italic>, <italic>E</italic>, or <italic>F</italic> are not strongly integrated and thus have Φ = 0 (only one example is shown).</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003588.g014" position="float" xlink:type="simple"/></fig></sec><sec id="s2c4">
<title>Identity between an experience and a maximally irreducible conceptual structure (MICS or quale “sensu lato”) generated by a complex</title>
<p>The notions and measures related to the information, integration, and exclusion postulates, both at the level of mechanisms and at the level of systems of mechanisms, are summarized in <xref ref-type="table" rid="pcbi-1003588-t001">Table 1</xref>. On this basis, it is possible to formulate the central identity proposed by IIT: <italic>an experience is identical with the maximally irreducible conceptual structure (MICS, integrated information structure, or quale “sensu lato”) specified by the mechanisms of a complex in a state</italic>. Subsets of elements within the complex constitute the concepts that make up the MICS. The maximally irreducible cause-effect repertoire (MICE) of each concept specifies what the concept is about (what it contributes to the quality of the experience, i.e. its <italic>quale “sensu stricto”</italic> (in the narrow sense of the term)). The value of irreducibility <italic>φ</italic><sup>Max</sup> of a concept specifies how much the concept is present in the experience. An experience (i.e. consciousness) is thus an <italic>intrinsic property</italic> of a complex of elements in a state: how they constrain – in a compositional manner – its space of possibilities, in the past and in the future.</p>
<p>In <xref ref-type="fig" rid="pcbi-1003588-g015">Figure 15</xref>, this identity is illustrated by showing an isolated system of physical mechanisms ABC in a particular state (bottom left). The above analysis allows one to determine that in this case the system does constitute a complex, and that it specifies a MICS or quale (top right). As before, the constellation of concepts in qualia space is plotted over 3 representative axes separately for past and future states of the system. For clarity, the concepts are also represented as probability distributions over all 16 past and future states (cause-effect repertoires, bottom right).</p>
<fig id="pcbi-1003588-g015" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003588.g015</object-id><label>Figure 15</label><caption>
<title>A quale: The maximally irreducible conceptual structure (MICS) generated by a complex.</title>
<p>An experience is identical with the constellation of concepts specified by the mechanisms of the complex. The Φ<sup>Max</sup> value of the complex corresponds to the quantity of the experience, the “shape” of the constellation of concepts in qualia space completely specifies the quality of a particular experience and distinguishes it from other experiences.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003588.g015" position="float" xlink:type="simple"/></fig>
<p>The central identity of IIT can also be formulated to express the classic distinction between <italic>level</italic> and <italic>content</italic> of consciousness <xref ref-type="bibr" rid="pcbi.1003588-Plum1">[26]</xref>: the quantity or level of consciousness corresponds to the Φ<sup>Max</sup> value of the quale; the quality or content of the experience corresponds to the particular constellation of concepts that constitutes the quale – a particular shape in qualia space. Note that, by specifying the quality of an experience, the particular shape of each constellation also distinguishes it from other possible experiences, just like the particular shape of a tetrahedron is what makes it a tetrahedron and distinguishes it from a cube, an icosahedron, and so on.</p>
<p>s indicated by the figure, once a phenomenological analysis of the essential properties (axioms) of consciousness has been translated into a set of postulates that the physical mechanisms generating consciousness must satisfy, it becomes possible to invert the process: One can now ask, for any set of physical mechanisms, whether it is associated with phenomenology (is there “something it is like to be it,” from its own intrinsic perspective), how much of it (the quantity or level of consciousness), and of which kind (the quality or content of the experience). As also indicated by the figure, these phenomenological properties should be considered as intrinsic properties of physical mechanisms arranged in a certain way, meaning that a complex of physical mechanisms in a certain state is necessarily associated with its quale.</p>
</sec></sec></sec><sec id="s3">
<title>Results/Discussion</title>
<p>The <xref ref-type="sec" rid="s2">Models</xref> section presented a way of constructing the experience or quale generated by a system of mechanisms in a state in a step-by-step, bottom up manner. The next section explores several implications of the postulates and concepts introduced above using example systems of mechanisms and the conceptual structures they generate.</p>
<sec id="s3a">
<title>A system may condense into a major complex and several minor complexes</title>
<p>In <xref ref-type="fig" rid="pcbi-1003588-g016">Figure 16</xref>, the previous example system <italic>ABC</italic> has been embedded within a larger network. In the larger system, elements <italic>I</italic>, <italic>J</italic>, and <italic>L</italic> cannot be a part of the complex because they lack either inputs or outputs, or both. <italic>H</italic> and <italic>K</italic> also cannot be part of the complex, since they are connected to the rest of the system in a strictly feed-forward manner. Nevertheless, elements <italic>H</italic> and <italic>K</italic> act as background conditions for the rest of the system. The remaining elements <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e149" xlink:type="simple"/></inline-formula> cannot form a complex as a whole, since the subset of elements <italic>FG</italic> is not connected to the rest of the system. The subset of elements <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e150" xlink:type="simple"/></inline-formula> does generate a small amount of integrated conceptual information Φ and could thus potentially form a complex. Among the power set of elements <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e151" xlink:type="simple"/></inline-formula>, however, it is the smaller subset <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e152" xlink:type="simple"/></inline-formula> that generates the local maximum of Φ<sup>Max</sup>. This excludes <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e153" xlink:type="simple"/></inline-formula> from being a complex, since an element can participate in only one complex at each point in time. The remaining elements <italic>DE</italic>, however, can still form a <italic>minor complex</italic>, with lower Φ<sup>Max</sup> than <italic>ABC</italic>. Thus, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e154" xlink:type="simple"/></inline-formula> condenses down to the major complex <italic>ABC</italic>, the minor complex <italic>DE</italic>, and their residual interactions. Finally, <italic>FG</italic> forms a minor complex that does not interact with the rest of the system.</p>
<fig id="pcbi-1003588-g016" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003588.g016</object-id><label>Figure 16</label><caption>
<title>A system can condense into a major complex and minor complexes that may or may not interact with it.</title>
<p>The set of elements <italic>ABC</italic> specifies the local maximum of integrated information Φ<sup>Max</sup> and thus forms the major complex of the system. The sets of elements <italic>DE</italic> and <italic>FG</italic> also specify local maxima of integrated information albeit with lower Φ<sup>Max</sup> than the main complex. <italic>DE</italic> and <italic>FG</italic> thus form minor complexes. The set of elements <italic>ABCDE</italic> is strongly integrated, but is excluded from forming a complex, since it overlaps with <italic>ABC</italic>, which is a local maximum of integrated information. The elements <italic>I</italic>, <italic>J</italic>, and <italic>L</italic> cannot be part of any complex since they do not have both causes and effects in the rest of the system. Neither can <italic>H</italic> and <italic>K</italic>, since they are part of a strictly feed-forward chain.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003588.g016" position="float" xlink:type="simple"/></fig>
<p>This simple example of “condensation” into major and minor complexes may be relevant also for much more complicated systems of interconnected elements. For example, IIT predicts that in the human brain there should be a dominant “main” complex of high Φ<sup>Max</sup>, constituted of neural elements within the cortical system, which satisfies the postulates described above and generates the changing qualia of waking consciousness <xref ref-type="bibr" rid="pcbi.1003588-Tononi4">[12]</xref>. The set of neuronal elements constituting this main complex is likely to be dynamic <xref ref-type="bibr" rid="pcbi.1003588-Tononi7">[27]</xref>, at times including and at times excluding particular subsets of neurons. Through its interface elements (called “ports-in” and “ports-out”), this main complex receives inputs and provides outputs to a vast number of smaller systems involved in parsing inputs and planning and executing outputs. While interacting with the main complex in both directions, many of these smaller systems may constitute minor complexes specifying little more than a few concepts, which would qualify them as “minimally conscious” (see below). In the healthy, adult human brain the qualia and Φ<sup>Max</sup> generated by the dominant main complex are likely to dwarf those specified by the minimally conscious minor complexes. In addition to the fully conscious main complex and minimally conscious minor complexes, there will be a multitude of unconscious processes mediated by purely feed-forward systems (see below) or by the residual interactions between main complex and minor complexes, as in <xref ref-type="fig" rid="pcbi-1003588-g016">Figure 16</xref>.</p>
<p>Under special circumstances, such as after split brain surgery, the main complex may split into two main complexes, both having high Φ<sup>Max</sup>. There is solid evidence that in such cases consciousness itself splits in two individual consciousnesses that are unaware of each other <xref ref-type="bibr" rid="pcbi.1003588-Gazzaniga1">[28]</xref>. A similar situation may occur in dissociative and conversion disorders, where splits of the main complex may be functional and reversible rather than structural and permanent <xref ref-type="bibr" rid="pcbi.1003588-Lynn1">[29]</xref>.</p>
<p>An intriguing dilemma is posed by behaviors that would seem to require a substantial amount of cognitive integration, such as semantic judgments (e.g. <xref ref-type="bibr" rid="pcbi.1003588-Mudrik1">[30]</xref>, <xref ref-type="bibr" rid="pcbi.1003588-Mudrik2">[31]</xref>). Such behaviors are usually assumed to be mediated by neural systems that are unconscious, because they can be shown to occur under experimental conditions, such as continuous flash suppression, where the speaking subject is not aware of them and cannot report about them. If such behaviors were carried out in a purely feed-forward manner, they would indeed qualify as unconscious in IIT (see below). However, at least some of these behaviors may constitute the output of minor complexes separated from the main one. According to IIT such minor complexes, if endowed with non-trivial values of Φ<sup>Max</sup>, should be considered <italic>paraconscious</italic> (i.e. conscious “on the side” of the conscious subject) rather than unconscious. In principle, the presence of paraconscious minor complexes could be demonstrated by developing experimental paradigms of dual report.</p>
<p>In brains substantially different from ours many other scenarios may occur. For example, the nervous system of highly intelligent invertebrates such as the octopus contains a central brain as well as large populations of neurons distributed in the nerve cords of its arms. It is an open question whether such a brain would give rise to a large, distributed main complex, or to multiple major complexes that generate separate consciousnesses. Similar issues apply to systems composed of non-neural elements, such as ant colonies, computer architectures, and so on. While determining rigorously how such systems condense in terms of major and minor complexes, and what kind of MICS they may generate, is not practically feasible, the predictions of IIT are in principle testable and should lead to definite answers.</p>
</sec><sec id="s3b">
<title>Consciousness and connectivity: Modular, homogeneous, and specialized networks</title>
<p>Whether a set of elements as a whole constitutes a complex or decomposes into several complexes depends first of all on the connectivity among its elementary mechanisms. In <xref ref-type="fig" rid="pcbi-1003588-g017">Figure 17</xref> we show the complexes and the associated MICS of three simple networks, representative of a modular, homogeneous, and specialized system architecture.</p>
<fig id="pcbi-1003588-g017" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003588.g017</object-id><label>Figure 17</label><caption>
<title>Qualia generated by modular, homogeneous and specialized networks.</title>
<p>(A) The modular network decomposes into three small complexes and their residual interactions. (B) The homogenous system forms a complex, but it has low Φ<sup>Max</sup> and only 5 identical concepts. (C) The specialized network also forms a complex, with all but one concepts of its power set and a high Φ<sup>Max</sup> value. In the middle row, the respective concepts of each system are listed. The bottom row shows the constellation of the respective complexes in qualia space (projected into 3 dimensions for the past and the future subspaces).</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003588.g017" position="float" xlink:type="simple"/></fig>
<p><xref ref-type="fig" rid="pcbi-1003588-g017">Figure 17A</xref> (top) shows a “modular” network of 3 COPY (<italic>ACE</italic>) and 3 AND (<italic>BDF</italic>) logic gates. In this network, the system as a whole is not a complex, despite being integrated due to the presence of inter-connections among all elements. Instead, each of the three modules (<italic>AB</italic>, <italic>CD</italic>, and <italic>EF</italic>) that consist of 1 COPY and 1 AND gate constitutes a complex, because each generates more Φ than the whole system, although each module has just two concepts. The purviews of module <italic>AB</italic>'s concepts are shown in <xref ref-type="fig" rid="pcbi-1003588-g017">Figure 17A</xref> (middle), and their representation in qualia space is displayed in <xref ref-type="fig" rid="pcbi-1003588-g017">Figure 17A</xref> (bottom).</p>
<p><xref ref-type="fig" rid="pcbi-1003588-g017">Figure 17B</xref> shows a “homogeneous” network of 5 OR gates (<italic>ABCDE</italic>), in which every element is connected to every other element including itself. Since all elements in the network specify the same cause-effect repertoire, their 5 first order (elementary) concepts are identical. Moreover, there are no higher order concepts, since combining elements yields nothing above the elementary mechanisms. In qualia space, the 5 identical concepts are concentrated on a single point (<xref ref-type="fig" rid="pcbi-1003588-g017">Figure 17B</xref>, bottom). Accordingly, the homogeneous network has a low value of <italic>CI</italic> and Φ<sup>Max</sup>.</p>
<p><xref ref-type="fig" rid="pcbi-1003588-g017">Figure 17C</xref> shows a “specialized” network consisting of 5 majority gates, which turn on when the majority of inputs is on. However, each gate has only 3 afferent and efferent connections, which differ for every element. Therefore, each elementary concept specifies a different cause-effect repertoire. For the same reason, there are many higher order concepts (all but the highest order concept of the power set). The specialized network thus gives rise to a rich constellation in qualia space (<xref ref-type="fig" rid="pcbi-1003588-g017">Figure 17C</xref>, bottom) with a high value of <italic>CI</italic> and Φ<sup>Max</sup>.</p>
<p>The example in <xref ref-type="fig" rid="pcbi-1003588-g017">Figure 17A</xref>, which shows that a network can be interconnected, either directly or indirectly, yet condense into a number of mini-complexes of low Φ<sup>Max</sup> if its architecture is primarily modular, is potentially consistent with neuropsychological evidence. As mentioned in the <xref ref-type="sec" rid="s1">Introduction</xref>, the cerebellum is a paramount example of a complicated neuronal network, comprising even more neurons than the cerebral cortex, that does not give rise to consciousness or contribute to it <xref ref-type="bibr" rid="pcbi.1003588-Glickstein1">[32]</xref>–<xref ref-type="bibr" rid="pcbi.1003588-Boyd1">[34]</xref>. This paradox could be explained by its anatomical and physiological organization, which seems to be such that small cerebellar modules process inputs and produce outputs largely independent of each other <xref ref-type="bibr" rid="pcbi.1003588-Cohen1">[35]</xref>, <xref ref-type="bibr" rid="pcbi.1003588-Bower1">[36]</xref>. By contrast, a prominent feature of the cerebral cortex, which instead can generate consciousness, is that it is comprised of elements that are functionally specialized and at the same time can interact rapidly and effectively <xref ref-type="bibr" rid="pcbi.1003588-Tononi1">[4]</xref>, <xref ref-type="bibr" rid="pcbi.1003588-Sporns1">[37]</xref>, <xref ref-type="bibr" rid="pcbi.1003588-vandenHeuvel1">[38]</xref>. This is the kind of organization that yields a comparatively high value of Φ<sup>Max</sup> in the simple example of <xref ref-type="fig" rid="pcbi-1003588-g017">Figure 17C</xref>. Finally, the example in <xref ref-type="fig" rid="pcbi-1003588-g017">Figure 17B</xref>, where connections are abundant but are organized in a homogeneous manner, may also have neurobiological counterparts. For instance, during deep slow wave sleep or in certain states of general anesthesia, the interactions among different cortical regions become highly stereotypical. Due to the characteristic bistability between on and off states of most neurons in the cerebral cortex, even though the anatomical connectivity is unchanged, functional and effective connectivity become virtually homogeneous <xref ref-type="bibr" rid="pcbi.1003588-Massimini1">[39]</xref>, <xref ref-type="bibr" rid="pcbi.1003588-Ferrarelli1">[40]</xref>. Under such conditions, consciousness invariably fades <xref ref-type="bibr" rid="pcbi.1003588-Casali1">[14]</xref>. The examples of <xref ref-type="fig" rid="pcbi-1003588-g017">Figure 17B and C</xref> also suggest that both the richness of concepts and the level of consciousness should increase with the refinement of cortical connections during neural development and the associate increase in functional specialization (e.g. <xref ref-type="bibr" rid="pcbi.1003588-Sanes1">[41]</xref>).</p>
</sec><sec id="s3c">
<title>Consciousness and activity: Inactive systems can be conscious</title>
<p>The conceptual structure generated by a complex depends not only on the connectivity among its elements and the input/output function they perform, but also on their current state. An important corollary of IIT is that both active and inactive elements can contribute to its conceptual structure. Moreover, high-order concepts will often be specified by subsets including both active and inactive elements.</p>
<p>In <xref ref-type="fig" rid="pcbi-1003588-g018">Figure 18</xref>, the system ABCD, comprised of 4 COPY gates, illustrates that a set of elements can form a complex and specify a MICS even though <italic>all</italic> of its elements are in state ‘0’ (off). This is because inactive elements, too, can selectively constrain past and future states of the system (as opposed to “inactivated” or non-functional elements, which cannot change state and thus cannot generate information). For example, element <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e155" xlink:type="simple"/></inline-formula> specifies an irreducible cause (<italic>D</italic> had to be off at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e156" xlink:type="simple"/></inline-formula>) and an irreducible effect (<italic>B</italic> will be on at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e157" xlink:type="simple"/></inline-formula>) within the complex. Thus, IIT predicts that, even if all the neurons in a main complex were inactive (or active at a low baseline rate), they would still generate consciousness as long as they are ready to respond to incoming spikes. An intriguing possibility is that a neurophysiological state of near-silence may be approximated through certain meditative practices that aim at reaching a state of “pure” awareness without content <xref ref-type="bibr" rid="pcbi.1003588-Balduzzi2">[18]</xref>, <xref ref-type="bibr" rid="pcbi.1003588-Sullivan1">[42]</xref>. This corollary of IIT contrasts with the common assumption that neurons can only contribute to consciousness if they are active in such a way that they can “signal” or “broadcast” the information they represent and “ignite” fronto-parietal networks <xref ref-type="bibr" rid="pcbi.1003588-Baars1">[7]</xref>, <xref ref-type="bibr" rid="pcbi.1003588-Dehaene1">[10]</xref>. This is because, in IIT, information is not in the message that is broadcasted by an element, but in the shape of the MICS that is specified by a complex.</p>
<fig id="pcbi-1003588-g018" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003588.g018</object-id><label>Figure 18</label><caption>
<title>Quale generated by an inactive system.</title>
<p>Neural activity is not necessary to generate experience, nor does it need to be “broadcasted” globally. Although all the elements in the system are off (0), the system still forms a complex and specifies a MICS. Moreover, an element can contribute to experience as long as it affects the shape of the MICS, without the need to “broadcast” its activity globally to affect every other element. This is because information is not in the message that is broadcasted by an element, but it is the shape of the MICS that is specified by a complex.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003588.g018" position="float" xlink:type="simple"/></fig>
<p>Another corollary of IIT that is relevant to neuroscience is that it is not necessary for the firing state of neurons to percolate or be “broadcasted” globally through the entire main complex for it to contribute to experience. For example, in the system in <xref ref-type="fig" rid="pcbi-1003588-g018">Figure 18</xref>, element <italic>A</italic> does not connect directly to element <italic>C</italic>. As a consequence, the activity (or inactivity) of <italic>A</italic> cannot affect <italic>C</italic>, and vice versa, within one time step. Nevertheless, <italic>ABCD</italic> still forms a complex and gives rise to a MICS at time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e158" xlink:type="simple"/></inline-formula>. Thus, according to IIT, the activation or deactivation of a neuron (over the time scale at which integrated information reaches a maximum <xref ref-type="bibr" rid="pcbi.1003588-Hoel1">[20]</xref>) can modify an experience as long as it affects the shape of the MICS specified by the complex to which the neuron belongs, without requiring any global “broadcast” of signals.</p>
</sec><sec id="s3d">
<title>Simple systems can be conscious: A “minimally conscious” photodiode</title>
<p>The previous section showed that activations and direct interactions between elements are not necessary to generate a MICS. Taking into account the axioms and postulates of IIT, we can now summarize what it takes to be conscious and give an example of a “minimally conscious system,” which will be called a “minimally conscious” photodiode.</p>
<p>The “photodiode” in <xref ref-type="fig" rid="pcbi-1003588-g019">Figure 19A</xref> consists of two elements: the detector <italic>D</italic> and the predictor <italic>P</italic>. <italic>D</italic> receives two external light inputs (and is thus a port-in) and one internal input from <italic>P</italic>, all with strength 1. As illustrated in <xref ref-type="fig" rid="pcbi-1003588-g019">Figure 19B</xref>, <italic>D</italic> turns on if it receives at least two inputs from internal and/or external sources. If <italic>D</italic> has switched on due to sufficiently strong external inputs, it activates element <italic>P</italic>, which serves as a “memory”. At the next time step, <italic>P</italic> acts as a “predictor” of the next external input to <italic>D</italic> by increasing its sensitivity to light.</p>
<fig id="pcbi-1003588-g019" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003588.g019</object-id><label>Figure 19</label><caption>
<title>Quantity and quality of experience of a “minimally conscious” photodiode.</title>
<p>(A) The minimally conscious photodiode <italic>DP</italic> consists of detector element <italic>D</italic> and predictor element <italic>P</italic>. <italic>D</italic> receives two external inputs and has a threshold ≥2. All connections have weight 1. (B) <italic>P</italic> serves as a memory for the previous state of <italic>D</italic> and its feed-back to <italic>D</italic> serves as a predictor of the next external input by effectively decreasing the threshold of <italic>D</italic>. (C) The MICS specified by the minimally conscious photodiode. <italic>D</italic> and <italic>P</italic> both specify a first order concept about the other element. (D) A minimally conscious thermistor or a minimally conscious blue detector with the same internal mechanisms as the minimally conscious photodiode generate the same MICS and therefore have the same minimal experience.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003588.g019" position="float" xlink:type="simple"/></fig>
<p>Simple as it is, the photodiode system satisfies the postulates of IIT: both of its elements specify selective causes and effects within the system (each element about the other one), their cause-effect repertoires are maximally irreducible, and the conceptual structure specified by the two elements is also maximally irreducible. Consequently, the system <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e159" xlink:type="simple"/></inline-formula> forms a complex that gives rise to a MICS, albeit one having just two concepts and a Φ<sup>Max</sup> value of 1 (<xref ref-type="fig" rid="pcbi-1003588-g019">Figure 19C</xref>). <italic>DP</italic> is therefore conscious, albeit minimally so.</p>
<p>It is instructive to consider the quality of experience specified by such a minimally conscious photodiode. From an observer's perspective, the photodiode detects light, but from the intrinsic perspective, the experience is only minimally specified, and in no way can convey the meaning “light”: <italic>D</italic> says something about <italic>P</italic>'s past and future, and <italic>P</italic> about <italic>D</italic>'s, and that is all. Accordingly, the shape in qualia space is a constellation having just two stars, and is thus minimally specific. This aspect is further emphasized if one considers that different physical systems, say a photodiode activated by blue light (a “blue” detector), or even a binary thermistor (a “temperature” detector) would generate the exact same MICS (<xref ref-type="fig" rid="pcbi-1003588-g019">Figure 19D</xref>) and thus the same minimal experience. Moreover, the symmetry of the MICS implies that the quality of the experience would be the same regardless of the system's state: the photodiode in state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e160" xlink:type="simple"/></inline-formula>, 01, or 10, receiving one external input, generates exactly the same MICS as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e161" xlink:type="simple"/></inline-formula>. In all the above cases, the experience might be described roughly as “it is like this rather than not like this”, with no further qualifications. The photodiode's experience is thus both quantitatively and qualitatively minimal. Only additional mechanisms that create new concepts and break the symmetries in the shape of the MICS can generate additional meaning. Ultimately, only a set of concepts comparable to that of our main complex can specify the shape of the experience “light” as it appears to us, and distinguish it from countless other shapes corresponding to different experiences <xref ref-type="bibr" rid="pcbi.1003588-Tononi3">[6]</xref>.</p>
</sec><sec id="s3e">
<title>Complex systems can be unconscious: A “zombie” feed-forward network</title>
<p>Another corollary of IIT is that certain structures do not give rise to consciousness even though they may perform complicated functions. Consider first an “unconscious” photodiode (<xref ref-type="fig" rid="pcbi-1003588-g020">Figure 20A</xref>), comprising again two elements: a detector <italic>D</italic> and output <italic>O</italic>. In this case, however, whether <italic>D</italic> is on or off is determined by external inputs only, and the output of <italic>O</italic> does not feed back into the system. Therefore, <italic>D</italic>'s response to light is just passed through the system, but never comes back to it. Although an observer may describe the two elements <italic>DO</italic> as a system, <italic>D</italic> and <italic>O</italic> do not have both causes and effects within the system <italic>DO</italic>, which is thus not a complex, and generates no quale.</p>
<fig id="pcbi-1003588-g020" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003588.g020</object-id><label>Figure 20</label><caption>
<title>Feed-forward “zombie” systems do not generate consciousness.</title>
<p>(A) An unconscious photodiode <italic>DO</italic> without recurrent connections. The detector element <italic>D</italic> affects output element <italic>O</italic>, but has no cause within the system <italic>DO</italic>. <italic>O</italic> is caused by <italic>D</italic>, but has no effect on the photodiode <italic>DO</italic>. Therefore, the elements do not form a complex and generate no quale. (B) Even complicated systems cannot form a complex if they have a strictly feed-forward architecture. This can be understood in the following way: for any system background imposed by an observer, the system's input layer has no causes within the system and the output layer has no effects on it, regardless of the elements' (logic) functions. Consequently, the system cannot form a complex and it remains unconscious, just like the unconscious photodiode <italic>DO</italic>.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003588.g020" position="float" xlink:type="simple"/></fig>
<p>The same lack of feed-back that disqualifies the unconscious photodiode can be extended, by recursion, to any feed-forward system, no matter how numerous its elements and complicated its connectivity (<xref ref-type="fig" rid="pcbi-1003588-g020">Figure 20B</xref>). From the viewpoint of an extrinsic observer, the system's borders can be set arbitrarily. However, the input layer is always determined entirely by external inputs and the output layer does not affect the rest of the system. Consequently, from the intrinsic perspective, both input and output layer cannot be part of the complex. Drawing the system boundaries closer and closer together in a recursive manner, one eventually ends up with just one input and output layer, made up of many “unconscious photodiodes”, and thus generating no quale. Therefore, systems with a purely feed-forward architecture cannot generate consciousness.</p>
<p>The idea that “feed-back”, “reentry”, or “recursion” of some kind may be an essential ingredient of consciousness has many proponents <xref ref-type="bibr" rid="pcbi.1003588-Tononi7">[27]</xref>, <xref ref-type="bibr" rid="pcbi.1003588-Edelman1">[43]</xref>–<xref ref-type="bibr" rid="pcbi.1003588-Hofstadter1">[45]</xref>. Recently, it has been suggested that the presence or absence of feed-back could be directly equated with the presence or absence of consciousness <xref ref-type="bibr" rid="pcbi.1003588-Lamme1">[46]</xref>. Moreover, several recent studies indicate that an impairment of reentrant interactions over feed-back connections is associated with loss of consciousness during anesthesia <xref ref-type="bibr" rid="pcbi.1003588-Imas1">[47]</xref>–<xref ref-type="bibr" rid="pcbi.1003588-Mashour1">[49]</xref> and in brain-damaged patients <xref ref-type="bibr" rid="pcbi.1003588-Boly2">[50]</xref>. However, it has been pointed out that the brain (and many other systems) is full of reentrant circuits, many of which do not seem to contribute to consciousness <xref ref-type="bibr" rid="pcbi.1003588-Koch2">[51]</xref>. IIT offers some specific insights with respect to these issues. First, the need for reciprocal interactions within a complex is not merely an empirical observation, but it has theoretical validity because it is derived directly from the phenomenological axiom of (strong) integration. Second, (strong) integration is by no means the only requirement for consciousness, but must be complemented by information and exclusion. Third, for IIT it is the potential for interactions among the parts of a complex that matters and not the actual occurrence of “feed-back” or “reentrant” signaling, as is usually assumed. As was discussed above, a complex can be conscious, at least in principle, even though none of its neurons may be firing, no feed-back or reentrant loop may be activated, and no “ignition” may have occurred.</p>
</sec><sec id="s3f">
<title>Conscious complexes and unconscious “zombie” systems can be functionally equivalent</title>
<p>The last section showed that according to IIT feed-forward systems cannot give rise to a quale. However, without restrictions on the number of nodes, feed-forward networks with multiple layers can in principle approximate almost any given function to an arbitrary (but finite) degree <xref ref-type="bibr" rid="pcbi.1003588-Cybenko1">[52]</xref>, <xref ref-type="bibr" rid="pcbi.1003588-Hornik1">[53]</xref>. Therefore, it is conceivable that an unconscious system could show the same input-output behavior as a “conscious” system.</p>
<p>An example is shown in <xref ref-type="fig" rid="pcbi-1003588-g021">Figure 21A</xref>. A strongly integrated system is compared to a feed-forward network that produces the same input-output behavior over at least 4 time steps (9<sup>4</sup> input states, <xref ref-type="fig" rid="pcbi-1003588-g021">Figure 21B</xref>). To achieve a memory of <italic>x</italic> past time steps in the feed-forward system, the relevant elements were unfolded over time: the state of each element is passed on through a chain of <italic>x</italic> nodes, one node for each of the <italic>x</italic> time steps <xref ref-type="bibr" rid="pcbi.1003588-Rumelhart1">[54]</xref>, <xref ref-type="bibr" rid="pcbi.1003588-Goldman1">[55]</xref>. In this way, the states of upstream elements in previous time steps can be combined (converge) in a feed-forward manner to determine the state of elements downstream, but can never feed back on elements upstream. As illustrated in the figure, while the recurrent system gives rise to a complex with Φ<sup>Max</sup>&gt;0 in every state, and would therefore be conscious, the feed-forward system does not constitute a complex and is thus unconscious.</p>
<fig id="pcbi-1003588-g021" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003588.g021</object-id><label>Figure 21</label><caption>
<title>Functionally equivalent conscious and unconscious systems.</title>
<p>(A) A strongly integrated system gives rise to a complex in every network state. In the depicted state (yellow: 1, white: 0), elements <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e162" xlink:type="simple"/></inline-formula> form a complex with Φ<sup>Max</sup> = 0.76 and 17 concepts. (B) Given many more elements and connections, it is possible to construct a feed-forward network implementing the same input-output function as the strongly integrated system in (A) for a certain number of time steps (here at least 4). This is done by unfolding the elements over time, keeping the memory of their past state in a feed-forward chain. The transition from the first layer to the second hidden layer in the feed-forward system is assumed to be faster than in the integrated system (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e163" xlink:type="simple"/></inline-formula>) to compensate for the additional layers (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e164" xlink:type="simple"/></inline-formula>). Despite the functional equivalence, the feed-forward system is unconscious, a “zombie” without phenomenological experience, since its elements do not form a complex.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003588.g021" position="float" xlink:type="simple"/></fig>
<p>This comparison highlights an important corollary of IIT: whether a system is conscious or not cannot be decided based on its input-output behavior only. In neuroscience, the ability to report is usually considered as the gold standard for assessing the presence of consciousness. Behavior and reportability can be reliable guides under ordinary conditions (typically adult awake humans) and can be employed to evaluate neural correlates of consciousness <xref ref-type="bibr" rid="pcbi.1003588-Koch1">[9]</xref> and to validate theoretical constructs <xref ref-type="bibr" rid="pcbi.1003588-Casali1">[14]</xref>. However, behavior and reportability become problematic for evaluating consciousness in pathological conditions, during development, in animals very different from us, and in machines that may perform sophisticated behaviors <xref ref-type="bibr" rid="pcbi.1003588-Tononi3">[6]</xref>. For example, programs running on powerful computers can not only play chess better than humans, but win in difficult question games such as “Jeopardy” <xref ref-type="bibr" rid="pcbi.1003588-Thompson1">[3]</xref>. Moreover, recent advances in machine learning have made it possible to construct simulated networks, primarily feed-forward, that can learn to recognize natural categories such as cats, dogs <xref ref-type="bibr" rid="pcbi.1003588-Le1">[1]</xref>, pedestrians <xref ref-type="bibr" rid="pcbi.1003588-Dalal1">[56]</xref>, <xref ref-type="bibr" rid="pcbi.1003588-Serre1">[57]</xref>, and/or faces <xref ref-type="bibr" rid="pcbi.1003588-Sung1">[58]</xref>–<xref ref-type="bibr" rid="pcbi.1003588-Poggio1">[60]</xref>. Hence, if behavior is the gold standard, it is not clear on what grounds we should deny consciousness to a phone “assistant” program that can answer many difficult questions, and can even be made to report about her internal feelings, or to a chip that recognizes thousands of different objects as well or better than we do, while granting it to a human who can barely follow an object with his eyes. IIT claims, by contrast, that input-output behavior is not always a reliable guide: one needs to investigate not just “what” functions are being performed by a system, but also “how” they are performed within the system. Thus, IIT admits the possibility of true “zombies”, which may behave more and more like us while lacking subjective experience <xref ref-type="bibr" rid="pcbi.1003588-Chalmers1">[11]</xref>.</p>
<p>The examples of <xref ref-type="fig" rid="pcbi-1003588-g021">Figure 21</xref> also suggest that, while it may be possible to build unconscious systems that perform many complex functions, there is an evident evolutionary advantage towards the selection of integrated architectures that can perform the same functions consciously. Among the benefits of integrated architectures are economy of units and wiring, speed, compositionality, context-dependency, memory, and the ability to learn adaptive functions rapidly, flexibly, and building upon previous knowledge <xref ref-type="bibr" rid="pcbi.1003588-Tononi3">[6]</xref>. Moreover, in a feed-forward network all system elements are entirely determined by the momentary external input passing through the system. By contrast, a (strongly) integrated system is autonomous, since it can act and react based on its internal states and goals.</p>
</sec><sec id="s3g">
<title>The concepts within a complex are self-generated, self-referential, and holistic</title>
<p>The final example (<xref ref-type="fig" rid="pcbi-1003588-g022">Figure 22A</xref>) considers a simple perceptual system – a recurrent segment/dot system. The segment/dot system consists of 10 heavily interconnected elements that, in their current state, form a complex (<xref ref-type="fig" rid="pcbi-1003588-g022">Figure 22A</xref>, blue circle). Elements <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e165" xlink:type="simple"/></inline-formula>, and <italic>C</italic> are the ports-in of the complex: they each receive 2 inputs from an external source in addition to feed-back inputs from within the complex. Elements <italic>F</italic> and <italic>J</italic> are the ports-out of the complex: they output to the external elements <italic>O</italic>1 and <italic>O</italic>2, respectively, in addition to their outputs within the complex. In this example, the ports-out are XOR logic gates. All other elements inside the segment/dot system are linear threshold units (LTUs). Connections within the complex are excitatory (+1, black) or inhibitory (−1, red).</p>
<fig id="pcbi-1003588-g022" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003588.g022</object-id><label>Figure 22</label><caption>
<title>A complex can have ports-in and ports-out from and to the external environment, but its qualia are solipsistic: Self-generated, self-referential, and holistic.</title>
<p>(A) A recurrent segment/dot system consisting of 10 elements (8 linear threshold units, and 2 XOR logic gates) that are linked by excitatory and inhibitory connections (black +1, red −1). <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e166" xlink:type="simple"/></inline-formula> and <italic>C</italic> are the ports-in of the complex. They receive external inputs of strength 0, 1, or 2. Elements <italic>F</italic> and <italic>J</italic> are the ports-out of the complex. They output to the external elements <italic>O</italic>1 and <italic>O</italic>2. The current state of the system corresponds to a sustained input with value 2-2-0. From an extrinsic perspective, the different layers of the complex can be interpreted as feature detectors having increasingly invariant selectivities (e.g. <italic>D</italic> indicates “two contiguous left elements”, <italic>F</italic> “invariant segment”, and <italic>J</italic> “invariant dot”). (B) Since the segment/dot system is highly interconnected with specialized mechanisms, all first order concepts and many higher order concepts exist. (C) Both, elementary mechanisms that are “on” (1) and those that are “off” (0) constitute concepts. Note that the cause repertoire of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e167" xlink:type="simple"/></inline-formula> is the mirror image of the cause repertoire of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e168" xlink:type="simple"/></inline-formula> (highlighted in blue). (C,D,E) From the intrinsic perspective, the function of a mechanism is given by its cause-effect repertoire. The purview of a concept can only contain elements within the complex. The concepts that constitute the MICS generated by the complex are self-generated (specified exclusively by elements belonging to the complex); self-referential (specified exclusively over elements belonging to the complex); and holistic (their meaning is constructed in the context of the other concepts in the MICS).</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003588.g022" position="float" xlink:type="simple"/></fig>
<p>The elementary mechanisms comprising the segment/dot system have specialized functions and generate elementary concepts. In the segment/dot system, the concepts of mechanisms in the “off” state (0) tend to have lower <italic>φ</italic><sup>Max</sup> values, because the mechanisms tend to be more selective in their “on” state (1) (see also <xref ref-type="fig" rid="pcbi-1003588-g003">Figure 3</xref>). As listed in <xref ref-type="fig" rid="pcbi-1003588-g022">Figure 22B</xref>, in addition to first order concepts, the segment-dot system gives rise to many higher order concepts. Dependent on the state of the system, certain higher order concepts may or may not exist. For instance, in the current state of the segment/dot system, the second order concept <italic>DI</italic> exists, while <italic>EG</italic> does not because it is reducible (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e169" xlink:type="simple"/></inline-formula>). If the segment/dot system were presented instead with a “right”-segment (inputs 022), <italic>DI</italic> would disappear and <italic>EG</italic> would emerge.</p>
<p>From the perspective of an external observer (e.g. a neuroscientist recording the activity of “neurons” <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e170" xlink:type="simple"/></inline-formula>), the function of a mechanism is typically described with respect to external inputs (e.g. a “segment” detector). In the segment/dot system, mechanisms at different hierarchical levels correspond to increasing levels of invariance: element <italic>D</italic>, for example, turns on if the two contiguous pixels on the left have been on persistently (with inputs of strength 2); higher up in the system, element <italic>F</italic> turns on if two contiguous pixels have been on either on the left or on the right, thus indicating the presence of the invariant “segment”. Element <italic>J</italic>, on the other hand, detects the invariant “dot”, either left, right, or center. The excitatory and inhibitory feed-back connections in the segment/dot system serve a predictive function: they temporarily increase/decrease the sensitivity to similar/opposed stimuli, allowing weaker inputs (with a value of 1) to be detected as segments and dots if the weaker external input is in accordance with the feed-back from within the complex.</p>
<p>From the intrinsic perspective of the system, instead, the function of each mechanism is given by its concept. Each concept is <italic>self-generated</italic>, because it must be specified exclusively by a subset of elements belonging to the complex. It is also <italic>self-referential</italic>, because its cause-effect repertoire refers exclusively to elements within the complex, and therefore only indirectly to external inputs. For example, the concept of <italic>D</italic>, in its current state 1, is about the purview <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e171" xlink:type="simple"/></inline-formula>. From the intrinsic perspective, the function of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e172" xlink:type="simple"/></inline-formula> is thus to constrain the possible past states of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e173" xlink:type="simple"/></inline-formula> and <italic>J</italic>, and to constrain the possible future state of <italic>A</italic> (<xref ref-type="fig" rid="pcbi-1003588-g022">Figure 22C</xref>). Therefore, <italic>D</italic> = 1 specifies a concept that is exclusively self-referential to the complex to which <italic>D</italic> belongs (note that, in this simple version of a recurrent segment/dot system, feed-forward and feed-back connections have the same absolute strength of 1. In a more realistic neural network, in which the function of the recurrent connections is mostly modulatory, a concept's past and future purviews would be modified accordingly). Nevertheless, in this case there is a good correspondence between the intrinsic and the extrinsic perspective, since the cause repertoire of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e174" xlink:type="simple"/></inline-formula> specifies as potential causes those states in which both ports-in <italic>A</italic> and <italic>B</italic> are 1, which happens when two contiguous pixels on the left are on. Importantly, the concept of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e175" xlink:type="simple"/></inline-formula> additionally takes into account the internal context <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e176" xlink:type="simple"/></inline-formula> (blue shaded states in <xref ref-type="fig" rid="pcbi-1003588-g022">Figure 22C</xref>). However, the correspondence between intrinsic and extrinsic perspective breaks down for the ports-in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e177" xlink:type="simple"/></inline-formula>: even though their state is partly determined by the external inputs, their concept specifies constraints about past and future states of elements higher up in the system, rather than about the environment (<xref ref-type="fig" rid="pcbi-1003588-g022">Figure 22D</xref>).</p>
<p>The self-referential property of the concepts specified by ports-in may have some implications with respect to the role of primary areas in consciousness. An influential hypothesis by Crick and Koch <xref ref-type="bibr" rid="pcbi.1003588-Crick2">[61]</xref> suggests that primary visual cortex (V1) and perhaps other primary cortical areas may not contribute directly to consciousness, a hypothesis that is now supported by a large number of experimental results. For example, during binocular rivalry neurons in V1 may fire selectively to horizontal bars that are shown to one eye, even though the subject does not see them and is conscious of a different stimulus presented to the other eye <xref ref-type="bibr" rid="pcbi.1003588-Blake1">[62]</xref>. On the other hand, the firing of units higher up in the visual system correlates tightly with the experience. While these results are compelling, other interpretations are possible if, as illustrated in the segment/dot system, V1 neurons were to constitute ports-in of the main complex. Under this assumption, V1 units would have to specify concepts about other units in the complex – either other V1 units or units in higher areas – rather than about their feed-forward inputs, which would remain outside the complex. V1 concepts could relate for example to Gestalt properties such as spatial continuity, rather than to oriented bars. In that case, what V1 contributes to consciousness during binocular rivalry – namely spatial continuity – would not change substantially between the two rivalrous percepts. Instead, concepts corresponding to oriented bars would be specified by units in higher areas, whose firing is sensitive to perceptual rivalry, <italic>over</italic> units in V1. In sum, V1 units would contribute to consciousness not only by generating their own concepts (such as spatial continuity), but also by providing the cause repertoire for concepts specified by units higher up (such as oriented bars). While this possibility may be far-fetched and counterintuitive, it would not be inconsistent with lesion studies that highlight the importance of V1 for most aspects of visual consciousness <xref ref-type="bibr" rid="pcbi.1003588-Tong1">[63]</xref>, <xref ref-type="bibr" rid="pcbi.1003588-Pollen1">[64]</xref>.</p>
<p>The self-referential nature of concepts within a complex has implications with respect to how concepts obtain their <italic>meaning</italic>. As mentioned above, a (conscious) external observer “knows” that element <italic>F</italic> in <xref ref-type="fig" rid="pcbi-1003588-g022">Figure 22E</xref> turns on whenever there is a “segment” in the input from the environment. However, from the intrinsic perspective of the complex, that meaning cannot be specified by <italic>F</italic> = 1 in isolation. This is because, while the cause repertoire of <italic>F</italic> = 1 specifies that either <italic>D</italic> or <italic>E</italic> must have been on, by itself it cannot specify what <italic>D</italic> and <italic>E</italic> mean in turn. In fact, the full meaning of “segment” can only be synthesized through the interlocking of cause-effect repertoires of multiple concepts within a MICS (such as that of element <italic>F</italic> interlocked with those of elements <italic>D</italic>, <italic>E</italic>, and so on). In this view, the meaning of a concept depends on the <italic>context</italic> provided by the entire MICS to which it belongs, and corresponds to how it constrains the overall “shape” of the MICS. Meaning is thus both self-referential (internalistic) and <italic>holistic</italic>. A proper treatment of how the conceptual structure of a complex of mechanisms can give rise to meaning from the intrinsic perspective is beyond the scope of the present work and will be addressed in more detail elsewhere.</p>
<p>While emphasizing the self-referential nature of concepts and meaning, IIT naturally recognizes that in the end most concepts owe their origin to the presence of regularities in the environment, to which they ultimately must refer, albeit only indirectly. This is because the mechanisms specifying the concepts have themselves been honed under selective pressure from the environment during evolution, development, and learning <xref ref-type="bibr" rid="pcbi.1003588-Tononi8">[65]</xref>–<xref ref-type="bibr" rid="pcbi.1003588-Friston2">[67]</xref>. Nevertheless, at any given time, environmental input can only act as a background condition, helping to “select” which particular concepts within the MICS will be “on” or “off”, and their meaning will be defined entirely within the quale. Every waking experience should then be seen as an “awake dream” selected by the environment. And indeed, once the architecture of the brain has been built and refined, having an experience – with its full complement of intrinsic meaning – does not require the environment at all, as demonstrated every night by the dreams that occur when we are asleep and disconnected from the world.</p>
</sec><sec id="s3h">
<title>Limitations and future directions</title>
<p>In finishing, we point out some limitations and unfinished business. IIT 3.0 starts from key properties of consciousness – the phenomenological axioms – and translates them into postulates that lay out how a system of mechanisms must be constructed to satisfy those axioms and thus generate consciousness. To be able to formulate the postulates in explicit, computable terms, we considered small systems of interconnected mechanisms that are fully characterized by their transition probability matrix (TPM). For each system, mechanisms are discrete in time and space (see also <xref ref-type="supplementary-material" rid="pcbi.1003588.s003">Text S2</xref>) and transition probabilities are available for every possible state. Directly applying this approach to physical systems of interest, such as brains, is unfeasible for several reasons: i) One would need either to discretize the variables of interest or to extend the theoretical treatment to continuous variables. ii) For biological systems, one is usually limited to observable system states, and the exhaustive perturbation of a system as the brain across all its possible states is unfeasible. Nevertheless, systematic perturbations of brain states using naturalistic stimuli such as movies can provide useful approximations. Also, circumscribed regions of the cerebral cortex could be perturbed systematically using optogenetic methods coupled with calcium imaging. Moreover, discrete, analytically tractable brain models based on neuroanatomical connectivity such as <xref ref-type="bibr" rid="pcbi.1003588-Deco1">[68]</xref> could provide a suitable approximation of large-scale neural mechanisms yet permit the rigorous measurement of integrated information. iii) Variables recorded in most neurophysiological experiments may not correspond to the spatial and temporal grain at which integrated information reaches a maximum, which is the appropriate level of analysis <xref ref-type="bibr" rid="pcbi.1003588-Hoel1">[20]</xref>. iv) The present analysis is unfeasible for systems of more than a dozen elements or so. This is because, to calculate Φ<sup>Max</sup> exhaustively, all possible partitions of every mechanism and of every system of mechanisms should be evaluated, which leads to a combinatorial explosion, not to mention that the analysis should be performed at every spatio-temporal grain. For these reasons, the primary aim of IIT 3.0 is simply to begin characterizing, in a self-consistent and explicit manner, the fundamental properties of consciousness and of the physical systems that can support it. Hopefully, heuristic measures and experimental approaches inspired by this theoretical framework will make it possible to test some of the predictions of the theory <xref ref-type="bibr" rid="pcbi.1003588-Casali1">[14]</xref>, <xref ref-type="bibr" rid="pcbi.1003588-Barrett1">[69]</xref>. Deriving bounded approximations to the explicit formalism of IIT 3.0 is also crucial for establishing in more complex networks how some of the properties described here scale with system size and as a function of system architecture.</p>
<p>The above formulation of IIT 3.0 is also incomplete: i) We did not discuss the relationship between MICS and specific aspects of phenomenology, such as the clustering into modalities and submodalities, and the characteristic “feel” of different aspects of experience (space, shape, color and so on; but see <xref ref-type="bibr" rid="pcbi.1003588-Tononi1">[4]</xref>–<xref ref-type="bibr" rid="pcbi.1003588-Tononi3">[6]</xref>, <xref ref-type="bibr" rid="pcbi.1003588-Balduzzi2">[18]</xref>). ii) In the examples above, we assumed that the “micro” spatio-temporal grain size of elementary logic gates updating every time step was optimal. In general, however, for any given system the optimal grain size needs to be established by examining at which spatio-temporal level integrated information reaches a maximum <xref ref-type="bibr" rid="pcbi.1003588-Hoel1">[20]</xref>. In terms of integrated information, then, the macro may emerge over the micro, just like the whole may emerge above the parts. iii) While emphasizing that meaning is always internal to a complex (it is self-generated and self-referential), we did not discuss in any detail how meaning originates through the nesting of concepts within MICS (its holistic nature). iv) In IIT, the relationship between the MICS generated by a complex of mechanisms, such as a brain, and the environment to which it is adapted, is not one of “information processing”, but rather one of “matching” between internal and external causal structures <xref ref-type="bibr" rid="pcbi.1003588-Tononi1">[4]</xref>, <xref ref-type="bibr" rid="pcbi.1003588-Tononi3">[6]</xref>. Matching can be quantified as the distance between the set of MICS generated when a system interacts with its typical environment and those generated when it is exposed to a structureless (“scrambled”) version of it <xref ref-type="bibr" rid="pcbi.1003588-Tononi3">[6]</xref>, <xref ref-type="bibr" rid="pcbi.1003588-Hashmi1">[70]</xref>. The notion of matching, and the prediction that adaptation to an environment should lead to an increase in matching and thereby to an increase in consciousness, will be investigated in future work, both by evolving simulated agents in virtual environments (“animats” <xref ref-type="bibr" rid="pcbi.1003588-Albantakis1">[71]</xref>–<xref ref-type="bibr" rid="pcbi.1003588-Joshi1">[73]</xref>), and through neurophysiological experiments. v) IIT 3.0 explicitly treats integrated information and causation as one and the same thing, but the many implications of this approach need to be explored in depth in future work. For example, IIT implies that each individual consciousness is a local maximum of causal power. Hence, if having causal power is a requirement for existence, then consciousness is maximally real. Moreover, it is real in and of itself – from its own intrinsic perspective – without the need for an external observer to come into being.</p>
</sec></sec><sec id="s4">
<title>Supporting Information</title>
<supplementary-material id="pcbi.1003588.s001" mimetype="application/pdf" xlink:href="info:doi/10.1371/journal.pcbi.1003588.s001" position="float" xlink:type="simple"><label>Figure S1</label><caption>
<p>Motivation for exclusion at the level of mechanisms. Core cause: only one cause exists intrinsically – the most irreducible one. A neuron that receives two strong inputs from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e178" xlink:type="simple"/></inline-formula> and four weak inputs <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e179" xlink:type="simple"/></inline-formula>. The core cause is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e180" xlink:type="simple"/></inline-formula> with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e181" xlink:type="simple"/></inline-formula> (in the case of identical <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e182" xlink:type="simple"/></inline-formula> values, the largest purview is chosen because it specifies information about more system elements for the same value of irreducibility). This example illustrates that a core cause is not the most comprehensive set of possible causes of a particular state (in this case <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003588.e183" xlink:type="simple"/></inline-formula>), but the subset that is most affected by a partition.</p>
<p>(PDF)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1003588.s002" mimetype="application/pdf" xlink:href="info:doi/10.1371/journal.pcbi.1003588.s002" position="float" xlink:type="simple"><label>Text S1</label><caption>
<p>Main differences between IIT 3.0 and earlier versions.</p>
<p>(PDF)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1003588.s003" mimetype="application/pdf" xlink:href="info:doi/10.1371/journal.pcbi.1003588.s003" position="float" xlink:type="simple"><label>Text S2</label><caption>
<p>Supplementary methods.</p>
<p>(PDF)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1003588.s004" mimetype="application/pdf" xlink:href="info:doi/10.1371/journal.pcbi.1003588.s004" position="float" xlink:type="simple"><label>Text S3</label><caption>
<p>Some differences between integrated information and Shannon information.</p>
<p>(PDF)</p>
</caption></supplementary-material></sec></body>
<back>
<ack>
<p>We thank Chiara Cirelli, Lice Ghilardi, Melanie Boly, Christof Koch, and Marcello Massimini for many invaluable discussions concerning the concepts presented here. We also thank Brad Postle, Barry van Veen, Virgil Griffiths, Atif Hashmi, Erik Hoel, Matteo Mainetti, Andy Nere, Umberto Olcese, and Puneet Rana. We are especially grateful to V. Griffith for his contribution to characterizing the concept of synergy and its relation to integrated information; to M. Mainetti for his help in characterizing the proper metric for conceptual spaces. For developing the software used to compute maximally irreducible integrated conceptual structures we are indebted to B. Shababo, A. Nere, A. Hashmi, U. Olcese, and P. Rana.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1003588-Le1"><label>1</label>
<mixed-citation publication-type="other" xlink:type="simple">Le QV, Ranzato MA, Monga R, Devin M, Chen K, <etal>et al</etal>.. (2011) Building high-level features using large scale unsupervised learning. In: ICML2012.</mixed-citation>
</ref>
<ref id="pcbi.1003588-The1"><label>2</label>
<mixed-citation publication-type="other" xlink:type="simple">The DeepQA Research Team (2013) Available: <ext-link ext-link-type="uri" xlink:href="http://researcher.ibm.com/researcher/view_project.php?id=2099" xlink:type="simple">http://researcher.ibm.com/researcher/view_project.php?id=2099</ext-link>. Accessed October 21, 2013.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Thompson1"><label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Thompson</surname><given-names>C</given-names></name> (<year>2010</year>) <article-title>Smarter Than You Think – I.B.M.s Supercomputer to Challenge Jeopardy! Champions</article-title>. <source>N Y Times Mag</source></mixed-citation>
</ref>
<ref id="pcbi.1003588-Tononi1"><label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tononi</surname><given-names>G</given-names></name> (<year>2004</year>) <article-title>An information integration theory of consciousness</article-title>. <source>BMC Neurosci</source> <volume>5</volume>: <fpage>42</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Tononi2"><label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tononi</surname><given-names>G</given-names></name> (<year>2008</year>) <article-title>Consciousness as integrated information: a provisional manifesto</article-title>. <source>Biol Bull</source> <volume>215</volume>: <fpage>216</fpage>–<lpage>242</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Tononi3"><label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tononi</surname><given-names>G</given-names></name> (<year>2012</year>) <article-title>Integrated information theory of consciousness: an updated account</article-title>. <source>Arch Ital Biol</source> <volume>150</volume>: <fpage>56</fpage>–<lpage>90</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Baars1"><label>7</label>
<mixed-citation publication-type="book" xlink:type="simple">Baars BJ (1988) A Cognitive Theory of Consciousness (Cambridge University Press).</mixed-citation>
</ref>
<ref id="pcbi.1003588-Crick1"><label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Crick</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Koch</surname><given-names>C</given-names></name> (<year>2003</year>) <article-title>A framework for consciousness</article-title>. <source>Nat Neurosci</source> <volume>6</volume>: <fpage>119</fpage>–<lpage>126</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Koch1"><label>9</label>
<mixed-citation publication-type="book" xlink:type="simple">Koch C (2004) The Quest for Consciousness: A Neurobiological Approach (Roberts and Co.).</mixed-citation>
</ref>
<ref id="pcbi.1003588-Dehaene1"><label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dehaene</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Changeux</surname><given-names>JP</given-names></name> (<year>2011</year>) <article-title>Experimental and theoretical approaches to conscious processing</article-title>. <source>Neuron</source> <volume>70</volume>: <fpage>20027</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Chalmers1"><label>11</label>
<mixed-citation publication-type="book" xlink:type="simple">Chalmers DJ (1996) The Conscious Mind: In Search of a Fundamental Theory (Oxford University Press).</mixed-citation>
</ref>
<ref id="pcbi.1003588-Tononi4"><label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tononi</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Koch</surname><given-names>C</given-names></name> (<year>2008</year>) <article-title>The neural correlates of consciousness: an update</article-title>. <source>Ann N Y Acad Sci</source> <volume>1124</volume>: <fpage>239</fpage>–<lpage>61</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Tononi5"><label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tononi</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Laureys</surname><given-names>S</given-names></name> (<year>2009</year>) <article-title>The neurology of consciousness: an overview</article-title>. <source>The neurology of con-sciousness</source> <fpage>375</fpage>–<lpage>412</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Casali1"><label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Casali</surname><given-names>AG</given-names></name>, <name name-style="western"><surname>Gosseries</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Rosanova</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Boly</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Sarasso</surname><given-names>S</given-names></name>, <etal>et al</etal>. (<year>2013</year>) <article-title>A theoretically based index of consciousness independent of sensory processing and behavior</article-title>. <source>Science translational medicine</source> <volume>5</volume> (<issue>198</issue>) <fpage>198ra105</fpage>–<lpage>198ra105</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-King1"><label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>King</surname><given-names>JR</given-names></name>, <name name-style="western"><surname>Sitt</surname><given-names>JD</given-names></name>, <name name-style="western"><surname>Faugeras</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Rohaut</surname><given-names>B</given-names></name>, <name name-style="western"><surname>El Karoui</surname><given-names>I</given-names></name>, <etal>et al</etal>. (<year>2013</year>) <article-title>Information sharing in the brain indexes consciousness in noncommunicative patients</article-title>. <source>Curr Biol</source> <volume>23</volume>: <fpage>19149</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Tononi6"><label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tononi</surname><given-names>G</given-names></name> (<year>2001</year>) <article-title>Information measures for conscious experience</article-title>. <source>Arch Ital Biol</source> <volume>139</volume>: <fpage>367</fpage>–<lpage>71</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Balduzzi1"><label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Balduzzi</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Tononi</surname><given-names>G</given-names></name> (<year>2008</year>) <article-title>Integrated information in discrete dynamical systems: Motivation and theoretical framework</article-title>. <source>PLoS Comput Biol</source> <volume>4</volume>: <fpage>e1000091</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Balduzzi2"><label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Balduzzi</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Tononi</surname><given-names>G</given-names></name> (<year>2009</year>) <article-title>Qualia: the geometry of integrated information</article-title>. <source>PLoS Comput Biol</source> <volume>5</volume>: <fpage>e1000462</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Ascoli1"><label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ascoli</surname><given-names>G</given-names></name> (<year>2013</year>) <article-title>The Mind-Brain Relationship as a Mathematical Problem</article-title>. <source>ISRN Neurosci</source> <volume>2013</volume>: <fpage>113</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Hoel1"><label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hoel</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Albantakis</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Tononi</surname><given-names>G</given-names></name> (<year>2013</year>) <article-title>Quantifying causal emergence shows that “macro” can beat “micro”</article-title>. <source>Proc Natl Acad Sci</source> <comment>[epub ahead of print] doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.1314922110" xlink:type="simple">10.1073/pnas.1314922110</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1003588-Ay1"><label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ay</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Polani</surname><given-names>D</given-names></name> (<year>2008</year>) <article-title>Information Flows in Causal Networks</article-title>. <source>Adv Complex Syst</source> <volume>11</volume>: <fpage>1741</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Korb1"><label>22</label>
<mixed-citation publication-type="book" xlink:type="simple">Korb KB, Nyberg EP, Hope L (2011) in Causality in the Sciences (Oxford University Press, Oxford).</mixed-citation>
</ref>
<ref id="pcbi.1003588-Griffith1"><label>23</label>
<mixed-citation publication-type="other" xlink:type="simple">Griffith V, Koch C (2012) Quantifying synergistic mutual information. arXiv preprint arXiv:1205.4265.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Rubner1"><label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rubner</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Tomasi</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Guibas</surname><given-names>L</given-names></name> (<year>2000</year>) <article-title>The earth movers distance as a metric for image retrieval</article-title>. <source>Int J Comput Vis</source> <volume>40</volume> (<issue>2</issue>) <fpage>99</fpage>–<lpage>121</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Wilson1"><label>25</label>
<mixed-citation publication-type="book" xlink:type="simple">Wilson RJ (1985) Introduction to Graph Theory, 3/e (Longman Scientific &amp; Technical).</mixed-citation>
</ref>
<ref id="pcbi.1003588-Plum1"><label>26</label>
<mixed-citation publication-type="book" xlink:type="simple">Plum F, Posner JB (1982) The Diagnosis of Stupor and Coma (Oxford University Press).</mixed-citation>
</ref>
<ref id="pcbi.1003588-Tononi7"><label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tononi</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Edelman</surname><given-names>GM</given-names></name> (<year>1998</year>) <article-title>Consciousness and complexity</article-title>. <source>Science</source> <volume>282</volume>: <fpage>1846</fpage>–<lpage>1851</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Gazzaniga1"><label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gazzaniga</surname><given-names>MS</given-names></name> (<year>2005</year>) <article-title>Forty-five years of split-brain research and still going strong</article-title>. <source>Nat Rev Neurosci</source> <volume>6</volume>: <fpage>6539</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Lynn1"><label>29</label>
<mixed-citation publication-type="book" xlink:type="simple">Lynn S, Rhue J (1994) Dissociation: Clinical and theoretical perspectives (Guilford Press).</mixed-citation>
</ref>
<ref id="pcbi.1003588-Mudrik1"><label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mudrik</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Breska</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Lamy</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Deouell</surname><given-names>LY</given-names></name> (<year>2011</year>) <article-title>Integration without awareness: expanding the limits of unconscious processing</article-title>. <source>Psychol Sci</source> <volume>22</volume>: <fpage>76470</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Mudrik2"><label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mudrik</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Faivre</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Koch</surname><given-names>S</given-names></name> (<year>2014</year>) <article-title>Information integration in the absence of awareness</article-title>. <source>Trends in Cognitive Sciences</source> in press.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Glickstein1"><label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Glickstein</surname><given-names>M</given-names></name> (<year>2007</year>) <article-title>What does the cerebellum really do?</article-title> <source>Curr Biol</source> <volume>17</volume>: <fpage>R824R827</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Schmahmann1"><label>33</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schmahmann</surname><given-names>JD</given-names></name>, <name name-style="western"><surname>Weilburg</surname><given-names>JB</given-names></name>, <name name-style="western"><surname>Sherman</surname><given-names>JC</given-names></name> (<year>2007</year>) <article-title>The neuropsychiatry of the cerebellum –insights from the clinic</article-title>. <source>Cerebellum</source> <volume>6</volume>: <fpage>25467</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Boyd1"><label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Boyd</surname><given-names>CAR</given-names></name> (<year>2010</year>) <article-title>Cerebellar agenesis revisited</article-title>. <source>Brain</source> <volume>133</volume>: <fpage>9414</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Cohen1"><label>35</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cohen</surname><given-names>D</given-names></name> (<year>1998</year>) <article-title>Patches of synchronized activity in the cerebellar cortex evoked by mossy-fiber stimulation: Questioning the role of parallel fibers</article-title>. <source>Proc Natl Acad Sci</source> <volume>95</volume>: <fpage>1503215036</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Bower1"><label>36</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bower</surname><given-names>JM</given-names></name> (<year>2002</year>) <article-title>The Organization of Cerebellar Cortical Circuitry Revisited. Implications for Function</article-title>. <source>Ann N Y Acad Sci</source> <volume>978</volume>: <fpage>135155</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Sporns1"><label>37</label>
<mixed-citation publication-type="book" xlink:type="simple">Sporns O (2010) Networks of the Brain (MIT Press).</mixed-citation>
</ref>
<ref id="pcbi.1003588-vandenHeuvel1"><label>38</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>van den Heuvel</surname><given-names>MP</given-names></name>, <name name-style="western"><surname>Sporns</surname><given-names>O</given-names></name> (<year>2013</year>) <article-title>An anatomical substrate for integration among functional networks in human cortex</article-title>. <source>J Neurosci</source> <volume>33</volume>: <fpage>14489500</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Massimini1"><label>39</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Massimini</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Ferrarelli</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Huber</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Esser</surname><given-names>SK</given-names></name>, <name name-style="western"><surname>Singh</surname><given-names>H</given-names></name>, <etal>et al</etal>. (<year>2005</year>) <article-title>Breakdown of cortical effective connectivity during sleep</article-title>. <source>Science</source> <volume>309</volume>: <fpage>222832</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Ferrarelli1"><label>40</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ferrarelli</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Massimini</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Sarasso</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Casali</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Riedner</surname><given-names>BA</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>Breakdown in cortical effective connectivity during midazolam-induced loss of consciousness</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>107</volume>: <fpage>26816</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Sanes1"><label>41</label>
<mixed-citation publication-type="book" xlink:type="simple">Sanes DH, Reh TA, Harris WA (2011) Development of the Nervous System (Academic Press).</mixed-citation>
</ref>
<ref id="pcbi.1003588-Sullivan1"><label>42</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sullivan</surname><given-names>PR</given-names></name> (<year>1995</year>) <article-title>Contentless Consciousness and Information-Processing Theories of Mind</article-title>. <source>Philos Psychiatry, Psychol</source> <volume>2</volume>: <fpage>5159</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Edelman1"><label>43</label>
<mixed-citation publication-type="book" xlink:type="simple">Edelman GM (1989) The Remembered Present: A Biological Theory of Consciousness (Basic Books).</mixed-citation>
</ref>
<ref id="pcbi.1003588-Harth1"><label>44</label>
<mixed-citation publication-type="book" xlink:type="simple">Harth E (1993) The creative loop: How the brain makes a mind (Addison-Wesley, Reading, MA).</mixed-citation>
</ref>
<ref id="pcbi.1003588-Hofstadter1"><label>45</label>
<mixed-citation publication-type="book" xlink:type="simple">Hofstadter DR (2007) I Am a Strange Loop (Basic Books).</mixed-citation>
</ref>
<ref id="pcbi.1003588-Lamme1"><label>46</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lamme</surname><given-names>VAF</given-names></name> (<year>2003</year>) <article-title>Why visual attention and awareness are different</article-title>. <source>Trends Cogn Sci</source> <volume>7</volume>: <fpage>1218</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Imas1"><label>47</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Imas</surname><given-names>OA</given-names></name>, <name name-style="western"><surname>Ropella</surname><given-names>KM</given-names></name>, <name name-style="western"><surname>Ward</surname><given-names>BD</given-names></name>, <name name-style="western"><surname>Wood</surname><given-names>JD</given-names></name>, <name name-style="western"><surname>Hudetz</surname><given-names>AG</given-names></name> (<year>2005</year>) <article-title>Volatile anesthetics disrupt frontal-posterior recurrent information transfer at gamma frequencies in rat</article-title>. <source>Neurosci Lett</source> <volume>387</volume>: <fpage>145150</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Boly1"><label>48</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Boly</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Moran</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Murphy</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Boveroux</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Bruno</surname><given-names>MA</given-names></name>, <etal>et al</etal>. (<year>2012</year>) <article-title>Connectivity changes underlying spectral EEG changes during propofol-induced loss of consciousness</article-title>. <source>J Neurosci</source> <volume>32</volume>: <fpage>708290</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Mashour1"><label>49</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mashour</surname><given-names>GA</given-names></name> (<year>2013</year>) <article-title>Cognitive unbinding: A neuroscientific paradigm of general anesthesia and related states of unconsciousness</article-title>. <source>Neurosci Biobehav Rev</source></mixed-citation>
</ref>
<ref id="pcbi.1003588-Boly2"><label>50</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Boly</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Garrido</surname><given-names>MI</given-names></name>, <name name-style="western"><surname>Gosseries</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Bruno</surname><given-names>MA</given-names></name>, <name name-style="western"><surname>Boveroux</surname><given-names>P</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <article-title>Preserved feedforward but impaired top-down processes in the vegetative state</article-title>. <source>Science</source> <volume>332</volume>: <fpage>85862</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Koch2"><label>51</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Koch</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Crick</surname><given-names>F</given-names></name> (<year>2001</year>) <article-title>The zombie within</article-title>. <source>Nature</source> <volume>411</volume>: <fpage>893</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Cybenko1"><label>52</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cybenko</surname><given-names>G</given-names></name> (<year>1989</year>) <article-title>Approximation by superpositions of a sigmoidal function</article-title>. <source>Math Control Signals Syst</source> <volume>2</volume>: <fpage>303</fpage>–<lpage>314</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Hornik1"><label>53</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hornik</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Stinchcombe</surname><given-names>M</given-names></name>, <name name-style="western"><surname>White</surname><given-names>H</given-names></name> (<year>1989</year>) <article-title>Multilayer feedforward networks are universal approx-imators</article-title>. <source>Neural Networks</source> <volume>2</volume>: <fpage>359</fpage>–<lpage>366</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Rumelhart1"><label>54</label>
<mixed-citation publication-type="book" xlink:type="simple">Rumelhart D, Hinton G, Williams R (1986) Learning internal representations by error propagation, Parallel distributed processing, 1986. Cambridge, MA.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Goldman1"><label>55</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Goldman</surname><given-names>M</given-names></name> (<year>2009</year>) <article-title>Memory without feedback in a neural network</article-title>. <source>Neuron</source> <volume>61</volume>: <fpage>499</fpage>–<lpage>501</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Dalal1"><label>56</label>
<mixed-citation publication-type="other" xlink:type="simple">Dalal N, Triggs B (2005) In: IEEE Computer Society Conference on Computer Vision and Pattern Recognition; 25–25 June 2005; San Diego, CA, United States. CVPR 2005. Available: <ext-link ext-link-type="uri" xlink:href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=1467360" xlink:type="simple">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp; arnumber=1467360</ext-link>. Accessed 17 March 2014.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Serre1"><label>57</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Serre</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Wolf</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Bileschi</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Riesenhuber</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Poggio</surname><given-names>T</given-names></name> (<year>2007</year>) <article-title>Robust object recognition with cortex-like mechanisms</article-title>. <source>IEEE Trans Pattern Anal Mach Intell</source> <volume>29</volume>: <fpage>41126</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Sung1"><label>58</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sung</surname><given-names>K-K</given-names></name>, <name name-style="western"><surname>Poggio</surname><given-names>T</given-names></name> (<year>1998</year>) <article-title>Example-based learning for view-based human face detection</article-title>. <source>IEEE Trans Pattern Anal Mach Intell</source> <volume>20</volume>: <fpage>3951</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Zhao1"><label>59</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zhao</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Chellappa</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Phillips</surname><given-names>PJ</given-names></name>, <name name-style="western"><surname>Rosenfeld</surname><given-names>A</given-names></name> (<year>2003</year>) <article-title>Face recognition</article-title>. <source>ACM Comput Surv</source> <volume>35</volume>: <fpage>399458</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Poggio1"><label>60</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Poggio</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Ullman</surname><given-names>S</given-names></name> (<year>2013</year>) <article-title>Vision: are models of object recognition catching up with the brain?</article-title> <source>Ann N Y Acad Sci</source> <volume>1305</volume>: <fpage>72</fpage>–<lpage>82</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Crick2"><label>61</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Crick</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Koch</surname><given-names>C</given-names></name> (<year>1995</year>) <article-title>Are we aware of neural activity in primary visual cortex?</article-title> <source>Nature</source> <volume>375</volume>: <fpage>121123</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Blake1"><label>62</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Blake</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Logothetis</surname><given-names>NK</given-names></name> (<year>2002</year>) <article-title>Visual competition</article-title>. <source>Nat Rev Neurosci</source> <volume>3</volume>: <fpage>1321</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Tong1"><label>63</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tong</surname><given-names>F</given-names></name> (<year>2003</year>) <article-title>Primary visual cortex and visual awareness</article-title>. <source>Nat Rev Neurosci</source> <volume>4</volume>: <fpage>21929</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Pollen1"><label>64</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pollen</surname><given-names>DA</given-names></name> (<year>2008</year>) <article-title>Fundamental requirements for primary visual perception</article-title>. <source>Cereb Cortex</source> <volume>18</volume>: <fpage>19918</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Tononi8"><label>65</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tononi</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Sporns</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Edelman</surname><given-names>GM</given-names></name> (<year>1996</year>) <article-title>A complexity measure for selective matching of signals by the brain</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>93</volume>: <fpage>34223427</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Friston1"><label>66</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Friston</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Kiebel</surname><given-names>S</given-names></name> (<year>2009</year>) <article-title>Predictive coding under the free-energy principle</article-title>. <source>Philos Trans R Soc Lond B Biol Sci</source> <volume>364</volume>: <fpage>121121</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Friston2"><label>67</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Friston</surname><given-names>K</given-names></name> (<year>2010</year>) <article-title>The free-energy principle: a unified brain theory?</article-title> <source>Nat Rev Neurosci</source> <volume>11</volume>: <fpage>12738</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Deco1"><label>68</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Deco</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Senden</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Jirsa</surname><given-names>V</given-names></name> (<year>2012</year>) <article-title>How anatomy shapes dynamics: a semi-analytical study of the brain at rest by a simple spin model</article-title>. <source>Front Comput Neurosci</source> <volume>6</volume>: <fpage>68</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Barrett1"><label>69</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Barrett</surname><given-names>AB</given-names></name>, <name name-style="western"><surname>Seth</surname><given-names>AK</given-names></name> (<year>2011</year>) <article-title>Practical measures of integrated information for time-series data</article-title>. <source>PLoS Comput Biol</source> <volume>7</volume>: <fpage>e1001052</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Hashmi1"><label>70</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hashmi</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Nere</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Tononi</surname><given-names>G</given-names></name> (<year>2013</year>) <article-title>Sleep-Dependent Synaptic Down-Selection (II): Single-Neuron Level Benefits for Matching, Selectivity, and Specificity</article-title>. <source>Front Neurol</source> <volume>4</volume>: <fpage>148</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Albantakis1"><label>71</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Albantakis</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Hintze</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Koch</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Adami</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Tononi</surname><given-names>G</given-names></name> (<year>2013</year>) <article-title>Information Matching – Environment dependent increase in integrated information (Φ)</article-title>. <source>European Conference on Complex Systems (ECCS13)</source></mixed-citation>
</ref>
<ref id="pcbi.1003588-Edlund1"><label>72</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Edlund</surname><given-names>JA</given-names></name>, <name name-style="western"><surname>Chaumont</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Hintze</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Koch</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Tononi</surname><given-names>G</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <article-title>Integrated information increases with fitness in the evolution of animats</article-title>. <source>PLoS Comput Biol</source> <volume>7</volume>: <fpage>e1002236</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003588-Joshi1"><label>73</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Joshi</surname><given-names>NJ</given-names></name>, <name name-style="western"><surname>Tononi</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Koch</surname><given-names>C</given-names></name> (<year>2013</year>) <article-title>The minimal complexity of adapting agents increases with fitness</article-title>. <source>PLoS Comput Biol</source> <volume>9</volume>: <fpage>e1003111</fpage>.</mixed-citation>
</ref>
</ref-list></back>
</article>
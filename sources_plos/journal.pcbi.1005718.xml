<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN" "http://jats.nlm.nih.gov/publishing/1.1d3/JATS-journalpublishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-17-00263</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1005718</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Cell biology</subject><subj-group><subject>Cellular types</subject><subj-group><subject>Animal cells</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cellular neuroscience</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Cell biology</subject><subj-group><subject>Cellular types</subject><subj-group><subject>Animal cells</subject><subj-group><subject>Neurons</subject><subj-group><subject>Afferent neurons</subject><subj-group><subject>Retinal ganglion cells</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cellular neuroscience</subject><subj-group><subject>Neurons</subject><subj-group><subject>Afferent neurons</subject><subj-group><subject>Retinal ganglion cells</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Cell biology</subject><subj-group><subject>Cellular types</subject><subj-group><subject>Animal cells</subject><subj-group><subject>Neurons</subject><subj-group><subject>Ganglion cells</subject><subj-group><subject>Retinal ganglion cells</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cellular neuroscience</subject><subj-group><subject>Neurons</subject><subj-group><subject>Ganglion cells</subject><subj-group><subject>Retinal ganglion cells</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Physics</subject><subj-group><subject>Thermodynamics</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Simulation and modeling</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Ocular system</subject><subj-group><subject>Ocular anatomy</subject><subj-group><subject>Retina</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Ocular system</subject><subj-group><subject>Ocular anatomy</subject><subj-group><subject>Retina</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Computational biology</subject><subj-group><subject>Computational neuroscience</subject><subj-group><subject>Coding mechanisms</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Computational neuroscience</subject><subj-group><subject>Coding mechanisms</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Applied mathematics</subject><subj-group><subject>Algorithms</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Simulation and modeling</subject><subj-group><subject>Algorithms</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Probability theory</subject><subj-group><subject>Probability distribution</subject></subj-group></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Signatures of criticality arise from random subsampling in simple population models</article-title>
<alt-title alt-title-type="running-head">Criticality and subsampling in simple population models</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-6044-6627</contrib-id>
<name name-style="western">
<surname>Nonnenmacher</surname> <given-names>Marcel</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-3623-352X</contrib-id>
<name name-style="western">
<surname>Behrens</surname> <given-names>Christian</given-names></name>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
<xref ref-type="aff" rid="aff004"><sup>4</sup></xref>
<xref ref-type="aff" rid="aff005"><sup>5</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-0199-4727</contrib-id>
<name name-style="western">
<surname>Berens</surname> <given-names>Philipp</given-names></name>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
<xref ref-type="aff" rid="aff004"><sup>4</sup></xref>
<xref ref-type="aff" rid="aff005"><sup>5</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Bethge</surname> <given-names>Matthias</given-names></name>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Resources</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
<xref ref-type="aff" rid="aff004"><sup>4</sup></xref>
<xref ref-type="aff" rid="aff006"><sup>6</sup></xref>
</contrib>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<name name-style="western">
<surname>Macke</surname> <given-names>Jakob H.</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Project administration</role>
<role content-type="http://credit.casrai.org/">Resources</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
</contrib-group>
<aff id="aff001">
<label>1</label>
<addr-line>Research Center caesar, an associate of the Max Planck Society, Bonn, Germany</addr-line>
</aff>
<aff id="aff002">
<label>2</label>
<addr-line>Max Planck Institute for Biological Cybernetics, Tübingen, Germany</addr-line>
</aff>
<aff id="aff003">
<label>3</label>
<addr-line>Bernstein Center for Computational Neuroscience, Tübingen, Germany</addr-line>
</aff>
<aff id="aff004">
<label>4</label>
<addr-line>Centre for Integrative Neuroscience, University of Tübingen, Tübingen, Germany</addr-line>
</aff>
<aff id="aff005">
<label>5</label>
<addr-line>Institute for Ophthalmic Research, University of Tübingen, Tübingen, Germany</addr-line>
</aff>
<aff id="aff006">
<label>6</label>
<addr-line>Institute of Theoretical Physics, University of Tübingen, Tübingen, Germany</addr-line>
</aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Latham</surname> <given-names>Peter E.</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>UCL, UNITED KINGDOM</addr-line>
</aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">marcel.nonnenmacher@caesar.de</email> (MN); <email xlink:type="simple">jakob.macke@caesar.de</email> (JHM)</corresp>
</author-notes>
<pub-date pub-type="collection">
<month>10</month>
<year>2017</year>
</pub-date>
<pub-date pub-type="epub">
<day>3</day>
<month>10</month>
<year>2017</year>
</pub-date>
<volume>13</volume>
<issue>10</issue>
<elocation-id>e1005718</elocation-id>
<history>
<date date-type="received">
<day>17</day>
<month>2</month>
<year>2017</year>
</date>
<date date-type="accepted">
<day>1</day>
<month>8</month>
<year>2017</year>
</date>
</history>
<permissions>
<copyright-year>2017</copyright-year>
<copyright-holder>Nonnenmacher et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1005718"/>
<abstract>
<p>The rise of large-scale recordings of neuronal activity has fueled the hope to gain new insights into the collective activity of neural ensembles. How can one link the statistics of neural population activity to underlying principles and theories? One attempt to interpret such data builds upon analogies to the behaviour of collective systems in statistical physics. Divergence of the specific heat—a measure of population statistics derived from thermodynamics—has been used to suggest that neural populations are optimized to operate at a “critical point”. However, these findings have been challenged by theoretical studies which have shown that common inputs can lead to diverging specific heat. Here, we connect “signatures of criticality”, and in particular the divergence of specific heat, back to statistics of neural population activity commonly studied in neural coding: firing rates and pairwise correlations. We show that the specific heat diverges whenever the average correlation strength does not depend on population size. This is necessarily true when data with correlations is randomly subsampled during the analysis process, irrespective of the detailed structure or origin of correlations. We also show how the characteristic shape of specific heat capacity curves depends on firing rates and correlations, using both analytically tractable models and numerical simulations of a canonical feed-forward population model. To analyze these simulations, we develop efficient methods for characterizing large-scale neural population activity with maximum entropy models. We find that, consistent with experimental findings, increases in firing rates and correlation directly lead to more pronounced signatures. Thus, previous reports of thermodynamical criticality in neural populations based on the analysis of specific heat can be explained by average firing rates and correlations, and are not indicative of an optimized coding strategy. We conclude that a reliable interpretation of statistical tests for theories of neural coding is possible only in reference to relevant ground-truth models.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author summary</title>
<p>Understanding how populations of neurons collectively encode sensory information is one of the central goals of computational neuroscience. In physics, systems are often characterized by identifying and describing critical points (e.g. the transition between two states of matter). The success of this approach has inspired a series of studies to search for analogous phenomena in nervous systems, and has lead to the hypothesis that these might be optimized to be poised at ‘thermodynamic critical points’. However, translating concepts from thermodynamics to neural data analysis has been a challenging endeavour. We here study the data analysis approaches that have been used to provide evidence for criticality in the brain. We find that observing signatures of criticality is closely linked to observing activity correlations between neurons– a ubiquitous phenomenon in neural data. Our study questions the experimental evidence that neural systems are optimised to exhibit thermodynamic critical behaviour. Finally, we provide practical, open-source tools for analyzing large-scale measurements of neural population activity using maximum entropy models.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100002347</institution-id>
<institution>Bundesministerium für Bildung und Forschung</institution>
</institution-wrap>
</funding-source>
<award-id>01GQ1002</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Macke</surname> <given-names>Jakob H.</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award002">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100002348</institution-id>
<institution>Bernstein Center for Computational Neuroscience Tübingen</institution>
</institution-wrap>
</funding-source>
<award-id>01GQ1601</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Macke</surname> <given-names>Jakob H.</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award003">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100001659</institution-id>
<institution>Deutsche Forschungsgemeinschaft</institution>
</institution-wrap>
</funding-source>
<award-id>Be 5601/1-1</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-0199-4727</contrib-id>
<name name-style="western">
<surname>Berens</surname> <given-names>Philipp</given-names></name>
</principal-award-recipient>
</award-group>
<funding-statement>Work was funded by the German Federal Ministry of Education and 568 Research (BMBF; FKZ: 01GQ1002, Bernstein Center Tübingen, FKZ 01GQ1601 to PB), the 569 German Research Foundation (BE 5601/1-1 to PB) the Max Planck Society and the caesar foundation. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="5"/>
<table-count count="0"/>
<page-count count="23"/>
</counts>
<custom-meta-group>
<custom-meta>
<meta-name>PLOS Publication Stage</meta-name>
<meta-value>vor-update-to-uncorrected-proof</meta-value>
</custom-meta>
<custom-meta>
<meta-name>Publication Update</meta-name>
<meta-value>2017-10-13</meta-value>
</custom-meta>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>All data used for our study was simulated, with some summary statistics extracted from publications cited within our manuscript. We uploaded our simulated data, the code used to generate the data, as well as code for data analysis and generation of the main figures to: <ext-link ext-link-type="uri" xlink:href="https://github.com/mackelab/critical_retina" xlink:type="simple">https://github.com/mackelab/critical_retina</ext-link></meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Recent advances in neural recording technology [<xref ref-type="bibr" rid="pcbi.1005718.ref001">1</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref002">2</xref>] and computational tools for describing neural population activity [<xref ref-type="bibr" rid="pcbi.1005718.ref003">3</xref>] make it possible to empirically examine the statistics of large neural populations and search for principles underlying their collective dynamics [<xref ref-type="bibr" rid="pcbi.1005718.ref004">4</xref>]. One hypothesis that has emerged from this approach is the idea that neural populations might be poised at a thermodynamic critical point [<xref ref-type="bibr" rid="pcbi.1005718.ref005">5</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref006">6</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref007">7</xref>], and that this might have consequences for how neural populations process sensory information [<xref ref-type="bibr" rid="pcbi.1005718.ref007">7</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref008">8</xref>]. As similar observations have been made in other biological systems [<xref ref-type="bibr" rid="pcbi.1005718.ref009">9</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref010">10</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref011">11</xref>], it has been suggested that this might reflect a more general organising principle [<xref ref-type="bibr" rid="pcbi.1005718.ref012">12</xref>]. Critical phenomena play a central role in physics: Phase transitions mark a special point in which media qualitatively change their properties by transitioning from one state of matter into another (e.g. liquid to gaseous at boiling point, ferro-magnetic and paramagnetic phases, or the emergence of super-conductivity). As such, the behaviour of a system at critical points is informative about its intrinsic properties. Moreover, critical points are ‘special’ in the sense that they classically only occupy a small portion of the parameter space. Thus, observing that a system is constantly poised at a critical point would be surprising, and would hint at an underlying organizing mechanism that keeps the system at this point. Given the fundamental importance of critical phenomena in physics, and their success in revealing the laws the determine the behaviour of physical systems, the hypothesis that these approaches might also shed lights on principles underlying neural coding is intriguing.</p>
<p>Evidence in favour of this hypothesis has been put forward by a series of studies which measured neural activity from large populations of retinal ganglion cells and reported that their statistics resemble those of physical systems at a critical point [<xref ref-type="bibr" rid="pcbi.1005718.ref007">7</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref008">8</xref>]. To this end, Tkačik and colleagues developed a data analysis framework to search for signatures of criticality in experimentally obtained measurements. Using large-scale multielectrode array recordings [<xref ref-type="bibr" rid="pcbi.1005718.ref002">2</xref>] and maximum entropy models [<xref ref-type="bibr" rid="pcbi.1005718.ref013">13</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref015">15</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref016">16</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref017">17</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref003">3</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref018">18</xref>], it was observed that the normalized variance of log-probabilities diverges as a function of population size. Importantly, this quantity is mathematically equivalent to the specific heat capacity, an important characteristic which diverges at critical points. In addition, when an artificial ‘temperature’ parameter was introduced, specific heat appeared to be maximal for the statistics of the observed data, rather than for statistics which have been perturbed by changing the temperature parameter. These properties of retinal populations resemble the behaviour of physical systems at critical points. It has been hypothesised [<xref ref-type="bibr" rid="pcbi.1005718.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref007">7</xref>] that the system needs to be optimized to keep itself at a critical point, for example through adaptation to stimulus statistics [<xref ref-type="bibr" rid="pcbi.1005718.ref019">19</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref020">20</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref021">21</xref>] or alternative mechanisms of self-organization [<xref ref-type="bibr" rid="pcbi.1005718.ref022">22</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref023">23</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref024">24</xref>].</p>
<p>A competing hypothesis states that instead generic mechanisms are sufficient to give rise to activity data with divergent specific heat, and that the presence of signatures of criticality does not provide evidence for retinal circuits being poised at a special state that is advantageous for coding. A series of theoretical studies [<xref ref-type="bibr" rid="pcbi.1005718.ref025">25</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref026">26</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref027">27</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref028">28</xref>] has shown that common input (i.e,. the presence of latent variables) can account for signatures of criticality: In particular, Schwab et al [<xref ref-type="bibr" rid="pcbi.1005718.ref026">26</xref>] and Aitchison et al [<xref ref-type="bibr" rid="pcbi.1005718.ref027">27</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref028">28</xref>] showed that Zipf scaling (an alternative characterization of criticality) and the divergence of the specific heat are closely related, and that in high-dimensional models with a low-dimensional latent variable, the specific heat diverges with system size under a wide range of circumstances [<xref ref-type="bibr" rid="pcbi.1005718.ref027">27</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref028">28</xref>]. Similarly, it has been shown empirically that a purely feedforward model can capture Zipf-like scaling in recordings from the salamander retina [<xref ref-type="bibr" rid="pcbi.1005718.ref029">29</xref>].</p>
<p>Interpreting findings of thermodynamic criticality for neural populations, identifying their mechanistic underpinnings, and clarifying their relationship with alternative theories, has been fraught with difficulty. We hypothesize that this difficulty stems from a subtle but crucial difference between how the scaling behaviour of system properties is studied in thermodynamics and in practical neural data analysis: Most theoretical approaches study how system properties scale as the size of the system, <italic>n</italic>, is varied. In contrast, in practical neural data analysis, different “<italic>n</italic>” do not correspond to different system sizes, but are obtained by subsampling neural populations from a large recording (which is itself a subsample of the underlying system). How does this sampling process affect estimates of whether the system is at a critical point? A second difficulty in interpreting these studies stems from the fact that they are based global statistical measures whose relationship with simple statistics such as firing rates and correlations— which are commonly used and have been extensively studied in neural coding [<xref ref-type="bibr" rid="pcbi.1005718.ref030">30</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref031">31</xref>]—is unclear. We here focus on one statistic that has been used as evidence of critical behaviour, namely the dependence of specific heat on population size and temperature. We study how it depends on neural firing rates and correlations, as well as on how this data is subsampled during data analysis:</p>
<p>First, we show explicitly that signatures of criticality, can be reproduced in canonical feed-forward models of neural population activity, as predicted by previous studies [<xref ref-type="bibr" rid="pcbi.1005718.ref025">25</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref026">26</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref028">28</xref>]. These studies did not have tools for studying population statistics in large simulations, and they were therefore limited to studying small (<italic>n</italic> ≤ 40) systems– for these small system sizes, it is difficult to make statements about the peak in the specific heat and its scaling with population size. In particular, the dominant peak near unit temperature only emerges for much larger systems. We overcome this difficulty by providing improved algorithms for efficiently fitting maximum entropy models to large neural populations (available at <ext-link ext-link-type="uri" xlink:href="https://github.com/mackelab/CorBinian" xlink:type="simple">https://github.com/mackelab/CorBinian</ext-link>), and use them to apply the analyses proposed by previous studies [<xref ref-type="bibr" rid="pcbi.1005718.ref007">7</xref>] to data simulated from a simple, feedforward encoding model of retinal processing [<xref ref-type="bibr" rid="pcbi.1005718.ref032">32</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref033">33</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref034">34</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref035">35</xref>].</p>
<p>Second, previous theoretical studies [<xref ref-type="bibr" rid="pcbi.1005718.ref026">26</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref027">27</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref028">28</xref>] treated only the limiting behavior of the specific heat at unit temperature, and did not investigate its dependence on firing rates and correlations. We here relate the characteristic shape of specific heat curves (i.e. the dependence of specific heat on temperature) to neural correlations and firing rates. The emergence of peak specific heat at the ‘inherent’ temperature <italic>T</italic> = 1 has given rise to the idea that correlations in the observed system are ‘special’, i.e. that systems with stronger or weaker correlations would not exhibit them [<xref ref-type="bibr" rid="pcbi.1005718.ref007">7</xref>]. We use an analytically tractable model of the analysis process to show that this is not the case– the more strongly correlated the population is, the more pronounced signatures of criticality will be. This analysis also shows that a ‘low-temperature’ regime (as reported by [<xref ref-type="bibr" rid="pcbi.1005718.ref018">18</xref>]) will be found whenever firing rates are sufficiently low.</p>
<p>Third, we analyze the structure of correlations which are sufficient to induce signatures of criticality, and find that it is sufficient if the average correlation is independent of population size. Such ‘criticality-inducing’ correlations can arise both from neural mechanisms such as common input or dense connectivity. Importantly, we show that they can also arise as a consequence of data analysis: Uniformly subsampling a recording with any non-zero correlations to construct subpopulations yields criticality-inducing correlations.</p>
<p>In summary, we show that statements about signatures of criticality derived from thermodynamics can be reduced to statements about firing rates and correlations, and that correlation structures which give rise to these signatures are ubiquitous in neural populations.</p>
</sec>
<sec id="sec002" sec-type="results">
<title>Results</title>
<sec id="sec003">
<title>Signatures of criticality arise in a simple model of retinal ganglion cell activity</title>
<p>A hallmark of criticality is that the specific heat capacity of the model diverges when the temperature reaches the critical temperature [<xref ref-type="bibr" rid="pcbi.1005718.ref005">5</xref>]. Tkačik et al. [<xref ref-type="bibr" rid="pcbi.1005718.ref007">7</xref>] developed an approach for translating this concept to neural data analysis (see <xref ref-type="fig" rid="pcbi.1005718.g001">Fig 1</xref>):. In this analysis, neural populations of different size <italic>n</italic> are generated from the full recording (of size <italic>N</italic>) by random subsampling. The statistics of activity for each population of size <italic>n</italic> are characterized using a maximum entropy model fit to population activity [<xref ref-type="bibr" rid="pcbi.1005718.ref013">13</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref016">16</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref017">17</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref003">3</xref>]. Finally, the maximum entropy models are perturbed by introducing a temperature parameter, and specific heat is computed for each population size <italic>n</italic> and temperature <italic>T</italic> from the (perturbed) maximum entropy model fit. Divergence of specific heat with population size <italic>n</italic>, and a peak of the specific heat near unit temperature <italic>T</italic> = 1 (the ‘temperature’ of the original data) are interpreted as indication for the system being at a critical point [<xref ref-type="bibr" rid="pcbi.1005718.ref007">7</xref>].</p>
<fig id="pcbi.1005718.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005718.g001</object-id>
<label>Fig 1</label>
<caption>
<title>How can one relate theories of thermodynamic criticality to the statistics of neural data?</title>
<p>In physical systems, the divergence of specific heat with system size can be interpreted as the system being at a critical point. We here study an analysis approach that has been proposed in order to search for similar signatures of criticality in the statistics of neural population activity. In this approach, different populations are subsampled from a large recording and summary statistics are extracted for each subpopulation (e.g. firing rates, correlations and population spike count statistics). Subsequently, maximum entropy models are fit to these data which assign a probability to each possible spike-pattern. Exploiting the mathematical relationship between the log-variance of probabilities (in statistics) and the specific heat (in thermodynamics) then allows one to compute and study the behaviour of the specific heat with population size. The goal of this study is to determine under which conditions (i.e., for which firing rates and correlations) such an analysis would report that the system is critical. To this end, we apply this approach to a simulation of neural population activity and analytically tractable models.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005718.g001" xlink:type="simple"/>
</fig>
<p>We wanted to verify that this phenomenon could be captured in feedforward models of retinal processing. We wanted to directly demonstrate that canonical mechanisms of retinal processing—such overlapping centre-surround receptive fields, spiking nonlinearities, shared Gaussian noise—are sufficient for the signatures of criticality to arise. We first created a simple phenomenological model of retinal ganglion cell (RGC) activity based on linear-nonlinear neurons [<xref ref-type="bibr" rid="pcbi.1005718.ref032">32</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref033">33</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref035">35</xref>]. In this model (<xref ref-type="fig" rid="pcbi.1005718.g002">Fig 2a</xref>), we assumed retinal ganglion cells to have centre-surround receptive fields [<xref ref-type="bibr" rid="pcbi.1005718.ref036">36</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref035">35</xref>] with linear spatial integration [<xref ref-type="bibr" rid="pcbi.1005718.ref037">37</xref>], sigmoid nonlinearities and stochastic binary spikes: in each time bin of size 20ms, each neuron <italic>i</italic> either emitted a spike (<italic>x</italic><sub><italic>i</italic></sub> = 1) or not (<italic>x</italic><sub><italic>i</italic></sub> = 0). We used a sequence of natural images as stimuli. In addition to the feedforward drive by the stimulus, nearby neurons received shared Gaussian noise, mimicking common input from bipolar cells [<xref ref-type="bibr" rid="pcbi.1005718.ref030">30</xref>]. Thus, cross-neural correlations in the model arise from correlations in the stimulus, receptive-field overlap and shared noise, but not from lateral connections between RGCs. As we will explain below, only the strength of correlations, but not their mechanistic origin or dependence on stimuli, is relevant for determining the specific heat. Parameters of the model were chosen to approximate the statistics of receptive-field centre locations of RGCs, as well as histograms of firing rates, pairwise correlation-coefficients and population spike-counts (<xref ref-type="fig" rid="pcbi.1005718.g002">Fig 2b</xref>).</p>
<fig id="pcbi.1005718.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005718.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Signatures of criticality in a simulation of retinal ganglion cell activity.</title>
<p><bold>a)</bold> Simulation schematic: Neurons have linear stimulus selectivity with centre-surround receptive fields and correlated Gaussian noise. <bold>b)</bold> Statistics of simulated population activity. Histograms of firing rates (left), correlation coefficients (centre) and frequency of population spike-counts (right). <bold>c)</bold> Estimation-error (normalised mean square error) in pairwise covariances as function of sample size, averaged across 10 populations of size <italic>n</italic> = 100. Rao-Blackwellization reduces the number of samples needed for a given level of accuracy by a factor ≈ 3. <bold>d)</bold> Quality of fit: Population models (here <italic>n</italic> = 100, example population) capture the mean firing rates (left), covariances (centre) and spike-counts (right). <bold>e)</bold> Divergence of specific heat: Average and individual traces for 10 randomly sampled populations for each of 6 different population sizes, exhibiting divergence of specific heat and peak in heat near unit temperature. Inset: Specific heat at unit temperature and at peak vs. population size. <bold>f)</bold> Specific heat for different temperatures and subsampled population sizes (here denoted by capital letter <italic>N</italic>) in recordings of salamander retinal ganglion cells responding to naturalistic stimuli, reproduced from [<xref ref-type="bibr" rid="pcbi.1005718.ref007">7</xref>].</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005718.g002" xlink:type="simple"/>
</fig>
<p>We subsampled populations of different sizes 20 ≤ <italic>n</italic> ≤ 120 by uniformly sampling cells from our simulated recording of total size <italic>N</italic> = 316 neurons. For each population we fit a ‘K-pairwise’ maximum entropy model [<xref ref-type="bibr" rid="pcbi.1005718.ref003">3</xref>]. This model assigns a probability <italic>P</italic>(<bold>x</bold>) to each spike-pattern <bold>x</bold>. It is an extension of pairwise maximum entropy models (i.e. Ising models) [<xref ref-type="bibr" rid="pcbi.1005718.ref013">13</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref014">14</xref>] which reproduce the firing rates and pairwise covariances, and has additional terms to capture population spike-counts [<xref ref-type="bibr" rid="pcbi.1005718.ref003">3</xref>] (see <xref ref-type="sec" rid="sec008">Materials</xref> for details of model specification and parameterisation). As we needed to efficiently fit this model [<xref ref-type="bibr" rid="pcbi.1005718.ref038">38</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref039">39</xref>] to multiple simulated data sets, we developed an improved fitting algorithm (see section 1 in <xref ref-type="supplementary-material" rid="pcbi.1005718.s001">S1 Supporting Information</xref>) based on maximum-likelihood techniques using Markov chain Monte Carlo (MCMC), building on work by [<xref ref-type="bibr" rid="pcbi.1005718.ref015">15</xref>]. In particular, we made the most computationally expensive component of the algorithm, the estimation of pairwise covariances via MCMC sampling, more efficient by using a ‘pairwise’ Gibbs-sampling scheme with Rao-Blackwellisation [<xref ref-type="bibr" rid="pcbi.1005718.ref040">40</xref>] (see section 1.1 in <xref ref-type="supplementary-material" rid="pcbi.1005718.s001">S1 Supporting Information</xref>). Most Gibbs-sampling approaches for maximum entropy models [<xref ref-type="bibr" rid="pcbi.1005718.ref015">15</xref>] update one neuron <italic>i</italic> at a time by re-sampling its state from the conditional distribution, given the state of the other <italic>n</italic> − 1 neurons in the population. We here in each iteration update a randomly chosen pair (<italic>i</italic>, <italic>j</italic>) simultaneously, given the state of the other <italic>n</italic> − 2 neurons. While each pairwise sample is more expensive to compute, this approach has the advantage of yielding a direct estimate of the (conditional) probability of <italic>i</italic> and <italic>j</italic> being active simultaneously. From these conditional probabilities, one can estimate pairwise covariances more efficiently than is possible through averaging samples, a process which is known as Rao-Blackwellization. Here, Rao-Blackwellization resulted in a reduction of the number of samples (and computation time) needed for achieving low-variance estimates of the covariances by a factor of approximately 3 (<xref ref-type="fig" rid="pcbi.1005718.g002">Fig 2c</xref>, Fig. A in <xref ref-type="supplementary-material" rid="pcbi.1005718.s001">S1 Supporting Information</xref>). After parameter fitting, the model reproduced the statistics of the simulated data (<xref ref-type="fig" rid="pcbi.1005718.g002">Fig 2d</xref>, Fig. B in <xref ref-type="supplementary-material" rid="pcbi.1005718.s001">S1 Supporting Information</xref>).</p>
<p>Following [<xref ref-type="bibr" rid="pcbi.1005718.ref007">7</xref>], we then introduced a temperature parameter which rescales the probabilities of the model,
<disp-formula id="pcbi.1005718.e001"><alternatives><graphic id="pcbi.1005718.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005718.e001" xlink:type="simple"/><mml:math display="block" id="M1"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>P</mml:mi> <mml:mi>T</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>∝</mml:mo> <mml:mi>P</mml:mi> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>/</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(1)</label></disp-formula>
where temperature <italic>T</italic> = 1 corresponds to the statistics of the empirical data. By changing <italic>T</italic> to other parameter values one can perturb the statistics of the system [<xref ref-type="bibr" rid="pcbi.1005718.ref041">41</xref>]: Increasing temperature leads to models with higher firing rates and weaker correlations (Fig. C in <xref ref-type="supplementary-material" rid="pcbi.1005718.s001">S1 Supporting Information</xref>), with <italic>P</italic><sub><italic>T</italic></sub>(<bold>x</bold>) approaching the uniform distribution for large <italic>T</italic>. If the temperature is decreased towards zero, <italic>P</italic><sub><italic>T</italic></sub>(<bold>x</bold>) has most of its probability mass over the most probable spike patterns. We compute the specific heat of a population directly from the probabilistic model fit to data [<xref ref-type="bibr" rid="pcbi.1005718.ref007">7</xref>], using
<disp-formula id="pcbi.1005718.e002"><alternatives><graphic id="pcbi.1005718.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005718.e002" xlink:type="simple"/><mml:math display="block" id="M2"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>c</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>T</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>n</mml:mi></mml:mfrac> <mml:mtext>Var</mml:mtext> <mml:mrow><mml:mo>[</mml:mo> <mml:mo form="prefix">log</mml:mo> <mml:msub><mml:mi>P</mml:mi> <mml:mi>T</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>X</mml:mi> <mml:mo>|</mml:mo> <mml:mo>λ</mml:mo> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(2)</label></disp-formula>
i.e. the variance of the log-probabilities of the model with parameters <italic>λ</italic>, normalised by <italic>n</italic>. While specific heat is typically motivated by thermodynamics, in this context it corresponds to a global statistical measure which provides a compact mathematical description of the collective statistical dynamics of the system. Just like the entropy corresponds to the (negative) average log-probability across all population states, the specific heat corresponds to the (normalized) variance of log-probabilities. Thus, specific heat is minimal for data in which all patterns <bold>x</bold> are equally probable, and big for data in which pattern-probabilities span a large range. We used MCMC-sampling to approximate the variance across all probabilities, and used this approach to calculate, for each population of size <italic>n</italic>, the specific heat as a function of temperature (Fig. D in <xref ref-type="supplementary-material" rid="pcbi.1005718.s001">S1 Supporting Information</xref>).</p>
<p>We found that the temperature curves obtained from the simulated data qualitatively reproduce the critical features of those that had been observed for large-scale recordings in the salamander [<xref ref-type="bibr" rid="pcbi.1005718.ref007">7</xref>] and rat [<xref ref-type="bibr" rid="pcbi.1005718.ref008">8</xref>] retina: The peak of the curves diverges as the population size <italic>n</italic> is increased, and moves closer to unit temperature for increasing <italic>n</italic> (<xref ref-type="fig" rid="pcbi.1005718.g002">Fig 2e</xref>). Consistent with experimental findings [<xref ref-type="bibr" rid="pcbi.1005718.ref042">42</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref007">7</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref008">8</xref>] (<xref ref-type="fig" rid="pcbi.1005718.g002">Fig 2f</xref>) and [<xref ref-type="bibr" rid="pcbi.1005718.ref028">28</xref>], we found that specific heat diverged linearly with population size. Finally, and also consistent with experimental studies, the peak specific heat is achieved for <italic>T</italic> &gt; 1, which is what has been interpreted as a ‘low-temperature’ state [<xref ref-type="bibr" rid="pcbi.1005718.ref018">18</xref>]. These results confirm that signatures of criticality arise in a simple feedforward LN cascade model based on generic properties of retinal ganglion cells, and do not require finely tuned parameters or sophisticated circuitry.</p>
</sec>
<sec id="sec004">
<title>A tractable mathematical model of the analysis process explains specific-heat curves and low-temperature states</title>
<p>In the phenomenological population model above, we observed that specific heat grew linearly with population size, as it did in previous studies built on experimental data [<xref ref-type="bibr" rid="pcbi.1005718.ref042">42</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref007">7</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref008">8</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref018">18</xref>]. Different ‘populations’ in these analyses are obtained by subsampling different populations from a large experimental recording, and that the parameters of each of these models are independently fit to each such population. How does this analysis process effect the rate of divergences of the specific heat, and the qualitative shape of specific heat curves? To answer these questions, we build a simple mathematical description of the analysis process: In the original papers, populations of different sizes are obtained by randomly subsampling a large recording (which is itself a sub-sample of the underlying circuit). As the simplest possible description of this sampling process, we assume that there is an underlying, infinitely large neural population, and that each population of size <italic>n</italic> is a random subsample. We assume that the underlying population is homogeneous, i.e. that all neurons have the same mean firing rate and pairwise correlations. As a consequence, K-pairwise maximum entropy models are fully specified by the distribution of population spike-count <italic>K</italic> = ∑<sub><italic>i</italic></sub> <italic>x</italic><sub><italic>i</italic></sub> [<xref ref-type="bibr" rid="pcbi.1005718.ref025">25</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref043">43</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref044">44</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref045">45</xref>] for each population of size <italic>n</italic>. We refer to models with this property as ‘flat models’ ([<xref ref-type="bibr" rid="pcbi.1005718.ref046">46</xref>] calls them ‘reduced’ maximum entropy models).</p>
<p>We introduce a new parametrised flat model in which the spike-count distribution is given by the beta-binomial distribution <italic>P</italic>(<italic>K</italic>|<italic>α</italic>, <italic>β</italic>, <italic>n</italic>), reducing the number of free parameters from <italic>n</italic> to 2. The beta-binomial model is a straightforward extension of an independent (i.e. binomial) population model: At each time-point, a new firing probability <italic>p</italic> is drawn from a beta-distribution with parameters <italic>α</italic> and <italic>β</italic>, and neurons then spike independently with probability <italic>p</italic>. Fluctuations in the latent variable <italic>p</italic> are shared across the population and lead to correlations in neural activity. Therefore, this model is a particular instance of a latent variable model. Signatures of criticality in latent variable models have been studied previously [<xref ref-type="bibr" rid="pcbi.1005718.ref026">26</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref027">27</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref028">28</xref>]. Our analytically-tractable model provides an explicit construction of how subsampling a large population determines the dependence of specific heat on population size.</p>
<p>Our beta-binomial model provided a good fit to the population spike-count distributions of the simulated data (<xref ref-type="fig" rid="pcbi.1005718.g003">Fig 3a</xref>) across different population sizes <italic>n</italic> (<xref ref-type="fig" rid="pcbi.1005718.g003">Fig 3b</xref>). Importantly, the best-fitting parameters <italic>α</italic> and <italic>β</italic> did not vary systematically across population sizes, and converged to values of <italic>α</italic> = 0.38 and <italic>β</italic> = 12.35 (Fig. E in <xref ref-type="supplementary-material" rid="pcbi.1005718.s001">S1 Supporting Informationa</xref>), corresponding to a probability of spiking of <italic>μ</italic> = 0.03 in each bin (i.e. each neuron has an average firing rate of <italic>μ</italic>/Δ = 1.5 Hz) and average pairwise correlations of <italic>ρ</italic> = 0.073. The beta-binomial model also provided good fits to published population spike-count distributions [<xref ref-type="bibr" rid="pcbi.1005718.ref043">43</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref045">45</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref008">8</xref>], as well as to those of retinal ganglion cell activity under different stimulus conditions in [<xref ref-type="bibr" rid="pcbi.1005718.ref018">18</xref>] (Fig. E in <xref ref-type="supplementary-material" rid="pcbi.1005718.s001">S1 Supporting Information</xref>). When we applied this flat model to populations subsampled from the RGC simulation, we could qualitatively reproduce the specific heat curves of the K-pairwise model (see also Fig. F in <xref ref-type="supplementary-material" rid="pcbi.1005718.s001">S1 Supporting Information</xref>). In particular, we found a linearly diverging peak that moved closer to <italic>T</italic> = 1 as the population size was increased (<xref ref-type="fig" rid="pcbi.1005718.g003">Fig 3c</xref>). Thus, linear divergence of specific heat is qualitatively captured by this model of how different populations are obtained by subsampling a large population.</p>
<fig id="pcbi.1005718.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005718.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Signatures of criticality and low-temperature states in a mathematically tractable model.</title>
<p><bold>a)</bold> Population spike-count distribution in RGC simulation, and approximation by models. Only the beta-binomial population model fits simulated data accurately, and for the full recording (<italic>N</italic> = 316) closely matches the shape of a beta distribution. <bold>b)</bold> Beta-binomial model fits for different population sizes. <bold>c)</bold> Specific heat traces for beta-binomial model, exhibiting signatures of criticality. Average and individual traces for 30 randomly sampled populations for each of 6 different population sizes. Inset: Specific heat at unit temperature and at peak vs. population size. <bold>d)</bold> Location of peak specific heat for independent model as function of firing rate. For <italic>μ</italic>/Δ = 4.16Hz (assuming Δ = 20ms bins), the peak is above unit temperature, a ‘low-temperature phase’. <bold>d)</bold> Location of peak specific heat as function of correlation, for <italic>n</italic> = 100 and three different firing rates. Peaks cross <italic>T</italic> = 1 only for firing rates ≥ 4.16Hz. <bold>e)</bold> ‘Low’ and ‘high’ temperature phases for beta-binomial model as function of firing rate and correlation strength and for population sizes (<italic>n</italic> = 20 to <italic>n</italic> = 120, colors as in <bold>b</bold>,<bold>c</bold>). Increasing correlations and population size expand the low-temperature regime beyond 4.16Hz. Data sets from previous studies had average firing rates well within low-temperature regime (arrows, colors as in Fig. E in <xref ref-type="supplementary-material" rid="pcbi.1005718.s001">S1 Supporting Information</xref>).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005718.g003" xlink:type="simple"/>
</fig>
<p>One of the difficulties of interpreting the scaling behaviour of maximum entropy models fit to neural data is the fact that the construction of the limit in <italic>n</italic> differs from those studied in statistical physics: In statistical physics, different ‘<italic>n</italic>’ typically correspond to systems of different total size, and the parameters are scaled as a deterministic function of <italic>n</italic> (e.g. drawn from a Gaussian with variance proportional to 1/<italic>n</italic> in spin-glasses [<xref ref-type="bibr" rid="pcbi.1005718.ref047">47</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref048">48</xref>]). In studies using maximum entropy models for neural data analysis, populations of different <italic>n</italic> are obtained by randomly subsampling a fixed large recording, and the parameters are fit to each subpopulation individually. Thus, there is no analytical relationship between population size and parameter values in this approach. With our model of the analysis process based on flat models, it is possible to analytically characterise the behaviour of the specific heat for large population sizes for this sampling process [<xref ref-type="bibr" rid="pcbi.1005718.ref025">25</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref044">44</xref>]. Using this approach, one can show (section 2.3 in <xref ref-type="supplementary-material" rid="pcbi.1005718.s001">S1 Supporting Information</xref> and [<xref ref-type="bibr" rid="pcbi.1005718.ref025">25</xref>] for details) that for virtually all flat models, the specific heat diverges linearly at unit temperature, but not for any other temperature <italic>T</italic> &gt; 1 or <italic>T</italic> &lt; 1 (section 2.4 in <xref ref-type="supplementary-material" rid="pcbi.1005718.s001">S1 Supporting Information</xref>). As a consequence, the peak must move to <italic>T</italic> = 1 as <italic>n</italic> is increased. Hence, almost any flat model analysed with the methods developed by [<xref ref-type="bibr" rid="pcbi.1005718.ref007">7</xref>] will exhibit signatures of criticality. In particular, these results hold also for models which are more weakly or more strongly correlated than real neural populations, and even for models with unrealistic population spike-count distributions (see Fig. G in <xref ref-type="supplementary-material" rid="pcbi.1005718.s001">S1 Supporting Information</xref> for an illustration). There are only two exceptions: The first one is a model in which all neurons are independent (i.e. a binomial population model), and the second one is a flat pairwise maximum entropy model—indeed, this is the only flat model with non-vanishing correlations for which the specific heat does not have its peak at unit temperature (see [<xref ref-type="bibr" rid="pcbi.1005718.ref025">25</xref>] for an illustration for the flat pairwise maximum entropy model).</p>
<p>Finally, it has been observed that the peak of the specific heat curve is consistently ‘to the right’ of <italic>T</italic> = 1, which was interpreted as the neural population activity in the retina being in a ‘low-temperature state’ [<xref ref-type="bibr" rid="pcbi.1005718.ref018">18</xref>]. Our analysis based on the flat model gives insights into this phenomenon: For correlation <italic>ρ</italic> = 0, the position of the peak can be calculated in closed form (<xref ref-type="fig" rid="pcbi.1005718.g003">Fig 3d</xref>). We observe that the peak will be at temperatures &gt;1 whenever the spike probability is smaller than <italic>μ</italic>* = 0.0832, which corresponds to a firing rate of <italic>μ</italic>*/Δ = 4.16Hz at a bin size of Δ = 20ms. Thus, in our model, the ‘temperature-state’ of a population can be reduced to a statement about the firing rate relative to the bin size used for analysis: For <italic>ρ</italic> &gt; 0 (<xref ref-type="fig" rid="pcbi.1005718.g003">Fig 3e</xref>) and for larger population sizes <italic>n</italic>, the firing rate at which the transition occurs are shifted to slightly higher firing rates, i.e. the ‘low-temperature’ regime is even bigger, and e.g. extends to firing rates up to 8.63Hz for average correlations of <italic>ρ</italic> = 0.25 and population size <italic>n</italic> = 120 (<xref ref-type="fig" rid="pcbi.1005718.g003">Fig 3f</xref>). While this dependence may be more complicated for full correlation structures, our analysis again connects global population measures from statistical mechanics to basic, directly measurable statistics of neural data: ‘being in a low-temperature state’ is a statement about the firing rates in the population being low.</p>
</sec>
<sec id="sec005">
<title>Strong neural correlations lead to fast divergence of specific heat</title>
<p>The rate at which the specific heat diverges provides a mean of quantifying the ‘strength’ of criticality. What is the relationship between correlations in a neural population and the rate of divergence? To study how the specific heat rate <inline-formula id="pcbi.1005718.e003"><alternatives><graphic id="pcbi.1005718.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005718.e003" xlink:type="simple"/><mml:math display="inline" id="M3"><mml:mrow><mml:mover accent="true"><mml:mi>c</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mi>c</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>T</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>/</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:math></alternatives></inline-formula> depends on the strength of correlations, we used a beta-binomial model to generate simulated data with firing rate <italic>μ</italic>/Δ = 1.5Hz (i.e. each neuron has a probability of spiking of <italic>μ</italic> = 0.03 per bin), and different pairwise correlation coefficient <italic>ρ</italic> ranging from <italic>ρ</italic> = 0.01 to <italic>ρ</italic> = 0.25 (<xref ref-type="fig" rid="pcbi.1005718.g004">Fig 4a</xref>). The heat curves had the same shape as in the analyses above, with a peak that increases and moves to unit temperature (<xref ref-type="fig" rid="pcbi.1005718.g004">Fig 4b</xref>). We found that the specific heat rates <inline-formula id="pcbi.1005718.e004"><alternatives><graphic id="pcbi.1005718.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005718.e004" xlink:type="simple"/><mml:math display="inline" id="M4"><mml:mover accent="true"><mml:mi>c</mml:mi> <mml:mo>˜</mml:mo></mml:mover></mml:math></alternatives></inline-formula> increased strictly monotonically with <italic>ρ</italic> (<xref ref-type="fig" rid="pcbi.1005718.g004">Fig 4b and 4c</xref>). For the beta-binomial model, the large-n value of <inline-formula id="pcbi.1005718.e005"><alternatives><graphic id="pcbi.1005718.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005718.e005" xlink:type="simple"/><mml:math display="inline" id="M5"><mml:mover accent="true"><mml:mi>c</mml:mi> <mml:mo>˜</mml:mo></mml:mover></mml:math></alternatives></inline-formula> can be calculated analytically (section 3.2 in <xref ref-type="supplementary-material" rid="pcbi.1005718.s001">S1 Supporting Information</xref> for details) as a function of the parameters <italic>α</italic> and <italic>β</italic>,
<disp-formula id="pcbi.1005718.e006"><alternatives><graphic id="pcbi.1005718.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005718.e006" xlink:type="simple"/><mml:math display="block" id="M6"><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mover accent="true"><mml:mi>c</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>α</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>ψ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>β</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>ψ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>β</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>+</mml:mo><mml:mi>β</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow/></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi>α</mml:mi><mml:mi>β</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>ψ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>ψ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>β</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>+</mml:mo><mml:mi>β</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:msub><mml:mi>ψ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(3)</label></disp-formula>
where <italic>ψ</italic><sub>0</sub>, <italic>ψ</italic><sub>1</sub> denote the di- and trigamma function, respectively. This analytical evaluation of <inline-formula id="pcbi.1005718.e007"><alternatives><graphic id="pcbi.1005718.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005718.e007" xlink:type="simple"/><mml:math display="inline" id="M7"><mml:mover accent="true"><mml:mi>c</mml:mi> <mml:mo>˜</mml:mo></mml:mover></mml:math></alternatives></inline-formula> (valid for large <italic>n</italic>) was in good agreement with numerical simulations (<xref ref-type="fig" rid="pcbi.1005718.g004">Fig 4c</xref> left). In the case of weak correlations <italic>ρ</italic>, <xref ref-type="disp-formula" rid="pcbi.1005718.e006">eq 3</xref> can be simplified: In this case, the specific heat rate is proportional to the strength of correlations (section 3.1 in <xref ref-type="supplementary-material" rid="pcbi.1005718.s001">S1 Supporting Information</xref> for details), i.e.
<disp-formula id="pcbi.1005718.e008"><alternatives><graphic id="pcbi.1005718.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005718.e008" xlink:type="simple"/><mml:math display="block" id="M8"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mover accent="true"><mml:mi>c</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mo>≈</mml:mo><mml:mi>ρ</mml:mi><mml:mspace width="1pt"/><mml:mi>μ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>μ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>log</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>μ</mml:mi></mml:mrow><mml:mi>μ</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></alternatives> <label>(4)</label></disp-formula>
and also increases strongly with firing rate for small <italic>μ</italic> (Fig. H in <xref ref-type="supplementary-material" rid="pcbi.1005718.s001">S1 Supporting Information</xref>). This expression can also be derived from the Gaussian model in [<xref ref-type="bibr" rid="pcbi.1005718.ref008">8</xref>] equation (4), by inserting the expected values of the mean and variance of the population spike-count under random subsampling. The monotonic relationship between correlations and specific heat is also consistent with the derivation in [<xref ref-type="bibr" rid="pcbi.1005718.ref027">27</xref>] for latent-variable models: inspection of equation (65) in [<xref ref-type="bibr" rid="pcbi.1005718.ref027">27</xref>] shows that the specific heat is related to a sum of conditional entropies– for binary random variables, these entropies are monotonically related to covariances, which effectively shows that, in their model, specific heat also increases with correlations.</p>
<fig id="pcbi.1005718.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005718.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Relationship between correlations and criticality.</title>
<p><bold>a)</bold> Specific heat traces for beta-binomial model, different correlation strengths and population sizes. Heat traces are qualitatively similar, but differ markedly quantitatively (see y-axes). <bold>b)</bold> Specific heat diverges linearly, and the slope depends on the strength of correlations. <bold>c)</bold> Divergence rate of specific heat for beta-binomial model as a function of correlation strength (left). Rightmost point (at infinity) corresponds to analytical prediction of large-<italic>n</italic> behaviour. Divergence rates are strictly increasing with correlation strength (right) which is captured by a weak-correlation approximation (dashed line). <bold>d)</bold> Specific heat increases with correlation in the K-pairwise maximum entropy model: average and individual traces for 10 randomly subsampled populations for 6 different population sizes. Left to right: checkerboard, natural images and full-field flicker stimuli presented to the population. Correlation strengths denote mean correlation coefficient in each population.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005718.g004" xlink:type="simple"/>
</fig>
<p>We found that the relationship between the strength of correlations and the ‘strength’ of criticality (i.e. the divergence rate of specific heat) also held in simulations of feedforward models of retinal population activity. In the original study [<xref ref-type="bibr" rid="pcbi.1005718.ref007">7</xref>], specific heat was computed from K-pairwise model fits to RGC activity resulting from three different kind of stimuli: random checkerboard stimuli (which do not have long-range spatial correlations, although stimulus-driven cross-neural correlations can arise from receptive field overlap), natural stimuli, which exhibit strong spatial correlations, and full-field flicker (which constitutes an extreme case of spatial correlations since all pixels in the display are identical). It was found that specific heat diverges in all three conditions (consistent with a more recent study [<xref ref-type="bibr" rid="pcbi.1005718.ref018">18</xref>]), and interpreted this as evidence that signatures of criticality are not ‘inherited from the stimulus’ [<xref ref-type="bibr" rid="pcbi.1005718.ref007">7</xref>]. When we simulated responses to different stimuli we found the divergence rates of the specific heat to follow the pattern of induced correlation strength, consistent with the monotonic relationship between correlation strength and specific heat growth rate shown above for the flat models (<xref ref-type="fig" rid="pcbi.1005718.g004">Fig 4d</xref>): For populations size <italic>n</italic> = 100, checkerboard/natural/full-field flicker stimulation lead to average correlation strengths of <italic>ρ</italic> = 0.033/0.075/0.341, respectively, and to specific heat growth rates of <inline-formula id="pcbi.1005718.e009"><alternatives><graphic id="pcbi.1005718.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005718.e009" xlink:type="simple"/><mml:math display="inline" id="M9"><mml:mrow><mml:mover accent="true"><mml:mi>c</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>0029</mml:mn><mml:mo>/</mml:mo><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>0046</mml:mn><mml:mo>/</mml:mo><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>0104</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>.</p>
<p>Tkačik et al. had found the lowest peak in divergence rate for checkerboard (max <italic>c</italic> ≈ 0.54), higher peak-divergence rates for natural movies (max <italic>c</italic> ≈ 0.92) and the highest peak for full-field flicker (max <italic>c</italic> ≈ 2.4, all results for <italic>n</italic> = 100). Thus, the ordering of the peak values of specific heat in their study is consistent with our results. However, when comparing the values at <italic>T</italic> = 1, they found a slightly higher divergence rate for natural movies (<inline-formula id="pcbi.1005718.e010"><alternatives><graphic id="pcbi.1005718.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005718.e010" xlink:type="simple"/><mml:math display="inline" id="M10"><mml:mrow><mml:mover accent="true"><mml:mi>c</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mo>≈</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>005</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>) than for full-field flicker (<inline-formula id="pcbi.1005718.e011"><alternatives><graphic id="pcbi.1005718.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005718.e011" xlink:type="simple"/><mml:math display="inline" id="M11"><mml:mrow><mml:mover accent="true"><mml:mi>c</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mo>≈</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>004</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>). This mismatch could result from adaptation or temporal dynamics of the stimulus affecting firing rates or correlations in their data [<xref ref-type="bibr" rid="pcbi.1005718.ref020">20</xref>], or from our simulations not precisely matching the statistics of their experimental data.</p>
<p>These statements also qualitatively hold in a modified temperature analysis [<xref ref-type="bibr" rid="pcbi.1005718.ref007">7</xref>] in which firing rates are kept constant (at the firing rates of <italic>T</italic> = 1) when temperature is varied (section 3.4 in <xref ref-type="supplementary-material" rid="pcbi.1005718.s001">S1 Supporting Information</xref> and in Fig. I in <xref ref-type="supplementary-material" rid="pcbi.1005718.s001">S1 Supporting Information</xref>). We conclude that the experimental evidence—which showed that the specific heat diverges, and how the speed of divergences depends on the stimulus ensemble—is largely consistent with a simple, feedforward phenomenological model of retinal processing. Thus, at least for flat models, ‘being very critical’ is a consequence of ‘being strongly correlated’, and not evidence for correlations being fine-tuned or self-organized to a particular value.</p>
</sec>
<sec id="sec006">
<title>Random subsampling gives rise to criticality-inducing correlations</title>
<p>In the above, we showed that a beta-binomial spike-count distribution can be sufficient for signatures of criticality to arise. For this to hold we need the variance of the population spike-count to grow quadratically with population size, i.e. Var(<italic>K</italic>) ∝ <italic>n</italic><sup>2</sup>. The variance of the population spike-count is equal to the sum of all variances and covariances in the population, <inline-formula id="pcbi.1005718.e012"><alternatives><graphic id="pcbi.1005718.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005718.e012" xlink:type="simple"/><mml:math display="inline" id="M12"><mml:mrow><mml:mtext>Var</mml:mtext> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>K</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msubsup><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>n</mml:mi></mml:msubsup> <mml:mtext>Var</mml:mtext> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msub><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>≠</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mtext>Cov</mml:mtext> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>. A sufficient condition for signatures of criticality to arise in these models is that the average covariances (and hence correlations) between neurons are independent of <italic>n</italic>, <inline-formula id="pcbi.1005718.e013"><alternatives><graphic id="pcbi.1005718.e013g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005718.e013" xlink:type="simple"/><mml:math display="inline" id="M13"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mi>n</mml:mi> <mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:mfrac> <mml:msub><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>≠</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mtext>Cov</mml:mtext> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≈</mml:mo> <mml:mtext>constant</mml:mtext></mml:mrow></mml:math></alternatives></inline-formula> [<xref ref-type="bibr" rid="pcbi.1005718.ref027">27</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref006">6</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref005">5</xref>]. We refer to correlations with this property as ‘criticality inducing’. One possible criticality-inducing correlation structure are so called ‘infinite range’ correlations: correlation between neurons do not drop off to zero for large spatial distances. In the extreme case of distance-independent correlations (<xref ref-type="fig" rid="pcbi.1005718.g005">Fig 5a</xref>), adding more and more neurons to a population will not change the average pairwise correlation within the population (<xref ref-type="fig" rid="pcbi.1005718.g005">Fig 5b</xref>). We note that infinite-range correlations are typically not present in the thermodynamic limit in physical systems at equilibrium. In neural systems, infinite-range correlations could be a consequence of densely connected circuitry, or of a shared stimulus drive.</p>
<fig id="pcbi.1005718.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005718.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Random subsampling leads to criticality-inducing correlations.</title>
<p><bold>a)</bold> Illustration: A population with 100 neurons and infinite-range correlations, the average correlation between any pair of neurons is close to 0.05. Correlation as function of inter-neuron distance (left) and full correlation matrix (right). <bold>b)</bold> Average correlation in subpopulation of different size <italic>n</italic> (left) and specific heat at <italic>T</italic> = 1 as function of <italic>n</italic> (right), when neurons are sampled from 1 to 100 (blue). Random sampling gives identical results (gray). <bold>c)</bold> Population with limited-range correlations, same plots as in panel a. <bold>d)</bold> Left: Average correlation as function of population size for spatially structured sampling (green) and uniform subsampling (gray). Right: Specific heat at <italic>T</italic> = 1 grows linearly for random subsampling, but shows signs of saturation for spatially structured sampling. <bold>e)</bold> Average correlation as function of inter-neuron distance in RGC simulation. For checkerboard and natural images, correlations drop to 0 for large distances. <bold>f)</bold> Specific heat at <italic>T</italic> = 1 for different stimulation conditions, for spatially structured (colour) or random subsampling (gray).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005718.g005" xlink:type="simple"/>
</fig>
<p>Importantly, criticality-inducing correlations can also result as a consequence of subsampling a large neural population: Even a neural population which does not have infinite-range correlations can appear critical if it is randomly subsampled during analysis. If different populations of size <italic>n</italic> are obtained as above by (uniformly) subsampling a large recording of size <italic>N</italic>, then the pairwise correlations in each subpopulation are also a random subsample of the large correlation matrix of the full recording. For any correlation structure on the full recording (including limited-range correlations, <xref ref-type="fig" rid="pcbi.1005718.g005">Fig 5c</xref>), the expected average correlation in a population of size <italic>n</italic> is identical to the average correlation in the full recording and hence independent of <italic>n</italic> (<xref ref-type="fig" rid="pcbi.1005718.g005">Fig 5d</xref> left, grey line). Despite the pairwise correlations being subsampled in blocks of principal submatrices rather than independently, the variance of the average correlation can drop with the square of the population size <italic>n</italic>, and is guaranteed to fall at least as 1/<italic>n</italic> (section 4.1 in <xref ref-type="supplementary-material" rid="pcbi.1005718.s001">S1 Supporting Information</xref>, and Fig. J in <xref ref-type="supplementary-material" rid="pcbi.1005718.s001">S1 Supporting Information</xref>). Because the average correlation will be independent of <italic>n</italic> and have negligible variance (<xref ref-type="fig" rid="pcbi.1005718.g005">Fig 5d</xref> left, shaded area), specific heat will diverge with constant slope (<xref ref-type="fig" rid="pcbi.1005718.g005">Fig 5d</xref> right). In contrast, if different population sizes are constructed by taking into account the spatial structure of the population (i.e. by iteratively adding neighbouring cells) then the average correlation in each subpopulation will drop with <italic>n</italic>, and the slope of specific heat growth will decrease with population size.</p>
<p>In our RGC simulation, pairwise correlations did drop off to zero with spatial distance for checkerboard and natural images, but not for full-field flicker (<xref ref-type="fig" rid="pcbi.1005718.g005">Fig 5e</xref>). Pairwise correlations in the full-field flicker condition initially drop off due to distance-dependent shared noise, but eventually saturate at a level far above zero that is determined by the full-field stimulus. Due to these strong infinite-range correlations, both spatially structured sampling and uniform sampling then give rise to linear growth in specific heat (<xref ref-type="fig" rid="pcbi.1005718.g005">Fig 5f</xref> left). For the other two stimulus conditions, however, the choice of subsampling scheme does result in markedly different behavior of the specific heat growth: Both for natural images and checkerboard stimuli, we can see the rate of growth decreases for large <italic>n</italic> under spatially structured subsampling (<xref ref-type="fig" rid="pcbi.1005718.g005">Fig 5f</xref> centre and right). This effect will be more pronounced for larger simulations, and in additional simulations we found specific heat to saturate once populations are substantially bigger than the spatial range of correlations. This behavior is not unique to the simplified flat models. Specific heat traces computed from K-pairwise models fit to populations obtained with spatially structured sampling also show a marked decrease in specific heat growth rates (section 4.2 in <xref ref-type="supplementary-material" rid="pcbi.1005718.s001">S1 Supporting Information</xref> and Fig. K in <xref ref-type="supplementary-material" rid="pcbi.1005718.s001">S1 Supporting Information</xref>).</p>
<p>In summary, populations will exhibit critical behaviour if correlations have infinite range (over the size of the recording), irrespective of the sampling scheme. In addition, if a population is randomly subsampled (as was done in [<xref ref-type="bibr" rid="pcbi.1005718.ref007">7</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref008">8</xref>]), then signatures of criticality will arise even if the underlying correlations have limited range.</p>
</sec>
</sec>
<sec id="sec007" sec-type="conclusions">
<title>Discussion</title>
<p>An intriguing hypothesis about the collective activity of large neural populations has been the idea that their statistics resemble those of physical systems at a critical point. In recent years, several studies [<xref ref-type="bibr" rid="pcbi.1005718.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref005">5</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref006">6</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref011">11</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref007">7</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref008">8</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref018">18</xref>] proposed a new approach to studying criticality in biological data, motivated by notions of criticality in thermodynamics. Signatures of criticality have also been observed in natural images [<xref ref-type="bibr" rid="pcbi.1005718.ref011">11</xref>] and cortical populations [<xref ref-type="bibr" rid="pcbi.1005718.ref006">6</xref>], and have been studied using the theory of finite-size scaling and critical exponents [<xref ref-type="bibr" rid="pcbi.1005718.ref006">6</xref>]. It has been argued that systems close to a critical point might be optimally sensitive to external perturbations [<xref ref-type="bibr" rid="pcbi.1005718.ref006">6</xref>] and that the large dynamic range of the code (i.e. large variance of log-probabilities) might be beneficial for encoding sensory events which likewise have a large distribution of occurrence probabilities [<xref ref-type="bibr" rid="pcbi.1005718.ref016">16</xref>].</p>
<p>This hypothesis that neural systems are poised at a thermodynamic critical point could open up further questions on how the system maintains its critical state and on implications for how neural populations encode sensory information and perform computations on it. Alternatively, generic mechanisms could be sufficient to give rise to data which satisfies the definition of criticality put forward in these studies. We had demonstrated in a previous theoretical study [<xref ref-type="bibr" rid="pcbi.1005718.ref025">25</xref>] that simple models with Gaussian common input can exhibit a diverging specific heat. More recently, it was shown [<xref ref-type="bibr" rid="pcbi.1005718.ref026">26</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref027">27</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref028">28</xref>] that common input (or other latent variables which lead to shared modulations in firing rates, such as non-stationarity [<xref ref-type="bibr" rid="pcbi.1005718.ref029">29</xref>]) can give rise to Zipf-like scaling of pattern probabilities, a second signature of criticality. Mathematically, Zipf’s Law is equivalent to stating that the plot of entropy vs energy (i.e. log-probability) is a straight line with unit slope [<xref ref-type="bibr" rid="pcbi.1005718.ref026">26</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref027">27</xref>]. Schwab et al [<xref ref-type="bibr" rid="pcbi.1005718.ref026">26</xref>] showed that particular latent variable models give rise to Zipf’s law. This result was generalized [<xref ref-type="bibr" rid="pcbi.1005718.ref027">27</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref028">28</xref>] to show that, under fairly general circumstances, high-dimensional latent variable models exhibit a wide distribution of energies (i.e. log-probabilities) and hence a large specific heat. It has also been argued that the use of data sets which are too small might give rise to spuriously big specific heats [<xref ref-type="bibr" rid="pcbi.1005718.ref049">49</xref>]: while this could be true in principle, additional analyses e.g. in [<xref ref-type="bibr" rid="pcbi.1005718.ref007">7</xref>] show that their results are robust with respect to data set size, and our results are also valid even in the case of infinite data. Finally, it has also been suggested that whether statistical models exhibit criticality depends on which variables are measured and constrained by the model fit [<xref ref-type="bibr" rid="pcbi.1005718.ref050">50</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref051">51</xref>].</p>
<p>Previously, criticality in neural systems has also been investigated extensively using a definition of criticality which is based on temporal dynamics with power-law statistics, so-called ‘avalanches’ [<xref ref-type="bibr" rid="pcbi.1005718.ref052">52</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref005">5</xref>]. Numerous studies have reported and studied ‘avalanche criticality’ [<xref ref-type="bibr" rid="pcbi.1005718.ref008">8</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref021">21</xref>], proposed possible mechanisms (e.g. based on self-organization [<xref ref-type="bibr" rid="pcbi.1005718.ref053">53</xref>]), and discussed finite-size effects and sub-sampling [<xref ref-type="bibr" rid="pcbi.1005718.ref054">54</xref>], as well as a need for rigorous statistical analysis [<xref ref-type="bibr" rid="pcbi.1005718.ref055">55</xref>]. We emphasize that the ‘avalanche’ definition of criticality is not equivalent to the thermodynamics-inspired definition used in these more recent studies [<xref ref-type="bibr" rid="pcbi.1005718.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref008">8</xref>]. Our study is only concerned with this more recent approach, and our results thus have no bearing on studies of ‘avalanche-criticality’.</p>
<p>We here related signatures of criticality to the structure of firing rates and correlations in the population: We found that average correlations which are independent of population size are sufficient for inducing criticality, irrespective of their origin. In the thermodynamic analysis of physical systems at equilibrium, long-range correlations typically vanish in the thermodynamic limit. In neural systems, however, ‘criticality-inducing’ correlations can arise as a consequence of various factors: First, in a local patch of retina, retinal ganglion cells have a large degree of receptive field overlap, and natural stimuli also contain strong spatial correlations. This can lead to correlations which do have unlimited range within the experimentally accessible length scales. Thus, fluctuations in the stimulus will lead to common activity modulations amongst neurons within the population. Empirically, correlations between pairs of retinal ganglion cells only fall off slowly with the distance between somata (or receptive field centres) [<xref ref-type="bibr" rid="pcbi.1005718.ref035">35</xref>]. Second, firing rates e.g. of cortical neurons are modulated by global fluctuations in excitability [<xref ref-type="bibr" rid="pcbi.1005718.ref045">45</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref056">56</xref>], resulting in neural correlations with infinite range. Third, and importantly, we showed that criticality-inducing correlations can also arise as a consequence of data analysis choices: Uniformly subsampling a large recording with correlations to construct subpopulations yields criticality-inducing correlations, even if the correlations itself do not have unlimited range.</p>
<p>We also showed that there is a direct relationship between ‘how critical’ and ‘how correlated’ a population is: The stronger correlations are, the more prominent the divergence in specific heat is. Mechanisms underlying correlations in spiking activity have been extensively studied in neuroscience [<xref ref-type="bibr" rid="pcbi.1005718.ref030">30</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref031">31</xref>], and our study makes it possible to relate ‘signatures of criticality’ derived from thermodynamics to these studies, and to interpret the significance of observing these effects: Given the ubiquity of criticality-inducing correlations, signatures of criticality are likely going to be found not just in retinal ganglion cells, but in multiple brain areas and model systems. They are entirely consistent with canonical properties of neural population activity, and require neither finely-tuned parameters in the population, nor sophisticated circuitry or active mechanisms for keeping the system at the critical point. The relationship between firing rates, correlations and criticality (eqs <xref ref-type="disp-formula" rid="pcbi.1005718.e006">3</xref> and <xref ref-type="disp-formula" rid="pcbi.1005718.e008">4</xref>) also yields a prediction about how adaptation in a classical sense should modulate signatures of criticality: The height of the peak is monotonically related to both correlation strength and firing rate. Adaptation typically reduces firing rates and correlations [<xref ref-type="bibr" rid="pcbi.1005718.ref057">57</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref058">58</xref>]. Taken together, this leads to the prediction that adaptation should <italic>reduce</italic> signatures of criticality– this is precisely the opposite of what has been predicted in [<xref ref-type="bibr" rid="pcbi.1005718.ref007">7</xref>]. Finally, the dependence of specific heat on correlations might also be an explanation of why Ioffe and Berry [<xref ref-type="bibr" rid="pcbi.1005718.ref018">18</xref>] found that a feedforward model fit to their retinal data (which had lower correlations) underestimated the specific heat.</p>
<p>In summary, we conclude that current attempts to interpret findings of thermodynamic criticality in neural population activity have limited potential to lead to new insights into theories of neural computation– in particular, they are not able to discriminate between different hypotheses about either the origin or the functional consequence of the statistics of neural activity. A reliable interpretation of any test for criticality is possible only in reference to a-priori knowledge about the outcome of the test on relevant ground truth models. In order to realise the potential of large-scale recordings of neural activity in the search of a theory of neural computation, we will need data analysis methods which are adapted to the specific properties of biological data, and in particular the fact that neural activity is highly subsampled [<xref ref-type="bibr" rid="pcbi.1005718.ref059">59</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref060">60</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref054">54</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref061">61</xref>]. One approach to dealing with subsampled data is to use latent-variable models which explicitly model the effect of unobserved inputs and states [<xref ref-type="bibr" rid="pcbi.1005718.ref062">62</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref063">63</xref>]. In addition, we will also require hypotheses about the normative principles which govern their computations. A possible link between neural activity and theories of criticality might emerge from recent work in machine learning, which is starting to study links between the information-processing capabilities of artificial neural networks and critical phenomena [<xref ref-type="bibr" rid="pcbi.1005718.ref064">64</xref>].</p>
</sec>
<sec id="sec008" sec-type="materials|methods">
<title>Materials and methods</title>
<sec id="sec009">
<title>Retina simulation</title>
<p>We simulated a population of <italic>N</italic> = 316 retinal ganglion cells as linear threshold neurons whose receptive fields were modelled by difference-of-Gaussian filters with ON-centres [<xref ref-type="bibr" rid="pcbi.1005718.ref037">37</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref035">35</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref033">33</xref>]. The simulation comprised two subgroups of cells with different receptive field sizes (surrounds 56μm and 30μm in retinal space, centres 28μm and 15μm, respectively, one third cells with large receptive fields). For both subgroups, the weight of the surround was 0.5 of the centre weight. Locations of receptive field centres (<xref ref-type="fig" rid="pcbi.1005718.g001">Fig 1</xref> left panel) were based on a reconstruction of 518 soma locations from a patch of mouse retina [<xref ref-type="bibr" rid="pcbi.1005718.ref065">65</xref>]. As the reconstructed locations in that data set also comprised about 40% amacrine cell somata, we randomly discarded 40% of the cell locations. The resulting patch of retina covered an area of 200 × 300μm<sup>2</sup>, corresponding to 100 × 150 pixels in stimulus space. Correlated noise across neurons was modelled using correlated additive Gaussian noise. Correlations dropped off exponentially with soma distance with a decay constant of <italic>τ</italic> = 30μm i.e. noise covariance matrix was chosen as <inline-formula id="pcbi.1005718.e014"><alternatives><graphic id="pcbi.1005718.e014g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005718.e014" xlink:type="simple"/><mml:math display="inline" id="M14"><mml:mrow><mml:mo>Σ</mml:mo> <mml:mo>=</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi>n</mml:mi> <mml:mi>o</mml:mi> <mml:mi>i</mml:mi> <mml:mi>s</mml:mi> <mml:mi>e</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>a</mml:mi> <mml:msub><mml:mi>I</mml:mi> <mml:mi>n</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:mi>b</mml:mi> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>D</mml:mi> <mml:mo>/</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msup> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, where <italic>D</italic><sub><italic>ij</italic></sub> is the distance between neurons <italic>i</italic> and <italic>j</italic> and <italic>a</italic><sup>2</sup> + <italic>b</italic><sup>2</sup> = 1. We set <italic>σ</italic><sub><italic>noise</italic></sub> = 0.022 and <italic>a</italic> = 0.45. We modelled neural spiking in discrete time using 20ms bins. In each bin <italic>t</italic>, the total input <italic>z</italic><sub><italic>i</italic></sub>(<italic>t</italic>) to neuron <italic>i</italic> was given by <inline-formula id="pcbi.1005718.e015"><alternatives><graphic id="pcbi.1005718.e015g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005718.e015" xlink:type="simple"/><mml:math display="inline" id="M15"><mml:mrow><mml:msub><mml:mi>z</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msubsup><mml:mi>w</mml:mi> <mml:mi>i</mml:mi> <mml:mi>⊤</mml:mi></mml:msubsup> <mml:mi>s</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msub><mml:mi>ϵ</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, where <italic>w</italic><sub><italic>i</italic></sub> is the receptive field of neuron <italic>i</italic>, <italic>s</italic>(<italic>t</italic>) the vectorised stimulus and <italic>ϵ</italic><sub><italic>i</italic></sub>(<italic>t</italic>) the input noise of neuron <italic>i</italic>. A neuron in a given bin is active (<italic>x</italic><sub><italic>i</italic></sub> = 1) if <italic>z</italic><sub><italic>i</italic></sub> + <italic>d</italic> &gt; 0.5 and inactive (<italic>x</italic><sub><italic>i</italic></sub> = 0) otherwise, with offset <italic>d</italic> = 0.168 [<xref ref-type="bibr" rid="pcbi.1005718.ref066">66</xref>]. Parameters of the simulation (centre and surround sizes, relative strength of centre and surround, magnitude and correlations of noise, spiking threshold) were chosen to roughly match the statistics of neural spiking (firing rates, pairwise correlations, population activity counts) reported in studies of salamander retinal ganglion cells [<xref ref-type="bibr" rid="pcbi.1005718.ref013">13</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref003">3</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref002">2</xref>].</p>
</sec>
<sec id="sec010">
<title>Stimuli</title>
<p>We used three types of stimuli for this study: natural images, checkerboard patterns and full-field flicker. For natural image stimuli, we used a sequence of 101 images of foliages. Each image was 400 × 400 pixels, and each image was presented for 20ms with 300 repetitions total. The luminance histograms of the images were transformed to a normal distribution with mean 0.5 and pixel values between 0 and 1.</p>
<p>For the full-field flicker stimulus, luminance levels were drawn from a Gaussian distribution with mean <italic>μ</italic> = 0.5 and variance <italic>σ</italic><sup>2</sup> = 0.06. Checkerboard stimuli consisted of 80 × 80 tiles of size 5 × 5 pixels each. Luminance levels (from within the interval [0, 1]) of each tile were chosen to be either 0.15 or 0.77 with probability 0.5. The parameters of both stimulus sets were chosen to match the dynamic range of the simulated retinal ganglion cells. For both types of stimuli, 2000 images were generated and the image sequences were presented with 10 repetitions. To calculate specific heat as function of increasing population size, we randomly selected 10 subsamples of the full simulated population of <italic>N</italic> = 316 cells at population sizes <italic>n</italic> ∈ {20, 40, 60, 80, 100, 120} by uniformly drawing <italic>n</italic> neurons out of the full population without replacement.</p>
</sec>
<sec id="sec011">
<title>Statistical model</title>
<p>We modelled retinal ganglion cell activity by using a ‘K-pairwise’ maximum entropy model [<xref ref-type="bibr" rid="pcbi.1005718.ref003">3</xref>]. In a maximum entropy model [<xref ref-type="bibr" rid="pcbi.1005718.ref067">67</xref>], the probability of observing the binary spike word <bold>x</bold> ∈ {0, 1}<sup><italic>n</italic></sup> for parameters <italic>λ</italic> = {<italic>h</italic>, <italic>J</italic>, <italic>V</italic>} is given by
<disp-formula id="pcbi.1005718.e016"><alternatives><graphic id="pcbi.1005718.e016g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005718.e016" xlink:type="simple"/><mml:math display="block" id="M16"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>P</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>|</mml:mo> <mml:mo>λ</mml:mo> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mi>Z</mml:mi> <mml:mo>(</mml:mo> <mml:mo>λ</mml:mo> <mml:mo>)</mml:mo></mml:mrow></mml:mfrac> <mml:mo form="prefix">exp</mml:mo> <mml:mo>(</mml:mo> <mml:msup><mml:mi>h</mml:mi> <mml:mi>⊤</mml:mi></mml:msup> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>+</mml:mo> <mml:msup><mml:mi mathvariant="bold">x</mml:mi> <mml:mi>⊤</mml:mi></mml:msup> <mml:mi>J</mml:mi> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>+</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn></mml:mrow> <mml:mi>n</mml:mi></mml:munderover> <mml:msub><mml:mi>V</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mi>δ</mml:mi> <mml:mo>(</mml:mo> <mml:mi>K</mml:mi> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(5)</label></disp-formula>
Here, the parameter vector <italic>h</italic> (of size <italic>n</italic> × 1) and the upper-triangular matrix <inline-formula id="pcbi.1005718.e017"><alternatives><graphic id="pcbi.1005718.e017g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005718.e017" xlink:type="simple"/><mml:math display="inline" id="M17"><mml:mrow><mml:mi>J</mml:mi> <mml:mo>∈</mml:mo> <mml:msup><mml:mi mathvariant="double-struck">R</mml:mi> <mml:mrow><mml:mi>n</mml:mi> <mml:mo>×</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> correspond to the bias terms and interaction terms in a pairwise maximum entropy model (also known as an Ising model or spin-glass) [<xref ref-type="bibr" rid="pcbi.1005718.ref013">13</xref>]. The term <inline-formula id="pcbi.1005718.e018"><alternatives><graphic id="pcbi.1005718.e018g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005718.e018" xlink:type="simple"/><mml:math display="inline" id="M18"><mml:mrow><mml:mi>K</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msubsup><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>n</mml:mi></mml:msubsup> <mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> denotes the population spike-count, i.e. the total number of spikes across the population within a single time bin, and the indicator-term <italic>δ</italic>(<italic>K</italic> = <italic>k</italic>) is 1 whenever the population spike-count equals <italic>k</italic>, and is 0 otherwise. The term <inline-formula id="pcbi.1005718.e019"><alternatives><graphic id="pcbi.1005718.e019g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005718.e019" xlink:type="simple"/><mml:math display="inline" id="M19"><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn></mml:mrow> <mml:mi>n</mml:mi></mml:msubsup> <mml:msub><mml:mi>V</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mi>δ</mml:mi> <mml:mo>(</mml:mo> <mml:mi>K</mml:mi> <mml:mo>=</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> was introduced [<xref ref-type="bibr" rid="pcbi.1005718.ref003">3</xref>] to ensure that the model precisely captures the population spike-count distribution of the data using <italic>n</italic> additional free parameters. The partition function <italic>Z</italic>(λ) is chosen such that the probabilities of the model sum to 1.</p>
</sec>
<sec id="sec012">
<title>Parameter fitting</title>
<p>To fit the model parameters λ = {<italic>h</italic>, <italic>J</italic>, <italic>V</italic>} to a data set, we maximised the penalised log-likelihood [<xref ref-type="bibr" rid="pcbi.1005718.ref068">68</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref069">69</xref>] of the data <inline-formula id="pcbi.1005718.e020"><alternatives><graphic id="pcbi.1005718.e020g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005718.e020" xlink:type="simple"/><mml:math display="inline" id="M20"><mml:mrow><mml:mi mathvariant="script">D</mml:mi> <mml:mo>=</mml:mo> <mml:mo>{</mml:mo> <mml:msup><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:msup><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>2</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:mo>…</mml:mo> <mml:mo>,</mml:mo> <mml:msup><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>M</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mo>}</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> under the model,
<disp-formula id="pcbi.1005718.e021"><alternatives><graphic id="pcbi.1005718.e021g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005718.e021" xlink:type="simple"/><mml:math display="block" id="M21"><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>J</mml:mi><mml:mo>,</mml:mo><mml:mi>V</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>:</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:munderover></mml:mstyle><mml:mtext>log</mml:mtext><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>x</mml:mi></mml:mstyle><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>m</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>|</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>J</mml:mi><mml:mo>,</mml:mo><mml:mi>V</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow/></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>h</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>‖</mml:mo><mml:mi>h</mml:mi><mml:msub><mml:mo>‖</mml:mo><mml:mn>1</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>J</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>‖</mml:mo><mml:mi>J</mml:mi><mml:msub><mml:mo>‖</mml:mo><mml:mn>1</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msup><mml:mi>V</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:msup><mml:mo>Σ</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi>V</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(6)</label></disp-formula>
Here, the <italic>l</italic>1-penalty controlled the magnitudes of parameters <italic>h</italic>, <italic>J</italic>, the term ‖<italic>J</italic>‖<sub>1</sub> favoured sparse coupling matrices, and the regularisation term <italic>Σ</italic> on the <italic>V</italic>-parameters ensures that the terms controlling the spike-count distribution vary smoothly in <italic>k</italic> (section 1 in <xref ref-type="supplementary-material" rid="pcbi.1005718.s001">S1 Supporting Information</xref>). This smoothness prior is particularly important for large spike counts, as it makes it possible to interpolate parameters for which the number of observed counts is small.</p>
<p>In maximum entropy models, exact evaluation of the penalised log-likelihood and its gradients requires the calculation of expectations under the model, E[<italic>x</italic><sub><italic>i</italic></sub>], E[<italic>x</italic><sub><italic>i</italic></sub> <italic>x</italic><sub><italic>j</italic></sub>] or equivalently <italic>cov</italic>(<italic>x</italic><sub><italic>i</italic></sub>, <italic>x</italic><sub><italic>j</italic></sub>), and <italic>P</italic>(<italic>K</italic> = <italic>k</italic>) (section 1.1 in <xref ref-type="supplementary-material" rid="pcbi.1005718.s001">S1 Supporting Information</xref>), which in turn requires summations over all 2<sup>n</sup> possible states <bold>x</bold> and is prohibitive for <italic>n</italic> &gt; 20. Following previous work [<xref ref-type="bibr" rid="pcbi.1005718.ref015">15</xref>], we used Gibbs sampling to approximate the relevant expectations (section 1.1 in <xref ref-type="supplementary-material" rid="pcbi.1005718.s001">S1 Supporting Information</xref> for derivations and implementation details). We used two modifications over previous applications of Gibbs sampling to fitting maximum entropy models to neural population spike train data, with the goals of speeding up parameter learning and alleviating memory usage:</p>
<p>First, we use Rao-Blackwellisation [<xref ref-type="bibr" rid="pcbi.1005718.ref040">40</xref>] to speed up convergence of the estimation of covariances of <bold>x</bold>: for this, we used pairwise Gibbs sampling (blocked Gibbs with block size 2), where each new sample in the MCMC chain was obtained by updating two entries <italic>i</italic> and <italic>j</italic> of <bold>x</bold> at a time, rather than just a single entry. This allowed us to get estimates of the conditional probabilities <italic>P</italic>(<italic>x</italic><sub><italic>i</italic></sub> <italic>x</italic><sub><italic>j</italic></sub> = 1|<italic>x</italic><sub>∼{<italic>i</italic>,<italic>j</italic>}</sub>), and to use them to speed up the estimation of the second moment <italic>E</italic>[<italic>x</italic><sub><italic>i</italic></sub> <italic>x</italic><sub><italic>j</italic></sub>] from empirical average of these conditional probabilities (section 1.1 in <xref ref-type="supplementary-material" rid="pcbi.1005718.s001">S1 Supporting Information</xref>).</p>
<p>Second, we used a variant of coordinate ascent that calculated all relevant quantities as running averages over the MCMC sample, and thereby avoided having to store the entire <inline-formula id="pcbi.1005718.e022"><alternatives><graphic id="pcbi.1005718.e022g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005718.e022" xlink:type="simple"/><mml:math display="inline" id="M22"><mml:mrow><mml:mi>n</mml:mi> <mml:mo>×</mml:mo> <mml:mover accent="true"><mml:mi>M</mml:mi> <mml:mo>˜</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula> MCMC sample in memory [<xref ref-type="bibr" rid="pcbi.1005718.ref015">15</xref>], where <inline-formula id="pcbi.1005718.e023"><alternatives><graphic id="pcbi.1005718.e023g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005718.e023" xlink:type="simple"/><mml:math display="inline" id="M23"><mml:mover accent="true"><mml:mi>M</mml:mi> <mml:mo>˜</mml:mo></mml:mover></mml:math></alternatives></inline-formula> is the length of the sample. Because all features of the maximum entropy model are either 0 or 1 (<italic>x</italic><sub><italic>i</italic></sub>, <italic>x</italic><sub><italic>i</italic></sub> <italic>x</italic><sub><italic>j</italic></sub> and the indicator function for the spike count), the gain in log-likelihood obtainable from either updating a single element of <italic>h</italic> or <italic>J</italic> [<xref ref-type="bibr" rid="pcbi.1005718.ref015">15</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref039">39</xref>], or from updating all <italic>V</italic> simultaneously (but not from updating multiple entries of <italic>h</italic> and <italic>J</italic>) can be computed directly from MCMC estimates of E[<italic>x</italic><sub><italic>i</italic></sub>], E[<italic>x</italic><sub><italic>i</italic></sub> <italic>x</italic><sub><italic>j</italic></sub>] and <italic>P</italic>(<italic>K</italic> = <italic>k</italic>) (section 1.2 in <xref ref-type="supplementary-material" rid="pcbi.1005718.s001">S1 Supporting Information</xref>). For each iteration, we calculated the gain in log-likelihood for each possible update of <italic>h</italic><sub><italic>i</italic></sub>, <italic>J</italic><sub><italic>ij</italic></sub> and full <italic>V</italic>, and picked the update which led to the largest gain [<xref ref-type="bibr" rid="pcbi.1005718.ref015">15</xref>].</p>
<p>We measured the length of Markov chains in sweeps, where one sweep corresponds to one round of <italic>n</italic>(<italic>n</italic> − 1)/2 Markov chain updates that encompasses all pairs of entries of <bold>x</bold> in random order. We set a learning schedule that started at 800 sweeps for the first parameter update and doubled the number of sweeps in the chain after each set of 1000 parameter updates. We monitored convergence of the algorithm using a normalised mean square error between empirical E[<italic>x</italic><sub><italic>i</italic></sub>], <italic>cov</italic>(<italic>x</italic><sub><italic>i</italic></sub>, <italic>x</italic><sub><italic>j</italic></sub>), <italic>P</italic>(<italic>K</italic> = <italic>k</italic>) and their estimates from the MCMC sample. For normalisation, we used the average squared values of the target quantity, e.g. <inline-formula id="pcbi.1005718.e024"><alternatives><graphic id="pcbi.1005718.e024g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005718.e024" xlink:type="simple"/><mml:math display="inline" id="M24"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:munderover><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mtext>E</mml:mtext><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> for the firing rates. We stopped the algorithm when a pre-set threshold was reached (0.01%, 0.25%, 0.01% for <italic>E</italic>[<italic>x</italic><sub><italic>i</italic></sub>], <italic>cov</italic>(<italic>x</italic><sub><italic>i</italic></sub>, <italic>x</italic><sub><italic>j</italic></sub>), <italic>P</italic>(<italic>K</italic> = <italic>k</italic>), respectively), or when the fitting algorithm took more than <inline-formula id="pcbi.1005718.e025"><alternatives><graphic id="pcbi.1005718.e025g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005718.e025" xlink:type="simple"/><mml:math display="inline" id="M25"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mi>n</mml:mi><mml:mrow><mml:mn>100</mml:mn></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>×</mml:mo><mml:mn>72</mml:mn><mml:mtext>h</mml:mtext></mml:mrow></mml:math></alternatives></inline-formula> of computation time on a single core (2.294 GHz AMD Opteron(TM) Processor 6276) (Fig. A in <xref ref-type="supplementary-material" rid="pcbi.1005718.s001">S1 Supporting Information</xref>). For 10 populations of size <italic>n</italic> = 100 (for natural images), the normalised MSEs after model-fitting were 0.43%, 2.80%, 0.42%). An implementation of the fitting algorithms in MATLAB is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/mackelab/CorBinian" xlink:type="simple">https://github.com/mackelab/CorBinian</ext-link>.</p>
</sec>
<sec id="sec013">
<title>Specific heat calculation</title>
<p>To investigate thermodynamic properties of neural population codes, Tkačik et al [<xref ref-type="bibr" rid="pcbi.1005718.ref007">7</xref>] introduced a temperature parameter <italic>T</italic> for <xref ref-type="disp-formula" rid="pcbi.1005718.e016">eq 5</xref>:
<disp-formula id="pcbi.1005718.e026"><alternatives><graphic id="pcbi.1005718.e026g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005718.e026" xlink:type="simple"/><mml:math display="block" id="M26"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>P</mml:mi> <mml:mi>T</mml:mi></mml:msub> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>|</mml:mo> <mml:mo>λ</mml:mo> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:msub><mml:mi>Z</mml:mi> <mml:mi>T</mml:mi></mml:msub></mml:mfrac> <mml:mo form="prefix">exp</mml:mo> <mml:mo>(</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>T</mml:mi></mml:mfrac> <mml:mo>(</mml:mo> <mml:msup><mml:mi>h</mml:mi> <mml:mi>⊤</mml:mi></mml:msup> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>+</mml:mo> <mml:msup><mml:mi mathvariant="bold">x</mml:mi> <mml:mi>⊤</mml:mi></mml:msup> <mml:mi>J</mml:mi> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>+</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn></mml:mrow> <mml:mi>n</mml:mi></mml:munderover> <mml:msub><mml:mi>V</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mi>δ</mml:mi> <mml:mo>(</mml:mo> <mml:mi>K</mml:mi> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo> <mml:mo>)</mml:mo> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(7)</label></disp-formula>
Model fits are obtained at <italic>T</italic> = 1, and the temperature parameter <italic>T</italic> is scaled to study the system (i.e. characterised by <italic>P</italic><sub><italic>T</italic></sub>(<bold>x</bold>|<italic>h</italic>, <italic>J</italic>, <italic>V</italic>) for <italic>T</italic> = 1). Varying <italic>T</italic>, in effect, modulates probabilities by exponentiating them with 1/<italic>T</italic>,
<disp-formula id="pcbi.1005718.e027"><alternatives><graphic id="pcbi.1005718.e027g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005718.e027" xlink:type="simple"/><mml:math display="block" id="M27"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>x</mml:mi></mml:mstyle><mml:mo>)</mml:mo></mml:mrow><mml:mo>∝</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>x</mml:mi></mml:mstyle><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></alternatives> <label>(8)</label></disp-formula>
and that the family of probability distributions obtained by varying <italic>T</italic> can be constructed for any distribution, not just maximum entropy models. For large temperatures <italic>P</italic><sub><italic>T</italic></sub> approaches a uniform distribution (<italic>P</italic><sub><italic>T</italic></sub>(<bold>x</bold>) ≈ 2<sup>−<italic>n</italic></sup> for each <bold>x</bold>), whereas for small temperatures it converges to a singleton, <italic>P</italic><sub><italic>T</italic></sub>(<bold>x</bold>*) ≈ 1 with <bold>x</bold>* = <italic>argmax</italic><sub><bold>x</bold></sub>(<italic>P</italic><sub><italic>T</italic> = 1</sub>(<bold>x</bold>)).</p>
<p>The specific heat, as given in <xref ref-type="disp-formula" rid="pcbi.1005718.e002">eq 2</xref>, can be obtained from the variance of the log-probabilities of the model. As the variance in practice cannot be computed for large <italic>n</italic>, we obtained estimates of <italic>c</italic>(<italic>T</italic>) using a pairwise Gibbs sampler. The specific heat does not depend on <italic>Z</italic><sub><italic>T</italic></sub>, as changing <italic>Z</italic><sub><italic>T</italic></sub> results in a constant, additive shift in log-probabilities which does not affect the variance. We tracked the variance of log-probabilities over an MCMC chain <inline-formula id="pcbi.1005718.e028"><alternatives><graphic id="pcbi.1005718.e028g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005718.e028" xlink:type="simple"/><mml:math display="inline" id="M28"><mml:mrow><mml:msup><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:mo>…</mml:mo> <mml:mo>,</mml:mo> <mml:msup><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>M</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> of length <inline-formula id="pcbi.1005718.e029"><alternatives><graphic id="pcbi.1005718.e029g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005718.e029" xlink:type="simple"/><mml:math display="inline" id="M29"><mml:mover accent="true"><mml:mi>M</mml:mi> <mml:mo>˜</mml:mo></mml:mover></mml:math></alternatives></inline-formula> sampled at temperature <italic>T</italic>, using
<disp-formula id="pcbi.1005718.e030"><alternatives><graphic id="pcbi.1005718.e030g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005718.e030" xlink:type="simple"/><mml:math display="block" id="M30"><mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>≈</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mtext>E</mml:mtext><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mtext>log</mml:mtext><mml:msub><mml:mi>P</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>x</mml:mi></mml:mstyle><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>m</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>|</mml:mo><mml:mo>λ</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow> <mml:mo>]</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mover accent="true"><mml:mtext>E</mml:mtext><mml:mo>^</mml:mo></mml:mover><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mtext>log</mml:mtext><mml:msub><mml:mi>P</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>x</mml:mi></mml:mstyle><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>m</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>|</mml:mo><mml:mo>λ</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></alternatives> <label>(9)</label></disp-formula>
where <inline-formula id="pcbi.1005718.e031"><alternatives><graphic id="pcbi.1005718.e031g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005718.e031" xlink:type="simple"/><mml:math display="inline" id="M31"><mml:mover accent="true"><mml:mtext>E</mml:mtext> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> denotes the average over spike words <bold>x</bold><sup>(<italic>m</italic>)</sup> sampled from the the MCMC chain. For each population, we evaluated <italic>c</italic>(<italic>T</italic>) for 31 temperatures between <italic>T</italic> = 0.8 and <italic>T</italic> = 2, and found the Gibbs sampler to provide reliable estimates over this temperature range—we in particular chose the minimal temperature <italic>T</italic> = 0.8 larger than previous previously in [<xref ref-type="bibr" rid="pcbi.1005718.ref007">7</xref>] to minimize possible effects from the sampler getting stuck (see e.g. [<xref ref-type="bibr" rid="pcbi.1005718.ref046">46</xref>]). We used a burn-in of 2.0e4 sweeps, and ran the sampler for <inline-formula id="pcbi.1005718.e032"><alternatives><graphic id="pcbi.1005718.e032g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005718.e032" xlink:type="simple"/><mml:math display="inline" id="M32"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mi>n</mml:mi><mml:mrow><mml:mn>100</mml:mn></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>×</mml:mo><mml:mn>4</mml:mn><mml:mtext>h</mml:mtext></mml:mrow></mml:math></alternatives></inline-formula> of CPU time, resulting in between 9.97e5 and 1.72e6 sweeps for <italic>n</italic> = 100 (i.e. between 4.94e9 and 8.52e9 sampled individual spike words).</p>
</sec>
<sec id="sec014">
<title>Simplified population models</title>
<p>For the theoretical analysis of the sampling process, we adopted a class of population models (here referred to as ‘flat’ models) in which all neurons are drawn from an infinite pool of neurons which all have identical mean firing rates, pairwise correlations and higher-order correlations [<xref ref-type="bibr" rid="pcbi.1005718.ref044">44</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref025">25</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref070">70</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref003">3</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref071">71</xref>]. Such a model is fully specified by the population spike-count distribution <italic>P</italic>(<italic>K</italic> = <italic>k</italic>), and all spike words with the same spike count are equally probable. As a result, the probabilities of individual patterns <bold>x</bold> can be read off from the spike-count distribution by
<disp-formula id="pcbi.1005718.e033"><alternatives><graphic id="pcbi.1005718.e033g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005718.e033" xlink:type="simple"/><mml:math display="block" id="M33"><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>x</mml:mi></mml:mstyle><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mrow/><mml:mi>k</mml:mi><mml:mi>n</mml:mi></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives> <label>(10)</label></disp-formula>
whenever <inline-formula id="pcbi.1005718.e034"><alternatives><graphic id="pcbi.1005718.e034g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005718.e034" xlink:type="simple"/><mml:math display="inline" id="M34"><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>n</mml:mi></mml:msubsup> <mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mi>k</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>. In a maximum entropy formalism, this model can be obtained by setting <italic>h</italic><sub><italic>i</italic></sub> = 0 and <italic>J</italic><sub><italic>ij</italic></sub> = 0 for all <italic>i</italic>, <italic>j</italic> ∈ {1, …, <italic>n</italic>} and only optimising entries of <italic>V</italic>. Without loss of generality, we fixed fixed <italic>V</italic><sub>0</sub> = 0 [<xref ref-type="bibr" rid="pcbi.1005718.ref043">43</xref>], resulting in <italic>n</italic> degrees of freedom for the model.</p>
<p>In flat models, it is possible to explicitly construct a limit <italic>n</italic> → ∞ which will help us understand population analyses performed on experimental data: We assume that there is a spike-count density <italic>f</italic>(<italic>r</italic>), <italic>r</italic> ∈ [0, 1], which describes the population spike-count distribution of an infinitely large population. <italic>f</italic>(<italic>r</italic>) denotes the probability density of a fraction of <italic>r</italic> neurons spiking simultaneously. Finite-size populations of <italic>n</italic> cells are then obtained as random subsamples out of this infinitely large system. Based on previous findings by [<xref ref-type="bibr" rid="pcbi.1005718.ref025">25</xref>], we show in section 2.3 in <xref ref-type="supplementary-material" rid="pcbi.1005718.s001">S1 Supporting Information</xref> that, in this construction, flat models always exhibit a linear divergence of specific heat, unless the limit <italic>f</italic>(<italic>r</italic>) is given by either a single delta peak or a mixture of two symmetric delta peaks. These two models corresponds to systems that (for large <italic>n</italic>) either behave like a fully independent population (whose spike-count distribution converges to a single delta peak), or a population described by a pure pairwise maximum entropy model (which converges to two delta peaks). In particular, any flat model with higher-order correlations [<xref ref-type="bibr" rid="pcbi.1005718.ref017">17</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref070">70</xref>, <xref ref-type="bibr" rid="pcbi.1005718.ref071">71</xref>], or a non-degenerate <italic>f</italic>(<italic>r</italic>), will exhibit ‘signatures of criticality’. Furthermore, we show that, for continuous <italic>f</italic>(<italic>r</italic>), <italic>c</italic>(<italic>T</italic>) does not diverge for any <italic>T</italic> ≠ 1. In combination, these results show that the peak of the specific heat is mathematically bound to converge to <italic>T</italic> = 1 for <italic>n</italic> → ∞ in this model class.</p>
<p>We further simplified the flat model by re-parametrising <italic>P</italic>(<italic>K</italic> = <italic>k</italic>) by a beta-binomial distribution, thereby reducing the number of parameters from <italic>n</italic> to two, and—importantly—obtaining parameters which do not explicitly depend on <italic>n</italic>. In this model,
<disp-formula id="pcbi.1005718.e035"><alternatives><graphic id="pcbi.1005718.e035g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005718.e035" xlink:type="simple"/><mml:math display="block" id="M35"><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mrow/><mml:mi>k</mml:mi><mml:mi>n</mml:mi></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mtext>Beta</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>+</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo>+</mml:mo><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mtext>Beta</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mrow/><mml:mi>k</mml:mi><mml:mi>n</mml:mi></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:mo>∫</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mi>r</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>r</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msup><mml:mi>d</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></alternatives> <label>(11)</label></disp-formula>
and
<disp-formula id="pcbi.1005718.e036"><alternatives><graphic id="pcbi.1005718.e036g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005718.e036" xlink:type="simple"/><mml:math display="block" id="M36"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>r</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mtext>Beta</mml:mtext> <mml:mo>(</mml:mo> <mml:mi>α</mml:mi> <mml:mo>,</mml:mo> <mml:mi>β</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mfrac> <mml:msup><mml:mi>r</mml:mi> <mml:mrow><mml:mi>α</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>r</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mi>β</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(12)</label></disp-formula>
For simulated data, we found values for <italic>α</italic>, <italic>β</italic> extracted from the beta-binomial fits to populations of different sizes <italic>n</italic> to be stable over a large range of <italic>n</italic> (<xref ref-type="fig" rid="pcbi.1005718.g003">Fig 3b</xref>). We used the beta-binomial parameters obtained from the largest investigated <italic>n</italic> to estimate the divergence rate <inline-formula id="pcbi.1005718.e037"><alternatives><graphic id="pcbi.1005718.e037g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005718.e037" xlink:type="simple"/><mml:math display="inline" id="M37"><mml:mover accent="true"><mml:mi>c</mml:mi> <mml:mo>˜</mml:mo></mml:mover></mml:math></alternatives></inline-formula> for <italic>n</italic> → ∞.</p>
</sec>
</sec>
<sec id="sec015">
<title>Supporting information</title>
<supplementary-material id="pcbi.1005718.s001" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005718.s001" xlink:type="simple">
<label>S1 Supporting Information</label>
<caption>
<title>Supporting derivations and analyses.</title>
<p>We provide more detailed descriptions of the maximum entropy fitting procedures used in this study. We derive limiting behavior of specific heat capacity for flat models, and analyze effects of uniform subsampling on sample means and variances. Furthermore, we provide control analyses for central findings of the study.</p>
<p>(PDF)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>We thank F. Franzen for help with figures and cluster computing, and S. Buchholz, D. Greenberg, S. Turaga and A. Renart for discussions and comments on the manuscript.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1005718.ref001">
<label>1</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kerr</surname> <given-names>JND</given-names></name>, <name name-style="western"><surname>Denk</surname> <given-names>W</given-names></name>. <article-title>Imaging in vivo: watching the brain in action</article-title>. <source>Nature Reviews Neurosci</source>. <year>2008</year>;<volume>9</volume>(<issue>3</issue>):<fpage>195</fpage>–<lpage>205</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nrn2338" xlink:type="simple">10.1038/nrn2338</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref002">
<label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Marre</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Amodei</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Deshmukh</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Sadeghi</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Soo</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Holy</surname> <given-names>TE</given-names></name>, <etal>et al</etal>. <article-title>Mapping a complete neural population in the retina</article-title>. <source>The Journal of Neuroscience</source>. <year>2012</year>;<volume>32</volume>(<issue>43</issue>):<fpage>14859</fpage>–<lpage>14873</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.0723-12.2012" xlink:type="simple">10.1523/JNEUROSCI.0723-12.2012</ext-link></comment> <object-id pub-id-type="pmid">23100409</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref003">
<label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Tkačik</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Marre</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Amodei</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Schneidman</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Bialek</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Berry</surname> <given-names>MJ</given-names> <suffix>2nd</suffix></name>. <article-title>Searching for collective behavior in a large network of sensory neurons</article-title>. <source>PLoS Comput Biol</source>. <year>2014</year>;<volume>10</volume>(<issue>1</issue>):<fpage>e1003408</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1003408" xlink:type="simple">10.1371/journal.pcbi.1003408</ext-link></comment> <object-id pub-id-type="pmid">24391485</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref004">
<label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gao</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Ganguli</surname> <given-names>S</given-names></name>. <article-title>On simplicity and complexity in the brave new world of large-scale neuroscience</article-title>. <source>Current opinion in neurobiology</source>. <year>2015</year>;<volume>32</volume>:<fpage>148</fpage>–<lpage>155</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.conb.2015.04.003" xlink:type="simple">10.1016/j.conb.2015.04.003</ext-link></comment> <object-id pub-id-type="pmid">25932978</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref005">
<label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Beggs</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Timme</surname> <given-names>N</given-names></name>. <article-title>Being critical of criticality in the brain</article-title>. <source>Frontiers in physiology</source>. <year>2012</year>;<volume>3</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fphys.2012.00163" xlink:type="simple">10.3389/fphys.2012.00163</ext-link></comment> <object-id pub-id-type="pmid">22701101</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref006">
<label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Yu</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Yang</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Shriki</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Plenz</surname> <given-names>D</given-names></name>. <article-title>Universal organization of resting brain activity at the thermodynamic critical point</article-title>. <source>Front Syst Neurosci</source>. <year>2013</year>;<volume>7</volume>:<fpage>42</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fnsys.2013.00042" xlink:type="simple">10.3389/fnsys.2013.00042</ext-link></comment> <object-id pub-id-type="pmid">23986660</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref007">
<label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Tkačik</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Mora</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Marre</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Amodei</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Palmer</surname> <given-names>SE</given-names></name>, <name name-style="western"><surname>Berry</surname> <given-names>MJ</given-names></name>, <etal>et al</etal>. <article-title>Thermodynamics and signatures of criticality in a network of neurons</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2015</year>;<volume>112</volume>(<issue>37</issue>):<fpage>11508</fpage>–<lpage>11513</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.1514188112" xlink:type="simple">10.1073/pnas.1514188112</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref008">
<label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Mora</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Deny</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Marre</surname> <given-names>O</given-names></name>. <article-title>Dynamical criticality in the collective activity of a population of retinal neurons</article-title>. <source>Physical review letters</source>. <year>2015</year>;<volume>114</volume>(<issue>7</issue>):<fpage>078105</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevLett.114.078105" xlink:type="simple">10.1103/PhysRevLett.114.078105</ext-link></comment> <object-id pub-id-type="pmid">25763977</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref009">
<label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Mora</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Walczak</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Bialek</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Callan</surname> <given-names>CG</given-names></name>. <article-title>Maximum entropy models for antibody diversity</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2010</year>;<volume>107</volume>(<issue>12</issue>):<fpage>5405</fpage>–<lpage>5410</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.1001705107" xlink:type="simple">10.1073/pnas.1001705107</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref010">
<label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bialek</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Cavagna</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Giardina</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Mora</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Silvestri</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Viale</surname> <given-names>M</given-names></name>, <etal>et al</etal>. <article-title>Statistical mechanics for natural flocks of birds</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2012</year>;<volume>109</volume>(<issue>13</issue>):<fpage>4786</fpage>–<lpage>4791</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.1118633109" xlink:type="simple">10.1073/pnas.1118633109</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref011">
<label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Stephens</surname> <given-names>GJ</given-names></name>, <name name-style="western"><surname>Mora</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Tkačik</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Bialek</surname> <given-names>W</given-names></name>. <article-title>Statistical thermodynamics of natural images</article-title>. <source>Phys Rev Lett</source>. <year>2013</year> <month>Jan</month>;<volume>110</volume>(<issue>1</issue>):<fpage>018701</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevLett.110.018701" xlink:type="simple">10.1103/PhysRevLett.110.018701</ext-link></comment> <object-id pub-id-type="pmid">23383852</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref012">
<label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Mora</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Bialek</surname> <given-names>W</given-names></name>. <article-title>Are biological systems poised at criticality?</article-title> <source>Journal of Statistical Physics</source>. <year>2011</year>;<volume>144</volume>(<issue>2</issue>):<fpage>268</fpage>–<lpage>302</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005718.ref013">
<label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schneidman</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Berry</surname> <given-names>MJn</given-names></name>, <name name-style="western"><surname>Segev</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Bialek</surname> <given-names>W</given-names></name>. <article-title>Weak pairwise correlations imply strongly correlated network states in a neural population</article-title>. <source>Nature</source>. <year>2006</year>;<volume>440</volume>(<issue>7087</issue>):<fpage>1007</fpage>–<lpage>12</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature04701" xlink:type="simple">10.1038/nature04701</ext-link></comment> <object-id pub-id-type="pmid">16625187</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref014">
<label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Shlens</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Field</surname> <given-names>GD</given-names></name>, <name name-style="western"><surname>Gauthier</surname> <given-names>JL</given-names></name>, <name name-style="western"><surname>Grivich</surname> <given-names>MI</given-names></name>, <name name-style="western"><surname>Petrusca</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Sher</surname> <given-names>A</given-names></name>, <etal>et al</etal>. <article-title>The structure of multi-neuron firing patterns in primate retina</article-title>. <source>J Neurosci</source>. <year>2006</year>;<volume>26</volume>(<issue>32</issue>):<fpage>8254</fpage>–<lpage>66</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.1282-06.2006" xlink:type="simple">10.1523/JNEUROSCI.1282-06.2006</ext-link></comment> <object-id pub-id-type="pmid">16899720</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref015">
<label>15</label>
<mixed-citation publication-type="other" xlink:type="simple">Broderick T, Dudik M, Tkacik G, Schapire RE, Bialek W. Faster solutions of the inverse pairwise Ising problem. arXiv. 2007;0712.2437v2.</mixed-citation>
</ref>
<ref id="pcbi.1005718.ref016">
<label>16</label>
<mixed-citation publication-type="other" xlink:type="simple">Tkacik G, Schneidman E, Berry MJ II, Bialek W. Spin glass models for a network of real neurons. arXiv:q-bio/0611072v2. 2009.</mixed-citation>
</ref>
<ref id="pcbi.1005718.ref017">
<label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ohiorhenuan</surname> <given-names>IE</given-names></name>, <name name-style="western"><surname>Mechler</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Purpura</surname> <given-names>KP</given-names></name>, <name name-style="western"><surname>Schmid</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Hu</surname> <given-names>Q</given-names></name>, <name name-style="western"><surname>Victor</surname> <given-names>JD</given-names></name>. <article-title>Sparse coding and high-order correlations in fine-scale cortical networks</article-title>. <source>Nature</source>. <year>2010</year>;<volume>466</volume>(<issue>7306</issue>):<fpage>617</fpage>–<lpage>621</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature09178" xlink:type="simple">10.1038/nature09178</ext-link></comment> <object-id pub-id-type="pmid">20601940</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref018">
<label>18</label>
<mixed-citation publication-type="other" xlink:type="simple">Ioffe ML, Berry II J Michael. The StructuredLow Temperature’Phase of the Retinal Population Code. arXiv preprint arXiv:160805751. 2016.</mixed-citation>
</ref>
<ref id="pcbi.1005718.ref019">
<label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hosoya</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Baccus</surname> <given-names>SA</given-names></name>, <name name-style="western"><surname>Meister</surname> <given-names>M</given-names></name>. <article-title>Dynamic predictive coding by the retina</article-title>. <source>Nature</source>. <year>2005</year>;<volume>436</volume>(<issue>7047</issue>):<fpage>71</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature03689" xlink:type="simple">10.1038/nature03689</ext-link></comment> <object-id pub-id-type="pmid">16001064</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref020">
<label>20</label>
<mixed-citation publication-type="other" xlink:type="simple">Prentice J, Simmons K, Tkacik G, Homann J, Yee H, Palmer S, et al. Transformation of stimulus correlations by the retina. In: APS Meeting Abstracts. vol. 1; 2014. p. 15002.</mixed-citation>
</ref>
<ref id="pcbi.1005718.ref021">
<label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Shew</surname> <given-names>WL</given-names></name>, <name name-style="western"><surname>Clawson</surname> <given-names>WP</given-names></name>, <name name-style="western"><surname>Pobst</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Karimipanah</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Wright</surname> <given-names>NC</given-names></name>, <name name-style="western"><surname>Wessel</surname> <given-names>R</given-names></name>. <article-title>Adaptation to sensory input tunes visual cortex to criticality</article-title>. <source>Nature Physics</source>. <year>2015</year>;<volume>11</volume>(<issue>8</issue>):<fpage>659</fpage>–<lpage>663</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nphys3370" xlink:type="simple">10.1038/nphys3370</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref022">
<label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bak</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Tang</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Wiesenfeld</surname> <given-names>K</given-names></name>. <article-title>Self-organized criticality: An explanation of the 1/f noise</article-title>. <source>Physical review letters</source>. <year>1987</year>;<volume>59</volume>(<issue>4</issue>):<fpage>381</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevLett.59.381" xlink:type="simple">10.1103/PhysRevLett.59.381</ext-link></comment> <object-id pub-id-type="pmid">10035754</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref023">
<label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Levina</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Herrmann</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Geisel</surname> <given-names>T</given-names></name>. <article-title>Phase transitions towards criticality in a neural system with adaptive interactions</article-title>. <source>Physical Review Letters</source>. <year>2009</year>;<volume>102</volume>(<issue>11</issue>):<fpage>118110</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevLett.102.118110" xlink:type="simple">10.1103/PhysRevLett.102.118110</ext-link></comment> <object-id pub-id-type="pmid">19392248</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref024">
<label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Meisel</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Gross</surname> <given-names>T</given-names></name>. <article-title>Adaptive self-organization in a realistic neural network model</article-title>. <source>Physical Review E</source>. <year>2009</year>;<volume>80</volume>(<issue>6</issue>):<fpage>061917</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevE.80.061917" xlink:type="simple">10.1103/PhysRevE.80.061917</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref025">
<label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Macke</surname> <given-names>JH</given-names></name>, <name name-style="western"><surname>Opper</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Bethge</surname> <given-names>M</given-names></name>. <article-title>Common input explains higher-order correlations and entropy in a simple model of neural population activity</article-title>. <source>Physical Review Letters</source>. <year>2011</year>;<volume>106</volume>(<issue>20</issue>):<fpage>208102</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevLett.106.208102" xlink:type="simple">10.1103/PhysRevLett.106.208102</ext-link></comment> <object-id pub-id-type="pmid">21668265</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref026">
<label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schwab</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Nemenman</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Mehta</surname> <given-names>P</given-names></name>. <article-title>Zipf’s law and criticality in multivariate data without fine-tuning</article-title>. <source>Physical review letters</source>. <year>2014</year>;<volume>113</volume>(<issue>6</issue>):<fpage>068102</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevLett.113.068102" xlink:type="simple">10.1103/PhysRevLett.113.068102</ext-link></comment> <object-id pub-id-type="pmid">25148352</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref027">
<label>27</label>
<mixed-citation publication-type="other" xlink:type="simple">Aitchison L, Corradi N, Latham PE. Zipf’s law arises naturally in structured, high-dimensional data. arXiv preprint. 2014;1407.7135v4.</mixed-citation>
</ref>
<ref id="pcbi.1005718.ref028">
<label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Aitchison</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Corradi</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Latham</surname> <given-names>PE</given-names></name>. <article-title>Zipf’s Law Arises Naturally When There Are Underlying, Unobserved Variables</article-title>. <source>PLoS Comput Biol</source>. <year>2016</year> <month>Dec</month>;<volume>12</volume>(<issue>12</issue>):<fpage>e1005110</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1005110" xlink:type="simple">10.1371/journal.pcbi.1005110</ext-link></comment> <object-id pub-id-type="pmid">27997544</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref029">
<label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Tyrcha</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Roudi</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Marsili</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Hertz</surname> <given-names>J</given-names></name>. <article-title>The effect of nonstationarity on models inferred from neural data</article-title>. <source>Journal of Statistical Mechanics: Theory and Experiment</source>. <year>2013</year>;<volume>2013</volume>(<issue>03</issue>):<fpage>P03005</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1088/1742-5468/2013/03/P03005" xlink:type="simple">10.1088/1742-5468/2013/03/P03005</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref030">
<label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Trong</surname> <given-names>PK</given-names></name>, <name name-style="western"><surname>Rieke</surname> <given-names>F</given-names></name>. <article-title>Origin of correlated activity between parasol retinal ganglion cells</article-title>. <source>Nature Neuroscience</source>. <year>2008</year>;<volume>11</volume>(<issue>11</issue>):<fpage>1343</fpage>–<lpage>1351</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.2199" xlink:type="simple">10.1038/nn.2199</ext-link></comment> <object-id pub-id-type="pmid">18820692</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref031">
<label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Doiron</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Litwin-Kumar</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Rosenbaum</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Ocker</surname> <given-names>GK</given-names></name>, <name name-style="western"><surname>Josić</surname> <given-names>K</given-names></name>. <article-title>The mechanics of state-dependent neural correlations</article-title>. <source>Nat Neurosci</source>. <year>2016</year> <month>Mar</month>;<volume>19</volume>(<issue>3</issue>):<fpage>383</fpage>–<lpage>93</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.4242" xlink:type="simple">10.1038/nn.4242</ext-link></comment> <object-id pub-id-type="pmid">26906505</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref032">
<label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Chichilnisky</surname> <given-names>E</given-names></name>. <article-title>A simple white noise analysis of neuronal light responses</article-title>. <source>Network: Computation in Neural Systems</source>. <year>2001</year>;<volume>12</volume>(<issue>2</issue>):<fpage>199</fpage>–<lpage>213</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1080/713663221" xlink:type="simple">10.1080/713663221</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref033">
<label>33</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Carandini</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Demb</surname> <given-names>JB</given-names></name>, <name name-style="western"><surname>Mante</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Tolhurst</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Dan</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Olshausen</surname> <given-names>BA</given-names></name>, <etal>et al</etal>. <article-title>Do we know what the early visual system does?</article-title> <source>J Neurosci</source>. <year>2005</year>;<volume>25</volume>(<issue>46</issue>):<fpage>10577</fpage>–<lpage>10597</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.3726-05.2005" xlink:type="simple">10.1523/JNEUROSCI.3726-05.2005</ext-link></comment> <object-id pub-id-type="pmid">16291931</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref034">
<label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Pillow</surname> <given-names>JW</given-names></name>, <name name-style="western"><surname>Shlens</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Paninski</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Sher</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Litke</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Chichilnisky</surname> <given-names>EJ</given-names></name>, <etal>et al</etal>. <article-title>Spatio-temporal correlations and visual signalling in a complete neuronal population</article-title>. <source>Nature</source>. <year>2008</year>;<volume>454</volume>(<issue>7207</issue>):<fpage>995</fpage>–<lpage>9</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature07140" xlink:type="simple">10.1038/nature07140</ext-link></comment> <object-id pub-id-type="pmid">18650810</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref035">
<label>35</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Pitkow</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Meister</surname> <given-names>M</given-names></name>. <article-title>Decorrelation and efficient coding by retinal ganglion cells</article-title>. <source>Nature neuroscience</source>. <year>2012</year>;<volume>15</volume>(<issue>4</issue>):<fpage>628</fpage>–<lpage>635</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.3064" xlink:type="simple">10.1038/nn.3064</ext-link></comment> <object-id pub-id-type="pmid">22406548</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref036">
<label>36</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kuffler</surname> <given-names>SW</given-names></name>. <article-title>Discharge patterns and functional organization of mammalian retina</article-title>. <source>Journal of neurophysiology</source>. <year>1953</year>;<volume>16</volume>(<issue>1</issue>):<fpage>37</fpage>–<lpage>68</lpage>. <object-id pub-id-type="pmid">13035466</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref037">
<label>37</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Rodieck</surname> <given-names>RW</given-names></name>. <article-title>Quantitative analysis of cat retinal ganglion cell response to visual stimuli</article-title>. <source>Vision research</source>. <year>1965</year>;<volume>5</volume>(<issue>12</issue>):<fpage>583</fpage>–<lpage>601</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/0042-6989(65)90033-7" xlink:type="simple">10.1016/0042-6989(65)90033-7</ext-link></comment> <object-id pub-id-type="pmid">5862581</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref038">
<label>38</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ferrenberg</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Swendsen</surname> <given-names>RH</given-names></name>. <article-title>New Monte Carlo technique for studying phase transitions</article-title>. <source>Physical review letters</source>. <year>1988</year>;<volume>61</volume>(<issue>23</issue>):<fpage>2635</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevLett.61.2635" xlink:type="simple">10.1103/PhysRevLett.61.2635</ext-link></comment> <object-id pub-id-type="pmid">10039183</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref039">
<label>39</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schwartz</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Macke</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Amodei</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Tang</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Berry</surname> <given-names>MJ</given-names> <suffix>2nd</suffix></name>. <article-title>Low error discrimination using a correlated population code</article-title>. <source>J Neurophysiol</source>. <year>2012</year>;<volume>108</volume>(<issue>4</issue>):<fpage>1069</fpage>–<lpage>88</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.00564.2011" xlink:type="simple">10.1152/jn.00564.2011</ext-link></comment> <object-id pub-id-type="pmid">22539825</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref040">
<label>40</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Radhakrishna Rao</surname> <given-names>C</given-names></name>. <article-title>Information and accuracy attainable in the estimation of statistical parameters</article-title>. <source>Bulletin of the Calcutta Mathematical Society</source>. <year>1945</year>;<volume>37</volume>(<issue>3</issue>):<fpage>81</fpage>–<lpage>91</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005718.ref041">
<label>41</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kirkpatrick</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Gelatt</surname> <given-names>CD</given-names></name>, <name name-style="western"><surname>Vecchi</surname> <given-names>MP</given-names></name>, <etal>et al</etal>. <article-title>Optimization by simulated annealing</article-title>. <source>science</source>. <year>1983</year>;<volume>220</volume>(<issue>4598</issue>):<fpage>671</fpage>–<lpage>680</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.220.4598.671" xlink:type="simple">10.1126/science.220.4598.671</ext-link></comment> <object-id pub-id-type="pmid">17813860</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref042">
<label>42</label>
<mixed-citation publication-type="other" xlink:type="simple">Tkacik G, Schneidman E, Berry II MJ, Bialek W. Ising models for networks of real neurons. arXiv preprint. 2006;0611072v1.</mixed-citation>
</ref>
<ref id="pcbi.1005718.ref043">
<label>43</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Tkačik</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Marre</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Mora</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Amodei</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Berry</surname> <given-names>MJ</given-names> <suffix>II</suffix></name>, <name name-style="western"><surname>Bialek</surname> <given-names>W</given-names></name>. <article-title>The simplest maximum entropy model for collective behavior in a neural network</article-title>. <source>Journal of Statistical Mechanics: Theory and Experiment</source>. <year>2013</year>;<volume>2013</volume>(<issue>03</issue>):<fpage>P03011</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1088/1742-5468/2013/03/P03011" xlink:type="simple">10.1088/1742-5468/2013/03/P03011</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref044">
<label>44</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Amari</surname> <given-names>Si</given-names></name>, <name name-style="western"><surname>Nakahara</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Wu</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Sakai</surname> <given-names>Y</given-names></name>. <article-title>Synchronous firing and higher-order interactions in neuron pool</article-title>. <source>Neural Computation</source>. <year>2003</year>;<volume>15</volume>(<issue>1</issue>):<fpage>127</fpage>–<lpage>142</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/089976603321043720" xlink:type="simple">10.1162/089976603321043720</ext-link></comment> <object-id pub-id-type="pmid">12590822</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref045">
<label>45</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Okun</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Yger</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Marguet</surname> <given-names>SL</given-names></name>, <name name-style="western"><surname>Gerard-Mercier</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Benucci</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Katzner</surname> <given-names>S</given-names></name>, <etal>et al</etal>. <article-title>Population rate dynamics and multineuron firing patterns in sensory cortex</article-title>. <source>J Neurosci</source>. <year>2012</year>;<volume>32</volume>(<issue>48</issue>):<fpage>17108</fpage>–<lpage>19</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.1831-12.2012" xlink:type="simple">10.1523/JNEUROSCI.1831-12.2012</ext-link></comment> <object-id pub-id-type="pmid">23197704</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref046">
<label>46</label>
<mixed-citation publication-type="other" xlink:type="simple">Rostami V, Mana PP, Helias M. Pairwise maximum-entropy models and their Glauber dynamics: bimodality, bistability, non-ergodicity problems, and their elimination via inhibition. arXiv preprint arXiv:160504740. 2016.</mixed-citation>
</ref>
<ref id="pcbi.1005718.ref047">
<label>47</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Sherrington</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Kirkpatrick</surname> <given-names>S</given-names></name>. <article-title>Solvable model of a spin-glass</article-title>. <source>Physical review letters</source>. <year>1975</year>;<volume>35</volume>(<issue>26</issue>):<fpage>1792</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevLett.35.1792" xlink:type="simple">10.1103/PhysRevLett.35.1792</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref048">
<label>48</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Mezard</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Parisi</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Virasoro</surname> <given-names>M</given-names></name>. <source>Spin Glass Theory and Beyond</source> (<publisher-loc>Singapore</publisher-loc>: <publisher-name>Word Scientific</publisher-name>); <year>1987</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005718.ref049">
<label>49</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Saremi</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Sejnowski</surname> <given-names>TJ</given-names></name>. <article-title>On Criticality in High-Dimensional Data</article-title>. <source>Neural Comput</source>. <year>2014</year> <month>Jul</month>;<volume>26</volume>(<issue>7</issue>):<fpage>1329</fpage>–<lpage>1339</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/NECO_a_00607" xlink:type="simple">10.1162/NECO_a_00607</ext-link></comment> <object-id pub-id-type="pmid">24708368</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref050">
<label>50</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Mastromatteo</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Marsili</surname> <given-names>M</given-names></name>. <article-title>On the criticality of inferred models</article-title>. <source>Journal of Statistical Mechanics: Theory and Experiment</source>. <year>2011</year>;<volume>2011</volume>(<issue>10</issue>):<fpage>P10012</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1088/1742-5468/2011/10/P10012" xlink:type="simple">10.1088/1742-5468/2011/10/P10012</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref051">
<label>51</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Marsili</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Mastromatteo</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Roudi</surname> <given-names>Y</given-names></name>. <article-title>On sampling and modeling complex systems</article-title>. <source>Journal of Statistical Mechanics: Theory and Experiment</source>. <year>2013</year>;<volume>2013</volume>(<issue>09</issue>):<fpage>P09003</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1088/1742-5468/2013/09/P09003" xlink:type="simple">10.1088/1742-5468/2013/09/P09003</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref052">
<label>52</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Beggs</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Plenz</surname> <given-names>D</given-names></name>. <article-title>Neuronal avalanches in neocortical circuits</article-title>. <source>The Journal of neuroscience</source>. <year>2003</year>;<volume>23</volume>(<issue>35</issue>):<fpage>11167</fpage>–<lpage>11177</lpage>. <object-id pub-id-type="pmid">14657176</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref053">
<label>53</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Levina</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Herrmann</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Geisel</surname> <given-names>T</given-names></name>. <article-title>Dynamical synapses causing self-organized criticality in neural networks</article-title>. <source>Nature physics</source>. <year>2007</year>;<volume>3</volume>(<issue>12</issue>):<fpage>857</fpage>–<lpage>860</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nphys758" xlink:type="simple">10.1038/nphys758</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref054">
<label>54</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Levina</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Priesemann</surname> <given-names>V</given-names></name>. <article-title>Subsampling scaling</article-title>. <source>Nature Communications</source>. <year>2017</year>;<volume>8</volume>:<fpage>15140</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/ncomms15140" xlink:type="simple">10.1038/ncomms15140</ext-link></comment> <object-id pub-id-type="pmid">28469176</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref055">
<label>55</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Touboul</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Destexhe</surname> <given-names>A</given-names></name>. <article-title>Power-law statistics and universal scaling in the absence of criticality</article-title>. <source>Physical Review E</source>. <year>2017</year>;<volume>95</volume>(<issue>1</issue>):<fpage>012413</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevE.95.012413" xlink:type="simple">10.1103/PhysRevE.95.012413</ext-link></comment> <object-id pub-id-type="pmid">28208383</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref056">
<label>56</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schölvinck</surname> <given-names>ML</given-names></name>, <name name-style="western"><surname>Saleem</surname> <given-names>AB</given-names></name>, <name name-style="western"><surname>Benucci</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Harris</surname> <given-names>KD</given-names></name>, <name name-style="western"><surname>Carandini</surname> <given-names>M</given-names></name>. <article-title>Cortical state determines global variability and correlations in visual cortex</article-title>. <source>J Neurosci</source>. <year>2015</year> <month>Jan</month>;<volume>35</volume>(<issue>1</issue>):<fpage>170</fpage>–<lpage>8</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.4994-13.2015" xlink:type="simple">10.1523/JNEUROSCI.4994-13.2015</ext-link></comment> <object-id pub-id-type="pmid">25568112</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref057">
<label>57</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Smirnakis</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Berry</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Warland</surname> <given-names>DK</given-names></name>, <name name-style="western"><surname>Bialek</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Meister</surname> <given-names>M</given-names></name>, <etal>et al</etal>. <article-title>Adaptation of retinal processing to image contrast and spatial scale</article-title>. <source>Nature</source>. <year>1997</year>;<volume>386</volume>(<issue>6620</issue>):<fpage>69</fpage>–<lpage>73</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/386069a0" xlink:type="simple">10.1038/386069a0</ext-link></comment> <object-id pub-id-type="pmid">9052781</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref058">
<label>58</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Nirenberg</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Bomash</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Pillow</surname> <given-names>JW</given-names></name>, <name name-style="western"><surname>Victor</surname> <given-names>JD</given-names></name>. <article-title>Heterogeneous response dynamics in retinal ganglion cells: the interplay of predictive coding and adaptation</article-title>. <source>Journal of neurophysiology</source>. <year>2010</year>;<volume>103</volume>(<issue>6</issue>):<fpage>3184</fpage>–<lpage>3194</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.00878.2009" xlink:type="simple">10.1152/jn.00878.2009</ext-link></comment> <object-id pub-id-type="pmid">20357061</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref059">
<label>59</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Turaga</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Buesing</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Packer</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Dalgleish</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Pettit</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Hausser</surname> <given-names>M</given-names></name>, <etal>et al</etal>. <chapter-title>Inferring neural population dynamics from multiple partial recordings of the same neural circuit</chapter-title>. In: <source>Advances in Neural Information Processing Systems</source>; <year>2013</year>. p. <fpage>539</fpage>–<lpage>547</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005718.ref060">
<label>60</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Soudry</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Keshri</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Stinson</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Oh</surname> <given-names>Mh</given-names></name>, <name name-style="western"><surname>Iyengar</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Paninski</surname> <given-names>L</given-names></name>. <article-title>Efficient “Shotgun” Inference of Neural Connectivity from Highly Sub-sampled Activity Data</article-title>. <source>PLoS Comput Biol</source>. <year>2015</year>;<volume>11</volume>(<issue>10</issue>):<fpage>e1004464</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1004464" xlink:type="simple">10.1371/journal.pcbi.1004464</ext-link></comment> <object-id pub-id-type="pmid">26465147</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref061">
<label>61</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Battistin</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Dunn</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Roudi</surname> <given-names>Y</given-names></name>. <article-title>Learning with unknowns: analyzing biological data in the presence of hidden variables</article-title>. <source>Current Opinion in Systems Biology</source>. <year>2017</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.coisb.2016.12.010" xlink:type="simple">10.1016/j.coisb.2016.12.010</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref062">
<label>62</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Macke</surname> <given-names>JH</given-names></name>, <name name-style="western"><surname>Buesing</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Cunningham</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Yu</surname> <given-names>BM</given-names></name>, <name name-style="western"><surname>Shenoy</surname> <given-names>KV</given-names></name>, <name name-style="western"><surname>Sahani</surname> <given-names>M</given-names></name>. <chapter-title>Empirical models of spiking in neural populations</chapter-title>. In: <source>Advances in Neural Information Processing Systems</source>. <volume>vol. 24</volume>; <year>2012</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005718.ref063">
<label>63</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Archer</surname> <given-names>EW</given-names></name>, <name name-style="western"><surname>Koster</surname> <given-names>U</given-names></name>, <name name-style="western"><surname>Pillow</surname> <given-names>JW</given-names></name>, <name name-style="western"><surname>Macke</surname> <given-names>JH</given-names></name>. <chapter-title>Low-dimensional models of neural population activity in sensory cortical circuits</chapter-title>. In: <source>Advances in Neural Information Processing Systems</source>; <year>2014</year>. p. <fpage>343</fpage>–<lpage>351</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005718.ref064">
<label>64</label>
<mixed-citation publication-type="other" xlink:type="simple">Schoenholz SS, Gilmer J, Ganguli S, Sohl-Dickstein J. Deep Information Propagation. arXiv preprint arXiv:161101232. 2016.</mixed-citation>
</ref>
<ref id="pcbi.1005718.ref065">
<label>65</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Baden</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Berens</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Franke</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Rosón</surname> <given-names>MR</given-names></name>, <name name-style="western"><surname>Bethge</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Euler</surname> <given-names>T</given-names></name>. <article-title>The functional diversity of retinal ganglion cells in the mouse</article-title>. <source>Nature</source>. <year>2016</year>;<volume>529</volume>(<issue>7586</issue>):<fpage>345</fpage>–<lpage>350</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature16468" xlink:type="simple">10.1038/nature16468</ext-link></comment> <object-id pub-id-type="pmid">26735013</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref066">
<label>66</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Lyamzin</surname> <given-names>DR</given-names></name>, <name name-style="western"><surname>Macke</surname> <given-names>JH</given-names></name>, <name name-style="western"><surname>Lesica</surname> <given-names>NA</given-names></name>. <article-title>Modeling population spike trains with specified time-varying spike rates, trial-to-trial variability, and pairwise signal and noise correlations</article-title>. <source>Frontiers in computational neuroscience</source>. <year>2010</year>;<volume>4</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fncom.2010.00144" xlink:type="simple">10.3389/fncom.2010.00144</ext-link></comment> <object-id pub-id-type="pmid">21152346</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref067">
<label>67</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Jaynes</surname> <given-names>ET</given-names></name>. <article-title>Information theory and statistical mechanics</article-title>. <source>Physical review</source>. <year>1957</year>;<volume>106</volume>(<issue>4</issue>):<fpage>620</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRev.106.620" xlink:type="simple">10.1103/PhysRev.106.620</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref068">
<label>68</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Dudík</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Schapire</surname> <given-names>RE</given-names></name>. <chapter-title>Maximum entropy distribution estimation with generalized regularization</chapter-title>. In: <source>Learning Theory</source>. <publisher-name>Springer</publisher-name>; <year>2006</year>. p. <fpage>123</fpage>–<lpage>138</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005718.ref069">
<label>69</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Altun</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Smola</surname> <given-names>A</given-names></name>. <chapter-title>Unifying divergence minimization and statistical inference via convex duality</chapter-title>. In: <source>Learning theory</source>. <publisher-name>Springer</publisher-name>; <year>2006</year>. p. <fpage>139</fpage>–<lpage>153</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005718.ref070">
<label>70</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Yu</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Yang</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Nakahara</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Santos</surname> <given-names>GS</given-names></name>, <name name-style="western"><surname>Nikolic</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Plenz</surname> <given-names>D</given-names></name>. <article-title>Higher-order interactions characterized in cortical activity</article-title>. <source>J Neurosci</source>. <year>2011</year>;<volume>31</volume>(<issue>48</issue>):<fpage>17514</fpage>–<lpage>17526</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.3127-11.2011" xlink:type="simple">10.1523/JNEUROSCI.3127-11.2011</ext-link></comment> <object-id pub-id-type="pmid">22131413</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005718.ref071">
<label>71</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Barreiro</surname> <given-names>AK</given-names></name>, <name name-style="western"><surname>Gjorgjieva</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Rieke</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Shea-Brown</surname> <given-names>E</given-names></name>. <article-title>When do microcircuits produce beyond-pairwise correlations?</article-title> <source>Front Comput Neurosci</source>. <year>2014</year>;<volume>8</volume>:<fpage>10</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fncom.2014.00010" xlink:type="simple">10.3389/fncom.2014.00010</ext-link></comment> <object-id pub-id-type="pmid">24567715</object-id></mixed-citation>
</ref>
</ref-list>
</back>
</article>
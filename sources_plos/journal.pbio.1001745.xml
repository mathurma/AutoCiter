<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="nlm-ta">PLoS Biol</journal-id>
<journal-id journal-id-type="pmc">plosbiol</journal-id><journal-title-group>
<journal-title>PLoS Biology</journal-title></journal-title-group>
<issn pub-type="ppub">1544-9173</issn>
<issn pub-type="epub">1545-7885</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PBIOLOGY-D-13-02315</article-id>
<article-id pub-id-type="doi">10.1371/journal.pbio.1001745</article-id>
<article-categories><subj-group subj-group-type="heading"><subject>Community Page</subject></subj-group></article-categories>
<title-group>
<article-title>Best Practices for Scientific Computing</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Wilson</surname><given-names>Greg</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Aruliah</surname><given-names>D. A.</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Brown</surname><given-names>C. Titus</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Chue Hong</surname><given-names>Neil P.</given-names></name><xref ref-type="aff" rid="aff4"><sup>4</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Davis</surname><given-names>Matt</given-names></name><xref ref-type="aff" rid="aff5"><sup>5</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Guy</surname><given-names>Richard T.</given-names></name><xref ref-type="aff" rid="aff6"><sup>6</sup></xref><xref ref-type="fn" rid="fn1"><sup>¤</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Haddock</surname><given-names>Steven H. D.</given-names></name><xref ref-type="aff" rid="aff7"><sup>7</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Huff</surname><given-names>Kathryn D.</given-names></name><xref ref-type="aff" rid="aff8"><sup>8</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Mitchell</surname><given-names>Ian M.</given-names></name><xref ref-type="aff" rid="aff9"><sup>9</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Plumbley</surname><given-names>Mark D.</given-names></name><xref ref-type="aff" rid="aff10"><sup>10</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Waugh</surname><given-names>Ben</given-names></name><xref ref-type="aff" rid="aff11"><sup>11</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>White</surname><given-names>Ethan P.</given-names></name><xref ref-type="aff" rid="aff12"><sup>12</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Wilson</surname><given-names>Paul</given-names></name><xref ref-type="aff" rid="aff13"><sup>13</sup></xref></contrib>
</contrib-group>
<aff id="aff1"><label>1</label><addr-line>Mozilla Foundation, Toronto, Ontario, Canada</addr-line></aff>
<aff id="aff2"><label>2</label><addr-line>University of Ontario Institute of Technology, Oshawa, Ontario, Canada</addr-line></aff>
<aff id="aff3"><label>3</label><addr-line>Michigan State University, East Lansing, Michigan, United States of America</addr-line></aff>
<aff id="aff4"><label>4</label><addr-line>Software Sustainability Institute, Edinburgh, United Kingdom</addr-line></aff>
<aff id="aff5"><label>5</label><addr-line>Space Telescope Science Institute, Baltimore, Maryland, United States of America</addr-line></aff>
<aff id="aff6"><label>6</label><addr-line>University of Toronto, Toronto, Ontario, Canada</addr-line></aff>
<aff id="aff7"><label>7</label><addr-line>Monterey Bay Aquarium Research Institute, Moss Landing, California, United States of America</addr-line></aff>
<aff id="aff8"><label>8</label><addr-line>University of California Berkeley, Berkeley, California, United States of America</addr-line></aff>
<aff id="aff9"><label>9</label><addr-line>University of British Columbia, Vancouver, British Columbia, Canada</addr-line></aff>
<aff id="aff10"><label>10</label><addr-line>Queen Mary University of London, London, United Kingdom</addr-line></aff>
<aff id="aff11"><label>11</label><addr-line>University College London, London, United Kingdom</addr-line></aff>
<aff id="aff12"><label>12</label><addr-line>Utah State University, Logan, Utah, United States of America</addr-line></aff>
<aff id="aff13"><label>13</label><addr-line>University of Wisconsin, Madison, Wisconsin, United States of America</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Eisen</surname><given-names>Jonathan A.</given-names></name>
<role>Academic Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group>
<aff id="edit1"><addr-line>University of California Davis, United States of America</addr-line></aff>
<author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">gvwilson@software-carpentry.org</email></corresp>
<fn fn-type="conflict"><p>The lead author (GVW) is involved in a pilot study of code review in scientific computing with <italic>PLOS Computational Biology</italic>.</p></fn>
<fn fn-type="con"><p>The author(s) have made the following declarations about their contributions: Wrote the paper: GVW DAA CTB NPCH MD RTG SHDH KH IMM MDP BW EPW PW.</p></fn>
<fn id="fn1" fn-type="current-aff"><label>¤</label><p>Current address: Microsoft, Inc., Seattle, Washington, United States of America</p></fn>
</author-notes>
<pub-date pub-type="collection"><month>1</month><year>2014</year></pub-date>
<pub-date pub-type="epub"><day>7</day><month>1</month><year>2014</year></pub-date>
<volume>12</volume>
<issue>1</issue>
<elocation-id>e1001745</elocation-id><permissions>
<copyright-year>2014</copyright-year>
<copyright-holder>Wilson et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple"><license-p>This is an open-access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions>
<abstract abstract-type="toc"><sec>
<title/>
<p>We describe a set of best practices for scientific software development, based on research and experience, that will improve scientists' productivity and the reliability of their software.</p>
</sec></abstract>
<funding-group><funding-statement>Neil Chue Hong was supported by the UK Engineering and Physical Sciences Research Council (EPSRC) Grant EP/H043160/1 for the UK Software Sustainability Institute. Ian M. Mitchell was supported by NSERC Discovery Grant #298211. Mark Plumbley was supported by EPSRC through a Leadership Fellowship (EP/G007144/1) and a grant (EP/H043101/1) for SoundSoftware.ac.uk. Ethan White was supported by a CAREER grant from the US National Science Foundation (DEB 0953694). Greg Wilson was supported by a grant from the Sloan Foundation. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="7"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>Scientists spend an increasing amount of time building and using software. However, most scientists are never taught how to do this efficiently. As a result, many are unaware of tools and practices that would allow them to write more reliable and maintainable code with less effort. We describe a set of best practices for scientific software development that have solid foundations in research and experience, and that improve scientists' productivity and the reliability of their software.</p>
<p>Software is as important to modern scientific research as telescopes and test tubes. From groups that work exclusively on computational problems, to traditional laboratory and field scientists, more and more of the daily operation of science revolves around developing new algorithms, managing and analyzing the large amounts of data that are generated in single research projects, combining disparate datasets to assess synthetic problems, and other computational tasks.</p>
<p>Scientists typically develop their own software for these purposes because doing so requires substantial domain-specific knowledge. As a result, recent studies have found that scientists typically spend 30% or more of their time developing software <xref ref-type="bibr" rid="pbio.1001745-Hannay1">[1]</xref>,<xref ref-type="bibr" rid="pbio.1001745-Prabhu1">[2]</xref>. However, 90% or more of them are primarily self-taught <xref ref-type="bibr" rid="pbio.1001745-Hannay1">[1]</xref>,<xref ref-type="bibr" rid="pbio.1001745-Prabhu1">[2]</xref>, and therefore lack exposure to basic software development practices such as writing maintainable code, using version control and issue trackers, code reviews, unit testing, and task automation.</p>
<p>We believe that software is just another kind of experimental apparatus <xref ref-type="bibr" rid="pbio.1001745-Vardi1">[3]</xref> and should be built, checked, and used as carefully as any physical apparatus. However, while most scientists are careful to validate their laboratory and field equipment, most do not know how reliable their software is <xref ref-type="bibr" rid="pbio.1001745-Hatton1">[4]</xref>,<xref ref-type="bibr" rid="pbio.1001745-Hatton2">[5]</xref>. This can lead to serious errors impacting the central conclusions of published research <xref ref-type="bibr" rid="pbio.1001745-Merali1">[6]</xref>: recent high-profile retractions, technical comments, and corrections because of errors in computational methods include papers in <italic>Science</italic> <xref ref-type="bibr" rid="pbio.1001745-Chang1">[7]</xref>,<xref ref-type="bibr" rid="pbio.1001745-Ferrari1">[8]</xref>, <italic>PNAS</italic> <xref ref-type="bibr" rid="pbio.1001745-Ma1">[9]</xref>, the <italic>Journal of Molecular Biology</italic> <xref ref-type="bibr" rid="pbio.1001745-Chang2">[10]</xref>, <italic>Ecology Letters</italic> <xref ref-type="bibr" rid="pbio.1001745-Lees1">[11]</xref>,<xref ref-type="bibr" rid="pbio.1001745-Currie1">[12]</xref>, the <italic>Journal of Mammalogy</italic> <xref ref-type="bibr" rid="pbio.1001745-Kelt1">[13]</xref>, <italic>Journal of the American College of Cardiology</italic> <xref ref-type="bibr" rid="pbio.1001745-Anon1">[14]</xref>, <italic>Hypertension</italic> <xref ref-type="bibr" rid="pbio.1001745-1">[15]</xref>, and <italic>The American Economic Review</italic> <xref ref-type="bibr" rid="pbio.1001745-Herndon1">[16]</xref>.</p>
<p>In addition, because software is often used for more than a single project, and is often reused by other scientists, computing errors can have disproportionate impacts on the scientific process. This type of cascading impact caused several prominent retractions when an error from another group's code was not discovered until after publication <xref ref-type="bibr" rid="pbio.1001745-Merali1">[6]</xref>. As with bench experiments, not everything must be done to the most exacting standards; however, scientists need to be aware of best practices both to improve their own approaches and for reviewing computational work by others.</p>
<p>This paper describes a set of practices that are easy to adopt and have proven effective in many research settings. Our recommendations are based on several decades of collective experience both building scientific software and teaching computing to scientists <xref ref-type="bibr" rid="pbio.1001745-Aranda1">[17]</xref>,<xref ref-type="bibr" rid="pbio.1001745-Wilson1">[18]</xref>, reports from many other groups <xref ref-type="bibr" rid="pbio.1001745-Heroux1">[19]</xref>–, guidelines for commercial and open source software development <xref ref-type="bibr" rid="pbio.1001745-Spolsky1">[26]</xref>,, and on empirical studies of scientific computing <xref ref-type="bibr" rid="pbio.1001745-Carver1">[28]</xref>–<xref ref-type="bibr" rid="pbio.1001745-Segal2">[31]</xref> and software development in general (summarized in <xref ref-type="bibr" rid="pbio.1001745-Oram1">[32]</xref>). None of these practices will guarantee efficient, error-free software development, but used in concert they will reduce the number of errors in scientific software, make it easier to reuse, and save the authors of the software time and effort that can used for focusing on the underlying scientific questions.</p>
<p>Our practices are summarized in <xref ref-type="boxed-text" rid="pbio-1001745-box001">Box 1</xref>; labels in the main text such as “(1a)” refer to items in that summary. For reasons of space, we do not discuss the equally important (but independent) issues of reproducible research, publication and citation of code and data, and open science. We do believe, however, that all of these will be much easier to implement if scientists have the skills we describe.</p>
<boxed-text id="pbio-1001745-box001" position="float">
<sec id="s1a">
<title>Box 1. Summary of Best Practices</title>
<list list-type="order"><list-item>
<p>Write programs for people, not computers.</p>
<list list-type="alpha-lower"><list-item>
<p>A program should not require its readers to hold more than a handful of facts in memory at once.</p>
</list-item><list-item>
<p>Make names consistent, distinctive, and meaningful.</p>
</list-item><list-item>
<p>Make code style and formatting consistent.</p>
</list-item></list>
</list-item><list-item>
<p>Let the computer do the work.</p>
<list list-type="alpha-lower"><list-item>
<p>Make the computer repeat tasks.</p>
</list-item><list-item>
<p>Save recent commands in a file for re-use.</p>
</list-item><list-item>
<p>Use a build tool to automate workflows.</p>
</list-item></list>
</list-item><list-item>
<p>Make incremental changes.</p>
<list list-type="alpha-lower"><list-item>
<p>Work in small steps with frequent feedback and course correction.</p>
</list-item><list-item>
<p>Use a version control system.</p>
</list-item><list-item>
<p>Put everything that has been created manually in version control.</p>
</list-item></list>
</list-item><list-item>
<p>Don't repeat yourself (or others).</p>
<list list-type="alpha-lower"><list-item>
<p>Every piece of data must have a single authoritative representation in the system.</p>
</list-item><list-item>
<p>Modularize code rather than copying and pasting.</p>
</list-item><list-item>
<p>Re-use code instead of rewriting it.</p>
</list-item></list>
</list-item><list-item>
<p>Plan for mistakes.</p>
<list list-type="alpha-lower"><list-item>
<p>Add assertions to programs to check their operation.</p>
</list-item><list-item>
<p>Use an off-the-shelf unit testing library.</p>
</list-item><list-item>
<p>Turn bugs into test cases.</p>
</list-item><list-item>
<p>Use a symbolic debugger.</p>
</list-item></list>
</list-item><list-item>
<p>Optimize software only after it works correctly.</p>
<list list-type="alpha-lower"><list-item>
<p>Use a profiler to identify bottlenecks.</p>
</list-item><list-item>
<p>Write code in the highest-level language possible.</p>
</list-item></list>
</list-item><list-item>
<p>Document design and purpose, not mechanics.</p>
<list list-type="alpha-lower"><list-item>
<p>Document interfaces and reasons, not implementations.</p>
</list-item><list-item>
<p>Refactor code in preference to explaining how it works.</p>
</list-item><list-item>
<p>Embed the documentation for a piece of software in that software.</p>
</list-item></list>
</list-item><list-item>
<p>Collaborate.</p>
<list list-type="alpha-lower"><list-item>
<p>Use pre-merge code reviews.</p>
</list-item><list-item>
<p>Use pair programming when bringing someone new up to speed and when tackling particularly tricky problems.</p>
</list-item><list-item>
<p>Use an issue tracking tool.</p>
</list-item></list>
</list-item></list>
</sec>
</boxed-text>
</sec><sec id="s2">
<title>Write Programs for People, Not Computers</title>
<p>Scientists writing software need to write code that both executes correctly and can be easily read and understood by other programmers (especially the author's future self). If software cannot be easily read and understood, it is much more difficult to know that it is actually doing what it is intended to do. To be productive, software developers must therefore take several aspects of human cognition into account: in particular, that human working memory is limited, human pattern matching abilities are finely tuned, and human attention span is short <xref ref-type="bibr" rid="pbio.1001745-Baddeley1">[33]</xref>–<xref ref-type="bibr" rid="pbio.1001745-Robinson1">[37]</xref>.</p>
<p>First, <bold><italic>a program should not require its readers to hold more than a handful of facts in memory at once (1a)</italic></bold>. Human working memory can hold only a handful of items at a time, where each item is either a single fact or a “chunk” aggregating several facts <xref ref-type="bibr" rid="pbio.1001745-Baddeley1">[33]</xref>,<xref ref-type="bibr" rid="pbio.1001745-Hock1">[34]</xref>, so programs should limit the total number of items to be remembered to accomplish a task. The primary way to accomplish this is to break programs up into easily understood functions, each of which conducts a single, easily understood, task. This serves to make each piece of the program easier to understand in the same way that breaking up a scientific paper using sections and paragraphs makes it easier to read.</p>
<p>Second, scientists should <bold><italic>make names consistent, distinctive, and meaningful (1b)</italic></bold>. For example, using non-descriptive names, like a and foo, or names that are very similar, like results and results2, is likely to cause confusion.</p>
<p>Third, scientists should <bold><italic>make code style and formatting consistent (1c)</italic></bold>. If different parts of a scientific paper used different formatting and capitalization, it would make that paper more difficult to read. Likewise, if different parts of a program are indented differently, or if programmers mix CamelCaseNaming and pothole_case_naming, code takes longer to read and readers make more mistakes <xref ref-type="bibr" rid="pbio.1001745-Letovsky1">[35]</xref>,<xref ref-type="bibr" rid="pbio.1001745-Binkley1">[36]</xref>.</p>
</sec><sec id="s3">
<title>Let the Computer Do the Work</title>
<p>Science often involves repetition of computational tasks such as processing large numbers of data files in the same way or regenerating figures each time new data are added to an existing analysis. Computers were invented to do these kinds of repetitive tasks but, even today, many scientists type the same commands in over and over again or click the same buttons repeatedly <xref ref-type="bibr" rid="pbio.1001745-Aranda1">[17]</xref>. In addition to wasting time, sooner or later even the most careful researcher will lose focus while doing this and make mistakes.</p>
<p>Scientists should therefore <bold><italic>make the computer repeat tasks (2a)</italic></bold> and <bold><italic>save recent commands in a file for re-use (2b)</italic></bold>. For example, most command-line tools have a “history” option that lets users display and re-execute recent commands, with minor edits to filenames or parameters. This is often cited as one reason command-line interfaces remain popular <xref ref-type="bibr" rid="pbio.1001745-Ray1">[38]</xref>,<xref ref-type="bibr" rid="pbio.1001745-Haddock1">[39]</xref>: “do this again” saves time and reduces errors.</p>
<p>A file containing commands for an interactive system is often called a <italic>script</italic>, though there is real no difference between this and a program. When these scripts are repeatedly used in the same way, or in combination, a workflow management tool can be used. The paradigmatic example is compiling and linking programs in languages such as Fortran, C++, Java, and C# <xref ref-type="bibr" rid="pbio.1001745-Dubois1">[40]</xref>. The most widely used tool for this task is probably Make (<ext-link ext-link-type="uri" xlink:href="http://www.gnu.org/software/make" xlink:type="simple">http://www.gnu.org/software/make</ext-link>), although many alternatives are now available <xref ref-type="bibr" rid="pbio.1001745-Smith1">[41]</xref>. All of these allow people to express dependencies between files, i.e., to say that if A or B has changed, then C needs to be updated using a specific set of commands. These tools have been successfully adopted for scientific workflows as well <xref ref-type="bibr" rid="pbio.1001745-Fomel1">[42]</xref>.</p>
<p>To avoid errors and inefficiencies from repeating commands manually, we recommend that scientists <bold><italic>use a build tool to automate workflows (2c)</italic></bold>, e.g., specify the ways in which intermediate data files and final results depend on each other, and on the programs that create them, so that a single command will regenerate anything that needs to be regenerated.</p>
<p>In order to maximize reproducibility, everything needed to re-create the output should be recorded automatically in a format that other programs can read. (Borrowing a term from archaeology and forensics, this is often called the <italic>provenance</italic> of data.) There have been some initiatives to automate the collection of this information, and standardize its format <xref ref-type="bibr" rid="pbio.1001745-Moreau1">[43]</xref>, but it is already possible to record the following without additional tools:</p>
<list list-type="bullet"><list-item>
<p>unique identifiers and version numbers for raw data records (which scientists may need to create themselves);</p>
</list-item><list-item>
<p>unique identifiers and version numbers for programs and libraries;</p>
</list-item><list-item>
<p>the values of parameters used to generate any given output; and</p>
</list-item><list-item>
<p>the names and version numbers of programs (however small) used to generate those outputs.</p>
</list-item></list>
</sec><sec id="s4">
<title>Make Incremental Changes</title>
<p>Unlike traditional commercial software developers, but very much like developers in open source projects or startups, scientific programmers usually don't get their requirements from customers, and their requirements are rarely frozen <xref ref-type="bibr" rid="pbio.1001745-Segal2">[31]</xref>,<xref ref-type="bibr" rid="pbio.1001745-Segal3">[44]</xref>. In fact, scientists often <italic>can't</italic> know what their programs should do next until the current version has produced some results. This challenges design approaches that rely on specifying requirements in advance.</p>
<p>Programmers are most productive when they <bold><italic>work in small steps with frequent feedback and course correction (3a)</italic></bold> rather than trying to plan months or years of work in advance. While the details vary from team to team, these developers typically work in steps that are sized to be about an hour long, and these steps are often grouped in iterations that last roughly one week. This accommodates the cognitive constraints discussed in the first section, and acknowledges the reality that real-world requirements are constantly changing. The goal is to produce working (if incomplete) code after each iteration. While these practices have been around for decades, they gained prominence starting in the late 1990s under the banner of <italic>agile development</italic> <xref ref-type="bibr" rid="pbio.1001745-Martin1">[45]</xref>,<xref ref-type="bibr" rid="pbio.1001745-Kniberg1">[46]</xref>.</p>
<p>Two of the biggest challenges scientists and other programmers face when working with code and data are keeping track of changes (and being able to revert them if things go wrong), and collaborating on a program or dataset <xref ref-type="bibr" rid="pbio.1001745-Matthews1">[23]</xref>. Typical solutions are to email software to colleagues or to copy successive versions of it to a shared folder, e.g., Dropbox (<ext-link ext-link-type="uri" xlink:href="http://www.dropbox.com" xlink:type="simple">http://www.dropbox.com</ext-link>). However, both approaches are fragile and can lead to confusion and lost work when important changes are overwritten or out-of-date files are used. It's also difficult to find out which changes are in which versions or to say exactly how particular results were computed at a later date.</p>
<p>The standard solution in both industry and open source is to <bold><italic>use a version control system (3b)</italic></bold> (VCS) <xref ref-type="bibr" rid="pbio.1001745-Fogel1">[27]</xref>,<xref ref-type="bibr" rid="pbio.1001745-McConnell1">[47]</xref>. A VCS stores snapshots of a project's files in a <italic>repository</italic> (or a set of repositories). Programmers can modify their working copy of the project at will, then <italic>commit</italic> changes to the repository when they are satisfied with the results to share them with colleagues.</p>
<p>Crucially, if several people have edited files simultaneously, the VCS highlights the differences and requires them to resolve any conflicts before accepting the changes. The VCS also stores the entire history of those files, allowing arbitrary versions to be retrieved and compared, together with metadata such as comments on what was changed and the author of the changes. All of this information can be extracted to provide provenance for both code and data.</p>
<p>Many good VCSes are open source and freely available, including Git (<ext-link ext-link-type="uri" xlink:href="http://git-scm.com" xlink:type="simple">http://git-scm.com</ext-link>), Subversion (<ext-link ext-link-type="uri" xlink:href="http://subversion.apache.org" xlink:type="simple">http://subversion.apache.org</ext-link>), and Mercurial (<ext-link ext-link-type="uri" xlink:href="http://mercurial.selenic.com" xlink:type="simple">http://mercurial.selenic.com</ext-link>). Many free hosting services are available as well, with GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com" xlink:type="simple">https://github.com</ext-link>), BitBucket (<ext-link ext-link-type="uri" xlink:href="https://bitbucket.org" xlink:type="simple">https://bitbucket.org</ext-link>), SourceForge (<ext-link ext-link-type="uri" xlink:href="http://sourceforge.net" xlink:type="simple">http://sourceforge.net</ext-link>), and Google Code (<ext-link ext-link-type="uri" xlink:href="http://code.google.com" xlink:type="simple">http://code.google.com</ext-link>) being the most popular. As with coding style, the best one to use is almost always whatever your colleagues are already using <xref ref-type="bibr" rid="pbio.1001745-Fogel1">[27]</xref>.</p>
<p>Reproducibility is maximized when scientists <bold><italic>put everything that has been created manually in version control (3c)</italic></bold>, including programs, original field observations, and the source files for papers. Automated output and intermediate files can be regenerated as needed. Binary files (e.g., images and audio clips) may be stored in version control, but it is often more sensible to use an archiving system for them, and store the metadata describing their contents in version control instead <xref ref-type="bibr" rid="pbio.1001745-Noble1">[48]</xref>.</p>
</sec><sec id="s5">
<title>Don't Repeat Yourself (or Others)</title>
<p>Anything that is repeated in two or more places is more difficult to maintain. Every time a change or correction is made, multiple locations must be updated, which increases the chance of errors and inconsistencies. To avoid this, programmers follow the DRY Principle <xref ref-type="bibr" rid="pbio.1001745-Hunt1">[49]</xref>, for “don't repeat yourself,” which applies to both data and code.</p>
<p>For data, this maxim holds that <bold><italic>every piece of data must have a single authoritative representation in the system (4a)</italic></bold>. Physical constants ought to be defined exactly once to ensure that the entire program is using the same value; raw data files should have a single canonical version, every geographic location from which data has been collected should be given an ID that can be used to look up its latitude and longitude, and so on.</p>
<p>The DRY Principle applies to code at two scales. At small scales, <bold><italic>modularize code rather than copying and pasting (4b)</italic></bold>. Avoiding “code clones” has been shown to reduce error rates <xref ref-type="bibr" rid="pbio.1001745-Juergens1">[50]</xref>: when a change is made or a bug is fixed, that change or fix takes effect everywhere, and people's mental model of the program (i.e., their belief that “this one's been fixed”) remains accurate. As a side effect, modularizing code allows people to remember its functionality as a single mental chunk, which in turn makes code easier to understand. Modularized code can also be more easily repurposed for other projects.</p>
<p>At larger scales, it is vital that scientific programmers <bold><italic>re-use code instead of rewriting it (4c)</italic></bold>. Tens of millions of lines of high-quality open source software are freely available on the web, and at least as much is available commercially. It is typically better to find an established library or package that solves a problem than to attempt to write one's own routines for well established problems (e.g., numerical integration, matrix inversions, etc.).</p>
</sec><sec id="s6">
<title>Plan for Mistakes</title>
<p>Mistakes are inevitable, so verifying and maintaining the validity of code over time is immensely challenging <xref ref-type="bibr" rid="pbio.1001745-Grubb1">[51]</xref>. While no single practice has been shown to catch or prevent all mistakes, several are very effective when used in combination <xref ref-type="bibr" rid="pbio.1001745-McConnell1">[47]</xref>,<xref ref-type="bibr" rid="pbio.1001745-Dubois2">[52]</xref>,<xref ref-type="bibr" rid="pbio.1001745-Sanders1">[53]</xref>.</p>
<p>The first line of defense is <italic>defensive programming</italic>. Experienced programmers <bold><italic>add assertions to programs to check their operation (5a)</italic></bold> because experience has taught them that everyone (including their future self) makes mistakes. An <italic>assertion</italic> is simply a statement that something holds true at a particular point in a program; as the example below shows, assertions can be used to ensure that inputs are valid, outputs are consistent, and so on.<disp-formula id="pbio.1001745.e001"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pbio.1001745.e001" xlink:type="simple"/></disp-formula>Assertions can make up a sizeable fraction of the code in well-written applications, just as tools for calibrating scientific instruments can make up a sizeable fraction of the equipment in a lab. These assertions serve two purposes. First, they ensure that if something does go wrong, the program will halt immediately, which simplifies debugging. Second, assertions are <italic>executable documentation</italic>, i.e., they explain the program as well as checking its behavior. This makes them more useful in many cases than comments since the reader can be sure that they are accurate and up to date.</p>
<p>The second layer of defense is <italic>automated testing</italic>. Automated tests can check to make sure that a single unit of code is returning correct results (<italic>unit tests</italic>), that pieces of code work correctly when combined (<italic>integration tests</italic>), and that the behavior of a program doesn't change when the details are modified (<italic>regression tests</italic>). These tests are conducted by the computer, so that they are easy to rerun every time the program is modified. Creating and managing tests is easier if programmers <bold><italic>use an off-the-shelf unit testing library (5b)</italic></bold> to initialize inputs, run tests, and report their results in a uniform way. These libraries are available for all major programming languages including those commonly used in scientific computing <xref ref-type="bibr" rid="pbio.1001745-List1">[54]</xref>–<xref ref-type="bibr" rid="pbio.1001745-Osherove1">[56]</xref>.</p>
<p>Tests check to see whether the code matches the researcher's expectations of its behavior, which depends on the researcher's understanding of the problem at hand <xref ref-type="bibr" rid="pbio.1001745-Hook1">[57]</xref>–<xref ref-type="bibr" rid="pbio.1001745-Oberkampf1">[59]</xref>. For example, in scientific computing, tests are often conducted by comparing output to simplified cases, experimental data, or the results of earlier programs that are trusted. Another approach for generating tests is to <bold><italic>turn bugs into test cases (5c)</italic></bold> by writing tests that trigger a bug that has been found in the code and (once fixed) will prevent the bug from reappearing unnoticed. In combination these kinds of testing can improve our confidence that scientific code is operating properly and that the results it produces are valid. An additional benefit of testing is that it encourages programmers to design and build code that is testable (i.e., self-contained functions and classes that can run more or less independently of one another). Code that is designed this way is also easier to understand and more reusable.</p>
<p>No matter how good one's computational practice is, reasonably complex code will always initially contain bugs. Fixing bugs that have been identified is often easier if you <bold><italic>use a symbolic debugger (5d)</italic></bold> to track them down. A better name for this kind of tool would be “interactive program inspector” since a debugger allows users to pause a program at any line (or when some condition is true), inspect the values of variables, and walk up and down active function calls to figure out why things are behaving the way they are. Debuggers are usually more productive than adding and removing print statements or scrolling through hundreds of lines of log output <xref ref-type="bibr" rid="pbio.1001745-Zeller1">[60]</xref>, because they allow the user to see exactly how the code is executing rather than just snapshots of state of the program at a few moments in time. In other words, the debugger allows the scientist to witness what is going wrong directly, rather than having to anticipate the error or infer the problem using indirect evidence.</p>
</sec><sec id="s7">
<title>Optimize Software Only after It Works Correctly</title>
<p>Today's computers and software are so complex that even experts find it hard to predict which parts of any particular program will be performance bottlenecks <xref ref-type="bibr" rid="pbio.1001745-Jones1">[61]</xref>. The most productive way to make code fast is therefore to make it work correctly, determine whether it's actually worth speeding it up, and—in those cases where it is—to <bold><italic>use a profiler to identify bottlenecks (6a)</italic></bold>.</p>
<p>This strategy also has interesting implications for choice of programming language. Research has confirmed that most programmers write roughly the same number of lines of code per unit time regardless of the language they use <xref ref-type="bibr" rid="pbio.1001745-Prechelt1">[62]</xref>. Since faster, lower level, languages require more lines of code to accomplish the same task, scientists are most productive when they <bold><italic>write code in the highest-level language possible (6b)</italic></bold>, and shift to low-level languages like C and Fortran only when they are sure the performance boost is needed. (Using higher-level languages also helps program comprehensibility, since such languages have, in a sense, “pre-chunked” the facts that programmers need to have in short-term memory.)</p>
<p>Taking this approach allows more code to be written (and tested) in the same amount of time. Even when it is known before coding begins that a low-level language will ultimately be necessary, rapid prototyping in a high-level language helps programmers make and evaluate design decisions quickly. Programmers can also use a high-level prototype as a test oracle for a high-performance low-level reimplementation, i.e., compare the output of the optimized (and usually more complex) program against the output from its unoptimized (but usually simpler) predecessor in order to check its correctness.</p>
</sec><sec id="s8">
<title>Document Design and Purpose, Not Mechanics</title>
<p>In the same way that a well documented experimental protocol makes research methods easier to reproduce, good documentation helps people understand code. This makes the code more reusable and lowers maintenance costs <xref ref-type="bibr" rid="pbio.1001745-McConnell1">[47]</xref>. As a result, code that is well documented makes it easier to transition when the graduate students and postdocs who have been writing code in a lab transition to the next career phase. Reference documentation and descriptions of design decisions are key for improving the understandability of code. However, inline documentation that recapitulates code is <italic>not</italic> useful. Therefore we recommend that scientific programmers <bold><italic>document interfaces and reasons, not implementations (7a)</italic></bold>. For example, a clear description like this at the beginning of a function that describes what it does and its inputs and outputs is useful:<disp-formula id="pbio.1001745.e002"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pbio.1001745.e002" xlink:type="simple"/></disp-formula>In contrast, the comment in the code fragment below does nothing to aid comprehension:<disp-formula id="pbio.1001745.e003"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pbio.1001745.e003" xlink:type="simple"/></disp-formula>If a substantial description of the implementation of a piece of software is needed, it is better to <bold><italic>refactor code in preference to explaining how it works (7b)</italic></bold>, i.e., rather than write a paragraph to explain a complex piece of code, reorganize the code itself so that it doesn't need such an explanation. This may not always be possible—some pieces of code are intrinsically difficult—but the onus should always be on the author to convince his or her peers of that.</p>
<p>The best way to create and maintain reference documentation is to <bold><italic>embed the documentation for a piece of software in that software (7c)</italic></bold>. Doing this increases the probability that when programmers change the code, they will update the documentation at the same time.</p>
<p>Embedded documentation usually takes the form of specially-formatted and placed comments. Typically, a <italic>documentation generator</italic> such as Javadoc, Doxygen, or Sphinx extracts these comments and generates well-formatted web pages and other human-friendly documents (<ext-link ext-link-type="uri" xlink:href="http://en.wikipedia.org/wiki/Comparison_of_documentation_generators" xlink:type="simple">http://en.wikipedia.org/wiki/Comparison_of_documentation_generators</ext-link>). Alternatively, code can be embedded in a larger document that includes information about what the code is doing (i.e., literate programming). Common approaches to this include this use of knitr <xref ref-type="bibr" rid="pbio.1001745-Xie1">[63]</xref> and IPython Notebooks <xref ref-type="bibr" rid="pbio.1001745-Prez1">[64]</xref>.</p>
</sec><sec id="s9">
<title>Collaborate</title>
<p>In the same way that having manuscripts reviewed by other scientists can reduce errors and make research easier to understand, reviews of source code can eliminate bugs and improve readability. A large body of research has shown that <italic>code reviews</italic> are the most cost-effective way of finding bugs in code <xref ref-type="bibr" rid="pbio.1001745-Fagan1">[65]</xref>,<xref ref-type="bibr" rid="pbio.1001745-Cohen1">[66]</xref>. They are also a good way to spread knowledge and good practices around a team. In projects with shifting membership, such as most academic labs, code reviews help ensure that critical knowledge isn't lost when a student or postdoc leaves the lab.</p>
<p>Code can be reviewed either before or after it has been committed to a shared version control repository. Experience shows that if reviews don't have to be done in order to get code into the repository, they will soon not be done at all <xref ref-type="bibr" rid="pbio.1001745-Fogel1">[27]</xref>. We therefore recommend that projects <bold><italic>use pre-merge code reviews (8a)</italic></bold>.</p>
<p>An extreme form of code review is <italic>pair programming</italic>, in which two developers sit together while writing code. One (the driver) actually writes the code; the other (the navigator) provides real-time feedback and is free to track larger issues of design and consistency. Several studies have found that pair programming improves productivity <xref ref-type="bibr" rid="pbio.1001745-Williams1">[67]</xref>, but many programmers find it intrusive. We therefore recommend that teams <bold><italic>use pair programming when bringing someone new up to speed and when tackling particularly tricky problems (8b)</italic></bold>.</p>
<p>Once a team grows beyond a certain size, it becomes difficult to keep track of what needs to be reviewed, or of who's doing what. Teams can avoid a lot of duplicated effort and dropped balls if they <bold><italic>use an issue tracking tool (8c)</italic></bold> to maintain a list of tasks to be performed and bugs to be fixed <xref ref-type="bibr" rid="pbio.1001745-Dubois3">[68]</xref>. This helps avoid duplicated work and makes it easier for tasks to be transferred to different people. Free repository hosting services like GitHub include issue tracking tools, and many good standalone tools exist as well, such as Trac (<ext-link ext-link-type="uri" xlink:href="http://trac.edgewall.org" xlink:type="simple">http://trac.edgewall.org</ext-link>).</p>
</sec><sec id="s10">
<title>Conclusion</title>
<p>We have outlined a series of recommended best practices for scientific computing based on extensive research, as well as our collective experience. These practices can be applied to individual work as readily as group work; separately and together, they improve the productivity of scientific programming and the reliability of the resulting code, and therefore the speed with which we produce results and our confidence in them. They are also, we believe, prerequisites for reproducible computational research: if software is not version controlled, readable, and tested, the chances of its authors (much less anyone else) being able to re-create results are remote.</p>
<p>Our 24 recommendations are a beginning, not an end. Individuals and groups who have incorporated them into their work will find links to more advanced practices at Software Carpentry (<ext-link ext-link-type="uri" xlink:href="http://software-carpentry.org" xlink:type="simple">http://software-carpentry.org</ext-link>).</p>
<p>Research suggests that the time cost of implementing these kinds of tools and approaches in scientific computing is almost immediately offset by the gains in productivity of the programmers involved <xref ref-type="bibr" rid="pbio.1001745-Aranda1">[17]</xref>. Even so, the recommendations described above may seem intimidating to implement. Fortunately, the different practices reinforce and support one another, so the effort required is less than the sum of adding each component separately. Nevertheless, we do not recommend that research groups attempt to implement all of these recommendations at once, but instead suggest that these tools be introduced incrementally over a period of time.</p>
<p>How to implement the recommended practices can be learned from many excellent tutorials available online or through workshops and classes organized by groups like Software Carpentry. This type of training has proven effective at driving adoption of these tools in scientific settings <xref ref-type="bibr" rid="pbio.1001745-Aranda1">[17]</xref>,<xref ref-type="bibr" rid="pbio.1001745-Wilson2">[69]</xref>.</p>
<p>For computing to achieve the level of rigor that is expected throughout other parts of science, it is necessary for scientists to begin to adopt the tools and approaches that are known to improve both the quality of software and the efficiency with which it is produced. To facilitate this adoption, universities and funding agencies need to support the training of scientists in the use of these tools and the investment of time and money in building better scientific software. Investment in these approaches by both individuals and institutions will improve our confidence in the results of computational science and will allow us to make more rapid progress on important scientific questions than would otherwise be possible.</p>
</sec></body>
<back>
<ack>
<p>We are grateful to Joel Adamson, Aron Ahmadia, Roscoe Bartlett, Erik Bray, Stephen Crouch, Michael Jackson, Justin Kitzes, Adam Obeng, Karthik Ram, Yoav Ram, and Tracy Teal for feedback on this paper.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pbio.1001745-Hannay1"><label>1</label>
<mixed-citation publication-type="other" xlink:type="simple">Hannay JE, Langtangen HP, MacLeod C, Pfahl D, Singer J, <etal>et al</etal>.. (2009) How do scientists develop and use scientific software? In: Proceedings Second International Workshop on Software Engineering for Computational Science and Engineering. pp. 1–8. doi:10.1109/SECSE.2009.5069155.</mixed-citation>
</ref>
<ref id="pbio.1001745-Prabhu1"><label>2</label>
<mixed-citation publication-type="other" xlink:type="simple">Prabhu P, Jablin TB, Raman A, Zhang Y, Huang J, <etal>et al</etal>.. (2011) A survey of the practice of computational science. In: Proceedings 24th ACM/IEEE Conference on High Performance Computing, Networking, Storage and Analysis. pp. 19:1–19:12. doi:10.1145/2063348.2063374.</mixed-citation>
</ref>
<ref id="pbio.1001745-Vardi1"><label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Vardi</surname><given-names>M</given-names></name> (<year>2010</year>) <article-title>Science has only two legs</article-title>. <source>Communications of the ACM</source> <volume>53</volume>: <fpage>5</fpage>.</mixed-citation>
</ref>
<ref id="pbio.1001745-Hatton1"><label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hatton</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Roberts</surname><given-names>A</given-names></name> (<year>1994</year>) <article-title>How accurate is scientific software?</article-title> <source>IEEE T Software Eng</source> <volume>20</volume>: <fpage>785</fpage>–<lpage>797</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001745-Hatton2"><label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hatton</surname><given-names>L</given-names></name> (<year>1997</year>) <article-title>The T experiments: errors in scientific software</article-title>. <source>Computational Science &amp; Engineering</source> <volume>4</volume>: <fpage>27</fpage>–<lpage>38</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001745-Merali1"><label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Merali</surname><given-names>Z</given-names></name> (<year>2010</year>) <article-title>Error: why scientific programming does not compute</article-title>. <source>Nature</source> <volume>467</volume>: <fpage>775</fpage>–<lpage>777</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001745-Chang1"><label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chang</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Roth</surname><given-names>CB</given-names></name>, <name name-style="western"><surname>Reyes</surname><given-names>CL</given-names></name>, <name name-style="western"><surname>Pornillos</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Chen</surname><given-names>YJ</given-names></name>, <etal>et al</etal>. (<year>2006</year>) <article-title>Retraction</article-title>. <source>Science</source> <volume>314</volume>: <fpage>1875</fpage>.</mixed-citation>
</ref>
<ref id="pbio.1001745-Ferrari1"><label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ferrari</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Jung</surname><given-names>YL</given-names></name>, <name name-style="western"><surname>Kharchenko</surname><given-names>PV</given-names></name>, <name name-style="western"><surname>Plachetka</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Alekseyenko</surname><given-names>AA</given-names></name>, <etal>et al</etal>. (<year>2013</year>) <article-title>Comment on “Drosophila dosage compensation involves enhanced Pol II recruitment to male X-Linked promoters”</article-title>. <source>Science</source> <volume>340</volume>: <fpage>273</fpage>.</mixed-citation>
</ref>
<ref id="pbio.1001745-Ma1"><label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ma</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Chang</surname><given-names>G</given-names></name> (<year>2007</year>) <article-title>Retraction for Ma and Chang, structure of the multidrug resistance efflux transporter EmrE from <italic>Escherichia coli</italic></article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>104</volume>: <fpage>3668</fpage>.</mixed-citation>
</ref>
<ref id="pbio.1001745-Chang2"><label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chang</surname><given-names>G</given-names></name> (<year>2007</year>) <article-title>Retraction of ‘Structure of MsbA from Vibrio cholera: A Multidrug Resistance ABC Transporter Homolog in a Closed Conformation’ [J. Mol. Biol. (2003) 330 419430]</article-title>. <source>Journal of Molecular Biology</source> <volume>369</volume>: <fpage>596</fpage>.</mixed-citation>
</ref>
<ref id="pbio.1001745-Lees1"><label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lees</surname><given-names>DC</given-names></name>, <name name-style="western"><surname>Colwell</surname><given-names>RK</given-names></name> (<year>2007</year>) <article-title>A strong Madagascan rainforest MDE and no equatorward increase in species richness: re-analysis of ‘The Missing Madagascan Mid-Domain Effect’, by Kerr JT, Perring M, Currie DJ (Ecol Lett 9:149159, 2006)</article-title>. <source>Ecol Lett</source> <volume>10</volume>: <fpage>E4</fpage>–<lpage>E8</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001745-Currie1"><label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Currie</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Kerr</surname><given-names>J</given-names></name> (<year>2007</year>) <article-title>Testing, as opposed to supporting, the mid-domain hypothesis: a response to lees and colwell</article-title>. <source>Ecol Lett</source> <volume>10</volume>: <fpage>E9</fpage>–<lpage>E10</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001745-Kelt1"><label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kelt</surname><given-names>DA</given-names></name>, <name name-style="western"><surname>Wilson</surname><given-names>JA</given-names></name>, <name name-style="western"><surname>Konno</surname><given-names>ES</given-names></name>, <name name-style="western"><surname>Braswell</surname><given-names>JD</given-names></name>, <name name-style="western"><surname>Deutschman</surname><given-names>D</given-names></name> (<year>2008</year>) <article-title>Differential responses of two species of kangaroo rat (Dipodomys) to heavy rains: a humbling reappraisal</article-title>. <source>J Mammal</source> <volume>89</volume>: <fpage>252</fpage>–<lpage>254</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001745-Anon1"><label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple"><collab xlink:type="simple">Anon</collab> (<year>2013</year>) <article-title>Retraction notice to “Plasma PCSK9 levels and clinical outcomes in the TNT (Treating to New Targets) Trial” [J Am Coll Cardiol 2012;59:17781784]</article-title>. <source>J Am Coll Cardiol</source> <volume>61</volume>: <fpage>1751</fpage>.</mixed-citation>
</ref>
<ref id="pbio.1001745-1"><label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple"><article-title>Hypertension 60: e29. Retraction. Implications of new hypertension guidelines in the United States. Retraction of Bertoia ML, Waring ME, Gupta PS, Roberts MB, Eaton CB</article-title>. <source>Hypertension (2011)</source> <volume>58</volume>: <fpage>361</fpage>–<lpage>366</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001745-Herndon1"><label>16</label>
<mixed-citation publication-type="other" xlink:type="simple">Herndon T, Ash M, Pollin R (2013). Does high public debt consistently stifle economic growth? A critique of Reinhart and Rogoff. Working paper, Political Economy Research Institute. Available: <ext-link ext-link-type="uri" xlink:href="http://www.peri.umass.edu/fileadmin/pdf/working" xlink:type="simple">http://www.peri.umass.edu/fileadmin/pdf/working</ext-link> papers/working papers 301-350/WP322.pdf.</mixed-citation>
</ref>
<ref id="pbio.1001745-Aranda1"><label>17</label>
<mixed-citation publication-type="other" xlink:type="simple">Aranda J (2012). Software carpentry assessment report. Available: <ext-link ext-link-type="uri" xlink:href="http://software-carpentry.org/papers/arandaassessment-2012-07.pdf" xlink:type="simple">http://software-carpentry.org/papers/arandaassessment-2012-07.pdf</ext-link>.</mixed-citation>
</ref>
<ref id="pbio.1001745-Wilson1"><label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wilson</surname><given-names>G</given-names></name> (<year>2006</year>) <article-title>Software carpentry: getting scientists to write better code by making them more productive</article-title>. <source>Comput Sci Eng</source> <fpage>66</fpage>–<lpage>69</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001745-Heroux1"><label>19</label>
<mixed-citation publication-type="other" xlink:type="simple">Heroux MA, Willenbring JM (2009) Barely-sufficient software engineering: 10 practices to improve your CSE software. In: Proceedings Second International Workshop on Software Engineering for Computational Science and Engineering. pp. 15–21. 10.1109/SECSE.2009.5069157.</mixed-citation>
</ref>
<ref id="pbio.1001745-Kane1"><label>20</label>
<mixed-citation publication-type="other" xlink:type="simple">Kane D (2003) Introducing agile development into bioinformatics: an experience report. In: Proceedings of the Conference on Agile Development, IEEE Computer Society, Washington (D.C.); 2003, 0-7695-2013-8, pp. 132–139, 10.1109/ADC.2003.1231463.</mixed-citation>
</ref>
<ref id="pbio.1001745-Kane2"><label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kane</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Hohman</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Cerami</surname><given-names>E</given-names></name>, <name name-style="western"><surname>McCormick</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Kuhlmman</surname><given-names>K</given-names></name>, <etal>et al</etal>. (<year>2006</year>) <article-title>Agile methods in biomedical software development: a multi-site experience report</article-title>. <source>BMC Bioinformatics</source> <volume>7</volume>: <fpage>273</fpage>.</mixed-citation>
</ref>
<ref id="pbio.1001745-Killcoyne1"><label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Killcoyne</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Boyle</surname><given-names>J</given-names></name> (<year>2009</year>) <article-title>Managing chaos: lessons learned developing software in the life sciences</article-title>. <source>Comput Sci Eng</source> <volume>11</volume>: <fpage>20</fpage>–<lpage>29</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001745-Matthews1"><label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Matthews</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Wilson</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Easterbrook</surname><given-names>S</given-names></name> (<year>2008</year>) <article-title>Configuration management for large-scale scientific computing at the UK Met office</article-title>. <source>Comput Sci Eng</source> <fpage>56</fpage>–<lpage>64</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001745-PittFrancis1"><label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pitt-Francis</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Bernabeu</surname><given-names>MO</given-names></name>, <name name-style="western"><surname>Cooper</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Garny</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Momtahan</surname><given-names>L</given-names></name>, <etal>et al</etal>. (<year>2008</year>) <article-title>Chaste: using agile programming techniques to develop computational biology software</article-title>. <source>Philos Trans A Math Phys Eng Sci</source> <volume>366</volume>: <fpage>3111</fpage>–<lpage>3136</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001745-Pouillon1"><label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pouillon</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Beuken</surname><given-names>JM</given-names></name>, <name name-style="western"><surname>Deutsch</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Torrent</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Gonze</surname><given-names>X</given-names></name> (<year>2011</year>) <article-title>Organizing software growth and distributed development: the case of abinit</article-title>. <source>Comput Sci Eng</source> <volume>13</volume>: <fpage>62</fpage>–<lpage>69</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001745-Spolsky1"><label>26</label>
<mixed-citation publication-type="other" xlink:type="simple">Spolsky J (2000). The Joel test: 12 steps to better code. Available: <ext-link ext-link-type="uri" xlink:href="http://www.joelonsoftware.com/articles/fog0000000043.html" xlink:type="simple">http://www.joelonsoftware.com/articles/fog0000000043.html</ext-link>. Accessed September 2013.</mixed-citation>
</ref>
<ref id="pbio.1001745-Fogel1"><label>27</label>
<mixed-citation publication-type="book" xlink:type="simple">Fogel K (2005) Producing open source software: how to run a successful free software project. Sepastopol (California): O'Reilly. Available: <ext-link ext-link-type="uri" xlink:href="http://producingoss.com" xlink:type="simple">http://producingoss.com</ext-link>.</mixed-citation>
</ref>
<ref id="pbio.1001745-Carver1"><label>28</label>
<mixed-citation publication-type="other" xlink:type="simple">Carver JC, Kendall RP, Squires SE, Post DE (2007) Software development environments for scientific and engineering software: a series of case studies. In: Proceedings 29th International Conference on Software Engineering. pp. 550–559. 10.1109/ICSE.2007.77.</mixed-citation>
</ref>
<ref id="pbio.1001745-Kelly1"><label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kelly</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Hook</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Sanders</surname><given-names>R</given-names></name> (<year>2009</year>) <article-title>Five recommended practices for computational scientists who write software</article-title>. <source>Comput Sci Eng</source> <volume>11</volume>: <fpage>48</fpage>–<lpage>53</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001745-Segal1"><label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Segal</surname><given-names>J</given-names></name> (<year>2005</year>) <article-title>When software engineers met research scientists: a case study</article-title>. <source>Empir Softw Eng</source> <volume>10</volume>: <fpage>517</fpage>–<lpage>536</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001745-Segal2"><label>31</label>
<mixed-citation publication-type="other" xlink:type="simple">Segal J (2008) Models of scientific software development. In: Proceedings First International Workshop on Software Engineering for Computational Science and Engineering. Available: <ext-link ext-link-type="uri" xlink:href="http://secse08.cs.ua.edu/Papers/Segal.pdf" xlink:type="simple">http://secse08.cs.ua.edu/Papers/Segal.pdf</ext-link>.</mixed-citation>
</ref>
<ref id="pbio.1001745-Oram1"><label>32</label>
<mixed-citation publication-type="book" xlink:type="simple">Oram A, Wilson G, editors(2010) Making software: what really works, and why we believe it. Sepastopol (California): O'Reilly.</mixed-citation>
</ref>
<ref id="pbio.1001745-Baddeley1"><label>33</label>
<mixed-citation publication-type="book" xlink:type="simple">Baddeley A, Eysenck MW, Anderson MC (2009) Memory. New York: Psychology Press.</mixed-citation>
</ref>
<ref id="pbio.1001745-Hock1"><label>34</label>
<mixed-citation publication-type="book" xlink:type="simple">Hock RR (2008) Forty studies that changed psychology: explorations into the history of psychological research, 6th edition. Upper Saddle River (New Jersey): Prentice Hall.</mixed-citation>
</ref>
<ref id="pbio.1001745-Letovsky1"><label>35</label>
<mixed-citation publication-type="other" xlink:type="simple">Letovsky S (1986) Cognitive processes in program comprehension. In: Proceedings First Workshop on Empirical Studies of Programmers. pp. 58–79. 10.1016/0164-1212(87)90032-X.</mixed-citation>
</ref>
<ref id="pbio.1001745-Binkley1"><label>36</label>
<mixed-citation publication-type="other" xlink:type="simple">Binkley D, Davis M, Lawrie D, Morrell C (2009) To CamelCase or under_score. In: Proceedings 2009 IEEE International Conference on Program Comprehension. pp. 158–167. 10.1109/ICPC.2009.5090039.</mixed-citation>
</ref>
<ref id="pbio.1001745-Robinson1"><label>37</label>
<mixed-citation publication-type="other" xlink:type="simple">Robinson E (2005) Why crunch mode doesn't work: six lessons. Available: <ext-link ext-link-type="uri" xlink:href="http://www.igda.org/why-crunch-modes-doesnt-work-six-lessons" xlink:type="simple">http://www.igda.org/why-crunch-modes-doesnt-work-six-lessons</ext-link>. Accessed: September 2013.</mixed-citation>
</ref>
<ref id="pbio.1001745-Ray1"><label>38</label>
<mixed-citation publication-type="book" xlink:type="simple">Ray DS, Ray EJ (2009) Unix and Linux: visual quickstart guide. 4th edition. San Francisco: Peachpit Press.</mixed-citation>
</ref>
<ref id="pbio.1001745-Haddock1"><label>39</label>
<mixed-citation publication-type="book" xlink:type="simple">Haddock S, Dunn C (2010) Practical computing for biologists. Sunderland (Massachusetts): Sinauer Associates.</mixed-citation>
</ref>
<ref id="pbio.1001745-Dubois1"><label>40</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dubois</surname><given-names>PF</given-names></name>, <name name-style="western"><surname>Epperly</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Kumfert</surname><given-names>G</given-names></name> (<year>2003</year>) <article-title>Why Johnny can't build (portable scientific software)</article-title>. <source>Comput Sci Eng</source> <volume>5</volume>: <fpage>83</fpage>–<lpage>88</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001745-Smith1"><label>41</label>
<mixed-citation publication-type="book" xlink:type="simple">Smith P (2011) Software build systems: principles and experience. Boston: Addison-Wesley.</mixed-citation>
</ref>
<ref id="pbio.1001745-Fomel1"><label>42</label>
<mixed-citation publication-type="other" xlink:type="simple">Fomel S, Hennenfent G (2007) Reproducible computational experiments using SCons. In: Proceedings 32nd International Conference on Acoustics, Speech, and Signal Processing. volume IV, pp. 1257–1260. 10.1109/ICASSP.2007.367305.</mixed-citation>
</ref>
<ref id="pbio.1001745-Moreau1"><label>43</label>
<mixed-citation publication-type="other" xlink:type="simple">Moreau L, Freire J, Futrelle J, McGrath RE, Myers J, <etal>et al</etal>.. (2007) The open provenance model (v1.00). Technical report, University of Southampton. Accessed September 2013.</mixed-citation>
</ref>
<ref id="pbio.1001745-Segal3"><label>44</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Segal</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Morris</surname><given-names>C</given-names></name> (<year>2008</year>) <article-title>Developing scientific software</article-title>. <source>IEEE Software</source> <volume>25</volume>: <fpage>18</fpage>–<lpage>20</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001745-Martin1"><label>45</label>
<mixed-citation publication-type="book" xlink:type="simple">Martin RC (2002) Agile software development, principles, patterns, and practices. Upper Saddle River (New Jersey): Prentice Hall.</mixed-citation>
</ref>
<ref id="pbio.1001745-Kniberg1"><label>46</label>
<mixed-citation publication-type="other" xlink:type="simple">Kniberg H (2007) Scrum and XP from the trenches. C4Media, 978-1-4303-2264-1, Available from <ext-link ext-link-type="uri" xlink:href="http://www.infoq.com/minibooks/scrum-xp-from-the-trenches" xlink:type="simple">http://www.infoq.com/minibooks/scrum-xp-from-the-trenches</ext-link>.</mixed-citation>
</ref>
<ref id="pbio.1001745-McConnell1"><label>47</label>
<mixed-citation publication-type="book" xlink:type="simple">McConnell S (2004) Code complete: a practical handbook of software construction, 2nd edition. Seattle: Microsoft Press.</mixed-citation>
</ref>
<ref id="pbio.1001745-Noble1"><label>48</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Noble</surname><given-names>WS</given-names></name> (<year>2009</year>) <article-title>A quick guide to organizing computational biology projects</article-title>. <source>PLoS Comput Biol</source> <volume>5</volume>: <fpage>e1000424</fpage> <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1000424" xlink:type="simple">10.1371/journal.pcbi.1000424</ext-link></comment></mixed-citation>
</ref>
<ref id="pbio.1001745-Hunt1"><label>49</label>
<mixed-citation publication-type="book" xlink:type="simple">Hunt A, Thomas D (1999) The pragmatic programmer: from journeyman to master. Boston: Addison-Wesley.</mixed-citation>
</ref>
<ref id="pbio.1001745-Juergens1"><label>50</label>
<mixed-citation publication-type="other" xlink:type="simple">Juergens E, Deissenboeck F, Hummel B, Wagner S (2009) Do code clones matter? In: Proceedings 31st International Conference on Software Engineering. pp. 485–495. 10.1109/ICSE.2009.5070547.</mixed-citation>
</ref>
<ref id="pbio.1001745-Grubb1"><label>51</label>
<mixed-citation publication-type="book" xlink:type="simple">Grubb P, Takang AA (2003) Software maintenance: concepts and practice, 2nd edition. Singapore: World Scientific.</mixed-citation>
</ref>
<ref id="pbio.1001745-Dubois2"><label>52</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dubois</surname><given-names>PF</given-names></name> (<year>2005</year>) <article-title>Maintaining correctness in scientific programs</article-title>. <source>Comput Sci Eng</source> <volume>7</volume>: <fpage>80</fpage>–<lpage>85</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001745-Sanders1"><label>53</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sanders</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Kelly</surname><given-names>D</given-names></name> (<year>2008</year>) <article-title>Dealing with risk in scientific software development</article-title>. <source>IEEE Software</source> <volume>25</volume>: <fpage>21</fpage>–<lpage>28</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001745-List1"><label>54</label>
<mixed-citation publication-type="other" xlink:type="simple">List of unit testing frameworks. Available: <ext-link ext-link-type="uri" xlink:href="http://en.wikipedia.org/wiki/List" xlink:type="simple">http://en.wikipedia.org/wiki/List</ext-link> of unit testing frameworks. Accessed September 2013.</mixed-citation>
</ref>
<ref id="pbio.1001745-Meszaros1"><label>55</label>
<mixed-citation publication-type="book" xlink:type="simple">Meszaros G (2007) xUnit test patterns: refactoring test code. Boston: Addison-Wesley.</mixed-citation>
</ref>
<ref id="pbio.1001745-Osherove1"><label>56</label>
<mixed-citation publication-type="book" xlink:type="simple">Osherove R (2009) The art of unit testing: with examples in.NET. Greenwich (Connecticut): Manning.</mixed-citation>
</ref>
<ref id="pbio.1001745-Hook1"><label>57</label>
<mixed-citation publication-type="other" xlink:type="simple">Hook D, Kelly D (2009) Testing for trustworthiness in scientific software. In: Proceedings Second International Workshop on Software Engineering for Computational Science and Engineering. pp. 59–64. 10.1109/SECSE.2009.5069163.</mixed-citation>
</ref>
<ref id="pbio.1001745-Kelly2"><label>58</label>
<mixed-citation publication-type="other" xlink:type="simple">Kelly D, Sanders R (2008) Assessing the quality of scientific software. In: Proceedings First International Workshop on Software Engineering for Computational Science and Engineering. Available: <ext-link ext-link-type="uri" xlink:href="http://secse08.cs.ua.edu/Papers/Kelly.pdf" xlink:type="simple">http://secse08.cs.ua.edu/Papers/Kelly.pdf</ext-link>.</mixed-citation>
</ref>
<ref id="pbio.1001745-Oberkampf1"><label>59</label>
<mixed-citation publication-type="book" xlink:type="simple">Oberkampf WL, Roy CJ (2010) Verification and validation in scientific computing. Cambridge: Cambridge University Press.</mixed-citation>
</ref>
<ref id="pbio.1001745-Zeller1"><label>60</label>
<mixed-citation publication-type="book" xlink:type="simple">Zeller A (2009) Why programs fail: a guide to systematic debugging. Burlington (Massachusetts): Morgan Kaufmann.</mixed-citation>
</ref>
<ref id="pbio.1001745-Jones1"><label>61</label>
<mixed-citation publication-type="other" xlink:type="simple">Jones MB, Regehr J (1999) The problems you're having may not be the problems you think you're having: results from a latency study of Windows NT. In: Proceedings 7th Workshop on Hot Topics in Operating Systems. pp. 96–101. 10.1109/RTTAS.1999.777681.</mixed-citation>
</ref>
<ref id="pbio.1001745-Prechelt1"><label>62</label>
<mixed-citation publication-type="book" xlink:type="simple">Prechelt L (2010) Two comparisons of programming languages. Oram A, Wilson G, editors. Making software: what really works, and why we believe it. Sepastopol (California): O'Reilly. pp. 239–258.</mixed-citation>
</ref>
<ref id="pbio.1001745-Xie1"><label>63</label>
<mixed-citation publication-type="other" xlink:type="simple">Xie Y (2013). knitr: A general-purpose tool for dynamic report generation in r. R package version 0.9. Available: <ext-link ext-link-type="uri" xlink:href="http://yihui.name/knitr/" xlink:type="simple">http://yihui.name/knitr/</ext-link>.</mixed-citation>
</ref>
<ref id="pbio.1001745-Prez1"><label>64</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pérez</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Granger</surname><given-names>BE</given-names></name> (<year>2007</year>) <article-title>IPython: a system for interactive scientific computing</article-title>. <source>Comput Sci Eng</source> <volume>9</volume>: <fpage>21</fpage>–<lpage>29</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001745-Fagan1"><label>65</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fagan</surname><given-names>ME</given-names></name> (<year>1976</year>) <article-title>Design and code inspections to reduce errors in program development</article-title>. <source>IBM Syst J</source> <volume>15</volume>: <fpage>182</fpage>–<lpage>211</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001745-Cohen1"><label>66</label>
<mixed-citation publication-type="book" xlink:type="simple">Cohen J (2010) Modern code review. Oram A, Wilson G, editors. Making software: what really works, and why we believe it. Sepastopol (California): O'Reilly. pp. 329–336.</mixed-citation>
</ref>
<ref id="pbio.1001745-Williams1"><label>67</label>
<mixed-citation publication-type="book" xlink:type="simple">Williams L (2010) Pair programming. Oram A, Wilson G, editors. Making software: what really works, and why we believe it. Sepastopol (California): O'Reilly. pp. 311–322.</mixed-citation>
</ref>
<ref id="pbio.1001745-Dubois3"><label>68</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dubois</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Johnson</surname><given-names>J</given-names></name> (<year>2003</year>) <article-title>Issue tracking</article-title>. <source>Comput Sci Eng</source> <volume>5</volume>: <fpage>71</fpage>–<lpage>77</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001745-Wilson2"><label>69</label>
<mixed-citation publication-type="other" xlink:type="simple">Wilson G (2013). Software carpentry: lessons learned. arXiv:1307.5448. Available: <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1307.5448" xlink:type="simple">http://arxiv.org/abs/1307.5448</ext-link>.</mixed-citation>
</ref>
</ref-list></back>
</article>
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN"><front><journal-meta><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id><journal-id journal-id-type="pmc">ploscomp</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS Computational Biology</journal-title></journal-title-group><issn pub-type="ppub">1553-734X</issn><issn pub-type="epub">1553-7358</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, USA</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">08-PLCB-RA-0054R2</article-id><article-id pub-id-type="doi">10.1371/journal.pcbi.1000085</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline"><subject>Computational Biology/Computational Neuroscience</subject><subject>Neuroscience/Motor Systems</subject><subject>Neuroscience/Sensory Systems</subject><subject>Neuroscience/Theoretical Neuroscience</subject></subj-group></article-categories><title-group><article-title>Silent Synapses, LTP, and the Indirect Parallel-Fibre Pathway: Computational Consequences of Optimal Cerebellar Noise-Processing</article-title><alt-title alt-title-type="running-head">Optimal Cerebellar Noise-Processing</alt-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Porrill</surname><given-names>John</given-names></name><xref ref-type="aff" rid="aff1"/><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Dean</surname><given-names>Paul</given-names></name><xref ref-type="aff" rid="aff1"/></contrib></contrib-group><aff id="aff1">          <addr-line>Department of Psychology, Sheffield University, Sheffield, United Kingdom</addr-line>       </aff><contrib-group><contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Friston</surname><given-names>Karl J.</given-names></name><role>Editor</role><xref ref-type="aff" rid="edit1"/></contrib></contrib-group><aff id="edit1">University College London, United Kingdom</aff><author-notes><corresp id="cor1">* E-mail: <email xlink:type="simple">j.porrill@sheffield.ac.uk</email></corresp><fn fn-type="con"><p>Conceived and designed the experiments: JP PD. Analyzed the data: JP. Wrote the paper: JP PD.</p></fn><fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn></author-notes><pub-date pub-type="collection"><month>5</month><year>2008</year></pub-date><pub-date pub-type="epub"><day>23</day><month>5</month><year>2008</year></pub-date><volume>4</volume><issue>5</issue><elocation-id>e1000085</elocation-id><history><date date-type="received"><day>24</day><month>1</month><year>2008</year></date><date date-type="accepted"><day>11</day><month>4</month><year>2008</year></date></history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2008</copyright-year><copyright-holder>Porrill, Dean</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract><p>Computational analysis of neural systems is at its most useful when it uncovers principles that provide a unified account of phenomena across multiple scales and levels of description. Here we analyse a widely used model of the cerebellar contribution to sensori-motor learning to demonstrate both that its response to intrinsic and sensor noise is optimal, and that the unexpected synaptic and behavioural consequences of this optimality can explain a wide range of experimental data. The response of the Marr-Albus adaptive-filter model of the cerebellar microcircuit to noise was examined in the context of vestibulo-ocular reflex calibration. We found that, when appropriately connected, an adaptive-filter model using the covariance learning rule to adjust the weights of synapses between parallel fibres and Purkinje cells learns weight values that are optimal given the relative amount of signal and noise carried by each parallel fibre. This optimality principle is consistent with data on the cerebellar role in smooth pursuit eye movements, and predicts that many synaptic weights must be very small, providing an explanation for the experimentally observed preponderance of silent synapses. Such a preponderance has in its turn two further consequences. First, an additional inhibitory pathway from parallel fibre to Purkinje cell is required if Purkinje cell activity is to be altered in either direction from a starting point of silent synapses. Second, cerebellar learning tasks must often proceed via LTP, rather than LTD as is widely assumed. Taken together, these considerations have profound behavioural consequences, including the optimal combination of sensori-motor information, and asymmetry and hysteresis of sensori-motor learning rates.</p></abstract><abstract abstract-type="summary"><title>Author Summary</title><p>The cerebellum or “little brain” is a fist-sized structure located towards the rear of the brain, containing as many neurons as the rest of the brain combined, whose functions include learning to perform skilled motor tasks accurately and automatically. It is wired up into repeating microcircuits, sometimes referred to as cerebellar chips, in which learning alters the strength of the synapses between the parallel fibres, which carry input information, and the large Purkinje cell neurons, which produce outputs contributing to skilled movements. The cerebellar chip has a striking resemblance to a mathematical structure called an adaptive filter used by control engineers, and we have used this analogy to analyse its information-processing properties. We show that it learns synaptic strengths that minimise the errors in performance caused by unavoidable noise in sensors and cerebellar circuitry. Optimality principles of this kind have proved to be powerful tools for understanding complex systems. Here we show that optimality explains neuronal-level features of cerebellar learning such as the mysterious preponderance of “silent” synapses between parallel fibres and Purkinje cells and behavioural-level features such as the dependence of rate of learning of a motor skill on learning history.</p></abstract><funding-group><funding-statement>This research was supported by the UK Engineering and Physical Sciences Research Council, under the Novel Computation Initiative (GR/T10602/01), and the UK Biology and Biotechnology Research Council under the Integrative Analysis of Brain and Behaviour Initiative (BBS/B/17026).</funding-statement></funding-group><counts><page-count count="9"/></counts></article-meta></front><body><sec id="s1"><title>Introduction</title><p>The uniformity of the cerebellar microcircuit <xref ref-type="bibr" rid="pcbi.1000085-Eccles1">[1]</xref> has long been attractive to modellers. The original Marr-Albus framework <xref ref-type="bibr" rid="pcbi.1000085-Marr1">[2]</xref>,<xref ref-type="bibr" rid="pcbi.1000085-Albus1">[3]</xref> continues to be influential, particularly in the adaptive-filter form developed by Fujita <xref ref-type="bibr" rid="pcbi.1000085-Fujita1">[4]</xref> to deal with time-varying signals <xref ref-type="bibr" rid="pcbi.1000085-Barlow1">[5]</xref>,<xref ref-type="bibr" rid="pcbi.1000085-Ito1">[6]</xref>. However, although variants of the cerebellar adaptive-filter model are widely used and show great promise for generic motor control problems <xref ref-type="bibr" rid="pcbi.1000085-Bartha1">[7]</xref>–<xref ref-type="bibr" rid="pcbi.1000085-Yamamoto1">[13]</xref>, they are typically constructed in a distributed form that makes mathematical analysis of their properties difficult. It is therefore still unclear whether the adaptive-filter model has the power and robustness needed to underlie the computational capacities of the cerebellum.</p><p>One method of addressing this question is to use a lumped version of the model, in simulated tasks that are simplified as much as possible while still retaining the computational demands of the real-world equivalent. This approach has indicated that, when wired in a recurrent architecture, the adaptive filter can use the <italic>sensory</italic> consequences of inaccurate movements for adaptive feedfoward control <xref ref-type="bibr" rid="pcbi.1000085-Dean1">[14]</xref>–<xref ref-type="bibr" rid="pcbi.1000085-Porrill3">[17]</xref>, thereby solving the classic problem of the unavailable motor-error signal <xref ref-type="bibr" rid="pcbi.1000085-Jordan1">[18]</xref>,<xref ref-type="bibr" rid="pcbi.1000085-Jordan2">[19]</xref>. The recurrent architecture allows the filter to decorrelate an efference copy of motor commands from the sensory signal, ensuring that any remaining movement inaccuracies are not the result of the inadequate commands. The translation of ‘simple’ motor commands into the detailed instructions required for accurate movements has long been considered a central function of the cerebellum <xref ref-type="bibr" rid="pcbi.1000085-Marr1">[2]</xref>, and this translation entails the adaptive compensation of time-varying biological motor plant (muscles, tendons, linkages, etc.). The demonstration that the adaptive filter in a recurrent architecture can achieve adaptive compensation using only physically available signals is thus an important step towards establishing its computational suitability as a model of the cerebellar microcircuit.</p><p>A second requirement of a cerebellar model is robustness in the face of typically biological features of motor control problems. One ubiquitous example of such a feature is the presence of noise in biological signals <xref ref-type="bibr" rid="pcbi.1000085-Stein1">[20]</xref>. In the modelling examples given above, both input and internal signals were assumed to be noise free. Here we investigate the performance of the model when noise is added to these signals. The investigation is in two parts. First, we show that an adaptive filter using the standard covariance learning rule behaves optimally with respect to input and internal noise. Secondly, we show there are important consequences of this computational optimality for both the neuronal implementation of the adaptive-filter, and for behavioural learning rates. These findings are significant for understanding not only cerebellar function, but also the relationship between computational and implementational aspects of neural modelling in general <xref ref-type="bibr" rid="pcbi.1000085-Marr2">[21]</xref>.</p></sec><sec id="s2"><title>Results</title><sec id="s2a"><title>Basic Model</title><p>The linear adaptive-filter model of the cerebellar microcircuit <xref ref-type="bibr" rid="pcbi.1000085-Fujita1">[4]</xref>,<xref ref-type="bibr" rid="pcbi.1000085-Kawato1">[22]</xref> is outlined in <xref ref-type="fig" rid="pcbi-1000085-g001">Figure 1</xref>. Filter inputs correspond to mossy fibre signals, conveying information about the current sensory and motor state of the organism. These inputs are recoded by a bank of linear filters representing the granular layer, whose outputs (PF signals) are weighted (PF synapses on Purkinje cells) then summed to constitute the filter output (Purkinje cell firing). Weights are adjusted in response to an error signal (climbing fibre input to Purkinje cell), using the covariance learning rule <xref ref-type="bibr" rid="pcbi.1000085-Sejnowski1">[23]</xref>. This rule, which assumes that signals are carried by modulation of a tonic firing rate so that positive and negative values can be coded, is identical in form to the powerful Least Mean Square rule of adaptive control theory <xref ref-type="bibr" rid="pcbi.1000085-Widrow1">[24]</xref>. It requires bidirectional plasticity (that is both LTD and LTP) at synapses between parallel fibres (PFs) and Purkinje cells <xref ref-type="bibr" rid="pcbi.1000085-Jrntell1">[25]</xref>, so that synaptic weights decrease when climbing fibre input is positively correlated with parallel fibre input, and increase when the correlation is negative. If the filter is properly connected, this learning rule learns weights which combine parallel fibre inputs so that the PC output has minimal mean square error. It should be noted that in <xref ref-type="fig" rid="pcbi-1000085-g001">Figure 1</xref> we follow the convention of referring only to parallel fibre synapses, without mentioning the synapses between the ascending axons of granule cells and Purkinje cells. However, the arguments in the paper would not be affected by inclusion of ascending axon synapses, provided their behaviour conformed to the covariance learning rule.</p><fig id="pcbi-1000085-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000085.g001</object-id><label>Figure 1</label><caption><title>Schematic diagram of the organisation of the cerebellar microcircuit and its interpretation as an adaptable filter.</title><p>(A) The mossy fibre input signals are distributed over many granule cells whose axons form parallel fibres (PFs) that synapse on Purkinje cells (PCs). In models of Marr-Albus type, correlated firing of a PF and the single climbing fibre (CF) which winds around the PC alters the efficacies of the PF/PC synapses. (B) Processing of MF inputs <italic>u<sub>k</sub></italic>(<italic>t</italic>) by the granule cell layer is interpreted as analysis by a bank of causal filters <italic>G<sub>i</sub></italic> so that the PFs carry signals which form an expansion re-coding <italic>p<sub>i</sub></italic> = <italic>G<sub>i</sub></italic>[<italic>u</italic><sub>1</sub>,…,<italic>u<sub>M</sub></italic>] of the MF inputs. PC output is modelled as a weighted sum <italic>z</italic>(<italic>t</italic>) = Σ<italic>w<sub>i</sub>p<sub>i</sub></italic>(<italic>t</italic>) of its PF inputs so the PC implements a linear-in-weights filter <italic>C</italic> = Σ<italic>w<sub>i</sub>G<sub>i</sub></italic>. The CF input is interpreted as a training signal <italic>e</italic>(<italic>t</italic>) which adapts synaptic weights <italic>w<sub>i</sub></italic> using Equation 2; this hetero-synaptic covariance learning rule <xref ref-type="bibr" rid="pcbi.1000085-Sejnowski1">[23]</xref> is consistent with known properties of LTD and LTP at PF/PC synapses and is identical in form to the LMS learning rule of adaptive control theory.</p></caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000085.g001" xlink:type="simple"/></fig><p>The uniformity of the cerebellar microcircuit implies that a model can be tested using any convenient cerebellar task. Adaptation of the vestibulo-ocular reflex (VOR) is relatively simple, has been extensively modelled and investigated <xref ref-type="bibr" rid="pcbi.1000085-Boyden1">[26]</xref>, and previously used to investigate the computational properties of adaptive-filter models <xref ref-type="bibr" rid="pcbi.1000085-Dean1">[14]</xref>,<xref ref-type="bibr" rid="pcbi.1000085-Porrill1">[15]</xref>,<xref ref-type="bibr" rid="pcbi.1000085-Porrill3">[17]</xref>. The simplified architecture used for the simulations is shown in <xref ref-type="fig" rid="pcbi-1000085-g002">Figure 2</xref>.</p><fig id="pcbi-1000085-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000085.g002</object-id><label>Figure 2</label><caption><title>Architecture used for simulations of horizontal VOR adaptation.</title><p>The task of the VOR is to convert the vestibular signal <italic>v</italic><sub>head</sub> into motor commands <italic>m</italic> to the oculomotor plant <italic>P</italic> which move the eye so as to exactly compensate head movements: <italic>v</italic><sub>eye</sub> = <italic>v</italic><sub>head</sub>. We model this reflex as a fixed pathway through the brainstem supplemented by forward and recurrent adaptable pathways via the cerebellum. In previous work we have argued that VOR plant compensation depends mainly on the recurrent pathway through <italic>C</italic> <xref ref-type="bibr" rid="pcbi.1000085-Dean1">[14]</xref>,<xref ref-type="bibr" rid="pcbi.1000085-Porrill1">[15]</xref>,<xref ref-type="bibr" rid="pcbi.1000085-Porrill3">[17]</xref>, which has the advantage that the required teaching signal is sensory error, that is the retinal slip <italic>e</italic> as shown. Feedback-error learning <xref ref-type="bibr" rid="pcbi.1000085-Kawato1">[22]</xref> uses an alternative architecture without the recurrent loop; in this case, the required teaching signal is motor error, <italic>e</italic><sub>M</sub> = <italic>P</italic><sup>−1</sup><italic>e</italic>. In more general adaptation problems both pathways seem to be necessary, with one being well-adapted to vestibular compensation and one to plant compensation <xref ref-type="bibr" rid="pcbi.1000085-Porrill3">[17]</xref>. In all these architectures, the requirement for learning stability is that the teaching signal <italic>e</italic> must be related by a strictly positive real (SPR) transfer function to error in cerebellar output (which is trivially satisfied for the case of adaptation of scalar gain). Given the SPR assumption, our conclusions apply equally to all these configurations.</p></caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000085.g002" xlink:type="simple"/></fig><p>Horizontal VOR accuracy requires that motor commands to eye muscles compensate for changes in the dynamic properties of both the oculomotor plant <italic>P</italic> and of vestibular processing V. We have previously shown that plant compensation can be learnt by an adaptive filter version of the Marr-Albus algorithm using the recurrent pathway illustrated in <xref ref-type="fig" rid="pcbi-1000085-g002">Figure 2</xref>, in which the filter receives an efference copy of the motor commands to the plant. In contrast, the forward pathway shown in <xref ref-type="fig" rid="pcbi-1000085-g002">Figure 2</xref> is suitable for compensating for changes in vestibular processing. In the simulations below both architectures are used although, since these simulations deal only with changes in scalar gain, this is not a crucial distinction.</p></sec><sec id="s2b"><title>Learning Rule Optimises Filter Weights for Noisy Signals</title><p>In general, appropriately connected adaptive-filters using the covariance learning-rule will achieve optimal filter weights that minimise the error measure <italic>e</italic> (<xref ref-type="fig" rid="pcbi-1000085-g001">Figures 1</xref> and <xref ref-type="fig" rid="pcbi-1000085-g002">2</xref>). Since <italic>e</italic> is a measure of task performance, these weights enable the filter to perform the task accurately. This optimal behaviour clearly generalises to the situation where noise is present in PF signals: because this noise affects the filter output, minimising <italic>e</italic> will also tend to minimise the effect of PF noise, by choosing weights that are optimal for eliminating disturbances due to PF noise.</p><p>The optimality principle can be illustrated by considering the case where a number of PFs carry signals <italic>p<sub>i</sub></italic> with different levels α<italic><sub>i</sub></italic> of a signal of interest <italic>s</italic> but contaminated by independent noise components <italic>n<sub>i</sub></italic> of power σ<sub>i</sub><sup>2</sup>. It is shown in the <xref ref-type="sec" rid="s4">Methods</xref> section (Equation 6) that mean square output error is minimised when the weights on these input signals have the ratios <italic>w<sub>i</sub>∶w<sub>j</sub></italic> = α<italic><sub>i</sub></italic>/σ<sub>i</sub><sup>2</sup>∶α<italic><sub>j</sub></italic>/σ<sub>j</sub><sup>2</sup>. <xref ref-type="fig" rid="pcbi-1000085-g003">Figure 3</xref> shows the time course of this learning, for the case where plant gain is suddenly decreased from 1.0 to 0.5. and the filter has four PF channels carrying differing amounts of efferent-copy signal and noise.</p><fig id="pcbi-1000085-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000085.g003</object-id><label>Figure 3</label><caption><title>Synaptic weights are optimal with respect to output noise.</title><p>Here the plant suffers a 50% decrease in gain and learning takes place in 4 PFs carrying levels <italic>α</italic><sub>i</sub> = 1, 1, 2, and 2 of the same unit power signal <italic>s</italic> and levels <italic>σ</italic><sub>i</sub> = 1/2, 1, 1/2, and 1 of independent noise (see legend below for [A]). During the fast learning phase, synaptic weights are learned that are approximately proportional to signal amplitude <italic>α</italic><sub>i</sub> on the relevant PF ([A]—the learning rate was chosen to make this phase last ∼1 h, as shown by the first vertical line). During this phase, performance improves dramatically (B) and overall VOR gain approaches a value just smaller than unity (C). This is followed by a slow learning phase (predicted length shown by second vertical line) in which weights rearrange themselves to be proportional to <italic>α</italic><sub>i</sub>/<italic>σ</italic><sub>i</sub><sup>2</sup> (predicted values shown by dotted lines). During this stage there is a small improvement in performance as the effect of the disturbance is minimised, but overall VOR gain is virtually unaffected.</p></caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000085.g003" xlink:type="simple"/></fig><p><xref ref-type="fig" rid="pcbi-1000085-g003">Figure 3A</xref> illustrates a general phenomenon for low levels of PF noise, namely the existence of fast and slow phases of learning (see <xref ref-type="sec" rid="s4">Methods</xref>). Initial learning is fast, producing a 5-fold drop in retinal slip error in ∼60 batches, nominally about 1 hour of input. During this phase the weight vector converges close to the subspace of weight combinations which performs the task in the absence of noise. Thus, the values of the weights attained after this early fast phase of learning are sufficient to achieve a near optimal VOR gain of just below 1.0. Subsequent learning is much slower (note log scale for <italic>x</italic>-axis), as the weight vector moves essentially within this subspace to bring all weights to the optimal values determined by Equation 6. During this learning phase performance improves, but less dramatically, as the smaller noise contribution to task errors is reduced. The slowest time constant for this phase of learning is lengthened by a factor approximately equal to the signal to noise ratio (Equation 10).</p></sec><sec id="s2c"><title>Implications for Sensory Processing</title><p>If the signals carried by parallel fibres correspond to a set of noisy sensory estimates of an environmental property, and appropriate cost information is carried on the climbing fibre, the adaptive-filter behaviour above leads to the optimal linear estimator in the Bayesian sense. Our analysis shows this explicitly for the simplest case of a minimum least square error estimator when the sensory estimate noises are independent. Such statistically optimal performance has been observed for humans integrating visual and haptic information <xref ref-type="bibr" rid="pcbi.1000085-Ernst1">[27]</xref>, and the above result suggests that the adaptive-filter model of the cerebellum can match the performance of the whole subject. This result has particular relevance to smooth pursuit, a class of eye-movement known to be dependent upon the cerebellum, whose accuracy (in the initial open-loop phase) appears to be limited primarily by sensory noise <xref ref-type="bibr" rid="pcbi.1000085-Osborne1">[28]</xref>. This example is considered further in the Discussion.</p></sec><sec id="s2d"><title>Implications for Weight Values</title><p>It can be seen from <xref ref-type="fig" rid="pcbi-1000085-g003">Figures 3</xref> and <xref ref-type="fig" rid="pcbi-1000085-g004">4</xref> that even weights for parallel fibres carrying relevant signals are driven to low values if they also carry high amounts of additive noise. We now consider a second type of noise, namely potentially useful signals carried by PFs but which are irrelevant to the current task (termed ‘nuisance’ signals in the control-theory literature), these signals could be correlated between different PFs. A simple example would be a parallel fibre that carries information about the conditioned stimulus in classical conditioning. Conditioned stimuli are deliberately chosen on the basis of their not having prior influence on the response to be conditioned, so before acquisition commences the corresponding parallel-fibre signal is essentially all noise. Its weight will therefore have been set to zero at the fast time scale before the start of formal training.</p><fig id="pcbi-1000085-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000085.g004</object-id><label>Figure 4</label><caption><title>Covariance rule eventually drives weights on nuisance inputs to zero.</title><p>In this simulation, the cerebellar input is carried on three parallel fibres. One (PF1) carries the required motor command <italic>s</italic>, and the other two (PF2, PF3) carry equal and opposite versions of a nuisance signal <italic>n</italic> with the same power as, but uncorrelated with, the motor command. In addition, each parallel fibre carries a small additive component of noise <italic>n<sub>i</sub></italic> with (σ = 0.1) representing intrinsic PF noise which is uncorrelated between parallel fibres (see legend below [A]). The initial synaptic weights on PF1, 2, and 3 are set to 0, 0.5, and 0.9, respectively. (A) shows that on a fast time scale, the signal synaptic weight converges to a value where the plant is compensated, and over the same time scale, the nuisance signal weights converge to equal values so that the correlated nuisance signal they carry cancels. On this time scale, performance improves dramatically. The non-zero weight values on the nuisance inputs are not stable, however, and the small component of intrinsic noise drives them to zero on a slower time scale. This process is associated with a smaller improvement in performance (shown in [B] and [C]).</p></caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000085.g004" xlink:type="simple"/></fig><p>A more interesting example is provided by the case of two parallel fibres, one carrying irrelevant information <italic>n</italic> and a second fibre carrying the same information with the opposite sign <italic>−n</italic>. Here the total contribution to the task will be zero if the weights are equal. From any arbitrary non-zero starting weights this state will be reached on the fast time scale. However if these PFs also carry an independent second component of noise (as they surely will) these redundant weights will go on changing to become zero on the slow time scale (illustrated in <xref ref-type="fig" rid="pcbi-1000085-g004">Figure 4</xref>). In general all non-zero weight combinations for which nuisance sources cancel will be unstable due to intrinsic noise. In a similar way large numbers of nuisance sources might cancel to good accuracy due to the central limit theorem, but their weights will nevertheless eventually converge to zero due to intrinsic noise.</p></sec><sec id="s2e"><title>Implications for Neuronal Implementation</title><p>Parallel fibres are thought to carry a widespread array of information about the sensorimotor context in which motor activity takes place, including sensory signals, copies of motor commands, and signals about the state of the organism such as arousal <xref ref-type="bibr" rid="pcbi.1000085-Ito2">[29]</xref>. The fact that there are so many (∼170,000) parallel-fibre inputs to a given Purkinje cell <xref ref-type="bibr" rid="pcbi.1000085-Ito1">[6]</xref> implies that most parallel fibres will inevitably carry information which is only weakly related (low signal to noise) or is simply unrelated (all noise) to a given task. From the analysis above the long-term optimal synaptic weights for such synapses will be small or zero. Hence it is a consequence of the optimal performance of the model that most synapses between parallel fibres and Purkinje cells are expected to be silent, consistent with experimental evidence <xref ref-type="bibr" rid="pcbi.1000085-Isope1">[30]</xref>–<xref ref-type="bibr" rid="pcbi.1000085-Ekerot1">[32]</xref>.</p><p>The second consequence of optimal performance is related to the first. In simplified computational models it is often assumed that a given synaptic weight can be either positive or negative. The fact that actual synapses do not change between excitatory or inhibitory forms can be finessed if the weights vary around some intermediate positive (or negative) value. However, if many of them are typically zero at the start of learning, the model can only be properly implemented if there is a second pathway from granule cells to Purkinje cells of opposite sign to the first, else learning would only be possible when it required Purkinje cell excitability to <italic>increase</italic>. Fortunately, this requirement appears to be consistent with recent experimental evidence indicating that there is climbing-fibre controlled plasticity in the synapses between parallel fibres and stellate and basket cells, which are inhibitory interneurons that project to Purkinje cells <xref ref-type="bibr" rid="pcbi.1000085-Jrntell2">[31]</xref>,<xref ref-type="bibr" rid="pcbi.1000085-Ekerot1">[32]</xref>. Thus there is a second, indirect, pathway from granule cells to Purkinje cells via inhibitory interneurons that can support the learning required by the adaptive-filter model.</p><p>The final consequence is almost a triviality. Clearly if most synapses are silent they are not available for long-term depression (LTD). Hence for a large class of tasks learning must initially proceed via long-term potentiation (LTP), in either the direct or indirect pathway from granule cells to Purkinje cells. LTP in the direct excitatory pathway would increase Purkinje cell excitability, whereas LTP in the indirect inhibitory pathway would reduce Purkinje cell excitability. The covariance learning rule thus implies that LTP and LTD are in general of equal significance, rather than cerebellar LTP merely playing a book-keeping role by normalising an LTD-lead learning process. The predominance of silent granule synapses goes further by implying that LTP may be particularly important for new learning.</p></sec><sec id="s2f"><title>Implications for Learning</title><p>The basic simplicity of the Marr-Albus mechanism as exemplified by the adaptive-filter model is substantially modified by the implementation issues just considered, in particular by the presence of both direct excitatory and indirect inhibitory pathways from granule cells to Purkinje cells. We have shown that synaptic positivity requires an indirect pathway whenever a task requires synaptic weights to be negative. Hence the locus of synaptic plasticity, in the direct or indirect pathway, will depend on the direction of the change to be learnt. This means that any differences between direct and indirect pathways will lead to asymmetries in learning behaviour.</p><p>An example is given in <xref ref-type="fig" rid="pcbi-1000085-g005">Figure 5</xref>, which illustrates the behaviour of a system with vestibular inputs arriving on both the direct excitatory pathway and an indirect inhibitory pathway. Signs were chosen so that gain down would initially be learnt by LTP on the direct pathway, consistent with <xref ref-type="bibr" rid="pcbi.1000085-Boyden2">[33]</xref>. It is further assumed that the learning rate in the direct pathway is smaller than that in the indirect pathway. The effect of these assumptions is to produce asymmetrical learning rates, with gain-up learning being about twice as fast as gain down (a similar result can be obtained using equal learning rates but with the indirect pathway carrying a more powerful signal than the direct pathway). This difference is similar to that found for VOR adaptation in the mouse <xref ref-type="bibr" rid="pcbi.1000085-Boyden2">[33]</xref>. <xref ref-type="fig" rid="pcbi-1000085-g005">Figure 5</xref> therefore shows how, in principle, the presence of a direct excitatory and indirect inhibitory pathway could contribute to an observed asymmetry in learning rate. Additional differences between these pathways with respect to, for example, generalisation could also contribute to other kinds of experimentally-observed learning asymmetries (see <xref ref-type="sec" rid="s3">Discussion</xref>).</p><fig id="pcbi-1000085-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000085.g005</object-id><label>Figure 5</label><caption><title>Effect of asymmetry between direct excitatory and indirect inhibitory pathways.</title><p>Vestibular compensation experiment simulated in forward architecture. Signs for the vestibular signal were chosen so that the direct excitatory pathway learned gain down and the indirect inhibitory pathway learned gain up ([A] and [B], respectively). The asymmetry between the two pathways was chosen to be a difference in learning rates. (C) shows that data (circles) from <xref ref-type="fig" rid="pcbi-1000085-g001">Figure 1E</xref> of Boyden and Raymond <xref ref-type="bibr" rid="pcbi.1000085-Boyden2">[33]</xref> were well-fitted when the learning rate in the indirect pathway was about 9 times faster than that in the direct pathway, leading to time constants of 10 min for gain up and 26 min for gain down. A similar result (not shown) was obtained assuming a factor of 3 asymmetry between indirect and direct signal strengths.</p></caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000085.g005" xlink:type="simple"/></fig><p>Finally, we have argued above that, if most synapses are inactive, learning novel tasks must proceed mainly via LTP. However once learning has taken place, these newly active synapses become available for learning via LTD. Hence the number of active synapses and the magnitude of the synaptic weight available for LTD will depend on previous experience, ensuring that learning rates will depend on previous learning history. An example of this hysteresis mechanism is given in <xref ref-type="fig" rid="pcbi-1000085-g006">Figure 6</xref>, which illustrates learning rates for an increase in VOR gain in the dark from 1.0 to 1.5, followed firstly by a decrease back to 1.0, then by another gain increase to 1.5. It is assumed that all weights are zero at the start of learning, and that the direct excitatory and indirect inhibitory pathways have identical signal strengths and learning rates. It can be seen that the initial learning of the gain increase (‘acquisition’) is slower than learning the subsequent decrease (‘extinction’), and also slower than re-learning the gain increase (‘re-acquisition’). As with the previous figure, <xref ref-type="fig" rid="pcbi-1000085-g006">Figure 6</xref> shows how in principle the presence of direct and indirect pathways could contribute to hysteresis in learning rates.</p><fig id="pcbi-1000085-g006" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000085.g006</object-id><label>Figure 6</label><caption><title>Hysteresis in vestibular compensation simulation in forward architecture.</title><p>In response to a decrease in plant gain (top plot), learning proceeds initially via LTP in the direct pathway (A) and increases VOR gain in the dark by 50% (B); the learning rate has been adjusted to give this stage a time constant of 15 min. When the plant gain is returned to its original value, learning occurs in both pathways: via LTD in the newly available synapse in the indirect inhibitory pathway, and via LTP in the synapse in the direct excitatory pathway, leading to faster learning (with a time constant of approximately 5 min) during this gain down phase of learning. This is followed by a second phase of gain up learning, again increasing VOR gain by 50%. Learning is still possible at both sites, and this gain up phase has a faster time constant (approximately 7 min) than the initial gain up phase.</p></caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000085.g006" xlink:type="simple"/></fig></sec></sec><sec id="s3"><title>Discussion</title><p>An important step in evaluating candidate models of the cerebellar microcircuit is to assess their computational power. We show here that the adaptive-filter version of the Marr-Albus framework using the covariance learning rule has the very desirable computational property of providing optimal estimates of sensory input signals from the information available in the parallel fibres. This is important both for the general reason that noise is ubiquitous in neural signals, and more specifically because there is evidence suggesting that the cerebellum itself can make optimal use of noisy signals.</p><sec id="s3a"><title>Optimal Cerebellar Performance in Smooth Pursuit</title><p>Analysis of inaccuracies in open-loop smooth pursuit movements indicates that more than 90% of the variance arises from errors in sensory estimation of the speed, timing and direction of target motion <xref ref-type="bibr" rid="pcbi.1000085-Osborne1">[28]</xref>, and that pursuit thresholds are similar to perceptual thresholds <xref ref-type="bibr" rid="pcbi.1000085-Osborne2">[34]</xref>. Since smooth pursuit is dependent upon the cerebellum (e.g., <xref ref-type="bibr" rid="pcbi.1000085-Krauzlis1">[35]</xref>), these findings suggest that the cerebellum can process noisy sensory information as well as the perceptual system as a whole. Moreover, at least in some instances perceptual processing of this kind has been shown to be statistically optimal (e.g., <xref ref-type="bibr" rid="pcbi.1000085-Ernst1">[27]</xref>). Recordings from smooth-pursuit related Purkinje cells in the cerebellar floccular complex suggest that variability in their open-loop responses is also driven primarily by sensory noise, with noise downstream from the Purkinje cells being of minor importance <xref ref-type="bibr" rid="pcbi.1000085-Medina2">[36]</xref>. These findings together suggest that smooth pursuit performance is close to optimal given the noise present in sensory measurements, and that the cerebellum can make optimal use of those measurements. An important criterion, therefore, for assessing cerebellar models is their computational ability to reproduce such optimality.</p></sec><sec id="s3b"><title>Complexity of Neuronal Implementation</title><p>A second feature of the present findings is the implication of the model's computational power for its implementation and performance. After long periods of training most of the model's weights are likely to be small or zero, consistent with recent experimental evidence <xref ref-type="bibr" rid="pcbi.1000085-Isope1">[30]</xref>–<xref ref-type="bibr" rid="pcbi.1000085-Ekerot1">[32]</xref>. We comment on four features of this finding.</p><list list-type="order"><list-item><p>The presence of many silent synapses may appear puzzling, given that <italic>in vitro</italic> studies of LTD typically report reductions in efficacy of only ∼50%. However, from the computational perspective the crucial point is whether the synapses are <italic>functionally</italic> silent, i.e. they do not influence Purkinje cell output. In fact Isope and Barbour <xref ref-type="bibr" rid="pcbi.1000085-Isope1">[30]</xref> found that “… a large fraction of these synapses is so weak as to produce no detectable response” (p. 9676), and evidence from <italic>in vivo</italic> studies suggests that LTD is able to render parallel-fibre synapses on Purkinje cells functionally silent <xref ref-type="bibr" rid="pcbi.1000085-Jrntell2">[31]</xref>,<xref ref-type="bibr" rid="pcbi.1000085-Ekerot1">[32]</xref>. The relationship between <italic>in vitro</italic> and <italic>in vivo</italic> LTD is an intriguing issue, but not directly germane to the central purpose of the present study.</p></list-item><list-item><p>As explained in the <xref ref-type="sec" rid="s2">Results</xref> section, the presence of many silent synapses implies the necessity for a second pathway from granule cell to Purkinje cell, of opposite sign to the first and also capable of plasticity in accordance with the covariance learning rule. Again, recent experimental evidence is consistent with this requirement <xref ref-type="bibr" rid="pcbi.1000085-Jrntell2">[31]</xref>,<xref ref-type="bibr" rid="pcbi.1000085-Ekerot1">[32]</xref>. This evidence also shows that the synapses between parallel fibres and interneurons in this pathway too are mainly silent, as our computational analysis would predict.</p></list-item><list-item><p>Perhaps unexpectedly, the addition of an indirect inhibitory pathway to the model's implementation substantially increase the complexity of its behaviour. Unless the direct and indirect pathways have identical properties, then learning tasks that engage them to different degrees will show differences in such properties as rate of learning (<xref ref-type="fig" rid="pcbi-1000085-g005">Figure 5</xref>), and exact nature of what is learned, as revealed for example by generalisation tests. Such differences have been demonstrated for gain-up and gain-down VOR learning <xref ref-type="bibr" rid="pcbi.1000085-Boyden1">[26]</xref>, <xref ref-type="bibr" rid="pcbi.1000085-Boyden2">[33]</xref>, <xref ref-type="bibr" rid="pcbi.1000085-Kimpo1">[37]</xref>–<xref ref-type="bibr" rid="pcbi.1000085-Hansel1">[39]</xref>, and our results show that a candidate explanation for the asymmetric learning rates is (a) the two tasks engage the direct excitatory and indirect inhibitory pathways to differing extents, and (b) the two pathways have different learning rates.</p></list-item><list-item><p>Finally, even if the two pathways were to have identical properties, a ‘new’ task (starting from zero weights in both pathways) will show learning rate hysteresis (<xref ref-type="fig" rid="pcbi-1000085-g006">Figure 6</xref>) as has been observed for VOR adaptation <xref ref-type="bibr" rid="pcbi.1000085-Boyden2">[33]</xref>,<xref ref-type="bibr" rid="pcbi.1000085-Cohen1">[40]</xref>,<xref ref-type="bibr" rid="pcbi.1000085-Kuki1">[41]</xref> and classical eyeblink conditioning <xref ref-type="bibr" rid="pcbi.1000085-Kehoe1">[42]</xref>,<xref ref-type="bibr" rid="pcbi.1000085-Jirenhed1">[43]</xref>. These observations establish that the presence of direct and indirect learning pathways is likely to contribute to learning-rate asymmetries and hysteresis, but of course do not rule out possible contributions from other sources, such as sites of plasticity in brainstem for the VOR or forebrain for classical conditioning, or in the granular layer for cerebellar learning in general.</p></list-item></list></sec><sec id="s3c"><title>Interpretation of Behavioural Experiments</title><p>The possibility that cerebellar learning can proceed via at least 4 separate processes (LTP and LTD in either pathway) complicates the interpretation of behavioural studies in which one or more of those processes are compromised. As can be seen from <xref ref-type="fig" rid="pcbi-1000085-g005">Figures 5</xref> and <xref ref-type="fig" rid="pcbi-1000085-g006">6</xref>, the contribution of each process depends both on the direction of learning, and the organism's past history. For example, the neural bases of a new learning task (possibly the initial acquisition of eyeblink conditioning to a tone) may differ from those of an ongoing familiar task (VOR or saccadic calibration). This complication may contribute to the difficulty of identifying these neural bases using behavioural studies of mutants <xref ref-type="bibr" rid="pcbi.1000085-DeZeeuw1">[44]</xref>, though again it must be emphasised that there are a number of other possible sources contributing to difficulty in this area.</p><p>A related issue concerns the processes underlying the fast and slow phases of learning illustrated in <xref ref-type="fig" rid="pcbi-1000085-g003">Figures 3</xref> and <xref ref-type="fig" rid="pcbi-1000085-g004">4</xref>. It can be seen that in principle there could be some tasks where early learning uses a single process, whereas later learning uses a mixture (e.g., <xref ref-type="fig" rid="pcbi-1000085-g003">Figure 3A</xref>). Although a distinction between fast early learning (‘acute’) and slow subsequent learning (‘chronic’) is familiar in the cerebellar literature <xref ref-type="bibr" rid="pcbi.1000085-Boyden1">[26]</xref>,<xref ref-type="bibr" rid="pcbi.1000085-DeZeeuw1">[44]</xref>, the mechanisms illustrated in <xref ref-type="fig" rid="pcbi-1000085-g003">Figure 3</xref> have not so far been considered as a possible basis. One additional implication of this figure is that the slow acquisition of many motor skills (to expert level) might be caused in part by cerebellar input noise.</p></sec><sec id="s3d"><title>Comparison With Other Cerebellar Models</title><p>The cerebellar algorithm we have described necessarily inherits the well-known optimality properties of the adaptive filter <xref ref-type="bibr" rid="pcbi.1000085-Widrow1">[24]</xref>. We have demonstrated statistical optimality explicitly and examined its consequences for a class of noisy inputs likely to be of importance in cerebellar learning. As far as we are aware, the cerebellar model described here is at present the only one demonstrated to guarantee statistical optimality in dealing with noisy inputs, and thus the only one known to be capable of, for example, the optimal smooth pursuit performance described experimentally <xref ref-type="bibr" rid="pcbi.1000085-Osborne1">[28]</xref>,<xref ref-type="bibr" rid="pcbi.1000085-Osborne2">[34]</xref>,<xref ref-type="bibr" rid="pcbi.1000085-Medina2">[36]</xref>.</p><p>There is an alternative account, however, of the experimentally observed preponderance of silent synapses between parallel fibres and either Purkinje cells or interneurons. The relation between weight distribution and storage capacity has been examined for perceptron models <xref ref-type="bibr" rid="pcbi.1000085-Brunel1">[45]</xref>, and the optimal distribution has been shown to contain a high proportion of very weak or silent synapses. This analysis is based on the assumptions i) that the cerebellar microcircuit acts like a perceptron in which both inputs and outputs are binary and ii) that weights are distributed so as to achieve maximum storage capacity. Under these assumptions it is shown that coding capacity is maximised when 50% of weights are silent, and that this proportion increases if a noise threshold is introduced to increase reliability of classification.</p><p>Although the derivation is rigorous, there is a question of how far the Perceptron is in fact a suitable representation of the cerebellar microcircuit in a motor control context. Although Perceptrons have been used as models for cerebellar cortex based on the Marr-Albus framework <xref ref-type="bibr" rid="pcbi.1000085-Kanerva1">[46]</xref>,<xref ref-type="bibr" rid="pcbi.1000085-Tyrrell1">[47]</xref> they are not usually applied to motor control problems where continuous time-varying signals are required. In general the adaptive filter interpretation is more suited to these sensori-motor applications, and it is more closely linked to theoretical developments in adaptive control. Moreover, the task of learning the coefficients of an adaptive filter is very unlike that of coding many random bit patterns with a single template. For example in a motor control problem the inputs would generally be confined to a low dimensional subset of input space, an assumption that is basic to current machine learning algorithms such as locally weighted linear regression <xref ref-type="bibr" rid="pcbi.1000085-Atkeson1">[48]</xref>. In these circumstances the requirement of maximising coding capacity is not relevant.</p></sec><sec id="s3e"><title>Levels of Analysis</title><p>Although the simplicity of the Marr-Albus algorithm may seem to imply correspondingly simple learning behaviour, we have shown how constraints at the hardware level can mask this algorithmic simplicity so that Marr-Albus systems exhibit complex phenomena such as multiple time scales, asymmetry and hysteresis. Marr <xref ref-type="bibr" rid="pcbi.1000085-Marr2">[21]</xref> distinguished between the computational, algorithmic and hardware levels of description in models of neural information processing. In fact models often have the greatest explanatory power when they integrate information across all three levels. Our previous work has concentrated primarily on the interaction between the two higher levels <xref ref-type="bibr" rid="pcbi.1000085-Dean1">[14]</xref>–<xref ref-type="bibr" rid="pcbi.1000085-Porrill3">[17]</xref>. Here we have extended this work to include two important hardware level constraints, namely system noise and weight positivity, and show that they have computational consequences which are critical to understanding neuronal and behavioural aspects of cerebellar learning. It is of interest that recent experimental work on VOR adaptation has emphasised the complexity of the learning processes involved <xref ref-type="bibr" rid="pcbi.1000085-Boyden1">[26]</xref>. The results here suggest that such complexity is not in principle incompatible with the original Marr-Albus framework.</p></sec></sec><sec id="s4"><title>Methods</title><sec id="s4a"><title>Simulations</title><p>In the simulations the model architecture shown in <xref ref-type="fig" rid="pcbi-1000085-g002">Figure 2</xref> was programmed in MATLAB with <italic>V</italic>, <italic>P</italic>, and <italic>B</italic> taken as scalar gains. In recurrent architecture <italic>V</italic> was a unit gain and the forward pathway through <italic>C</italic> was not used giving an overall loop gain of <italic>BP</italic>/(1−<italic>BC</italic>). Initially <italic>P</italic> = 1, <italic>B</italic> = 1 so the plant is initially perfectly compensated when <italic>C</italic> = 0. For example when <italic>P</italic> is reduced to 0.5 exact compensation requires <italic>C</italic> = <italic>B</italic><sup>−1</sup>−<italic>P</italic> = 0.5. In adaptive filter models the cerebellar filter <italic>C</italic> analyses its input <italic>m(t)</italic> into many parallel fiber signals <italic>p<sub>i</sub></italic> which are re-synthesized to form the output <italic>z</italic> = Σ <italic>w<sub>i</sub>p<sub>i</sub></italic>. Since the simulations here deal only with scalar gains we do not require <italic>p<sub>i</sub></italic> containing information about the past history of <italic>m</italic> as in our previous work. Assumptions about the nature of the <italic>p<sub>i</sub></italic> are described separately for each simulation. Since the time dependence of the inputs is irrelevant to learning a scalar gain the input was taken to be constant. All noise signals were represented as white noise, results would be the same for other types of noise with the same variance and correlations.</p><p>The learning rule (Equation 2 below) at the parallel fibre/Purkinje cell synapse was implemented as a batch update rule, accumulating the total change in weight over the batch for fixed weights and then updating at the end of the batch. A batch consisted of 6,000 time steps so that with <italic>dt</italic> = 0.01 s a batch had a nominal duration of 1 min.The teaching signal <italic>e</italic> was retinal slip <italic>v</italic><sub>head</sub>-<italic>v</italic><sub>eye</sub>. The learning rate β was chosen to fix the fast time scale for each simulation. Although batch update was used for efficiency the results are essentially identical for continuous time update. The code for the all the simulations is available in <xref ref-type="supplementary-material" rid="pcbi.1000085.s001">Dataset S1</xref>.</p></sec><sec id="s4b"><title>Analysis</title><p>The mossy fibre inputs to the granule cell layer are expansion-recoded as parallel fibre signals <italic>p<sub>i</sub></italic> (note that these signals are assumed to be carried by modulation of a tonic firing rate so that both positive and negative signal values can be coded). These parallel fibre inputs are re-combined by the Purkinje cell to produce its output<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000085.e001" xlink:type="simple"/><label>(1)</label></disp-formula>If the desired output is γ<italic>s</italic> (i.e., the required gain is <italic>γ</italic>), the error in PC output is <italic>z</italic>−<italic>γ</italic><italic>s</italic>. Learning stability requires that the climbing fibre input <italic>e</italic> is an approximation to this output error; that is, <italic>e</italic>≈<italic>z</italic>−<italic>γ</italic><italic>s</italic>. The level of approximation required is that these quantities be related by a strictly positive real transfer function <xref ref-type="bibr" rid="pcbi.1000085-Sastry1">[49]</xref>. It has been shown that in recurrent architecture <italic>e</italic> can be an error in task space, that is, a sensory error, while forward architectures such as feedback-error learning require that <italic>e</italic> be a motor error signal. This distinction (discussed further in <xref ref-type="bibr" rid="pcbi.1000085-Porrill1">[15]</xref>,<xref ref-type="bibr" rid="pcbi.1000085-Porrill2">[16]</xref>) is not relevant to the phenomena discussed here. The learning rule is the covariance learning rule<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000085.e002" xlink:type="simple"/><label>(2)</label></disp-formula>If the strict positive realness condition is satisfied this learning rule can be shown to minimise mean square error <italic>E</italic> = 〈<italic>e</italic><sup>2</sup>〉.</p><p>We consider an illustrative situation in which each parallel fibre carries a combination of the signal of interest <italic>s</italic> and uncorrelated noise <italic>n<sub>i</sub></italic><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000085.e003" xlink:type="simple"/><label>(3)</label></disp-formula>(the noise sources are assumed to be pairwise uncorrelated). The mean square error has the form<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000085.e004" xlink:type="simple"/><label>(4)</label></disp-formula>whose minimum is at<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000085.e005" xlink:type="simple"/><label>(5)</label></disp-formula>so that the optimal weights are in the ratios<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000085.e006" xlink:type="simple"/><label>(6)</label></disp-formula>Note that in general the optimal weights give an optimal gain <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000085.e007" xlink:type="simple"/></inline-formula>, which is smaller than γ, this is due to the usual trade-off between bias and variance for an optimal estimator.</p><p>The rate of approach to the optimal weights is determined by the covariance learning rule which takes the form<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000085.e008" xlink:type="simple"/><label>(7)</label></disp-formula>Rigorous bounds on the time constants of this system can be obtained using the eigenvalue interlacing theorem <xref ref-type="bibr" rid="pcbi.1000085-Horn1">[50]</xref>, here we use a simpler heuristic approach. Suppose there was zero noise. Then weight update would take place entirely in the direction (α<italic><sub>i</sub></italic>) with time constant<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000085.e009" xlink:type="simple"/><label>(8)</label></disp-formula></p><p>Superimposed on this is a motion in each coordinate direction generated by the noise term with time constants<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000085.e010" xlink:type="simple"/><label>(9)</label></disp-formula>(given subscripts fast and slow because noise power will usually be much smaller than signal power). The ratio of the slow to fast time constants is thus determined by the signal to noise ratio:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000085.e011" xlink:type="simple"/><label>(10)</label></disp-formula></p></sec></sec><sec id="s5"><title>Supporting Information</title><supplementary-material id="pcbi.1000085.s001" mimetype="application/zip" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000085.s001" xlink:type="simple"><label>Dataset S1</label><caption><p>Zipped folder containg MatLab code to generate <xref ref-type="fig" rid="pcbi-1000085-g003">Figures 3</xref>–<xref ref-type="fig" rid="pcbi-1000085-g004"/><xref ref-type="fig" rid="pcbi-1000085-g005"/><xref ref-type="fig" rid="pcbi-1000085-g006">6</xref>.</p><p>(1.23 MB ZIP)</p></caption></supplementary-material></sec></body><back><ref-list><title>References</title><ref id="pcbi.1000085-Eccles1"><label>1</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Eccles</surname><given-names>JC</given-names></name><name name-style="western"><surname>Ito</surname><given-names>M</given-names></name><name name-style="western"><surname>Szentágothai</surname><given-names>J</given-names></name></person-group>             <year>1967</year>             <source>The Cerebellum as a Neuronal Machine</source>             <publisher-loc>Berlin</publisher-loc>             <publisher-name>Springer-Verlag</publisher-name>          </element-citation></ref><ref id="pcbi.1000085-Marr1"><label>2</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Marr</surname><given-names>D</given-names></name></person-group>             <year>1969</year>             <article-title>A theory of cerebellar cortex.</article-title>             <source>J Physiol (Lond)</source>             <volume>202</volume>             <fpage>437</fpage>             <lpage>470</lpage>          </element-citation></ref><ref id="pcbi.1000085-Albus1"><label>3</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Albus</surname><given-names>JS</given-names></name></person-group>             <year>1971</year>             <article-title>A theory of cerebellar function.</article-title>             <source>Math Biosci</source>             <volume>10</volume>             <fpage>25</fpage>             <lpage>61</lpage>          </element-citation></ref><ref id="pcbi.1000085-Fujita1"><label>4</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Fujita</surname><given-names>M</given-names></name></person-group>             <year>1982</year>             <article-title>Adaptive filter model of the cerebellum.</article-title>             <source>Biol Cybern</source>             <volume>45</volume>             <fpage>195</fpage>             <lpage>206</lpage>          </element-citation></ref><ref id="pcbi.1000085-Barlow1"><label>5</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Barlow</surname><given-names>JS</given-names></name></person-group>             <year>2002</year>             <source>The Cerebellum and Adaptive Control</source>             <publisher-loc>New York</publisher-loc>             <publisher-name>Cambridge University Press</publisher-name>          </element-citation></ref><ref id="pcbi.1000085-Ito1"><label>6</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Ito</surname><given-names>M</given-names></name></person-group>             <year>2006</year>             <article-title>Cerebellar circuitry as a neuronal machine.</article-title>             <source>Prog Neurobiol</source>             <volume>78</volume>             <fpage>272</fpage>             <lpage>303</lpage>          </element-citation></ref><ref id="pcbi.1000085-Bartha1"><label>7</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Bartha</surname><given-names>GT</given-names></name><name name-style="western"><surname>Thompson</surname><given-names>RF</given-names></name><name name-style="western"><surname>Gluck</surname><given-names>MA</given-names></name></person-group>             <year>1991</year>             <article-title>Sensorimotor learning and the cerebellum.</article-title>             <person-group person-group-type="editor"><name name-style="western"><surname>Arbib</surname><given-names>M</given-names></name><name name-style="western"><surname>J-P</surname><given-names>Ewert</given-names></name></person-group>             <source>Visual structures and integrated functions</source>             <publisher-loc>Berlin</publisher-loc>             <publisher-name>Springer-Verlag</publisher-name>             <fpage>381</fpage>             <lpage>396</lpage>          </element-citation></ref><ref id="pcbi.1000085-Gomi1"><label>8</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Gomi</surname><given-names>H</given-names></name><name name-style="western"><surname>Kawato</surname><given-names>M</given-names></name></person-group>             <year>1992</year>             <article-title>Adaptive feedback control models of the vestibulocerebellum and spinocerebellum.</article-title>             <source>Biol Cybern</source>             <volume>68</volume>             <fpage>105</fpage>             <lpage>114</lpage>          </element-citation></ref><ref id="pcbi.1000085-Coenen1"><label>9</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Coenen</surname><given-names>OJMD</given-names></name><name name-style="western"><surname>Sejnowski</surname><given-names>TJ</given-names></name></person-group>             <year>1996</year>             <article-title>Learning to make predictions in the cerebellum may explain the anticipatory modulation of the vestibulo-ocular reflex (VOR) gain with vergence.</article-title>             <source>Proceedings of the 3rd Joint Symposium on Neural Computation. University of California San Diego: Institute of Neural Computation</source>             <fpage>202</fpage>             <lpage>221</lpage>          </element-citation></ref><ref id="pcbi.1000085-Kettner1"><label>10</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kettner</surname><given-names>RE</given-names></name><name name-style="western"><surname>Mahamud</surname><given-names>S</given-names></name><name name-style="western"><surname>Leung</surname><given-names>HC</given-names></name><name name-style="western"><surname>Sitkoff</surname><given-names>N</given-names></name><name name-style="western"><surname>Houk</surname><given-names>JC</given-names></name><etal/></person-group>             <year>1997</year>             <article-title>Prediction of complex two-dimensional trajectories by a cerebellar model of smooth pursuit eye movement.</article-title>             <source>J Neurophysiol</source>             <volume>77</volume>             <fpage>2115</fpage>             <lpage>2130</lpage>          </element-citation></ref><ref id="pcbi.1000085-Schweighofer1"><label>11</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Schweighofer</surname><given-names>N</given-names></name><name name-style="western"><surname>Spoelstra</surname><given-names>J</given-names></name><name name-style="western"><surname>Arbib</surname><given-names>MA</given-names></name><name name-style="western"><surname>Kawato</surname><given-names>M</given-names></name></person-group>             <year>1998</year>             <article-title>Role of the cerebellum in reaching movements in humans. II. A neural model of the intermediate cerebellum.</article-title>             <source>Eur J Neurosci</source>             <volume>10</volume>             <fpage>95</fpage>             <lpage>105</lpage>          </element-citation></ref><ref id="pcbi.1000085-Medina1"><label>12</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Medina</surname><given-names>JF</given-names></name><name name-style="western"><surname>Nores</surname><given-names>WL</given-names></name><name name-style="western"><surname>Mauk</surname><given-names>MD</given-names></name></person-group>             <year>2002</year>             <article-title>Inhibition of climbing fibres is a signal for the extinction of conditioned eyelid responses.</article-title>             <source>Nature</source>             <volume>416</volume>             <fpage>330</fpage>             <lpage>333</lpage>          </element-citation></ref><ref id="pcbi.1000085-Yamamoto1"><label>13</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Yamamoto</surname><given-names>K</given-names></name><name name-style="western"><surname>Kobayashi</surname><given-names>Y</given-names></name><name name-style="western"><surname>Takemura</surname><given-names>A</given-names></name><name name-style="western"><surname>Kawano</surname><given-names>K</given-names></name><name name-style="western"><surname>Kawato</surname><given-names>M</given-names></name></person-group>             <year>2002</year>             <article-title>Computational studies on acquisition and adaptation of ocular following responses based on cerebellar synaptic plasticity.</article-title>             <source>J Neurophysiol</source>             <volume>87</volume>             <fpage>1554</fpage>             <lpage>1571</lpage>          </element-citation></ref><ref id="pcbi.1000085-Dean1"><label>14</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Dean</surname><given-names>P</given-names></name><name name-style="western"><surname>Porrill</surname><given-names>J</given-names></name><name name-style="western"><surname>Stone</surname><given-names>JV</given-names></name></person-group>             <year>2002</year>             <article-title>Decorrelation control by the cerebellum achieves oculomotor plant compensation in simulated vestibulo-ocular reflex.</article-title>             <source>Proc R Soc Lond B Biol Sci</source>             <volume>269</volume>             <fpage>1895</fpage>             <lpage>1904</lpage>          </element-citation></ref><ref id="pcbi.1000085-Porrill1"><label>15</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Porrill</surname><given-names>J</given-names></name><name name-style="western"><surname>Dean</surname><given-names>P</given-names></name><name name-style="western"><surname>Stone</surname><given-names>JV</given-names></name></person-group>             <year>2004</year>             <article-title>Recurrent cerebellar architecture solves the motor error problem.</article-title>             <source>Proc R Soc Lond B Biol Sci</source>             <volume>271</volume>             <fpage>789</fpage>             <lpage>796</lpage>          </element-citation></ref><ref id="pcbi.1000085-Porrill2"><label>16</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Porrill</surname><given-names>J</given-names></name><name name-style="western"><surname>Dean</surname><given-names>P</given-names></name></person-group>             <year>2007</year>             <article-title>Recurrent cerebellar loops simplify adaptive control of redundant and nonlinear motor systems.</article-title>             <source>Neural Comput</source>             <volume>19</volume>             <fpage>170</fpage>             <lpage>193</lpage>          </element-citation></ref><ref id="pcbi.1000085-Porrill3"><label>17</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Porrill</surname><given-names>J</given-names></name><name name-style="western"><surname>Dean</surname><given-names>P</given-names></name></person-group>             <year>2007</year>             <article-title>Cerebellar motor learning: when is cortical plasticity not enough?</article-title>             <source>PLoS Comp Biol</source>             <volume>3</volume>             <fpage>1935</fpage>             <lpage>1950</lpage>          </element-citation></ref><ref id="pcbi.1000085-Jordan1"><label>18</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Jordan</surname><given-names>MI</given-names></name></person-group>             <year>1996</year>             <article-title>Computational aspects of motor control and motor learning.</article-title>             <person-group person-group-type="editor"><name name-style="western"><surname>Heuer</surname><given-names>H</given-names></name><name name-style="western"><surname>Keele</surname><given-names>S</given-names></name></person-group>             <source>Handbook of Perception and Action, Volume 2: Motor Skills</source>             <publisher-loc>London</publisher-loc>             <publisher-name>Academic Press</publisher-name>             <fpage>71</fpage>             <lpage>120</lpage>          </element-citation></ref><ref id="pcbi.1000085-Jordan2"><label>19</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Jordan</surname><given-names>MI</given-names></name><name name-style="western"><surname>Wolpert</surname><given-names>DM</given-names></name></person-group>             <year>2000</year>             <article-title>Computational Motor Control.</article-title>             <person-group person-group-type="editor"><name name-style="western"><surname>Gazzaniga</surname><given-names>MS</given-names></name></person-group>             <source>The New Cognitive Neurosciences. 2nd ed</source>             <publisher-loc>Cambridge, MA</publisher-loc>             <publisher-name>MIT Press</publisher-name>             <fpage>601</fpage>             <lpage>618</lpage>          </element-citation></ref><ref id="pcbi.1000085-Stein1"><label>20</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Stein</surname><given-names>RB</given-names></name><name name-style="western"><surname>Gossen</surname><given-names>ER</given-names></name><name name-style="western"><surname>Jones</surname><given-names>KE</given-names></name></person-group>             <year>2005</year>             <article-title>Neuronal variability: noise or part of the signal?</article-title>             <source>Nature Rev Neurosci</source>             <volume>6</volume>             <fpage>389</fpage>             <lpage>397</lpage>          </element-citation></ref><ref id="pcbi.1000085-Marr2"><label>21</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Marr</surname><given-names>D</given-names></name></person-group>             <year>1982</year>             <source>Vision: A Computational Investigation into the Human Representation and Processing of Visual Information</source>             <publisher-loc>San Francisco</publisher-loc>             <publisher-name>W.H.Freeman</publisher-name>          </element-citation></ref><ref id="pcbi.1000085-Kawato1"><label>22</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kawato</surname><given-names>M</given-names></name></person-group>             <year>1995</year>             <article-title>Cerebellum and Motor Control.</article-title>             <person-group person-group-type="editor"><name name-style="western"><surname>Arbib</surname><given-names>MA</given-names></name></person-group>             <source>The Handbook of Brain Theory and Neural Networks</source>             <publisher-loc>Cambridge, MA</publisher-loc>             <publisher-name>The MIT Press</publisher-name>             <fpage>172</fpage>             <lpage>178</lpage>          </element-citation></ref><ref id="pcbi.1000085-Sejnowski1"><label>23</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Sejnowski</surname><given-names>TJ</given-names></name></person-group>             <year>1977</year>             <article-title>Storing covariance with nonlinearly interacting neurons.</article-title>             <source>J Math Biol</source>             <volume>4</volume>             <fpage>303</fpage>             <lpage>321</lpage>          </element-citation></ref><ref id="pcbi.1000085-Widrow1"><label>24</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Widrow</surname><given-names>B</given-names></name><name name-style="western"><surname>Stearns</surname><given-names>SD</given-names></name></person-group>             <year>1985</year>             <source>Adaptive Signal Processing</source>             <publisher-loc>Engelwood Cliffs , NJ</publisher-loc>             <publisher-name>Prentice-Hall Inc</publisher-name>          </element-citation></ref><ref id="pcbi.1000085-Jrntell1"><label>25</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Jörntell</surname><given-names>H</given-names></name><name name-style="western"><surname>Hansel</surname><given-names>C</given-names></name></person-group>             <year>2006</year>             <article-title>Synaptic memories upside down: bidirectional plasticity at cerebellar parallel fiber-Purkinje cell synapses.</article-title>             <source>Neuron</source>             <volume>52</volume>             <fpage>227</fpage>             <lpage>238</lpage>          </element-citation></ref><ref id="pcbi.1000085-Boyden1"><label>26</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Boyden</surname><given-names>ES</given-names></name><name name-style="western"><surname>Katoh</surname><given-names>A</given-names></name><name name-style="western"><surname>Raymond</surname><given-names>JL</given-names></name></person-group>             <year>2004</year>             <article-title>Cerebellum-dependent learning: the role of multiple plasticity mechanisms.</article-title>             <source>Annu Rev Neurosci</source>             <volume>27</volume>             <fpage>581</fpage>             <lpage>609</lpage>          </element-citation></ref><ref id="pcbi.1000085-Ernst1"><label>27</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Ernst</surname><given-names>MO</given-names></name><name name-style="western"><surname>Banks</surname><given-names>MS</given-names></name></person-group>             <year>2002</year>             <article-title>Humans integrate visual and haptic information in a statistically optimal fashion.</article-title>             <source>Nature</source>             <volume>415</volume>             <fpage>429</fpage>             <lpage>433</lpage>          </element-citation></ref><ref id="pcbi.1000085-Osborne1"><label>28</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Osborne</surname><given-names>LC</given-names></name><name name-style="western"><surname>Lisberger</surname><given-names>SG</given-names></name><name name-style="western"><surname>Bialek</surname><given-names>W</given-names></name></person-group>             <year>2005</year>             <article-title>A sensory source for motor variation.</article-title>             <source>Nature</source>             <volume>437</volume>             <fpage>412</fpage>             <lpage>416</lpage>          </element-citation></ref><ref id="pcbi.1000085-Ito2"><label>29</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Ito</surname><given-names>M</given-names></name></person-group>             <year>1984</year>             <source>The cerebellum and neural control</source>             <publisher-loc>New York</publisher-loc>             <publisher-name>Raven Press</publisher-name>          </element-citation></ref><ref id="pcbi.1000085-Isope1"><label>30</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Isope</surname><given-names>P</given-names></name><name name-style="western"><surname>Barbour</surname><given-names>B</given-names></name></person-group>             <year>2002</year>             <article-title>Properties of unitary granule cell -&gt; Purkinje cell synapses in adult rat cerebellar slices.</article-title>             <source>J Neurosci</source>             <volume>22</volume>             <fpage>9668</fpage>             <lpage>9678</lpage>          </element-citation></ref><ref id="pcbi.1000085-Jrntell2"><label>31</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Jörntell</surname><given-names>H</given-names></name><name name-style="western"><surname>Ekerot</surname><given-names>CF</given-names></name></person-group>             <year>2002</year>             <article-title>Receptive field plasticity profoundly alters the cutaneous parallel fiber synaptic input to cerebellar interneurons <italic>in vivo</italic>.</article-title>             <source>J Neurosci</source>             <volume>23</volume>             <fpage>9620</fpage>             <lpage>9631</lpage>          </element-citation></ref><ref id="pcbi.1000085-Ekerot1"><label>32</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Ekerot</surname><given-names>CF</given-names></name><name name-style="western"><surname>Jorntell</surname><given-names>H</given-names></name></person-group>             <year>2003</year>             <article-title>Parallel fiber receptive fields: a key to understanding cerebellar operation and learning.</article-title>             <source>Cerebellum</source>             <volume>2</volume>             <fpage>101</fpage>             <lpage>109</lpage>          </element-citation></ref><ref id="pcbi.1000085-Boyden2"><label>33</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Boyden</surname><given-names>ES</given-names></name><name name-style="western"><surname>Raymond</surname><given-names>JL</given-names></name></person-group>             <year>2003</year>             <article-title>Active reversal of motor memories reveals rules governing memory encoding.</article-title>             <source>Neuron</source>             <volume>39</volume>             <fpage>1031</fpage>             <lpage>1042</lpage>          </element-citation></ref><ref id="pcbi.1000085-Osborne2"><label>34</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Osborne</surname><given-names>LC</given-names></name><name name-style="western"><surname>Hohl</surname><given-names>SS</given-names></name><name name-style="western"><surname>Bialek</surname><given-names>W</given-names></name><name name-style="western"><surname>Lisberger</surname><given-names>SG</given-names></name></person-group>             <year>2007</year>             <article-title>Time course of precision in smooth-pursuit eye movements of monkeys.</article-title>             <source>J Neurosci</source>             <volume>27</volume>             <fpage>2987</fpage>             <lpage>2998</lpage>          </element-citation></ref><ref id="pcbi.1000085-Krauzlis1"><label>35</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Krauzlis</surname><given-names>RJ</given-names></name></person-group>             <year>2004</year>             <article-title>Recasting the smooth pursuit eye movement system.</article-title>             <source>J Neurophysiol</source>             <volume>91</volume>             <fpage>591</fpage>             <lpage>603</lpage>          </element-citation></ref><ref id="pcbi.1000085-Medina2"><label>36</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Medina</surname><given-names>JF</given-names></name><name name-style="western"><surname>Lisberger</surname><given-names>SG</given-names></name></person-group>             <year>2007</year>             <article-title>Variation, signal, and noise in cerebellar sensory-motor processing for smooth-pursuit eye movements.</article-title>             <source>J Neurosci</source>             <volume>27</volume>             <fpage>6832</fpage>             <lpage>6842</lpage>          </element-citation></ref><ref id="pcbi.1000085-Kimpo1"><label>37</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kimpo</surname><given-names>RR</given-names></name><name name-style="western"><surname>Boyden</surname><given-names>ES</given-names></name><name name-style="western"><surname>Katoh</surname><given-names>A</given-names></name><name name-style="western"><surname>Ke</surname><given-names>MC</given-names></name><name name-style="western"><surname>Raymond</surname><given-names>JL</given-names></name></person-group>             <year>2005</year>             <article-title>Distinct patterns of stimulus generalization of increases and decreases in VOR gain.</article-title>             <source>J Neurophysiol</source>             <volume>94</volume>             <fpage>3092</fpage>             <lpage>3100</lpage>          </element-citation></ref><ref id="pcbi.1000085-Boyden3"><label>38</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Boyden</surname><given-names>ES</given-names></name><name name-style="western"><surname>Katoh</surname><given-names>A</given-names></name><name name-style="western"><surname>Pyle</surname><given-names>JL</given-names></name><name name-style="western"><surname>Chatila</surname><given-names>TA</given-names></name><name name-style="western"><surname>Tsien</surname><given-names>RW</given-names></name><etal/></person-group>             <year>2006</year>             <article-title>Selective engagement of plasticity mechanisms for motor memory storage.</article-title>             <source>Neuron</source>             <volume>51</volume>             <fpage>823</fpage>             <lpage>834</lpage>          </element-citation></ref><ref id="pcbi.1000085-Hansel1"><label>39</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hansel</surname><given-names>C</given-names></name><name name-style="western"><surname>de Jeu</surname><given-names>M</given-names></name><name name-style="western"><surname>Belmeguenai</surname><given-names>A</given-names></name><name name-style="western"><surname>Houtman</surname><given-names>SH</given-names></name><name name-style="western"><surname>Buitendijk</surname><given-names>GH</given-names></name><etal/></person-group>             <year>2006</year>             <article-title>alphaCaMKII Is essential for cerebellar LTD and motor learning.</article-title>             <source>Neuron</source>             <volume>51</volume>             <fpage>835</fpage>             <lpage>843</lpage>          </element-citation></ref><ref id="pcbi.1000085-Cohen1"><label>40</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Cohen</surname><given-names>MR</given-names></name><name name-style="western"><surname>Meissner</surname><given-names>GW</given-names></name><name name-style="western"><surname>Schafer</surname><given-names>RJ</given-names></name><name name-style="western"><surname>Raymond</surname><given-names>JL</given-names></name></person-group>             <year>2004</year>             <article-title>Reversal of motor learning in the vestibulo-ocular reflex in the absence of visual input.</article-title>             <source>Learn Mem</source>             <volume>11</volume>          </element-citation></ref><ref id="pcbi.1000085-Kuki1"><label>41</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kuki</surname><given-names>Y</given-names></name><name name-style="western"><surname>Hirata</surname><given-names>Y</given-names></name><name name-style="western"><surname>Blazquez</surname><given-names>PM</given-names></name><name name-style="western"><surname>Heiney</surname><given-names>SA</given-names></name><name name-style="western"><surname>Highstein</surname><given-names>SM</given-names></name></person-group>             <year>2004</year>             <article-title>Memory retention of vestibuloocular reflex motor learning in squirrel monkeys.</article-title>             <source>NeuroReport</source>             <volume>15</volume>             <fpage>1007</fpage>             <lpage>1011</lpage>          </element-citation></ref><ref id="pcbi.1000085-Kehoe1"><label>42</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kehoe</surname><given-names>EJ</given-names></name></person-group>             <year>2006</year>             <article-title>Repeated acquisitions and extinctions in classical conditioning of the rabbit nictitating membrane response.</article-title>             <source>Learn Mem</source>             <volume>13</volume>             <fpage>366</fpage>             <lpage>375</lpage>          </element-citation></ref><ref id="pcbi.1000085-Jirenhed1"><label>43</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Jirenhed</surname><given-names>DA</given-names></name><name name-style="western"><surname>Bengtsson</surname><given-names>F</given-names></name><name name-style="western"><surname>Hesslow</surname><given-names>G</given-names></name></person-group>             <year>2007</year>             <article-title>Acquisition, extinction, and reacquisition of a cerebellar cortical memory trace.</article-title>             <source>J Neurosci</source>             <volume>27</volume>             <fpage>2493</fpage>             <lpage>2502</lpage>          </element-citation></ref><ref id="pcbi.1000085-DeZeeuw1"><label>44</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>De Zeeuw</surname><given-names>CI</given-names></name><name name-style="western"><surname>Yeo</surname><given-names>CH</given-names></name></person-group>             <year>2005</year>             <article-title>Time and tide in cerebellar memory formation.</article-title>             <source>Curr Opin Neurobiol</source>             <volume>15</volume>             <fpage>667</fpage>             <lpage>674</lpage>          </element-citation></ref><ref id="pcbi.1000085-Brunel1"><label>45</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Brunel</surname><given-names>N</given-names></name><name name-style="western"><surname>Hakim</surname><given-names>V</given-names></name><name name-style="western"><surname>Isope</surname><given-names>P</given-names></name><name name-style="western"><surname>Nadal</surname><given-names>JP</given-names></name><name name-style="western"><surname>Barbour</surname><given-names>B</given-names></name></person-group>             <year>2004</year>             <article-title>Optimal information storage and the distribution of synaptic weights: Perceptron versus Purkinje cell.</article-title>             <source>Neuron</source>             <volume>43</volume>             <fpage>745</fpage>             <lpage>757</lpage>          </element-citation></ref><ref id="pcbi.1000085-Kanerva1"><label>46</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kanerva</surname><given-names>P</given-names></name></person-group>             <year>1992</year>             <article-title>Associative-memory models of the cerebellum.</article-title>             <person-group person-group-type="editor"><name name-style="western"><surname>Aleksander</surname><given-names>I</given-names></name><name name-style="western"><surname>Taylor</surname><given-names>J</given-names></name></person-group>             <source>International Conference on Artificial Neural Networks</source>             <publisher-loc>Brighton, UK</publisher-loc>             <publisher-name>North-Holland</publisher-name>             <fpage>23</fpage>             <lpage>34</lpage>          </element-citation></ref><ref id="pcbi.1000085-Tyrrell1"><label>47</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Tyrrell</surname><given-names>T</given-names></name><name name-style="western"><surname>Willshaw</surname><given-names>D</given-names></name></person-group>             <year>1992</year>             <article-title>Cerebellar cortex: its simulation and the relevance of Marr's theory.</article-title>             <source>Philos Trans R Soc Lond B Biol Sci</source>             <volume>336</volume>             <fpage>239</fpage>             <lpage>257</lpage>          </element-citation></ref><ref id="pcbi.1000085-Atkeson1"><label>48</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Atkeson</surname><given-names>CG</given-names></name><name name-style="western"><surname>Moore</surname><given-names>AW</given-names></name><name name-style="western"><surname>Schaal</surname><given-names>S</given-names></name></person-group>             <year>1997</year>             <article-title>Locally weighted learning for control.</article-title>             <source>Artificial Intelligence Rev</source>             <volume>11</volume>             <fpage>75</fpage>             <lpage>113</lpage>          </element-citation></ref><ref id="pcbi.1000085-Sastry1"><label>49</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Sastry</surname><given-names>S</given-names></name><name name-style="western"><surname>Bodson</surname><given-names>M</given-names></name></person-group>             <year>1989</year>             <source>Adaptive Control: Stability, Convergence, and Robustness</source>             <publisher-loc>Englewood Cliffs, N.J.</publisher-loc>             <publisher-name>Prentice-Hall International</publisher-name>          </element-citation></ref><ref id="pcbi.1000085-Horn1"><label>50</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Horn</surname><given-names>RA</given-names></name><name name-style="western"><surname>Johnson</surname><given-names>CR</given-names></name></person-group>             <year>1985</year>             <source>Matrix Analysis</source>             <publisher-loc>New York</publisher-loc>             <publisher-name>Cambridge University Press</publisher-name>          </element-citation></ref></ref-list></back></article>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN" "http://jats.nlm.nih.gov/publishing/1.1d3/JATS-journalpublishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="other" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">plosbiol</journal-id>
<journal-title-group>
<journal-title>PLOS Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1544-9173</issn>
<issn pub-type="epub">1545-7885</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pbio.2005468</article-id>
<article-id pub-id-type="publisher-id">pbio.2005468</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Matters</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Research design</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Research assessment</subject><subj-group><subject>Peer review</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Science policy</subject><subj-group><subject>Science and technology workforce</subject><subj-group><subject>Careers in research</subject><subj-group><subject>Scientists</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>People and places</subject><subj-group><subject>Population groupings</subject><subj-group><subject>Professions</subject><subj-group><subject>Scientists</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Science policy</subject><subj-group><subject>Research funding</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Research assessment</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Science policy</subject><subj-group><subject>Research integrity</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Academic skills</subject><subj-group><subject>Numeracy</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Academic skills</subject><subj-group><subject>Numeracy</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Academic skills</subject><subj-group><subject>Numeracy</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Astronomical sciences</subject><subj-group><subject>Astrophysics</subject><subj-group><subject>Dark matter</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Physics</subject><subj-group><subject>Astrophysics</subject><subj-group><subject>Dark matter</subject></subj-group></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Meta-research: Why research on research matters</article-title>
<alt-title alt-title-type="running-head">Meta-research matters</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-3118-6859</contrib-id>
<name name-style="western">
<surname>Ioannidis</surname>
<given-names>John P. A.</given-names>
</name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
</contrib-group>
<aff id="aff001"><label>1</label> <addr-line>Meta-Research Innovation Center at Stanford (METRICS), Stanford University, Stanford, California, United States of America</addr-line></aff>
<aff id="aff002"><label>2</label> <addr-line>Department of Medicine, Department of Health Research and Policy, and Department of Biomedical Data Science, Stanford University School of Medicine, Stanford, California, United States of America</addr-line></aff>
<aff id="aff003"><label>3</label> <addr-line>Department of Statistics, Stanford University School of Humanities and Sciences, Stanford, California, United States of America</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">jioannid@stanford.edu</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>13</day>
<month>3</month>
<year>2018</year>
</pub-date>
<pub-date pub-type="collection">
<month>3</month>
<year>2018</year>
</pub-date>
<volume>16</volume>
<issue>3</issue>
<elocation-id>e2005468</elocation-id>
<permissions>
<copyright-year>2018</copyright-year>
<copyright-holder>Ioannidis John P. A.</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pbio.2005468"/>
<abstract>
<p>Meta-research is the study of research itself: its methods, reporting, reproducibility, evaluation, and incentives. Given that science is the key driver of human progress, improving the efficiency of scientific investigation and yielding more credible and more useful research results can translate to major benefits. The research enterprise grows very fast. Both new opportunities for knowledge and innovation and new threats to validity and scientific integrity emerge. Old biases abound, and new ones continuously appear as novel disciplines emerge with different standards and challenges. Meta-research uses an interdisciplinary approach to study, promote, and defend robust science. Major disruptions are likely to happen in the way we pursue scientific investigation, and it is important to ensure that these disruptions are evidence based.</p>
</abstract>
<funding-group>
<funding-statement>Laura and John Arnold Foundation. The Meta-Research Innovation Center at Stanford (METRICS) has been funded by the Laura and John Arnold Foundation. The work of John Ioannidis is funded by an unrestricted gift from Sue and Bob O’Donnell. The funder had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="0"/>
<table-count count="0"/>
<page-count count="6"/>
</counts>
<custom-meta-group>
<custom-meta>
<meta-name>PLOS Publication Stage</meta-name>
<meta-value>vor-update-to-uncorrected-proof</meta-value>
</custom-meta>
<custom-meta>
<meta-name>Publication Update</meta-name>
<meta-value>2018-03-23</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<p>Science, like all human endeavors, is prone to biases. Yet science can assess its own methods, reporting, reproducibility, evaluation, and incentives [<xref ref-type="bibr" rid="pbio.2005468.ref001">1</xref>]. A relatively new discipline, called meta-research, covers a wide range of theoretical, observational, and experimental investigations designed to study research itself and its practices. The objective is to understand and improve how we perform, communicate, verify, evaluate, and reward research [<xref ref-type="bibr" rid="pbio.2005468.ref001">1</xref>].</p>
<p>Before elaborating on a discipline that studies biases, I should disclose some of my own. First, all scientists are meta-researchers to some extent, though most usually work on focused subject matter disciplines. And though the advice of my early lab mentors—“focus, focus, focus”—still rings in my ears, the piles on my desk and the files in my computers can be notoriously unfocused. I don’t have attention-deficit disorder, but plain unconstrained curiosity. What attracted me to science was its vastness and diversity. In my early training years, I enjoyed roaming in libraries in Athens and Boston, discovering scientific journals with fancy names, encountering intriguing articles, drifting from my initial search. Without yet realizing it, I was interested primarily in research itself apparently, much as others were interested primarily in <italic>Caenorhabditis elegans</italic>, volcanic eruptions, or automata.</p>
<p>Science and its literature is a marvelous maze of data, arguments, biases, errors, and the greatest achievements of humans. What can be more rewarding to study scientifically? Thirty years later, I still feel like a researcher-in-training—actually, in early training—barely scratching the surface. However, much has changed. Thirty years ago, articles had to be handpicked like flowers one by one from their journal shelves and photocopied one page at a time. Now, one can text mine a million articles overnight. Good research, however, still takes time and focus. Take, for example, a recent project I worked on with my friend David Chavalarias. We text mined 12,821,790 abstracts and 843,884 full-text articles. We initially joked that it would take two days max. Eventually, it took four years of work with innumerable iterations, meticulous corrections, and repeated downloads.</p>
<p>My other personal bias is a heightened interest in methods rather than results. Result narratives are supposedly always exciting. I find them unbearably boring. Conversely, methods typically are missing in action, left unsung, or hidden in small print. Many researchers hope to clarify how to do experiments chatting in corridors or conferences. Study design and analysis are still mostly taught (if at all) in statistics-lite courses. Most of us have mastered how to write papers through reading other (mostly poorly reported) papers. We freely volunteer peer review but lack formal training on how to do it. In many fields, issues surrounding reproducibility were dormant until recently.</p>
<p>Science remains the key driver of human progress, yet we have little evidence on how to best fund science and incentivize high-quality work. We do know that leaving research practices to serendipity, biasing influences, methodological illiteracy, and statistical innumeracy is inefficient. Science needs science to avoid wasted effort and optimize resources. Amateur approaches face the current gigantic magnitudes of the research endeavor. Google Scholar currently includes about 180,000,000 documents, accruing approximately 4,000,000 new papers annually [<xref ref-type="bibr" rid="pbio.2005468.ref002">2</xref>]. Along this universe of visible (published) matter, dark matter abounds; probably most observations and data analyses remain unpublished. Ulrich’s directory includes more than 40,000 refereed academic journals, and this is probably an underestimate [<xref ref-type="bibr" rid="pbio.2005468.ref003">3</xref>]. Thousands of journals follow predatory practices or have uncertain value. The Science, Technology, Engineering, and Math (STEM) publishing business market size ($28 billion) roughly equals the National Institutes of Health (NIH) budget. Webometrics lists 26,368 research-producing universities [<xref ref-type="bibr" rid="pbio.2005468.ref004">4</xref>], and many other entities generate research. Probably 100,000 biomedical conferences happen annually [<xref ref-type="bibr" rid="pbio.2005468.ref005">5</xref>]. Global Research and Development (R&amp;D) investment recently exceeded $2 trillion per year. Industry has the lion’s share, while public funding is limited for basic research and it is even more sparse for evidence-based evaluation research. Financial conflicts may shape research agendas, results, and interpretations [<xref ref-type="bibr" rid="pbio.2005468.ref006">6</xref>]. Consider that the $1 trillion tobacco industry still runs “research” on its products despite killing millions of people who use them as directed. Big Pharma, another behemoth of similar financial magnitude, but which probably saves lives (albeit often at high cost), has to sponsor most research on its own products. Understanding who should do what and how in research needs better study.</p>
<p>Science is no longer the occupation of few intellectual dilettanti. Millions (co)author scientific papers. Even more people participate in research. Currently, health record databases engulf hundreds of millions of individuals. Social media databases generate the possibility of using data on billions—active monthly Facebook users, for example, exceeded 2 billion by July 2017.</p>
<p>Currently, generated research data are massive but also fragmented and often nontransparent. Full data sharing and preregistration of protocols are still uncommon in most fields [<xref ref-type="bibr" rid="pbio.2005468.ref007">7</xref>]. We need to understand whether results and inferences are correct, modestly biased, or plain wrong. Comparing patterns of data and biases across the vast number of available studies, one can help answer this important question [<xref ref-type="bibr" rid="pbio.2005468.ref008">8</xref>]. We have mapped 235 biases in biomedical research alone [<xref ref-type="bibr" rid="pbio.2005468.ref009">9</xref>]. With increasing research complexity, multifarious choices emerge on how to design studies and analyze data. With 20 binary choices, 2<sup>20</sup> = 1,048,576 different ways exist to analyze the same data. Therefore, almost any result is possible, unless we safeguard methods and analysis standards. Surveys show that questionable research practices are used by most scientists: not fraud (which is rare) but “cutting corners” to achieve more interesting-looking results [<xref ref-type="bibr" rid="pbio.2005468.ref010">10</xref>]. Understanding the boundaries between bias and creative exploration is important. Efforts to reproduce high-profile studies have shown high rates of nonreproducibility [<xref ref-type="bibr" rid="pbio.2005468.ref011">11</xref>] and most scientists agree that a reproducibility crisis exists [<xref ref-type="bibr" rid="pbio.2005468.ref012">12</xref>]. Meta-analyses—efforts to combine all data on a given question—become increasingly popular but face their own problems and biases [<xref ref-type="bibr" rid="pbio.2005468.ref013">13</xref>].</p>
<p>How should a scientist best train, work, collaborate, and contribute to scientific and broader communities? Researchers spend most of their time on grants [<xref ref-type="bibr" rid="pbio.2005468.ref014">14</xref>] and administrative chores of unclear utility. Journal peer review takes another 64 million hours annually for biomedical papers alone [<xref ref-type="bibr" rid="pbio.2005468.ref015">15</xref>]. Justifiably, we all despise bureaucracy and obstructions. Poor research practices make things worse.</p>
<p>Thousands of new scientific fields emerge, merge, split, and evolve [<xref ref-type="bibr" rid="pbio.2005468.ref016">16</xref>]. Different disciplines may differ in research standards and challenges (<xref ref-type="boxed-text" rid="pbio.2005468.box001">Box 1</xref>). Meta-research can help us disseminate efficient research practices and abandon wasteful ones. Publication and peer review models, scientific education, funding, and academic reward systems need to adapt successfully to a rapidly changing world. Some predict [<xref ref-type="bibr" rid="pbio.2005468.ref017">17</xref>] that even researchers may disappear within decades, replaced by artificial intelligence. While this sounds extreme, several aspects of current “business as usual” in research will face disruption. Even 1% improvement in the yield and translation of useful discoveries effected through better research practices reflects value equivalent of many Nobel or Breakthrough prizes.</p>
<boxed-text id="pbio.2005468.box001" position="float">
<sec sec-type="sec001">
<title>Box 1. Features of research practices, opportunities, and threats that vary across fields.</title>
<list list-type="bullet">
<list-item><p>Type of research, designs, tools, and statistical methods</p>
<list list-type="simple">
<list-item><p>◦ Type of mix of research (basic, applied translational, evaluation, implementation)</p></list-item>
<list-item><p>◦ Types of study designs commonly used or misused</p></list-item>
<list-item><p>◦ Types of experimental/measurement tools commonly used or misused</p></list-item>
<list-item><p>◦ Types of statistical methods commonly used or misused</p></list-item>
</list>
</list-item>
</list>
<list list-type="bullet">
<list-item><p> Biases and questionable/detrimental practices</p>
<list list-type="simple">
<list-item><p>◦ Types of common biases encountered and whether they are easy to fix or not</p></list-item>
<list-item><p>◦ Extent of use of methods to prevent or correct for biases</p></list-item>
<list-item><p>◦ Prevalence of different types of questionable/detrimental research practices</p></list-item>
</list>
</list-item>
</list>
<list list-type="bullet">
<list-item><p> Targeted effects and signals</p>
<list list-type="simple">
<list-item><p>◦ Distribution of effect sizes observed</p></list-item>
<list-item><p>◦ Typical heterogeneity of results across studies</p></list-item>
<list-item><p>◦ Proportion of results that are true, exaggerated, or entirely false</p></list-item>
<list-item><p>◦ Reputational impact for bias or wrong, refuted results</p></list-item>
</list>
</list-item>
</list>
<list list-type="bullet">
<list-item><p> Publication and peer review practices</p>
<list list-type="simple">
<list-item><p>◦ Proportion of studies and analyses that are published</p></list-item>
<list-item><p>◦ Number and types of available publication venues</p></list-item>
<list-item><p>◦ Implementation of prepublication peer review (e.g., preprints)</p></list-item>
<list-item><p>◦ Implementation of postpublication peer review</p></list-item>
<list-item><p>◦ Extent from adoption of various research reporting standards</p></list-item>
</list>
</list-item>
</list>
<list list-type="bullet">
<list-item><p> Scientific workforce standards</p>
<list list-type="simple">
<list-item><p>◦ Commonly accepted authorship and contributorship norms</p></list-item>
<list-item><p>◦ Extent of adoption of team science and consortia</p></list-item>
<list-item><p>◦ Type of training for scientists in the field</p></list-item>
<list-item><p>◦ Extent of methodological and statistical literacy/numeracy</p></list-item>
</list>
</list-item>
</list>
<list list-type="bullet">
<list-item><p> Replication and transparency standards</p>
<list list-type="simple">
<list-item><p>◦ Extent and enforcement of preregistration of protocols</p></list-item>
<list-item><p>◦ Extent of use of replication studies</p></list-item>
<list-item><p>◦ Extent of use of exact replication versus corroboration or triangulation</p></list-item>
<list-item><p>◦ Extent of sharing of primary raw data and/or processed data</p></list-item>
<list-item><p>◦ Extent of sharing of software and code</p></list-item>
<list-item><p>◦ Extent and types of evidence synthesis used</p></list-item>
</list>
</list-item>
</list>
<list list-type="bullet">
<list-item><p> Reward structures and standards</p>
<list list-type="simple">
<list-item><p>◦ Main funders (government, industry, other) and types of studies that they fund</p></list-item>
<list-item><p>◦ Project-based versus person-based funding</p></list-item>
<list-item><p>◦ Mix and interplay of institutions performing research (university, industry, other)</p></list-item>
<list-item><p>◦ Types of metrics and criteria used for assessing researchers and institutions</p></list-item>
</list>
</list-item>
</list>
<list list-type="bullet">
<list-item><p> Conflicts</p>
<list list-type="simple">
<list-item><p>◦ Typical conflicts of interest operating in the field</p></list-item>
<list-item><p>◦ Completeness of disclosure of conflicts of interest</p></list-item>
</list>
</list-item>
</list>
<list list-type="bullet">
<list-item><p> Public interface</p>
<list list-type="simple">
<list-item><p>◦ Extent and fidelity of dissemination of research findings to the general public</p></list-item>
<list-item><p>◦ Extent of public misperceptions about the field</p></list-item>
<list-item><p>◦ Threats from antiscience advocates attacking the field</p></list-item>
</list>
</list-item>
</list>
</sec>
</boxed-text>
<p>Meta-research is interdisciplinary. For example, it benefits from better tools and methods in statistics and informatics. Complex issues of behavior change converge on modeling, psychology, sociology, and behavioral economics. Newly introduced, sophisticated measurement tools and techniques in various disciplines introduce new, peculiar errors and biases; their understanding requires combining expertise in biology, bioengineering, and data sciences. Properly communicating science and its value requires combining expertise in multiple fields and has become increasingly critical nowadays, when mistrust of science runs high and multiple interests hold a stake in influencing research results. Some interests set out to manipulate science and cause damage when their intentional bias pollutes the scientific record (e.g., tobacco companies or climate change deniers). Meta-research may be our best chance to defend science, gain public support for research, and counter antiscience movements. It may help provide a correcting mechanism closer to real time than the self-correcting scientific process that otherwise may take much longer.</p>
<p>Moreover, bird’s-eye metaviews of science are not separate and detached from focused field-specific research. In my experience, inspiration for new projects has often come from mistakes, shortcomings, or difficulties that I encountered while doing field-specific research. It is sometimes difficult to convey a message that something is wrong. However, it is paradoxically easier when the message says that thousands or millions of papers are doing something wrong rather than arousing personal animosity for a single failed paper. It is also easier when the constructive critique comes from within a field, recognized as necessary improvement rather than intrusion. Learning by collaborating with researchers in diverse disciplines and trying to understand the daily challenges in a specific field can be a highly rewarding experience for a meta-researcher. We need scientific curiosity but also intellectual humility and commitment to improve our efforts.</p>
</body>
<back>
<fn-group>
<fn fn-type="other" id="fn001">
<p><bold>Provenance:</bold> Commissioned; not externally peer reviewed</p>
</fn>
</fn-group>
<glossary>
<title>Abbreviations</title>
<def-list>
<def-item><term>NIH</term>
<def><p>National Institutes of Health</p></def>
</def-item>
<def-item><term>R&amp;D</term>
<def><p>Research and Development</p></def>
</def-item>
<def-item><term>STEM</term>
<def><p>Science, Technology, Engineering, and Math</p></def>
</def-item>
</def-list>
</glossary>
<ref-list>
<title>References</title>
<ref id="pbio.2005468.ref001"><label>1</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ioannidis</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Fanelli</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Dunne</surname> <given-names>DD</given-names></name>, <name name-style="western"><surname>Goodman</surname> <given-names>SN</given-names></name>. <article-title>Meta-research: Evaluation and improvement of research methods and practices</article-title>. <source>PLoS Biol</source>. <year>2015</year>;<volume>13</volume>: <fpage>e1002264</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pbio.1002264" xlink:type="simple">10.1371/journal.pbio.1002264</ext-link></comment> <object-id pub-id-type="pmid">26431313</object-id></mixed-citation></ref>
<ref id="pbio.2005468.ref002"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Orduna-Malea</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Ayllon</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Martin-Martin</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Lopez-Cozar</surname> <given-names>ED</given-names></name>. <article-title>Methods for estimating the size of Google Scholar</article-title>. <source>Scientometrics</source>. <year>2015</year>;<volume>104</volume>: <fpage>931</fpage>–<lpage>49</lpage>.</mixed-citation></ref>
<ref id="pbio.2005468.ref003"><label>3</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wang</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Hu</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Liu</surname> <given-names>M</given-names></name>. <article-title>The geotemporal demographics of academic journals from 1950 to 2013 according to Ulrich's database</article-title>. <source>J Informetrics</source>. <year>2017</year>;<volume>11</volume>: <fpage>655</fpage>–<lpage>71</lpage>.</mixed-citation></ref>
<ref id="pbio.2005468.ref004"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Webometrics. List of universities (as of January 2017). [Cited 21 January 2018]. Available from: <ext-link ext-link-type="uri" xlink:href="http://www.webometrics.info/en/node/54" xlink:type="simple">http://www.webometrics.info/en/node/54</ext-link>.</mixed-citation></ref>
<ref id="pbio.2005468.ref005"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ioannidis</surname> <given-names>JP</given-names></name>. <article-title>Are medical conferences useful? And for whom?</article-title> <source>JAMA</source>. <year>2012</year>;<volume>307</volume>: <fpage>1257</fpage>–<lpage>8</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1001/jama.2012.360" xlink:type="simple">10.1001/jama.2012.360</ext-link></comment> <object-id pub-id-type="pmid">22453564</object-id></mixed-citation></ref>
<ref id="pbio.2005468.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bekelman</surname> <given-names>JE</given-names></name>, <name name-style="western"><surname>Li</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Gross</surname> <given-names>CP</given-names></name>. <article-title>Scope and impact of financial conflicts of interest in biomedical research: a systematic review</article-title>. <source>JAMA</source>. <year>2003</year>;<volume>289</volume>: <fpage>454</fpage>–<lpage>465</lpage>. <object-id pub-id-type="pmid">12533125</object-id></mixed-citation></ref>
<ref id="pbio.2005468.ref007"><label>7</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Iqbal</surname> <given-names>SA</given-names></name>, <name name-style="western"><surname>Wallach</surname> <given-names>JD</given-names></name>, <name name-style="western"><surname>Khoury</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Schully</surname> <given-names>SD</given-names></name>, <name name-style="western"><surname>Ioannidis</surname> <given-names>JP</given-names></name>. <article-title>Reproducible research practices and transparency across the biomedical literature</article-title>. <source>PLoS Biol</source>. <year>2016</year>;<volume>14</volume>: <fpage>e1002333</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pbio.1002333" xlink:type="simple">10.1371/journal.pbio.1002333</ext-link></comment> <object-id pub-id-type="pmid">26726926</object-id></mixed-citation></ref>
<ref id="pbio.2005468.ref008"><label>8</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fanelli</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Costas</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Ioannidis</surname> <given-names>JP</given-names></name>. <article-title>Meta-assessment of bias in science</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2017</year>;<volume>114</volume>: <fpage>3714</fpage>–<lpage>3719</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1618569114" xlink:type="simple">10.1073/pnas.1618569114</ext-link></comment> <object-id pub-id-type="pmid">28320937</object-id></mixed-citation></ref>
<ref id="pbio.2005468.ref009"><label>9</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chavalarias</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Ioannidis</surname> <given-names>JP</given-names></name>. <article-title>Science mapping analysis characterizes 235 biases in biomedical research</article-title>. <source>J Clin Epidemiol</source>. <year>2010</year>;<volume>63</volume>: <fpage>1205</fpage>–<lpage>15</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.jclinepi.2009.12.011" xlink:type="simple">10.1016/j.jclinepi.2009.12.011</ext-link></comment> <object-id pub-id-type="pmid">20400265</object-id></mixed-citation></ref>
<ref id="pbio.2005468.ref010"><label>10</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fanelli</surname> <given-names>D</given-names></name>. <article-title>How many scientists fabricate and falsify research? A systematic review and meta-analysis of survey data</article-title>. <source>PLoS ONE</source>. <year>2009</year>;<volume>4</volume>: <fpage>e5738</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0005738" xlink:type="simple">10.1371/journal.pone.0005738</ext-link></comment> <object-id pub-id-type="pmid">19478950</object-id></mixed-citation></ref>
<ref id="pbio.2005468.ref011"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ioannidis</surname> <given-names>JPA</given-names></name>. <article-title>The reproducibility wars: successful, unsuccessful, uninterpretable, exact, conceptual, triangulated, contested replication</article-title>. <source>Clin Chem</source>. <year>2017</year>;<volume>63</volume>: <fpage>943</fpage>–<lpage>945</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1373/clinchem.2017.271965" xlink:type="simple">10.1373/clinchem.2017.271965</ext-link></comment> <object-id pub-id-type="pmid">28298413</object-id></mixed-citation></ref>
<ref id="pbio.2005468.ref012"><label>12</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Baker</surname> <given-names>M</given-names></name>. <article-title>1,500 scientists lift the lid on reproducibility</article-title>. <source>Nature</source>. <year>2016</year>;<volume>533</volume>: <fpage>452</fpage>–<lpage>4</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/533452a" xlink:type="simple">10.1038/533452a</ext-link></comment> <object-id pub-id-type="pmid">27225100</object-id></mixed-citation></ref>
<ref id="pbio.2005468.ref013"><label>13</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ioannidis</surname> <given-names>JP</given-names></name>. <article-title>The mass production of redundant, misleading, and conflicted systematic reviews and meta-analyses</article-title>. <source>Milbank Q</source>. <year>2016</year>;<volume>94</volume>: <fpage>485</fpage>–<lpage>514</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/1468-0009.12210" xlink:type="simple">10.1111/1468-0009.12210</ext-link></comment> <object-id pub-id-type="pmid">27620683</object-id></mixed-citation></ref>
<ref id="pbio.2005468.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Herbert</surname> <given-names>DL</given-names></name>, <name name-style="western"><surname>Barnett</surname> <given-names>AG</given-names></name>, <name name-style="western"><surname>Clarke</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Graves</surname> <given-names>N</given-names></name>. <article-title>On the time spent preparing grant proposals: an observational study of Australian researchers</article-title>. <source>BMJ Open</source>. <year>2013</year>;<volume>3</volume>: <fpage>e002800</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1136/bmjopen-2013-002800" xlink:type="simple">10.1136/bmjopen-2013-002800</ext-link></comment> <object-id pub-id-type="pmid">23793700</object-id></mixed-citation></ref>
<ref id="pbio.2005468.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kovanis</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Porcher</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Ravaud</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Trinquart</surname> <given-names>L</given-names></name>. <article-title>The global burden of journal peer review in the biomedical literature: strong imbalance in the collective enterprise</article-title>. <source>PLoS ONE</source>. <year>2016</year>;<volume>11</volume>: <fpage>e0166387</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0166387" xlink:type="simple">10.1371/journal.pone.0166387</ext-link></comment> <object-id pub-id-type="pmid">27832157</object-id></mixed-citation></ref>
<ref id="pbio.2005468.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Börner</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Klavans</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Patek</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Zoss</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Biberstine</surname> <given-names>JR</given-names></name>, <name name-style="western"><surname>Light</surname> <given-names>RP</given-names></name>, <name name-style="western"><surname>Larivière</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Boyack</surname> <given-names>KW</given-names></name>. <article-title>Design and update of a classification system: the UCSD map of science</article-title>. <source>PLoS ONE</source>. <year>2012</year>;<volume>7</volume>: <fpage>e39464</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0039464" xlink:type="simple">10.1371/journal.pone.0039464</ext-link></comment> <object-id pub-id-type="pmid">22808037</object-id></mixed-citation></ref>
<ref id="pbio.2005468.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Grace</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Salvatier</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Dafoe</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Zhang</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Evans</surname> <given-names>O</given-names></name>. <article-title>When will AI exceed human performance? Evidence from AI experts</article-title>. <source>arXiv</source>. <year>2017</year>;1705.08807v2 [cs.AI].</mixed-citation></ref>
</ref-list>
</back>
</article>
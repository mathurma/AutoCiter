<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN" "http://jats.nlm.nih.gov/publishing/1.1d3/JATS-journalpublishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">plosbiol</journal-id>
<journal-title-group>
<journal-title>PLOS Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1544-9173</issn>
<issn pub-type="epub">1545-7885</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pbio.1002578</article-id>
<article-id pub-id-type="publisher-id">PBIOLOGY-D-16-00735</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Emotions</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Emotions</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Attention</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Attention</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Attention</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Brain</subject><subj-group><subject>Amygdala</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Brain</subject><subj-group><subject>Amygdala</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Psychophysics</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Psychophysics</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Psychophysics</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Psychophysics</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Psychophysics</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Brain mapping</subject><subj-group><subject>Functional magnetic resonance imaging</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Diagnostic medicine</subject><subj-group><subject>Diagnostic radiology</subject><subj-group><subject>Magnetic resonance imaging</subject><subj-group><subject>Functional magnetic resonance imaging</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Imaging techniques</subject><subj-group><subject>Diagnostic radiology</subject><subj-group><subject>Magnetic resonance imaging</subject><subj-group><subject>Functional magnetic resonance imaging</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Radiology and imaging</subject><subj-group><subject>Diagnostic radiology</subject><subj-group><subject>Magnetic resonance imaging</subject><subj-group><subject>Functional magnetic resonance imaging</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Imaging techniques</subject><subj-group><subject>Neuroimaging</subject><subj-group><subject>Functional magnetic resonance imaging</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neuroimaging</subject><subj-group><subject>Functional magnetic resonance imaging</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Head</subject><subj-group><subject>Face</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Head</subject><subj-group><subject>Face</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Sensory physiology</subject><subj-group><subject>Visual system</subject><subj-group><subject>Eye movements</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Sensory physiology</subject><subj-group><subject>Visual system</subject><subj-group><subject>Eye movements</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory systems</subject><subj-group><subject>Visual system</subject><subj-group><subject>Eye movements</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Statistics (mathematics)</subject><subj-group><subject>Statistical data</subject></subj-group></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>A Normalization Framework for Emotional Attention</article-title>
<alt-title alt-title-type="running-head">Normalization Depends on Emotional Valence</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<name name-style="western">
<surname>Zhang</surname>
<given-names>Xilin</given-names>
</name>
<xref ref-type="corresp" rid="cor001">*</xref>
<xref ref-type="aff" rid="aff001"/>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Japee</surname>
<given-names>Shruti</given-names>
</name>
<xref ref-type="aff" rid="aff001"/>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Safiullah</surname>
<given-names>Zaid</given-names>
</name>
<xref ref-type="aff" rid="aff001"/>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-4438-1856</contrib-id>
<name name-style="western">
<surname>Mlynaryk</surname>
<given-names>Nicole</given-names>
</name>
<xref ref-type="aff" rid="aff001"/>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Ungerleider</surname>
<given-names>Leslie G.</given-names>
</name>
<xref ref-type="aff" rid="aff001"/>
</contrib>
</contrib-group>
<aff id="aff001"><addr-line>Laboratory of Brain and Cognition, National Institute of Mental Health, National Institutes of Health, Bethesda, Maryland, United States of America</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Tong</surname>
<given-names>Frank</given-names>
</name>
<role>Academic Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1"><addr-line>Vanderbilt University, UNITED STATES</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<fn fn-type="con">
<p><list list-type="simple">
<list-item><p><bold>Conceptualization:</bold> XZ.</p></list-item>
<list-item><p><bold>Formal analysis:</bold> XZ SJ.</p></list-item>
<list-item><p><bold>Funding acquisition:</bold> LGU.</p></list-item>
<list-item><p><bold>Investigation:</bold> XZ SJ ZS NM.</p></list-item>
<list-item><p><bold>Methodology:</bold> XZ.</p></list-item>
<list-item><p><bold>Supervision:</bold> LGU.</p></list-item>
<list-item><p><bold>Visualization:</bold> XZ LGU.</p></list-item>
<list-item><p><bold>Writing – original draft:</bold> XZ SJ LGU.</p></list-item>
<list-item><p><bold>Writing – review &amp; editing:</bold> XZ SJ LGU.</p></list-item></list></p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">xilin.zhang@nih.gov</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>21</day>
<month>11</month>
<year>2016</year>
</pub-date>
<pub-date pub-type="collection">
<month>11</month>
<year>2016</year>
</pub-date>
<volume>14</volume>
<issue>11</issue>
<elocation-id>e1002578</elocation-id>
<history>
<date date-type="received">
<day>29</day>
<month>3</month>
<year>2016</year>
</date>
<date date-type="accepted">
<day>20</day>
<month>10</month>
<year>2016</year>
</date>
</history>
<permissions>
<license xlink:href="https://creativecommons.org/publicdomain/zero/1.0/" xlink:type="simple">
<license-p>This is an open access article, free of all copyright, and may be freely reproduced, distributed, transmitted, modified, built upon, or otherwise used by anyone for any lawful purpose. The work is made available under the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/" xlink:type="simple">Creative Commons CC0</ext-link> public domain dedication.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pbio.1002578"/>
<abstract>
<p>The normalization model of attention proposes that attention can affect performance by response- or contrast-gain changes, depending on the size of the stimulus and attention field. Here, we manipulated the attention field by emotional valence, negative faces versus positive faces, while holding stimulus size constant in a spatial cueing task. We observed changes in the cueing effect consonant with changes in response gain for negative faces and contrast gain for positive faces. Neuroimaging experiments confirmed that subjects’ attention fields were narrowed for negative faces and broadened for positive faces. Importantly, across subjects, the self-reported emotional strength of negative faces and positive faces correlated, respectively, both with response- and contrast-gain changes and with primary visual cortex (V1) narrowed and broadened attention fields. Effective connectivity analysis showed that the emotional valence-dependent attention field was closely associated with feedback from the dorsolateral prefrontal cortex (DLPFC) to V1. These findings indicate a crucial involvement of DLPFC in the normalization processes of emotional attention.</p>
</abstract>
<abstract abstract-type="toc">
<p>Using a combination of psychophysics and functional MRI, this study reveals that emotional attention interacts with normalization processes depending on emotional valence (positive or negative faces), best explained by feedback modulation from the dorsolateral prefrontal cortex.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author Summary</title>
<p>Attentional selection is the mechanism by which the subset of incoming information is preferentially processed at the expense of distractors. The normalization model of attention suggests that attention-triggered modulatory effects on sensory responses in the visual cortex depend on two factors: the stimulus size and the attention field size. However, little is known regarding whether emotional attention shapes perception by means of the normalization framework. To test this hypothesis, we manipulated the attention field by emotional valence—negative faces versus positive faces—while holding the stimulus size constant in a spatial cueing task. We observed that attention increased response gain for negative faces, with the largest cueing effects occurring at high contrasts and little to no effect at low and mid-contrasts; however, attention increased contrast gain for positive faces, with the largest cueing effects occurring at mid-contrasts and little to no effect at low and high contrasts. A complementary neuroimaging experiment confirmed that subjects' attention fields were narrowed for negative faces and broadened for positive faces. Across subjects, the self-reported emotional strength of negative faces and positive faces correlated, respectively, both with response-gain and contrast-gain changes and with narrowed and broadened attention fields in the primary visual cortex. Mechanistically, we found that the emotional valence-dependent attention field was closely associated with feedback from the dorsolateral prefrontal cortex to the primary visual cortex. Our findings provide evidence for a normalization framework for emotional attention and for the critical role of feedback from the prefrontal cortex to the early visual cortex in this normalization.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000025</institution-id>
<institution>National Institute of Mental Health</institution>
</institution-wrap>
</funding-source>
<award-id>NCT00001360</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Zhang</surname>
<given-names>Xilin</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="award002">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000025</institution-id>
<institution>National Institute of Mental Health</institution>
</institution-wrap>
</funding-source>
<award-id>NCT00001360</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Japee</surname>
<given-names>Shruti</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="award003">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000025</institution-id>
<institution>National Institute of Mental Health</institution>
</institution-wrap>
</funding-source>
<award-id>NCT00001360</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Safiullah</surname>
<given-names>Zaid</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="award004">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000025</institution-id>
<institution>National Institute of Mental Health</institution>
</institution-wrap>
</funding-source>
<award-id>NCT00001360</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-4438-1856</contrib-id>
<name name-style="western">
<surname>Mlynaryk</surname>
<given-names>Nicole</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="award005">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000025</institution-id>
<institution>National Institute of Mental Health</institution>
</institution-wrap>
</funding-source>
<award-id>NCT00001360</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Ungerleider</surname>
<given-names>Leslie G.</given-names>
</name>
</principal-award-recipient>
</award-group>
<funding-statement>This work was supported by the National Institute of Mental Health Intramural Research Program (NCT00001360). URL: <ext-link ext-link-type="uri" xlink:href="http://clinicalstudies.info.nih.gov/cgi/detail.cgi?A_1993-M-0170.html" xlink:type="simple">http://clinicalstudies.info.nih.gov/cgi/detail.cgi?A_1993-M-0170.html</ext-link>. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="5"/>
<table-count count="0"/>
<page-count count="25"/>
</counts>
<custom-meta-group>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>All relevant data are within the paper and its Supporting Information files.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Attentional selection is the mechanism by which the subset of incoming information is preferentially processed at the expense of distractors. Numerous studies have suggested that attentional selection modulates both visual performance and neuronal activity in striate and extrastriate visual cortices [<xref ref-type="bibr" rid="pbio.1002578.ref001">1</xref>]. However, studies have found disparate attentional selection effects on stimulus-evoked neural responses, such as the contrast-response function (CRF) [<xref ref-type="bibr" rid="pbio.1002578.ref002">2</xref>,<xref ref-type="bibr" rid="pbio.1002578.ref003">3</xref>]. Some have reported that attentional selection primarily enhances neural responses to high-contrast stimuli (response gain) [<xref ref-type="bibr" rid="pbio.1002578.ref004">4</xref>–<xref ref-type="bibr" rid="pbio.1002578.ref009">9</xref>], whereas others have reported that attentional selection primarily enhances neural responses to medium-contrast stimuli (contrast gain) [<xref ref-type="bibr" rid="pbio.1002578.ref002">2</xref>,<xref ref-type="bibr" rid="pbio.1002578.ref003">3</xref>,<xref ref-type="bibr" rid="pbio.1002578.ref010">10</xref>,<xref ref-type="bibr" rid="pbio.1002578.ref011">11</xref>]. Still others have reported that attentional selection either enhances the entire contrast range or produces a combination of both response-gain and contrast-gain changes [<xref ref-type="bibr" rid="pbio.1002578.ref012">12</xref>–<xref ref-type="bibr" rid="pbio.1002578.ref016">16</xref>].</p>
<p>The normalization model of attention suggests that these seemingly conflicting modulatory effects of attention on sensory responses in the visual cortex may depend on two factors: the stimulus size and the attention field size [<xref ref-type="bibr" rid="pbio.1002578.ref006">6</xref>,<xref ref-type="bibr" rid="pbio.1002578.ref017">17</xref>–<xref ref-type="bibr" rid="pbio.1002578.ref019">19</xref>]. Changes in the relative size of these two factors can tip the balance between neuronal excitatory and inhibitory processes, thereby resulting in response-gain changes, contrast-gain changes, or various combinations of the two [<xref ref-type="bibr" rid="pbio.1002578.ref019">19</xref>]. Specifically, this model predicts that attention increases response gain when the stimulus is large and the attention field is small and increases contrast gain when the stimulus is small and the attention field is large. Previous psychophysical [<xref ref-type="bibr" rid="pbio.1002578.ref017">17</xref>] and electroencephalography [<xref ref-type="bibr" rid="pbio.1002578.ref020">20</xref>] studies have reported that the pattern of both behavioral performance and steady-state visual evoked potentials is consistent with the normalization model of attention. However, little is known about whether emotional attention also shapes perception by means of the normalization framework.</p>
<p>Emotional stimuli, both negative and positive emotion, tend to attract attention in humans as well as other primates [<xref ref-type="bibr" rid="pbio.1002578.ref021">21</xref>–<xref ref-type="bibr" rid="pbio.1002578.ref026">26</xref>]. However, there is a critical distinction between the perceptual correlates of negative and positive emotions, with negative emotion narrowing and positive emotion broadening the scope of attention or perception [<xref ref-type="bibr" rid="pbio.1002578.ref027">27</xref>–<xref ref-type="bibr" rid="pbio.1002578.ref030">30</xref>]. For example, negative emotion shows lower and positive emotion shows higher sensory responses to unattended extrafoveal stimuli than neutral emotion [<xref ref-type="bibr" rid="pbio.1002578.ref031">31</xref>]. The narrowing of the attention field by negative emotion is sometimes referred to as “weapon focus,” in which peripheral details of stimuli are more poorly encoded, as measured in later memory [<xref ref-type="bibr" rid="pbio.1002578.ref032">32</xref>] and repeated adaptation [<xref ref-type="bibr" rid="pbio.1002578.ref031">31</xref>]. Similarly, negative emotion is associated with a greater tendency to perceive local components of visuospatial stimuli [<xref ref-type="bibr" rid="pbio.1002578.ref033">33</xref>], whereas positive emotion is associated with a greater tendency to perceive their global components [<xref ref-type="bibr" rid="pbio.1002578.ref034">34</xref>]. Therefore, emotional stimuli, negative versus positive, offer a unique opportunity to change the size of the attention field relative to the stimulus, differentially modulating the gain of attentional selection.</p>
<p>Here, the size of the attention field was manipulated by emotional valence—negative faces versus positive faces—while the stimulus size was held constant, and the stimulus contrast was varied in a spatial cueing task [<xref ref-type="bibr" rid="pbio.1002578.ref019">19</xref>,<xref ref-type="bibr" rid="pbio.1002578.ref035">35</xref>]. We measured the gain pattern of CRFs on the spatial cueing effect derived by the emotional faces and empirically revealed an interaction between emotion and attention: gain modulation depended on emotional valence, with a change in the spatial cueing effect consonant with a change in response gain for negative faces and a change in contrast gain for positive faces. A functional magnetic resonance imaging (fMRI) experiment confirmed that subjects’ attention fields were narrowed and broadened by negative faces and positive faces, respectively, as indexed by the decreased and increased primary visual cortex (V1) responses to flanking gratings. Furthermore, the self-reported emotional strength of the emotional faces significantly correlated with the psychophysical gain modulations, and with the V1 blood oxygenation-level-dependent (BOLD) signal changes, across individual subjects. Finally, effective connectivity analysis showed that emotional valence controlled the attention field through the modulation of feedback from the dorsolateral prefrontal cortex (DLPFC) to V1. These findings indicate that emotional attention interacts with the normalization processes depending on emotional valence, which is best explained by feedback modulation to the visual cortex from DLPFC.</p>
</sec>
<sec id="sec002" sec-type="results">
<title>Results</title>
<sec id="sec003">
<title>Psychophysical Experiments</title>
<p>In the psychophysical experiment, subjects performed an orientation discrimination task on one of two target grating patches; each was presented at five different contrasts (the contrasts of both gratings were identical on any given trial and covaried across trials in random order). Covert attention (without eye movements, <xref ref-type="supplementary-material" rid="pbio.1002578.s011">S1 Fig</xref>) was captured by the emotional face (negative or positive), which also modulated the attention field: negative faces narrowed and positive faces broadened the attention field (<xref ref-type="fig" rid="pbio.1002578.g001">Fig 1B and 1C</xref>). A response cue at the stimulus offset indicated the target location, yielding congruent cue (the emotional face matched the response cue) and incongruent cue (mismatched) conditions (<xref ref-type="fig" rid="pbio.1002578.g001">Fig 1A</xref>). Comparing performance accuracy (<italic>d′</italic>) for congruent and incongruent trials revealed the spatial cueing effect for each target contrast.</p>
<fig id="pbio.1002578.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.1002578.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Psychophysical protocol and the normalization model of attention modulated by emotional valence.</title>
<p>(A) Psychophysical protocol. A pair of faces (one emotional and the other neutral; the faces of a coauthor here are for illustration purposes only; they were not used in the experiments. The experimental faces were chosen from the NimStim Set of Facial Expressions: <ext-link ext-link-type="uri" xlink:href="http://www.macbrain.org/resources.htm" xlink:type="simple">http://www.macbrain.org/resources.htm</ext-link> [<xref ref-type="bibr" rid="pbio.1002578.ref036">36</xref>] and could not be published under the Creative Commons Attribution license) were presented for 150 ms, followed by a 50 ms fixation interval. Then, a pair of gratings were presented for 33 ms in the left and right hemifields, one of which was the target. Subjects were asked to discriminate the orientation of the target grating and received auditory feedback if their response was incorrect. The target location was indicated by a peripheral 100 ms response cue (0.5° white line) above one of the grating locations, but not at the grating location to avoid masking. A congruent cue was defined as a match between the emotional face location and response cue location; an incongruent cue was a mismatch. (B) Relative to the stimulus size, the attention field was narrowed by negative faces. Under this configuration, the normalization model predicts a response-gain shift, with the largest effects occurring at high contrasts and little to no effect at low and mid-contrasts. (C) Relative to the stimulus size, the attention field was broadened by positive faces. Under this configuration, the normalization model predicts a contrast-gain shift, with the largest effects occurring at mid-contrasts and little to no effect at low and high contrasts. The dashed red circles indicate simulated attention field size.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.1002578.g001" xlink:type="simple"/>
</fig>
<p>The mean <italic>d′</italic> plotted as psychometric functions of stimulus contrast and emotional valence are shown in <xref ref-type="fig" rid="pbio.1002578.g002">Fig 2A</xref>: the negative emotion yielded a pattern that qualitatively resembled response gain (left), and the positive emotion yielded a pattern that qualitatively resembled contrast gain (right). The measured psychometric function for each emotional valence (negative and positive) and each trial condition (congruent and incongruent) was fit with the standard Naka–Rushton equation [<xref ref-type="bibr" rid="pbio.1002578.ref037">37</xref>]. The two parameters <italic>d'</italic> <sub>max</sub> (asymptotic performance at high-contrast levels) and <italic>c</italic><sub>50</sub> (the contrast yielding half-maximum performance) determined response gain and contrast gain, respectively. The exponent <italic>n</italic> (slope) was fixed at 2 in the current analysis [<xref ref-type="bibr" rid="pbio.1002578.ref017">17</xref>,<xref ref-type="bibr" rid="pbio.1002578.ref038">38</xref>]. The <italic>d'</italic> <sub>max</sub> for emotional valence (negative and positive) and trial conditions (congruent and incongruent) are shown in <xref ref-type="fig" rid="pbio.1002578.g002">Fig 2B</xref> and were submitted to a repeated-measures ANOVA with emotional valence and trial condition as within-subjects factors. The main effect of emotional valence (F<sub>1, 22</sub> = 1.734, <italic>p</italic> = 0.201) was not significant, but the main effect of the trial condition (F<sub>1, 22</sub> = 34.971, <italic>p</italic> &lt; 0.001) and the interaction between these two factors (F<sub>1, 22</sub> = 13.742, <italic>p</italic> = 0.001) were both significant. Further <italic>t</italic> tests showed that the <italic>d'</italic> <sub>max</sub> of congruent trials was higher than that of incongruent trials (t<sub>22</sub> = 14.422, <italic>p</italic> &lt; 0.001) for negative emotion, but not for positive emotion (t<sub>22</sub> = 0.789, <italic>p</italic> = 0.438); the <italic>d'</italic> <sub>max</sub> for negative emotion was higher than that for positive emotion in the congruent trials (t<sub>22</sub> = 2.181, <italic>p</italic> = 0.040), but not in the incongruent trials (t<sub>22</sub> = 0.083, <italic>p</italic> = 0.934). Similarly, for the <italic>c</italic><sub>50</sub> (<xref ref-type="fig" rid="pbio.1002578.g002">Fig 2C</xref>), the main effect of emotional valence was not significant (F<sub>1, 22</sub> = 1.072, <italic>p</italic> = 0.312), but the main effect of the trial condition (F<sub>1, 22</sub> = 40.884, <italic>p</italic> &lt; 0.001) and the interaction between these two factors (F<sub>1, 22</sub> = 30.950, <italic>p</italic> &lt; 0.001) were both significant. Further <italic>t</italic> tests showed that the <italic>c</italic><sub>50</sub> of congruent trials was lower than that of incongruent trials for positive emotion (t<sub>22</sub> = −7.676, <italic>p</italic> &lt; 0.001), but not for negative emotion (t<sub>22</sub> = −1.377, <italic>p</italic> = 0.182); the <italic>c</italic><sub>50</sub> for negative emotion was lower than that for positive emotion in the incongruent trials (t<sub>22</sub> = −2.172, <italic>p</italic> = 0.041), but not in the congruent trials (t<sub>22</sub> = 0.464, <italic>p</italic> = 0.647). These results thus suggest that gain modulation of attentional selection depends on emotional valence.</p>
<fig id="pbio.1002578.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.1002578.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Spatial cueing effects on performance (<italic>d'</italic>) as a function of contrast.</title>
<p>(A) Mean <italic>d'</italic> plotted as psychometric functions of stimulus contrast and emotional valence (negative, left; positive, right) for congruent and incongruent trials. <italic>d'</italic> <sub>max</sub>: asymptotic performance at high-contrast levels; <italic>c</italic><sub>50</sub>: the contrast yielding half-maximum performance. (B) <italic>d'</italic> <sub>max</sub> and (C) <italic>c</italic><sub>50</sub> for trial conditions and emotional valence. Error bars denote 1 standard error of the mean (SEM) calculated across subjects. (D) Correlations between the mean self-reported emotional strength of the faces and the <italic>d'</italic> <sub>max</sub> differences between congruent and incongruent trials across individual subjects. (E) Correlations between the mean self-reported emotional strength of the faces and the <italic>c</italic><sub>50</sub> differences between congruent and incongruent trials across individual subjects. The data are in the Supporting Information (see <xref ref-type="supplementary-material" rid="pbio.1002578.s001">S1 Data</xref>).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.1002578.g002" xlink:type="simple"/>
</fig>
<p>To evaluate further the role of emotional valence in the gain modulation of attention, we calculated the correlation coefficients between the self-reported emotional strength of the faces and psychophysical measures (<italic>d'</italic> <sub>max</sub> and <italic>c</italic><sub>50</sub>) across individual subjects. The self-reported emotional strength of negative faces significantly correlated with the <italic>d'</italic> <sub>max</sub> difference between congruent and incongruent trials (r = 0.536, <italic>p</italic> = 0.008, <xref ref-type="fig" rid="pbio.1002578.g002">Fig 2D</xref>, left), but not with the <italic>c</italic><sub>50</sub> difference between congruent and incongruent trials (r = 0.014, <italic>p</italic> = 0.948, <xref ref-type="fig" rid="pbio.1002578.g002">Fig 2E</xref>, left). Conversely, the self-reported emotional strength of positive faces significantly correlated with the <italic>c</italic><sub>50</sub> difference between congruent and incongruent trials (r = −0.536, <italic>p</italic> = 0.008, <xref ref-type="fig" rid="pbio.1002578.g002">Fig 2E</xref>, right), but not with the <italic>d'</italic> <sub>max</sub> difference between congruent and incongruent trials (r = 0.205, <italic>p</italic> = 0.348, <xref ref-type="fig" rid="pbio.1002578.g002">Fig 2D</xref>, right). These results thus demonstrate a close relationship between emotional valence and gain modulation of attentional selection (response-gain and contrast-gain changes in psychophysical performance). Furthermore, given that subjects performed the negative and positive sessions on two different days (the order of the two sessions was counterbalanced across subjects), we performed an additional analysis to confirm that the order of these two sessions did not influence our psychophysical results (<xref ref-type="supplementary-material" rid="pbio.1002578.s012">S2 Fig</xref>).</p>
</sec>
<sec id="sec004">
<title>fMRI Experiments</title>
<p>To directly investigate whether negative emotion narrowed and positive emotion broadened subjects’ attention fields, a block-design fMRI experiment was designed to measure the V1 responses to task-irrelevant gratings (<xref ref-type="fig" rid="pbio.1002578.g003">Fig 3A</xref>). Each run consisted of 12 stimulus blocks of 16 s, interleaved with 12 blank intervals of 16 s. There were 6 kinds of stimulus blocks: 2 (visual field: left/right) × 3 (emotional valence: negative/neutral/positive), and each stimulus block was randomly repeated two times in each run. For each type of emotional valence, data from the left and right visual fields were pooled together for analysis. Each stimulus block consisted of 8 trials; on each trial, a target face was centered at 4.65° eccentricity in the left or right hemifield and flanked by four gratings. The center-to-center distance between the target face and nearby gratings and between the target face and far gratings was 2.54° and 4.52°, respectively (<xref ref-type="fig" rid="pbio.1002578.g003">Fig 3A and 3B</xref>). The target face and flanking gratings were presented for 0.3 s, followed by a 1.7-s fixation interval, and subjects were asked to discriminate the gender of the target face (male or female) while maintaining central fixation throughout the trial (<xref ref-type="fig" rid="pbio.1002578.g003">Fig 3C</xref>). The accuracy rates (mean percent correct ± standard error of the mean [SEM]) were 91.35% ± 1.09%, 91.95% ± 0.86%, and 92.44% ± 1.15%, while the reaction times (mean reaction time ± SEM) were 813.06 ± 19.95 ms, 821.96 ± 19.09 ms, and 827.94 ± 20.16 ms for negative, neutral, and positive conditions, respectively. For these measurements, there was no significant difference (all <italic>p</italic> &gt; 0.05) in subject performance among the three types of emotional valence of the target faces.</p>
<fig id="pbio.1002578.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.1002578.g003</object-id>
<label>Fig 3</label>
<caption>
<title>FMRI stimuli and protocol.</title>
<p>(A) The target face (the faces of a coauthor here are for illustration purposes only; they were not used in the experiments) was centered in either the left or right visual field and was flanked by four gratings, two in the upper visual field and two in the lower visual field (L: left visual field; R: right visual field). (B) Region-of-interest (ROI) definition. The flickering patches were used to define ROIs in V1, corresponding to the target face (left), nearby gratings (middle), and far gratings (right). (C) FMRI procedure. Each face flanked by four gratings was presented for 0.3 s, followed by a 1.7-s fixation interval. Subjects were asked to discriminate the gender of each face (male or female) while maintaining central fixation throughout the trial.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.1002578.g003" xlink:type="simple"/>
</fig>
<p>Regions of interest (ROIs) in V1 were defined as the cortical regions responding significantly to the target face, nearby gratings, and far gratings (<xref ref-type="fig" rid="pbio.1002578.g003">Fig 3B</xref>). We focused our analysis on V1 because activated areas in extrastriate cortex that corresponded to these three different stimuli showed a great deal of overlap. BOLD signals were extracted from these ROIs and then averaged according to emotional valence. For each stimulus block, the 2 s preceding the block served as a baseline, and the mean BOLD signal from 5 s to 16 s after stimulus onset was used as a measure of the response amplitude. The BOLD amplitudes in V1 evoked by the target face and flanking gratings (nearby + far) are shown in <xref ref-type="fig" rid="pbio.1002578.g004">Fig 4B and 4C</xref>, respectively, and were submitted to a repeated-measures ANOVA with emotional valence as a within-subjects factor. For the target face, the main effect of emotional valence was not significant (F<sub>2, 28</sub> = 2.416, <italic>p</italic> = 0.112). For the flanking gratings, however, the main effect of emotional valence was significant (F<sub>2, 28</sub> = 16.582, <italic>p</italic> = 0.001); post hoc paired <italic>t</italic> tests revealed that V1 response during the neutral condition was significantly lower than that during the positive condition (t<sub>14</sub> = −4.165, <italic>p</italic> = 0.003) but significantly higher than that during the negative condition (t<sub>14</sub> = 3.806, <italic>p</italic> = 0.006). We further evaluated the role of emotional valence in the modulation of V1 responses to flanking gratings and calculated the correlation coefficients between the self-reported emotional strength of the faces and fMRI measures across individual subjects. Compared to the neutral condition, the decreased BOLD signal in the negative condition and the increased BOLD signal in the positive condition correlated significantly with the self-reported emotional strength of negative faces (r = −0.746, <italic>p</italic> = 0.001, <xref ref-type="fig" rid="pbio.1002578.g004">Fig 4D</xref>, left) and positive faces (r = 0.633, <italic>p</italic> = 0.011, <xref ref-type="fig" rid="pbio.1002578.g004">Fig 4D</xref>, right), respectively. Moreover, these decreased and increased BOLD signals also correlated significantly with the response-gain (<xref ref-type="fig" rid="pbio.1002578.g004">Fig 4F</xref>, left) and contrast-gain (<xref ref-type="fig" rid="pbio.1002578.g004">Fig 4G</xref>, right) changes, respectively, in the psychophysical experiment.</p>
<fig id="pbio.1002578.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.1002578.g004</object-id>
<label>Fig 4</label>
<caption>
<title>FMRI results.</title>
<p>(A) ROIs. Flickering round-checkered patches with a full contrast were used to define the ROIs. They occupied the same spatial extents as the target face and the four flanking gratings. Cortical activations by the five patches are depicted in a representative inflated brain. The yellow, red, and blue areas correspond to ROIs of the target face, nearby gratings, and far gratings, respectively. The boundaries of V1, defined by retinotopic mapping, are indicated by the black lines. (B) BOLD signal amplitudes in V1 evoked by target faces. (C) BOLD signal amplitudes in V1 evoked by nearby and far gratings. (D) Correlations between the mean self-reported emotional strength of the faces and the decreased (left, the negative condition) and increased (right, the positive condition) BOLD signal in V1 (compared with the neutral condition) across individual subjects. (E) BOLD signal amplitudes in V1 evoked by nearby gratings (left) and by far gratings (right). (F and G) Correlations between the V1 BOLD signal changes modulated by emotional valence and gain modulation of attentional selection in psychophysical performance. (H and J) The whole-brain search for the pulvinar and DLPFC, with both showing opposite modulations for negative and positive emotions, and their BOLD signal amplitudes. (I and K) Correlations between the V1 BOLD signal changes modulated by emotional valence and that in the pulvinar and DLPFC across individual subjects. Error bars denote 1 SEM calculated across subjects. The data are in the Supporting Information (see <xref ref-type="supplementary-material" rid="pbio.1002578.s002">S2 Data</xref> and <xref ref-type="supplementary-material" rid="pbio.1002578.s010">S10 Data</xref>).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.1002578.g004" xlink:type="simple"/>
</fig>
<p>Our results thus indicated that negative emotion decreased and positive emotion increased the encoding of flanking gratings, as indexed by the BOLD signal changes in V1 evoked by four gratings (nearby + far). However, at least three potential mechanisms could explain the same result: (1) emotional valence modulates the scope of perceptual encoding, with negative emotion narrowing and positive emotion broadening the attention field (<xref ref-type="supplementary-material" rid="pbio.1002578.s014">S4A Fig</xref>); (2) emotional valence modulates the brain state (e.g., arousal), with negative emotion decreasing and positive emotion increasing the V1 signal (<xref ref-type="supplementary-material" rid="pbio.1002578.s014">S4B Fig</xref>); or (3) a combination of hypotheses 1 and 2, with negative emotion narrowing the attention field and decreasing the V1 signal and positive emotion broadening the attention field and increasing the V1 signal (<xref ref-type="supplementary-material" rid="pbio.1002578.s014">S4C Fig</xref>). Accordingly, for each emotional condition, we analyzed the BOLD amplitudes in V1 evoked by nearby gratings and far gratings separately. We hypothesized that these different mechanisms would show different patterns in V1 responses to nearby gratings and far gratings (<xref ref-type="supplementary-material" rid="pbio.1002578.s014">S4 Fig</xref>). The BOLD amplitudes in V1 evoked by nearby gratings and far gratings are shown in <xref ref-type="fig" rid="pbio.1002578.g004">Fig 4E</xref> (left and right, respectively) and were submitted to a repeated-measures ANOVA with emotional valence (negative, neutral, and positive) and grating distance (nearby and far) as within-subjects factors. The main effect of emotional valence (F<sub>2, 28</sub> = 17.227, <italic>p</italic> = 0.001), the main effect of the grating distance (F<sub>1, 14</sub> = 8.140, <italic>p</italic> = 0.013), and the interaction between these two factors (F<sub>2, 28</sub> = 8.887, <italic>p</italic> = 0.003) were all significant. Thus, these data were submitted to a further simple effect analysis. For the nearby gratings, the main effect of emotional valence was significant (F<sub>2, 28</sub> = 13.487, <italic>p</italic> = 0.002); post hoc paired <italic>t</italic> tests revealed that there was no significant difference between neutral and positive conditions (t<sub>14</sub> = −1.866, <italic>p</italic> = 0.250), and both were significantly higher than the negative condition (neutral versus negative: t<sub>14</sub> = 5.211, <italic>p</italic> &lt; 0.001; positive versus negative: t<sub>14</sub> = 3.672, <italic>p</italic> = 0.008). For the far gratings, the main effect of emotional valence was also significant (F<sub>2, 28</sub> = 18.989, <italic>p</italic> &lt; 0.001); post hoc paired <italic>t</italic> tests revealed that there was no significant difference between negative and neutral conditions (t<sub>14</sub> = −1.900, <italic>p</italic> = 0.235), and both were significantly lower than the positive condition (negative versus positive: t<sub>14</sub> = −4.322, <italic>p</italic> = 0.002; neutral versus positive: t<sub>14</sub> = −6.426, <italic>p</italic> &lt; 0.001). For both the negative and neutral conditions, the nearby gratings were significantly higher than the far gratings (negative: t<sub>14</sub> = 2.849, <italic>p</italic> = 0.013; neutral: t<sub>14</sub> = 3.366, <italic>p</italic> = 0.005), but significant for the positive condition (t<sub>14</sub> = 2.160, <italic>p</italic> = 0.049). These findings are consistent with the first hypothesis that emotional valence modulates the scope of perceptual encoding in V1 by narrowing and broadening the attention field.</p>
<p>To examine potential cortical or subcortical area(s) that showed a consistent pattern of activation with that in V1, where negative and positive emotions modulated its responses to flanking gratings in opposite ways (<xref ref-type="fig" rid="pbio.1002578.g004">Fig 4C</xref>), we performed a group analysis and did a whole-brain search for cortical and subcortical area(s) that showed opposite modulations of flanking gratings for negative and positive emotions, relative to the neutral condition. The results showed that only early visual cortical areas, the pulvinar thalamic nucleus, and DLPFC demonstrated this effect. The BOLD amplitudes in the pulvinar and DLPFC for the three types of emotional valence are shown in <xref ref-type="fig" rid="pbio.1002578.g004">Fig 4H and 4J</xref>, respectively, and were submitted to a repeated-measures ANOVA with emotional valence as a within-subjects factor. The main effect in both the pulvinar (F<sub>2, 28</sub> = 9.092, <italic>p</italic> = 0.001) and DLPFC (F<sub>2, 28</sub> = 23.081, <italic>p</italic> &lt; 0.001) was significant; post hoc paired <italic>t</italic> tests revealed that, for the pulvinar, the negative condition was significantly higher than that during the positive condition (t<sub>14</sub> = 3.801, <italic>p</italic> = 0.006), but no significant difference was found between the neutral and negative conditions or between the neutral and positive conditions (all <italic>p</italic> &gt; 0.05). For the DLPFC, however, the neutral condition was significantly lower than that during the negative condition (t<sub>14</sub> = −5.336, <italic>p</italic> &lt; 0.001) but significantly higher than that during the positive condition (t<sub>14</sub> = 3.779, <italic>p</italic> = 0.006). Furthermore, we found that V1 responses to flanking gratings were significantly correlated with DLPFC responses (<xref ref-type="fig" rid="pbio.1002578.g004">Fig 4K</xref>), but not with pulvinar responses (<xref ref-type="fig" rid="pbio.1002578.g004">Fig 4I</xref>). Compared to the neutral condition, V1’s decreased BOLD signal in the negative condition and increased BOLD signal in the positive condition correlated significantly with DLPFC`s increased BOLD signal in the negative condition (r = −0.631, <italic>p</italic> = 0.012) and decreased BOLD signal in the positive condition (r = −0.704, <italic>p</italic> = 0.003), respectively. Taken together, these findings suggest that the modulation of the attention field size in V1 by emotional valence may be derived by feedback from DLPFC.</p>
<p>Additionally, to further exclude the possibility that emotional valence modulation of the attention field size in V1 could be derived from feedback from other attention-specific (i.e., the frontal eye field [FEF] and the posterior parietal cortex [PPC]) or emotion-specific (i.e., the amygdala and medial orbitofrontal cortex [mOFC]) cortical areas, we performed a supplemental analysis and found that the BOLD responses in both the amygdala and mOFC, but not in either FEF or PPC, were significantly modulated by emotional valence. For the amygdala, as well as mOFC, both the negative and positive conditions were significantly higher than the neutral condition; however, no significant difference was found between these two conditions (<xref ref-type="supplementary-material" rid="pbio.1002578.s015">S5 Fig</xref>), showing an inconsistent pattern of activation with that in V1, where the negative condition was significantly lower than the positive condition.</p>
</sec>
<sec id="sec005">
<title>Effective Connectivity Analyses</title>
<p>To directly confirm whether emotional valence modulated the attention field size in V1 through the modulation of feedback from DLPFC, we used dynamic causal modeling (DCM) to examine functional changes in directional connectivity among the amygdala, DLPFC, the pulvinar, and V1 related to negative and positive emotions. The pulvinar was selected in the models since it showed a consistent pattern of activation with DLPFC (<xref ref-type="fig" rid="pbio.1002578.g004">Fig 4H</xref>), while the amygdala was selected in the models since it is well known as a critical brain area for emotion processing [<xref ref-type="bibr" rid="pbio.1002578.ref024">24</xref>], showing significantly greater responses to emotional faces than neutral faces (<xref ref-type="supplementary-material" rid="pbio.1002578.s015">S5 Fig</xref>). Given the extrinsic visual input into V1, we defined seven different models with modulatory inputs (either the negative emotion or positive emotion, <xref ref-type="fig" rid="pbio.1002578.g005">Fig 5A</xref>). The modulatory inputs could modulate the feedback from the amygdala (Model 1), from the pulvinar (Model 2), from both the amygdala and pulvinar (Model 3), from DLPFC (Model 4), from both the amygdala and DLPFC (Model 5), from both DLPFC and the pulvinar (Model 6), and from all three areas (Model 7) to V1. We examined these seven models for modeling the modulatory effect by negative and positive emotions and fit each of these seven models for each subject.</p>
<fig id="pbio.1002578.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.1002578.g005</object-id>
<label>Fig 5</label>
<caption>
<title>DCM of connectivities among the amygdala, DLPFC, the pulvinar, and V1.</title>
<p>(A) Seven different models for modeling the modulatory effect of negative and positive emotions. Amy, amygdala; Pul, pulvinar. (B) Exceedance probabilities for the seven models with negative (up) and positive (down) emotions as the modulatory input. (C) The strength of the modulatory connections for negative (up) and positive (down) emotions and its significance levels (*<italic>p</italic> &lt; 0.05 and **<italic>p</italic> &lt; 0.01, respectively). (D) Correlations between the V1 BOLD signal changes of emotional valence and effective connection strengths across individual subjects. The data are in the Supporting Information (see <xref ref-type="supplementary-material" rid="pbio.1002578.s003">S3 Data</xref>).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.1002578.g005" xlink:type="simple"/>
</fig>
<p>For negative emotion, we computed the exceedance probability of each model [<xref ref-type="bibr" rid="pbio.1002578.ref039">39</xref>]. The result showed that Models 1 through 7 had exceedance probabilities of 2.55%, 5.14%, 2.88%, 30.45%, 14.35%, 23.57%, and 21.05%, respectively, suggesting that Model 4 was the best one to explain the modulatory effect by negative emotion (<xref ref-type="fig" rid="pbio.1002578.g005">Fig 5B</xref>, up). The negative emotion significantly increased the feedback connectivity from the amygdala to both DLPFC (t<sub>14</sub> = 2.906, <italic>p</italic> = 0.011) and the pulvinar (t<sub>14</sub> = 2.213, <italic>p</italic> = 0.044) but decreased the feedback connectivity from DLPFC to V1 (t<sub>14</sub> = −3.792, <italic>p</italic> = 0.002) (<xref ref-type="fig" rid="pbio.1002578.g005">Fig 5C</xref>, up). For positive emotion, the exceedance probabilities of Model 1 to Model 7 were 2.89%, 3.98%, 5.37%, 32.24%, 15.60%, 21.02%, and 18.91%, respectively, suggesting that the modulatory effect by positive emotion was also best explained by Model 4 (<xref ref-type="fig" rid="pbio.1002578.g005">Fig 5B</xref>, down). However, the positive emotion significantly decreased the feedback connectivity from the amygdala to both DLPFC (t<sub>14</sub> = −2.743, <italic>p</italic> = 0.016) and the pulvinar (t<sub>14</sub> = −2.573, <italic>p</italic> = 0.022) but increased the feedback connectivity from DLPFC to V1 (t<sub>14</sub> = 3.923, <italic>p</italic> = 0.002) (<xref ref-type="fig" rid="pbio.1002578.g005">Fig 5C</xref>, down). Furthermore, we calculated the correlation coefficients between V1 responses and the effective connection strengths (the sum of the intrinsic and modulatory connectivities) from DLPFC to V1 across individual subjects. Compared to the neutral condition, the decreased V1 BOLD signal in the negative condition (r = 0.620, <italic>p</italic> = 0.014) and the increased V1 BOLD signal in the positive condition (r = 0.587, <italic>p</italic> = 0.021) correlated significantly with feedback connectivity from DLPFC to V1 (<xref ref-type="fig" rid="pbio.1002578.g005">Fig 5D</xref>). Additionally, a supplemental DCM analysis with mOFC, instead of the amygdala, showed significantly greater responses to emotional faces than neutral faces, confirming these results (<xref ref-type="supplementary-material" rid="pbio.1002578.s016">S6 Fig</xref>). Together, these results further support the idea that emotional valence-dependent modulations of the attention field size in V1 may be derived by feedback from DLPFC.</p>
</sec>
</sec>
<sec id="sec006" sec-type="conclusions">
<title>Discussion</title>
<p>This study examined whether emotional attention shapes perception via a normalization framework. The normalization model of attention proposes that attention can affect performance by response- or contrast-gain changes, depending on the stimulus size and the attention field size [<xref ref-type="bibr" rid="pbio.1002578.ref019">19</xref>]. Previous studies have suggested that negative emotion could narrow and positive emotion could broaden the scope of perceptual encoding [<xref ref-type="bibr" rid="pbio.1002578.ref029">29</xref>,<xref ref-type="bibr" rid="pbio.1002578.ref031">31</xref>,<xref ref-type="bibr" rid="pbio.1002578.ref032">32</xref>], which offers a unique opportunity to change the size of the attention field relative to the stimulus size. Here, we measured the gain pattern of CRFs on the spatial cueing effect derived from negative and positive faces. We found a change in the spatial cueing effect consistent with a change in response gain for negative faces and in contrast gain for positive faces. The fMRI experiment confirmed that emotional valence modulated the attention field in V1; negative faces decreased and positive faces increased V1 responses to flanking gratings. Importantly, across subjects, the self-reported emotional strength of negative and positive faces correlated, respectively, both with response- and contrast-gain changes and with V1 decreased and increased responses to flanking gratings. Furthermore, effective connectivity analysis showed that the V1 attention field size controlled by emotional valence was best explained by increased and decreased feedback from DLPFC to V1.</p>
<p>Our data provide, to our knowledge, the first neural evidence that emotional attention interacts with normalization processes depending on emotional valence. Our behavioral data can be interpreted by a hypothesis that behavioral performance is limited by the neuronal activity with an additive, independent, and identically distributed noise, and the decision-making process with a maximum-likelihood decision rule [<xref ref-type="bibr" rid="pbio.1002578.ref040">40</xref>]. Performance accuracy <italic>d'</italic>, used in both Herrmann et al. [<xref ref-type="bibr" rid="pbio.1002578.ref017">17</xref>] and our studies, is proportional to the signal-to-noise ratio of the underlying neuronal responses. Thus, it can reflect in parallel any change in neuronal CRFs in our study. Indeed, we found that a change in the cueing effect (<xref ref-type="fig" rid="pbio.1002578.g002">Fig 2A</xref>) was consonant with a change in response gain of CRF (<xref ref-type="fig" rid="pbio.1002578.g001">Fig 1B</xref>) for negative faces and a change in contrast gain of CRF (<xref ref-type="fig" rid="pbio.1002578.g001">Fig 1C</xref>) for positive faces. These emotional valence-dependent gain modulations of attentional selection not only are consistent with existing psychophysical [<xref ref-type="bibr" rid="pbio.1002578.ref030">30</xref>,<xref ref-type="bibr" rid="pbio.1002578.ref032">32</xref>,<xref ref-type="bibr" rid="pbio.1002578.ref041">41</xref>] and brain imaging [<xref ref-type="bibr" rid="pbio.1002578.ref031">31</xref>,<xref ref-type="bibr" rid="pbio.1002578.ref042">42</xref>] studies suggesting that negative emotion narrows and positive emotion broadens the scope of perceptual encoding, but also support and extend the normalization model of attention [<xref ref-type="bibr" rid="pbio.1002578.ref019">19</xref>]. This model proposes that, in the absence of attention (e.g., in the incongruent cue condition), two factors determine the firing rate of a visually responsive neuron. One is the stimulus drive (excitatory component) determined by the contrast of the stimulus placed in the receptive field of a neuron. The other is the suppressive drive (inhibitory component) determined by the summed activity of other neighboring neurons, which serves to normalize the overall spike rate of the given neuron via mutual inhibition [<xref ref-type="bibr" rid="pbio.1002578.ref043">43</xref>,<xref ref-type="bibr" rid="pbio.1002578.ref044">44</xref>]. Attention (e.g., in the congruent cue condition) modulates the pattern of neural activity by altering the balance between these excitatory and inhibitory components, depending on the relative sizes of the attention field to the stimulus size, and thereby exhibiting response-gain changes, contrast-gain changes, and various combinations of the two. In our study, given the fixed size of the target stimuli in the spatial cueing task, the narrowed attention field by negative emotion led to response-gain changes because attentional gain enhanced the entire stimulus drive but enhanced only the center of the suppressive drive. Conversely, the broadened attention field by positive emotion led to contrast-gain changes because attentional gain was applied equally to the stimulus and suppressive drives.</p>
<p>The fMRI data confirmed these emotional valence-dependent changes of the attention field; negative emotion narrowed and positive emotion broadened the attention field in V1. Importantly, this result cannot be explained by brain state changes or by the combination of brain state and attention field changes (<xref ref-type="supplementary-material" rid="pbio.1002578.s014">S4 Fig</xref>). Moreover, the result cannot be explained by a number of other factors, such as low-level features, task difficulty, target face processing, or eye movement. First, the size and contrast of the flanking gratings were identical on any given trial, and the phase and orientation were random across trials, suggesting no physical difference of the gratings among the different emotional conditions. Second, during scanning, the flanking gratings were never task relevant for the subjects, who performed a gender discrimination task on the faces. There was no significant difference in subject performance among the three types of emotional valence of the faces, suggesting no difference in task difficulty. Third, the finding of no significant activation difference in V1 for the emotional faces excluded the possibility of a trade-off between attention to the target face and flanking gratings (<xref ref-type="fig" rid="pbio.1002578.g004">Fig 4B</xref>). Finally, the eye movement data showed that the subjects’ eye movements were small and their eye position distributions were statistically indistinguishable for the three types of emotional valence (<xref ref-type="supplementary-material" rid="pbio.1002578.s013">S3 Fig</xref>). Although our eye movement data were recorded in a psychophysics lab (outside the scanner), it should be noted that the recordings were made when subjects performed the same task as the one in the fMRI experiments. Differences in eye movements for the three types of emotional valence may be a potential confound, but it is highly unlikely since our recordings outside the scanner did not detect any such differences.</p>
<p>One should note that emotional valence-dependent modulations of attention fields in our study were indexed by the decreased and increased V1 responses to flanking gratings, which were irrelevant and presumably ignored while subjects attended to the target face. Thus, how does emotional valence differentially modulate V1 responses to these distractors? Previous neurophysiological and brain neuroimaging studies have implicated prefrontal areas in the filtering of distractors [<xref ref-type="bibr" rid="pbio.1002578.ref045">45</xref>–<xref ref-type="bibr" rid="pbio.1002578.ref050">50</xref>], and our findings are consistent with such an influence. Our findings suggest that distractor suppression by emotional valence in V1 could be associated with feedback from DLPFC. First, DLPFC responses were significantly modulated by emotional valence and showed a pattern of activation consistent with that in V1, where negative and positive emotions modulated its responses to task-irrelevant distractors in opposite ways. This consistent pattern of activation between V1 and DLPFC was also confirmed by a group analysis and a whole-brain search for cortical and subcortical area(s) that showed opposite responses for negative and positive emotions (<xref ref-type="fig" rid="pbio.1002578.g004">Fig 4J</xref>). Second, V1 responses to flanking distractors were significantly predicted by DLPFC responses (<xref ref-type="fig" rid="pbio.1002578.g004">Fig 4K</xref>). Finally, the DCM analysis indicated that negative emotion increased and positive emotion decreased suppression from DLPFC to V1, and these suppression effects significantly predicted the V1 responses to flanking distractors (<xref ref-type="fig" rid="pbio.1002578.g005">Fig 5C and 5D</xref>).</p>
<p>Our study succeeded in linking emotional valence-dependent feedback from the DLPFC to V1 directly with distractor suppression. Based on our fMRI findings, in conjunction with existing neurophysiological [<xref ref-type="bibr" rid="pbio.1002578.ref051">51</xref>], behavioral [<xref ref-type="bibr" rid="pbio.1002578.ref030">30</xref>,<xref ref-type="bibr" rid="pbio.1002578.ref032">32</xref>], and neuroimaging [<xref ref-type="bibr" rid="pbio.1002578.ref042">42</xref>,<xref ref-type="bibr" rid="pbio.1002578.ref052">52</xref>] data, we speculate that emotional valence-dependent distractor suppression is derived from DLPFC influences on the scope of inhibitory control. Inhibitory control is thought to limit the amount of information entering the focus of attention [<xref ref-type="bibr" rid="pbio.1002578.ref053">53</xref>], which, in turn, affects the scope of attentional selection, and DLPFC is thought to play a very important role in this function [<xref ref-type="bibr" rid="pbio.1002578.ref048">48</xref>]. We speculate that, in our study, when the emotional faces were negative, both feedback from the amygdala to DLPFC and the BOLD signal in DLPFC increased and thus decreased effective connectivity (i.e., increased suppression) from DLPFC to V1, as revealed by the DCM analysis, which then would increase the inhibitory control, in other words, increase the inhibition of ignored distractors, resulting in a narrowed focus of attention and reduced processing of the flanking gratings. Conversely, when the emotional faces were positive, both feedback from the amygdala to DLPFC and the BOLD signal in DLPFC decreased and thus increased effective connectivity (i.e., decreased suppression) from DLPFC to V1, which would decrease the inhibition of ignored distractors, resulting in a broadened scope of attention and flanking gratings that were more fully processed. It should be noted that our speculation only provides a possible mechanism for emotional valence-dependent attention field in V1, which should be tested with neurophysiological techniques in the future.</p>
<p>Our results also indicate that the pulvinar may be involved in emotional valence-dependent modulations of distractor suppression in V1, consistent with previous lesion [<xref ref-type="bibr" rid="pbio.1002578.ref054">54</xref>], neurophysiological [<xref ref-type="bibr" rid="pbio.1002578.ref055">55</xref>], and brain neuroimaging [<xref ref-type="bibr" rid="pbio.1002578.ref056">56</xref>] studies, implicating the pulvinar’s involvement in the filtering of unwanted information. However, it is important to note that the ROIs in the pulvinar defined in our study were across dorsal and ventral parts. The dorsal pulvinar predominantly projects to areas within the frontoparietal network and superior anterior temporal cortex [<xref ref-type="bibr" rid="pbio.1002578.ref057">57</xref>]; the ventral pulvinar, conversely, exhibits reciprocal connections with successive occipitotemporal cortical areas along the ventral processing stream [<xref ref-type="bibr" rid="pbio.1002578.ref058">58</xref>,<xref ref-type="bibr" rid="pbio.1002578.ref059">59</xref>]. Thus, further work is needed to use high-spatial resolution fMRI or neurophysiological techniques to parse the relative contributions of the dorsal and ventral pulvinar to emotional valence-dependent modulations of distractor suppression.</p>
<p>One should note that our results cannot be explained by a number of other factors, including poststimulus modulation by the response cue, greater attention directed to negative faces, or an effect of emotional faces on decisional rather than perceptual processing of the target. First, although previous studies have suggested that the poststimulus cue (for example, the response cue in our study) can influence not only subjects’ nonperceptual decision [<xref ref-type="bibr" rid="pbio.1002578.ref060">60</xref>] but also the perception of stimuli presented before it [<xref ref-type="bibr" rid="pbio.1002578.ref015">15</xref>,<xref ref-type="bibr" rid="pbio.1002578.ref061">61</xref>,<xref ref-type="bibr" rid="pbio.1002578.ref062">62</xref>], the response cue in our study was totally randomized and uninformative about the target; we thus believe that our psychophysical results cannot be explained by the response cue. Second, although previous studies have found that negative faces tend to attract more attention and show a greater response than positive faces [<xref ref-type="bibr" rid="pbio.1002578.ref025">25</xref>,<xref ref-type="bibr" rid="pbio.1002578.ref026">26</xref>], this effect was not obtained in our study; no significant difference in response to negative and positive faces was found in V1 (<xref ref-type="fig" rid="pbio.1002578.g004">Fig 4B</xref>), the amygdala, or mOFC (<xref ref-type="supplementary-material" rid="pbio.1002578.s015">S5 Fig</xref>), thus eliminating the specific impact of negative faces as a factor affecting our fMRI results. Finally, if the emotional faces (negative versus positive) affected subjects’ decisional rather than their perceptual processing of the target stimuli, then these two conditions should have produced different responses in the orbitofrontal cortex (OFC), an area critically involved in decision making [<xref ref-type="bibr" rid="pbio.1002578.ref063">63</xref>,<xref ref-type="bibr" rid="pbio.1002578.ref064">64</xref>]; however, no significant difference between these two conditions was found in OFC (<xref ref-type="supplementary-material" rid="pbio.1002578.s015">S5 Fig</xref>), indicating that the observed difference between the negative and positive conditions was most likely caused by perceptual rather than decision-making processes. In addition, our study used the normalization model to predict and explain psychophysical performance only. Our fMRI experiment did not measure the BOLD response for different contrast levels but instead examined whether negative emotion narrowed and positive emotion broadened subjects’ attention fields. The design of our fMRI study took into account the results of several papers reporting that the attentional effect on the BOLD response is constant across different contrast levels, showing a baseline increase/additive shift rather than either a response gain or contrast gain [<xref ref-type="bibr" rid="pbio.1002578.ref012">12</xref>,<xref ref-type="bibr" rid="pbio.1002578.ref014">14</xref>,<xref ref-type="bibr" rid="pbio.1002578.ref015">15</xref>]. In those studies, the attention field was manipulated by focused (narrowed attention field) and distributed (broadened attention field) cues. These two cues, however, either enhanced the entire contrast range or produced a combination of both response-gain and contrast-gain changes, indicating inconsistent predictions of the normalization model [<xref ref-type="bibr" rid="pbio.1002578.ref019">19</xref>]. Previous studies have suggested that their results may be because BOLD signals integrate the activity across neurons showing different attention modulatory effects, which would result in various combinations of both response and contrast gains [<xref ref-type="bibr" rid="pbio.1002578.ref015">15</xref>,<xref ref-type="bibr" rid="pbio.1002578.ref016">16</xref>]. Moreover, attention-triggered BOLD signals can be driven by both bottom-up stimuli and top-down goals [<xref ref-type="bibr" rid="pbio.1002578.ref014">14</xref>,<xref ref-type="bibr" rid="pbio.1002578.ref065">65</xref>]; hence, the increased BOLD signals to the attended low and mid-contrast stimuli may be mainly driven by the top-down modulation rather than the bottom-up stimuli.</p>
<p>In sum, our study provides strong evidence that gain modulation of emotional attention depends on emotional valence. Negative emotion and positive emotion modulate the attention field in V1 in opposite ways, maybe depending on the increased or decreased feedback from DLPFC, thereby changing the suppression of distractors [<xref ref-type="bibr" rid="pbio.1002578.ref053">53</xref>]. The prominent role of the prefrontal cortex in distractor suppression evident here is consistent with recent neurophysiological findings that have begun to address how prefrontal areas directly influence sensory representations to filter out distractors [<xref ref-type="bibr" rid="pbio.1002578.ref049">49</xref>,<xref ref-type="bibr" rid="pbio.1002578.ref051">51</xref>,<xref ref-type="bibr" rid="pbio.1002578.ref066">66</xref>]. Identifying DLPFC as a potential neural substrate of emotional valence-dependent normalization processing of attention gives insight into how the interaction between emotion and attention shapes our experience of the world.</p>
</sec>
<sec id="sec007" sec-type="materials|methods">
<title>Materials and Methods</title>
<sec id="sec008">
<title>Subjects</title>
<p>A total of 23 human subjects (8 males, 21–41 y old) participated in the study. All 23 participated in the psychophysical experiment, and 15 (8 males, 21–41 y old) of them participated in the fMRI experiment. All subjects were naїve to the purpose of the study. They reported normal or corrected-to-normal vision and had no known neurological, psychiatric, or visual disorders. They gave written informed consent in accordance with protocols approved by the National Institute of Mental Health (NIMH) Institutional Review Board (93-M-0170).</p>
</sec>
<sec id="sec009">
<title>Stimuli</title>
<p>Forty angry, forty happy, and forty neutral faces were chosen from the NimStim Set of Facial Expressions (<ext-link ext-link-type="uri" xlink:href="http://www.macbrain.org/resources.htm" xlink:type="simple">http://www.macbrain.org/resources.htm</ext-link>) [<xref ref-type="bibr" rid="pbio.1002578.ref036">36</xref>]. All faces were masked to exclude ears, neck, hair, and hairline and were scaled to the same size (diameter: 2.2°) (<xref ref-type="fig" rid="pbio.1002578.g001">Fig 1A</xref>). In the psychophysical experiment, a pair of faces were centered in the left and right hemifields at 4.65° eccentricity, one of which was an emotional face. Target gratings (spatial frequency: 4.0 cycles/°; diameter: 2.2°; phase: random) were presented at five possible contrasts: 0.03, 0.08, 0.20, 0.45, and 0.75. In the fMRI experiment, a single face (diameter: 2.2°) was centered in either the left or right hemifield at 4.65° eccentricity and was flanked by four gratings (diameter: 1.4°; spatial frequency: 4.0 cycles/°; contrast: 0.20; phase: random; orientation: randomly chosen from 0° to 180°). The center-to-center distance between the face and nearby gratings and between the face and far gratings was 2.54° and 4.52°, respectively (<xref ref-type="fig" rid="pbio.1002578.g003">Fig 3A and 3B</xref>).</p>
</sec>
<sec id="sec010">
<title>Psychophysical Experiments</title>
<p>Visual stimuli were displayed on a BENQ LCD monitor (model: XL2420Z; refresh rate: 60 Hz; resolution: 1,920 × 1,080; size: 24 in) at a viewing distance of 57 cm. The subjects’ head position was stabilized using a chin rest. A white fixation (diameter: 0.1°) cross was always present at the center of the monitor.</p>
<p>Each trial began with central fixation. A pair of faces (one emotional) were presented in the left and right hemifields for 150 ms, followed by a 50 ms fixation interval. The emotional face served as a cue to attract covert spatial attention. Then, a pair of gratings (with identical contrasts) were presented for 33 ms in the left and right hemifields at 4.65° eccentricity, one of which was the target. Subjects were asked to press one of two buttons to indicate the orientation of the grating (leftward or rightward tilted) and received auditory feedback if their response was incorrect. Target location was indicated by a peripheral 100 ms response cue (0.5° white line) above one of the grating locations, but not at the grating location to avoid masking. A congruent cue was defined as a match between the emotional face location and response cue location (half the trials); an incongruent cue was defined as a mismatch (half the trials). Participants were explicitly told that the emotional faces were randomized and uninformative about the target location (<xref ref-type="fig" rid="pbio.1002578.g001">Fig 1A</xref>). The experiment consisted of two sessions (negative emotion and positive emotion of the faces), with the two sessions occurring on different days; the order of the two sessions was counterbalanced across subjects. Each session consisted of 30 blocks; each block had 80 trials, from randomly interleaving 16 trials from each of the five contrasts. Contrast varied from trial to trial in randomly shuffled order, and stimuli were presented briefly (i.e., 33 ms) to avoid any possible dependence of attentional state on stimulus contrast. The attentional effect for each grating contrast was quantified as the difference between the performance accuracy (<italic>d'</italic>) in the congruent and incongruent cue conditions. After each session, subjects were asked to rate (on a seven-point Likert scale) their self-perception of the emotional strength of each emotional face. For each subject, the self-reported emotional strength of positive and negative emotion was the mean rating for 40 positive and 40 negative faces, respectively.</p>
</sec>
<sec id="sec011">
<title>Psychophysical Data Analysis</title>
<p>To quantitatively examine the pattern of gain (either response or contrast gain) separately for positive emotion and negative emotion, for each subject, performance—i.e., <italic>d'</italic> = z (hit rate)–z (false alarm rate)—was assessed across experimental blocks for each contrast and each trial condition (congruent and incongruent). A rightward response to a rightward stimulus tilt was (arbitrarily) considered to be a hit, and a rightward response to a leftward stimulus was considered to be a false alarm. For each subject, the mean <italic>d'</italic> contrast response functions (CRFs) obtained for congruent and incongruent trials were fit with the standard Naka–Rushton equation [<xref ref-type="bibr" rid="pbio.1002578.ref037">37</xref>]:
<disp-formula id="pbio.1002578.e001">
<alternatives>
<graphic id="pbio.1002578.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pbio.1002578.e001" xlink:type="simple"/>
<mml:math display="block" id="M1">
<mml:mrow><mml:mi>d</mml:mi><mml:mo>′</mml:mo><mml:mspace width="0.25em"/><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>d</mml:mi><mml:msub><mml:mo>′</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mspace width="0.25em"/><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>c</mml:mi><mml:mi>n</mml:mi></mml:msup><mml:mspace width="0.25em"/><mml:mo>/</mml:mo><mml:mspace width="0.25em"/><mml:mo stretchy="false">[</mml:mo><mml:msup><mml:mi>c</mml:mi><mml:mi>n</mml:mi></mml:msup><mml:mo>+</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mn>50</mml:mn></mml:mrow></mml:msub><mml:msup><mml:mrow/><mml:mi>n</mml:mi></mml:msup><mml:mo stretchy="false">]</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
where <italic>d'</italic> is performance as a function of contrast (<italic>c</italic>), <italic>d'</italic> <sub><italic>max</italic></sub> determines the asymptotic performance at high contrasts, <italic>c</italic><sub>50</sub> is the contrast corresponding to half the asymptotic performance, and <italic>n</italic> is an exponent that determines the slope of the CRFs. In this analysis, <italic>n</italic> was fixed at 2 [<xref ref-type="bibr" rid="pbio.1002578.ref017">17</xref>,<xref ref-type="bibr" rid="pbio.1002578.ref038">38</xref>].</p>
</sec>
<sec id="sec012">
<title>fMRI Experiments</title>
<p>Using a block design, the experiment consisted of six functional runs. Each run consisted of 12 stimulus blocks of 16 s, interleaved with 12 blank intervals of 16 s. There were 6 different stimulus blocks: 2 (visual field: left/right) × 3 (emotional valence: negative/neutral/positive). Each stimulus block was randomly repeated two times in each run, and consisted of 8 trials; on each trial, a face flanked by four gratings was presented for 0.3 s, followed by a 1.7-s fixation interval, and subjects were asked to discriminate the gender of the face (male or female) while maintaining central fixation throughout the trial (<xref ref-type="fig" rid="pbio.1002578.g003">Fig 3C</xref>).</p>
<p>The V1 boundary was defined by a standard phase-encoded method developed by Sereno et al. [<xref ref-type="bibr" rid="pbio.1002578.ref067">67</xref>] and Engel et al. [<xref ref-type="bibr" rid="pbio.1002578.ref068">68</xref>], in which subjects viewed rotating wedge and expanding ring stimuli that created traveling waves of neural activity in visual cortex. A block-design scan was used to localize the ROIs in V1 corresponding to the target face, nearby gratings, and far gratings (<xref ref-type="fig" rid="pbio.1002578.g003">Fig 3B</xref>). The localizer scan consisted of 12 stimulus blocks of 12 s, interleaved with 12 blank intervals of 12 s. In a stimulus block, subjects passively viewed 8-Hz flickering patches. Each block type was repeated four times in the run, which lasted 288 s.</p>
</sec>
<sec id="sec013">
<title>MRI Data Acquisition</title>
<p>MRI data were collected using a 3T Siemens Trio scanner with a 32-channel phase-array coil. In the scanner, the stimuli were back-projected via a video projector (refresh rate: 60 Hz; spatial resolution: 1,280 × 800) onto a translucent screen placed inside the scanner bore. Subjects viewed the stimuli through a mirror located above their eyes. The viewing distance was 115 cm. BOLD signals were measured with an echo-planar imaging sequence (TR: 2,000 ms; TE: 30 ms; FOV: 192 × 192 mm<sup>2</sup>; matrix: 64 × 64; flip angle: 90°; slice thickness: 3 mm; gap: 0 mm; number of slices: 34; slice orientation: axial). The bottom slice was positioned at the bottom of the temporal lobes. A 3D MPRAGE structural dataset (resolution: 1 ×1 × 1 mm<sup>3</sup>; TR: 2,600 ms; TE: 30 ms; FOV: 256 × 224 mm<sup>2</sup>; flip angle: 8°; number of slices: 176; slice orientation: sagittal) was collected in the same session before the functional scans. Subjects underwent two sessions, one for retinotopic mapping and the other for the main experiment.</p>
</sec>
<sec id="sec014">
<title>MRI Data Analysis</title>
<p>The anatomical volume for each subject in the retinotopic mapping session was transformed into a brain space that was common for all subjects [<xref ref-type="bibr" rid="pbio.1002578.ref069">69</xref>] and then inflated using BrainVoyager QX. Functional volumes in both sessions for each subject were preprocessed, including 3-D motion correction, linear trend removal, and high-pass (0.015 Hz) filtering using BrainVoyager QX [<xref ref-type="bibr" rid="pbio.1002578.ref070">70</xref>]. Head motion within any fMRI session was &lt;2 mm for all subjects. The images were then aligned to the anatomical volume from the retinotopic mapping session and transformed into Talairach space [<xref ref-type="bibr" rid="pbio.1002578.ref069">69</xref>]. The first 8 s of BOLD signals were discarded to minimize transient magnetic saturation effects. A general linear model (GLM) procedure was used to determine the V1’s boundary and ROI analysis. V1 boundaries were delineated by a standard retinotopic mapping method [<xref ref-type="bibr" rid="pbio.1002578.ref067">67</xref>,<xref ref-type="bibr" rid="pbio.1002578.ref068">68</xref>]. The ROIs within V1 were defined as regions that responded more strongly to the flickering patches than to the blank screen (<italic>p</italic> &lt; 10<sup>−3</sup>, uncorrected).</p>
</sec>
<sec id="sec015">
<title>DCM</title>
<p>To directly confirm whether emotional valence modulated the attention field size in V1 through the modulation of feedback from DLPFC, we applied DCM analysis in SPM10 to our fMRI data [<xref ref-type="bibr" rid="pbio.1002578.ref039">39</xref>]. For each subject and each hemisphere, using BrainVoyager QX, the amygdala and V1 (including dorsal and ventral parts) voxels were identified as those activated by the emotional block and the flanking gratings at a significance level of <italic>p</italic> &lt; 0.005, respectively; both the pulvinar and DLPFC voxels were identified as those activated by the stimulus block at a significance level of <italic>p</italic> &lt; 0.005. The mean Talairach coordinates of these voxels and the standard errors across subjects in the amygdala, dorsal V1, ventral V1, the pulvinar, and DLPFC were [−22 ± 1.4, −7 ± 1.0, −13 ± 1.1], [−7 ± 0.8, −93 ± 1.0, −12 ± 1.3], [−3 ± 1.1, −84 ± 1.1, −16 ± 1.2], [−18 ± 1.9, −27 ± 1.2, 7 ± 0.9], and [−44 ± 1.6, 25 ± 1.7, 29 ± 2.7] for the left hemisphere and [25 ± 1.6, −9 ± 1.0, −15 ± 1.0], [7 ± 1.1, −94 ± 0.6, −8 ± 2.2], [3 ± 0.8, −83 ± 1.1, −14 ± 1.7], [17 ± 1.7, −29 ± 1.0, 7 ± 0.9], and [45 ± 1.7, 21 ± 3.1, 31 ± 2.3] for the right hemisphere, respectively. For each subject and each hemisphere, these Talairach coordinates were converted to Montreal Neurological Institute (MNI) coordinates using the tal2mni conversion utility (<ext-link ext-link-type="uri" xlink:href="http://imaging.mrc-cbu.cam.ac.uk/downloads/MNI2tal/tal2mni.m" xlink:type="simple">http://imaging.mrc-cbu.cam.ac.uk/downloads/MNI2tal/tal2mni.m</ext-link>). In SPM, for each of these areas, we extracted voxels within a 4-mm sphere centered on the most significant voxel and used their time series for the DCM analysis. The estimated DCM parameters were later averaged across dorsal and ventral V1 and the two hemispheres using the Bayesian model averaging method [<xref ref-type="bibr" rid="pbio.1002578.ref039">39</xref>].</p>
<p>DCMs have three sets of parameters: (1) extrinsic input into one or more regions; (2) intrinsic connectivities among the modeled regions; and (3) bilinear parameters encoding the modulations of the specified intrinsic connections by experimental manipulations [<xref ref-type="bibr" rid="pbio.1002578.ref039">39</xref>,<xref ref-type="bibr" rid="pbio.1002578.ref071">71</xref>,<xref ref-type="bibr" rid="pbio.1002578.ref072">72</xref>]. The third set of parameters is used to quantify modulatory effects, which reflect increases or decreases in connectivity between two regions given some experimental manipulation, compared with the intrinsic connections between the same regions that capture connectivity in the absence of experimental manipulation. FMRI data were modeled using GLM, with regressors for negative, neutral, and positive emotions, as well as a fourth condition comprising all visual input. The fourth condition was added specifically for the DCM analysis to be used as a direct visual input. Given the extrinsic visual input into V1, we defined seven different models with modulatory inputs (either the negative emotion or positive emotion, <xref ref-type="fig" rid="pbio.1002578.g005">Fig 5A</xref>). The modulatory inputs could modulate feedback from the amygdala (Model 1), from the pulvinar (Model 2), from both the amygdala and pulvinar (Model 3), from DLPFC (Model 4), from both the amygdala and DLPFC (Model 5), from both DLPFC and the pulvinar (Model 6), and from all three areas (Model 7) to V1. We examined these seven models for modeling the modulatory effect by negative and positive emotions. We fit each of these seven models for each subject. Using a hierarchical Bayesian approach [<xref ref-type="bibr" rid="pbio.1002578.ref073">73</xref>], we compared the seven models by computing the exceedance probability of each model, i.e., the probability to which a given model is more likely than any other included model to have generated data from a randomly selected subject [<xref ref-type="bibr" rid="pbio.1002578.ref039">39</xref>,<xref ref-type="bibr" rid="pbio.1002578.ref071">71</xref>,<xref ref-type="bibr" rid="pbio.1002578.ref072">72</xref>]. In the best model (Model 4), we examined the modulatory effects by negative and positive emotions.</p>
</sec>
<sec id="sec016">
<title>Eye Movement Recordings</title>
<p>Eye movements were recorded with an ASL EyeTrac 6000 (Applied Science Laboratories, Bedford, Massachusetts) in a psychophysics lab (outside the scanner). Its temporal resolution was 60 Hz, and its spatial resolution was 0.25°. Recording was performed when subjects performed the same task as the psychophysical and fMRI experiments. <xref ref-type="supplementary-material" rid="pbio.1002578.s011">S1 Fig</xref> and <xref ref-type="supplementary-material" rid="pbio.1002578.s013">S3 Fig</xref> show that subjects’ eye movements were small and statistically indistinguishable across all conditions.</p>
</sec>
</sec>
<sec id="sec017">
<title>Supporting Information</title>
<supplementary-material id="pbio.1002578.s001" mimetype="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet" position="float" xlink:href="info:doi/10.1371/journal.pbio.1002578.s001" xlink:type="simple">
<label>S1 Data</label>
<caption>
<title>Data for <xref ref-type="fig" rid="pbio.1002578.g002">Fig 2</xref>.</title>
<p>(XLSX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.1002578.s002" mimetype="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet" position="float" xlink:href="info:doi/10.1371/journal.pbio.1002578.s002" xlink:type="simple">
<label>S2 Data</label>
<caption>
<title>Data for <xref ref-type="fig" rid="pbio.1002578.g004">Fig 4</xref>.</title>
<p>(XLSX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.1002578.s003" mimetype="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet" position="float" xlink:href="info:doi/10.1371/journal.pbio.1002578.s003" xlink:type="simple">
<label>S3 Data</label>
<caption>
<title>Data for <xref ref-type="fig" rid="pbio.1002578.g005">Fig 5</xref>.</title>
<p>(XLSX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.1002578.s004" mimetype="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet" position="float" xlink:href="info:doi/10.1371/journal.pbio.1002578.s004" xlink:type="simple">
<label>S4 Data</label>
<caption>
<title>Data for <xref ref-type="supplementary-material" rid="pbio.1002578.s011">S1 Fig</xref>.</title>
<p>(XLSX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.1002578.s005" mimetype="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet" position="float" xlink:href="info:doi/10.1371/journal.pbio.1002578.s005" xlink:type="simple">
<label>S5 Data</label>
<caption>
<title>Data for <xref ref-type="supplementary-material" rid="pbio.1002578.s012">S2 Fig</xref>.</title>
<p>(XLSX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.1002578.s006" mimetype="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet" position="float" xlink:href="info:doi/10.1371/journal.pbio.1002578.s006" xlink:type="simple">
<label>S6 Data</label>
<caption>
<title>Data for <xref ref-type="supplementary-material" rid="pbio.1002578.s013">S3 Fig</xref>.</title>
<p>(XLSX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.1002578.s007" mimetype="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet" position="float" xlink:href="info:doi/10.1371/journal.pbio.1002578.s007" xlink:type="simple">
<label>S7 Data</label>
<caption>
<title>Data for <xref ref-type="supplementary-material" rid="pbio.1002578.s014">S4 Fig</xref>.</title>
<p>(XLSX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.1002578.s008" mimetype="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet" position="float" xlink:href="info:doi/10.1371/journal.pbio.1002578.s008" xlink:type="simple">
<label>S8 Data</label>
<caption>
<title>Data for <xref ref-type="supplementary-material" rid="pbio.1002578.s015">S5 Fig</xref>.</title>
<p>(XLSX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.1002578.s009" mimetype="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet" position="float" xlink:href="info:doi/10.1371/journal.pbio.1002578.s009" xlink:type="simple">
<label>S9 Data</label>
<caption>
<title>Data for <xref ref-type="supplementary-material" rid="pbio.1002578.s016">S6 Fig</xref>.</title>
<p>(XLSX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.1002578.s010" mimetype="application/zip" position="float" xlink:href="info:doi/10.1371/journal.pbio.1002578.s010" xlink:type="simple">
<label>S10 Data</label>
<caption>
<title>The dataset contains the Brain Voyager t-value images (vmp and nifti-1 formats) of the statistical maps of <xref ref-type="fig" rid="pbio.1002578.g004">Fig 4</xref> and <xref ref-type="supplementary-material" rid="pbio.1002578.s015">S5 Fig</xref> and the individual fMRI data.</title>
<p>(ZIP)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.1002578.s011" mimetype="application/eps" position="float" xlink:href="info:doi/10.1371/journal.pbio.1002578.s011" xlink:type="simple">
<label>S1 Fig</label>
<caption>
<title>Eye movement data for the psychophysical experiment.</title>
<p>Histograms of horizontal (up) and vertical (down) eye positions after removing blinks and artifacts in the congruent (A) and incongruent (B) cues. A congruent cue was defined as a match between the emotional face location and response cue location; an incongruent cue was defined as a mismatch. Eye movements were small, and eye position distributions were very similar between the negative and positive conditions. <italic>T</italic> tests showed that the horizontal and vertical mean eye positions of all the distributions did not deviate significantly from the fixation point (all <italic>p</italic> &gt; 0.05). The data are in the Supporting Information (see <xref ref-type="supplementary-material" rid="pbio.1002578.s004">S4 Data</xref>).</p>
<p>(EPS)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.1002578.s012" mimetype="application/eps" position="float" xlink:href="info:doi/10.1371/journal.pbio.1002578.s012" xlink:type="simple">
<label>S2 Fig</label>
<caption>
<title>Spatial cueing effects on performance (<italic>d'</italic>) as a function of contrast for the negative first group and the positive first group.</title>
<p>Negative first group: subjects finished the negative session (negative faces) in the first day and the positive session (positive faces) in the second day. Positive first group: subjects finished these two sessions in the opposite order. (A) Mean <italic>d'</italic> plotted as psychometric functions of stimulus contrast, session order, and emotional valence for congruent and incongruent trials. (B) Correlations between the mean self-reported emotional strength of the faces and the <italic>d'</italic> <sub><italic>max</italic></sub> differences between congruent and incongruent trials across individual subjects. (C) Correlations between the mean self-reported emotional strength of the faces and the <italic>c</italic><sub><italic>50</italic></sub> differences between congruent and incongruent trials across individual subjects. (D) <italic>d'</italic> <sub><italic>max</italic></sub> and (E) <italic>c</italic><sub><italic>50</italic></sub> for trial conditions, session order, and emotional valence. Error bars denote 1 SEM calculated across subjects. Both <italic>d'</italic> <sub>max</sub> and <italic>c</italic><sub><italic>50</italic></sub> were submitted to a three-way mixed ANOVA with session order (negative first and positive first) as the between-subjects factor and emotional valence (negative and positive) and trial condition (congruent and incongruent) as the within-subjects factors. For <italic>d'</italic> <sub>max</sub>, the interaction between session order and emotional valence (F<sub>1, 21</sub> = 0.028, <italic>p</italic> = 0.869), the interaction between session order and trial condition (F<sub>1, 21</sub> = 0.007, <italic>p</italic> = 0.934), and the interaction among these three factors (F<sub>1, 21</sub> = 0.010, <italic>p</italic> = 0.919) were all insignificant. Similarly, for <italic>c</italic><sub><italic>50</italic>,</sub> the interaction between session order and emotional valence (F<sub>1, 21</sub> = 0.194, <italic>p</italic> = 0.664), the interaction between session order and trial condition (F<sub>1, 21</sub> = 0.073, <italic>p</italic> = 0.790), and the interaction among these three factors (F<sub>1, 21</sub> = 1.569, <italic>p</italic> = 0.224) were all insignificant. These results suggest that the order of the two sessions did not influence our psychophysical results. The data are in the Supporting Information (see <xref ref-type="supplementary-material" rid="pbio.1002578.s005">S5 Data</xref>).</p>
<p>(EPS)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.1002578.s013" mimetype="application/eps" position="float" xlink:href="info:doi/10.1371/journal.pbio.1002578.s013" xlink:type="simple">
<label>S3 Fig</label>
<caption>
<title>Eye movement data for the fMRI experiment.</title>
<p>Histograms of horizontal (up) and vertical (down) eye positions after removing blinks and artifacts when the stimuli were presented in the left (A) and right (B) visual fields. Their eye movements were small, and eye position distributions were very similar among the negative, neutral, and positive conditions. <italic>T</italic> test analyses showed that the horizontal and vertical mean eye positions of all the distributions did not deviate significantly from the fixation point (all <italic>p</italic> &gt; 0.05). The data are in the Supporting Information (see <xref ref-type="supplementary-material" rid="pbio.1002578.s006">S6 Data</xref>).</p>
<p>(EPS)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.1002578.s014" mimetype="application/eps" position="float" xlink:href="info:doi/10.1371/journal.pbio.1002578.s014" xlink:type="simple">
<label>S4 Fig</label>
<caption>
<title>Three hypotheses about the modulation of V1 responses to irrelevant flanking gratings by emotional valence.</title>
<p>(A) Hypothesis 1: emotional valence modulates the scope of perceptual encoding, with negative emotion narrowing and positive emotion (the faces of a coauthor here are for illustration purposes only; they were not used in the experiments) broadening the attention field (the diameter of disk indicates the size of the attention field). (B) Hypothesis 2: emotional valence modulates the brain state (e.g., arousal), with negative emotion decreasing and positive emotion increasing the V1 signal (the gray level of disk indicates the level of brain signal). (C) Hypothesis 3: a combination of hypotheses 1 and 2, with negative emotion narrowing the attention field and decreasing the V1 signal and positive emotion broadening the attention field and increasing the V1 signal. We predicted that these hypotheses could explain the same result, i.e., that negative emotion decreases and positive emotion increases the encoding of the irrelevant flanking gratings, as indexed by the BOLD signal changes in V1 evoked by the nearby and far gratings (D, E, and F, left). However, when analyzing BOLD signals in V1 evoked by nearby gratings and far gratings separately, these different hypotheses should show different patterns (D, E, and F, right). First, if emotional valence modulates the scope of perceptual encoding (A and D), then for the nearby gratings, V1 should show a lower response in the negative condition than that in the neutral and positive conditions, but no significant difference between the neutral and positive conditions should be found. However, for the far gratings, V1 should show a higher response in the positive condition than that in the negative and neutral conditions, but no significant difference between the negative and neutral conditions should be found. Second, if emotional valence modulates the brain state (B and E), for both the nearby and far gratings, V1 should show the lowest, median, and highest response in the negative, neutral, and positive conditions, respectively. Third, if emotional valence modulates both the scope of perceptual encoding and the brain state (C and F), for the nearby gratings, V1 should show a similar pattern to that in hypothesis 2, with the lowest, median, and highest response in the negative, neutral, and positive conditions, respectively. However, for the far gratings, V1 should show a similar pattern to that in hypothesis 1, with a higher response in the positive condition than that in the negative and neutral conditions, but no significant difference between the negative and neutral conditions should be found. The data are in the Supporting Information (see <xref ref-type="supplementary-material" rid="pbio.1002578.s007">S7 Data</xref>).</p>
<p>(EPS)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.1002578.s015" mimetype="application/eps" position="float" xlink:href="info:doi/10.1371/journal.pbio.1002578.s015" xlink:type="simple">
<label>S5 Fig</label>
<caption>
<title>BOLD signal for the three types of emotion valence in the ROIs in the amygdala, mOFC, FEF, and PPC.</title>
<p>(A and B) Emotion- and attention-specific cortical/subcortical areas (the results of DLPFC were shown in <xref ref-type="fig" rid="pbio.1002578.g004">Fig 4</xref>). mOFC: medial orbitofrontal cortex; FEF: frontal eye field; PPC: posterior parietal cortex. The BOLD amplitudes in these areas for the three types of emotional valence were submitted to a repeated-measures ANOVA with emotional valence as a within-subjects factor. The main effect in both FEF (F<sub>2, 28</sub> = 0.053, <italic>p</italic> = 0.902) and PPC (F<sub>2, 28</sub> = 2.320, <italic>p</italic> = 0.133) was not significant. However, the main effect in both the amygdala (F<sub>2, 28</sub> = 14.473, <italic>p</italic> = 0.001) and mOFC (F<sub>2, 28</sub> = 20.693, <italic>p</italic> &lt; 0.001) was significant; post hoc paired <italic>t</italic> tests revealed that, for both the amygdala and mOFC, the neutral condition was significantly lower than both the negative condition (the amygdala: t<sub>14</sub> = −4.136, <italic>p</italic> = 0.003; mOFC: t<sub>14</sub> = −3.419, <italic>p</italic> = 0.012) and the positive condition (the amygdala: t<sub>14</sub> = −3.674, <italic>p</italic> = 0.008; mOFC: t<sub>14</sub> = −7.139, <italic>p</italic> &lt; 0.001); no significant difference was found between the negative and positive conditions (the amygdala: t<sub>14</sub> = 2.243, <italic>p</italic> = 0.125; mOFC: t<sub>14</sub> = −2.487, <italic>p</italic> = 0.078). Error bars denote 1 SEM calculated across subjects. (C) Correlations between the BOLD signal difference between negative and neutral conditions in V1 and in the amygdala, mOFC, FEF, and PPC across individual subjects. (D) Correlations between the BOLD signal difference between positive and neutral conditions in V1 and in the amygdala, mOFC, FEF, and PPC across individual subjects. The data are in the Supporting Information (see <xref ref-type="supplementary-material" rid="pbio.1002578.s008">S8 Data</xref> and <xref ref-type="supplementary-material" rid="pbio.1002578.s010">S10 Data</xref>).</p>
<p>(EPS)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.1002578.s016" mimetype="application/eps" position="float" xlink:href="info:doi/10.1371/journal.pbio.1002578.s016" xlink:type="simple">
<label>S6 Fig</label>
<caption>
<title>DCM of connectivities among the mOFC, DLPFC, the pulvinar, and V1.</title>
<p>(A) Seven different models for modeling the modulatory effect of negative and positive emotions (mOFC was selected in the models since it also showed significantly greater responses to emotional faces than neutral faces, similar to the amygdala; see <xref ref-type="supplementary-material" rid="pbio.1002578.s015">S5 Fig</xref>). mOFC: medial orbitofrontal cortex (Talairach coordinates: [−11 ± 1.4, 56 ± 1.6, 5 ± 1.6] and [10 ± 1.6, 55 ± 1.9, 6 ± 1.6] for the left and right hemispheres, respectively); Pul: pulvinar. (B) For negative emotion, the exceedance probabilities of Models 1 through 7 were 2.33%, 11.87%, 6.29%, 26.78%, 11.98%, 23.88%, and 16.87%, respectively, suggesting that Model 4 was the best one to explain the modulatory effect by negative emotion (up); for positive emotion, the exceedance probabilities of Models 1 through 7 were 5.60%, 10.72%, 8.79%, 24.21%, 13.10%, 21.09%, and 16.49%, respectively, suggesting that the modulatory effect by positive emotion was also best explained by Model 4 (down). (C) The strength of the modulatory connections for negative (up) and positive (down) emotions, and its significance levels (*<italic>p</italic> &lt; 0.05 and **<italic>p</italic> &lt; 0.01, respectively). The negative emotion significantly increased the feedback connectivity from mOFC to both DLPFC (t<sub>14</sub> = 3.069, <italic>p</italic> = 0.008) and the pulvinar (t<sub>14</sub> = 2.793, <italic>p</italic> = 0.014) but decreased the feedback connectivity from DLPFC to V1 (t<sub>14</sub> = −3.295, <italic>p</italic> = 0.005); the positive emotion significantly decreased the feedback connectivity from mOFC to both DLPFC (t<sub>14</sub> = −2.621, <italic>p</italic> = 0.020) and the pulvinar (t<sub>14</sub> = −2.880, <italic>p</italic> = 0.012) but increased the feedback connectivity from DLPFC to V1 (t<sub>14</sub> = 3.688, <italic>p</italic> = 0.002). (D) Correlations between the V1 BOLD signal changes of emotional valence and effective connection strengths across individual subjects. The data are in the Supporting Information (see <xref ref-type="supplementary-material" rid="pbio.1002578.s009">S9 Data</xref>).</p>
<p>(EPS)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>We are grateful to Valentinos Zachariou, Souheil Inati, John Ingeholm, Ruyuan Zhang, and Yang Zhang for help with psychophysics, fMRI, eye tracking, Naka–Rushton fitting, and Analyze file exporting, respectively.</p>
</ack>
<glossary>
<title>Abbreviations</title>
<def-list>
<def-item><term>BOLD</term>
<def><p>blood oxygenation-level-dependent</p></def>
</def-item>
<def-item><term>CRF</term>
<def><p>contrast-response function</p></def>
</def-item>
<def-item><term>DCM</term>
<def><p>dynamic causal modeling</p></def>
</def-item>
<def-item><term>DLPFC</term>
<def><p>dorsolateral prefrontal cortex</p></def>
</def-item>
<def-item><term>FEF</term>
<def><p>frontal eye field</p></def>
</def-item>
<def-item><term>fMRI</term>
<def><p>functional magnetic resonance imaging</p></def>
</def-item>
<def-item><term>MNI</term>
<def><p>Montreal Neurological Institute</p></def>
</def-item>
<def-item><term>mOFC</term>
<def><p>medial orbitofrontal cortex</p></def>
</def-item>
<def-item><term>PPC</term>
<def><p>posterior parietal cortex</p></def>
</def-item>
<def-item><term>ROI</term>
<def><p>region of interest</p></def>
</def-item>
<def-item><term>SEM</term>
<def><p>standard error of the mean</p></def>
</def-item>
<def-item><term>V1</term>
<def><p>primary visual cortex</p></def>
</def-item>
</def-list>
</glossary>
<ref-list>
<title>References</title>
<ref id="pbio.1002578.ref001"><label>1</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Desimone</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Duncan</surname> <given-names>J</given-names></name>. <article-title>Neural mechanisms of selective visual attention</article-title>. <source>Annu Rev Neurosci</source>. <year>1995</year>; <volume>18</volume>:<fpage>193</fpage>–<lpage>222</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1146/annurev.ne.18.030195.001205" xlink:type="simple">10.1146/annurev.ne.18.030195.001205</ext-link></comment> <object-id pub-id-type="pmid">7605061</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref002"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Martínez-Trujillo</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Treue</surname> <given-names>S</given-names></name>. <article-title>Attentional modulation strength in cortical area MT depends on stimulus contrast</article-title>. <source>Neuron</source>. <year>2002</year>; <volume>35</volume>: <fpage>365</fpage>–<lpage>370</lpage>. <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0896-6273(02)00778-X" xlink:type="simple">http://dx.doi.org/10.1016/S0896-6273(02)00778-X</ext-link>. <object-id pub-id-type="pmid">12160753</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref003"><label>3</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Reynolds</surname> <given-names>JH</given-names></name>, <name name-style="western"><surname>Pasternak</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Desimone</surname> <given-names>R</given-names></name>. <article-title>Attention increases sensitivity of V4 neurons</article-title>. <source>Neuron</source>. <year>2000</year>; <volume>26</volume>: <fpage>703</fpage>–<lpage>714</lpage>. <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0896-6273(00)81206-4" xlink:type="simple">http://dx.doi.org/10.1016/S0896-6273(00)81206-4</ext-link>. <object-id pub-id-type="pmid">10896165</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Di Russo</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Spinelli</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Morrone</surname> <given-names>MC</given-names></name>. <article-title>Automatic gain control contrast mechanisms are modulated by attention in humans: evidence from visual evoked potentials</article-title>. <source>Vision Res</source>. <year>2001</year>; <volume>41</volume>: <fpage>2435</fpage>–<lpage>2447</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0042-6989(01)00134-1" xlink:type="simple">10.1016/S0042-6989(01)00134-1</ext-link></comment> <object-id pub-id-type="pmid">11483175</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref005"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kim</surname> <given-names>YJ</given-names></name>, <name name-style="western"><surname>Grabowecky</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Paller</surname> <given-names>KA</given-names></name>, <name name-style="western"><surname>Muthu</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Suzuki</surname> <given-names>S</given-names></name>. <article-title>Attention induces synchronization-based response gain in steady-state visual evoked potentials</article-title>. <source>Nat Neurosci</source>. <year>2007</year>; <volume>10</volume>: <fpage>117</fpage>–<lpage>125</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn1821" xlink:type="simple">10.1038/nn1821</ext-link></comment> <object-id pub-id-type="pmid">17173045</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lee</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Maunsell</surname> <given-names>JH</given-names></name>. <article-title>A normalization model of attentional modulation of single unit responses</article-title>. <source>PLoS ONE</source> <year>2009</year>; <volume>4</volume>: <fpage>e4651</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0004651" xlink:type="simple">10.1371/journal.pone.0004651</ext-link></comment> <object-id pub-id-type="pmid">19247494</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref007"><label>7</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ling</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Carrasco</surname> <given-names>M</given-names></name>. <article-title>Sustained and transient covert attention enhance the signal via different contrast response functions</article-title>. <source>Vision Res</source>. <year>2006</year>: <volume>46</volume>: <fpage>1210</fpage>–<lpage>1220</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.visres.2005.05.008" xlink:type="simple">10.1016/j.visres.2005.05.008</ext-link></comment> <object-id pub-id-type="pmid">16005931</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref008"><label>8</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>McAdams</surname> <given-names>CJ</given-names></name>, <name name-style="western"><surname>Maunsell</surname> <given-names>JH</given-names></name>. <article-title>Effects of attention on orientationtuning functions of single neurons in macaque cortical area V4</article-title>. <source>J Neurosci</source>. <year>1999</year>: <volume>19</volume>: <fpage>431</fpage>–<lpage>441</lpage>. <object-id pub-id-type="pmid">9870971</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref009"><label>9</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Morrone</surname> <given-names>MC</given-names></name>, <name name-style="western"><surname>Denti</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Spinelli</surname> <given-names>D</given-names></name>. <article-title>Color and luminance contrasts attract independent attention</article-title>. <source>Curr Biol</source>. <year>2002</year>; <volume>12</volume>: <fpage>1134</fpage>–<lpage>1137</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0960-9822(02)00921-1" xlink:type="simple">10.1016/S0960-9822(02)00921-1</ext-link></comment> <object-id pub-id-type="pmid">12121622</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref010"><label>10</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Li</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Lu</surname> <given-names>ZL</given-names></name>, <name name-style="western"><surname>Tjan</surname> <given-names>BS</given-names></name>, <name name-style="western"><surname>Dosher</surname> <given-names>BA</given-names></name>, <name name-style="western"><surname>Chu</surname> <given-names>W</given-names></name>. <article-title>Blood oxygenation level–dependent contrast response functions identify mechanisms of covert attention in early visual areas</article-title>. <source>Proc Natl Acad Sci</source>. <year>2008</year>: <volume>105</volume>: <fpage>6202</fpage>–<lpage>6207</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.0801390105" xlink:type="simple">10.1073/pnas.0801390105</ext-link></comment> <object-id pub-id-type="pmid">18413602</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref011"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Reynolds</surname> <given-names>JH</given-names></name>, <name name-style="western"><surname>Chelazzi</surname> <given-names>L</given-names></name>. <article-title>Attentional modulation of visual processing</article-title>. <source>Annu Rev Neurosci</source>. <year>2004</year>; <volume>27</volume>: <fpage>611</fpage>–<lpage>647</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1146/annurev.neuro.26.041002.131039" xlink:type="simple">10.1146/annurev.neuro.26.041002.131039</ext-link></comment> <object-id pub-id-type="pmid">15217345</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref012"><label>12</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Buracas</surname> <given-names>GT</given-names></name>, <name name-style="western"><surname>Boynton</surname> <given-names>GM</given-names></name>. <article-title>The effect of spatial attention on contrast response functions in human visual cortex</article-title>. <source>J Neurosci</source>. <year>2007</year>; <volume>27</volume>: <fpage>93</fpage>–<lpage>97</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.3162-06.2007" xlink:type="simple">10.1523/JNEUROSCI.3162-06.2007</ext-link></comment> <object-id pub-id-type="pmid">17202476</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref013"><label>13</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Huang</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Dobkins</surname> <given-names>KR</given-names></name>. <article-title>Attentional effects on contrast discrimination in humans: evidence for both contrast gain and response gain</article-title>. <source>Vision Res</source>. <year>2005</year>; <volume>45</volume>: <fpage>1201</fpage>–<lpage>1212</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.visres.2004.10.024" xlink:type="simple">10.1016/j.visres.2004.10.024</ext-link></comment> <object-id pub-id-type="pmid">15707928</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Murray</surname> <given-names>SO</given-names></name>. <article-title>The effects of spatial attention in early human visual cortex are stimulus independent</article-title>. <source>J Vis</source>. <year>2008</year>; <volume>8</volume>: <fpage>1</fpage>–<lpage>11</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1167/8.10.2" xlink:type="simple">10.1167/8.10.2</ext-link></comment> <object-id pub-id-type="pmid">19146344</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pestilli</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Carrasco</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Heeger</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Gardner</surname> <given-names>JL</given-names></name>. <article-title>Attentional enhancement via selection and pooling of early sensory responses in human visual cortex</article-title>. <source>Neuron</source>. <year>2011</year>; <volume>72</volume>: <fpage>832</fpage>–<lpage>846</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2011.09.025" xlink:type="simple">10.1016/j.neuron.2011.09.025</ext-link></comment> <object-id pub-id-type="pmid">22153378</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Williford</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Maunsell</surname> <given-names>JH</given-names></name>. <article-title>Effects of spatial attention on contrast response functions in macaque area V4</article-title>. <source>J Neurophysiol</source>. <year>2006</year>; <volume>96</volume>: <fpage>40</fpage>–<lpage>54</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.01207.2005" xlink:type="simple">10.1152/jn.01207.2005</ext-link></comment> <object-id pub-id-type="pmid">16772516</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Herrmann</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Montaser-Kouhsari</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Carrasco</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Heeger</surname> <given-names>DJ</given-names></name>. <article-title>When size matters: attention affects performance by contrast or response gain</article-title>. <source>Nat Neurosci</source>. <year>2010</year>; <volume>13</volume>: <fpage>1554</fpage>–<lpage>1559</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.2669" xlink:type="simple">10.1038/nn.2669</ext-link></comment> <object-id pub-id-type="pmid">21057509</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref018"><label>18</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Reynolds</surname> <given-names>JH</given-names></name>, <name name-style="western"><surname>Chelazzi</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Desimone</surname> <given-names>R</given-names></name>. <article-title>Competitive mechanisms subserve attention in macaque areas V2 and V4</article-title>. <source>J Neurosci</source>. <year>1999</year>; <volume>19</volume>: <fpage>1736</fpage>–<lpage>1753</lpage>. <object-id pub-id-type="pmid">10024360</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref019"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Reynolds</surname> <given-names>JH</given-names></name>, <name name-style="western"><surname>Heeger</surname> <given-names>DJ</given-names></name>. <article-title>The normalization model of attention</article-title>. <source>Neuron</source>. <year>2009</year>; <volume>61</volume>: <fpage>168</fpage>–<lpage>185</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2009.01.002" xlink:type="simple">10.1016/j.neuron.2009.01.002</ext-link></comment> <object-id pub-id-type="pmid">19186161</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref020"><label>20</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Itthipuripat</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Garcia</surname> <given-names>JO</given-names></name>, <name name-style="western"><surname>Rungratsameetaweemana</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Sprague</surname> <given-names>TC</given-names></name>, <name name-style="western"><surname>Serences</surname> <given-names>JT</given-names></name>. <article-title>Changing the spatial scope of attention alters patterns of neural gain in human cortex</article-title>. <source>J Neurosci</source>. <year>2014</year>; <volume>34</volume>: <fpage>112</fpage>–<lpage>123</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.3943-13.2014" xlink:type="simple">10.1523/JNEUROSCI.3943-13.2014</ext-link></comment> <object-id pub-id-type="pmid">24381272</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref021"><label>21</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Landman</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Sharma</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Sur</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Desimone</surname> <given-names>R</given-names></name>. <article-title>Effect of distracting faces on visual selective attention in the monkey</article-title>. <source>Proc Natl Acad Sci</source>. <year>2014</year>; <volume>111</volume>: <fpage>18037</fpage>–<lpage>18042</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.1420167111" xlink:type="simple">10.1073/pnas.1420167111</ext-link></comment> <object-id pub-id-type="pmid">25472846</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref022"><label>22</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Parr</surname> <given-names>LA</given-names></name>. <article-title>The evolution of face processing in primates</article-title>. <source>Philos Trans R Soc Lond B Biol Sci</source>. <year>2011</year>; <volume>366</volume>: <fpage>1764</fpage>–<lpage>1777</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1098/rstb.2010.0358" xlink:type="simple">10.1098/rstb.2010.0358</ext-link></comment> <object-id pub-id-type="pmid">21536559</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref023"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pessoa</surname> <given-names>L</given-names></name>. <article-title>On the relationship between emotion and cognition</article-title>. <source>Nat Rev Neurosci</source>. <year>2008</year>; <volume>9</volume>: <fpage>148</fpage>–<lpage>158</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nrn2317" xlink:type="simple">10.1038/nrn2317</ext-link></comment> <object-id pub-id-type="pmid">18209732</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref024"><label>24</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pessoa</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Adolphs</surname> <given-names>R</given-names></name>. <article-title>Emotion processing and the amygdala: from a ‘low road' to 'many roads' of evaluating biological significance</article-title>. <source>Nat Rev Neurosci</source>. <year>2010</year>; <volume>11</volume>: <fpage>773</fpage>–<lpage>783</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nrn2920" xlink:type="simple">10.1038/nrn2920</ext-link></comment> <object-id pub-id-type="pmid">20959860</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref025"><label>25</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pessoa</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Ungerleider</surname> <given-names>LG</given-names></name>. <article-title>Neuroimaging studies of attention and the processing of emotion-laden stimuli</article-title>. <source>Prog Brain Res</source>. <year>2004</year>; <volume>144</volume>: <fpage>171</fpage>–<lpage>182</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0079-6123(03)14412-3" xlink:type="simple">10.1016/S0079-6123(03)14412-3</ext-link></comment> <object-id pub-id-type="pmid">14650848</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref026"><label>26</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Vuilleumier</surname> <given-names>P</given-names></name>. <article-title>How brains beware: neural mechanisms of emotional attention</article-title>. <source>Trends Cogn Sci</source>. <year>2005</year>; <volume>9</volume>: <fpage>585</fpage>–<lpage>594</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.tics.2005.10.011" xlink:type="simple">10.1016/j.tics.2005.10.011</ext-link></comment> <object-id pub-id-type="pmid">16289871</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref027"><label>27</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Derryberry</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Tucker</surname> <given-names>DM</given-names></name>. <chapter-title>Motivating the focus of attention</chapter-title>. In: <source>The heart’s eye: emotional influences in perception and attention</source> (<name name-style="western"><surname>Niedenthal</surname> <given-names>PM</given-names></name>, <name name-style="western"><surname>Kitayama</surname> <given-names>S</given-names></name>, eds). <year>1994</year>; pp. <fpage>167</fpage>–<lpage>196</lpage>. <publisher-loc>San Diego</publisher-loc>: <publisher-name>Academic</publisher-name>.</mixed-citation></ref>
<ref id="pbio.1002578.ref028"><label>28</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Easterbrook</surname> <given-names>JA</given-names></name>. <article-title>The effect of emotion on cue utilization and the organization of behavior</article-title>. <source>Psychol Rev</source>. <year>1959</year>; <volume>66</volume>: <fpage>183</fpage>–<lpage>201</lpage>. <object-id pub-id-type="pmid">13658305</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref029"><label>29</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fredrickson</surname> <given-names>BL</given-names></name>. <article-title>Positive emotions broaden and build</article-title>. <source>Adv Exp Soc Psychol</source>. <year>2013</year>; <volume>47</volume>: <fpage>1</fpage>–<lpage>53</lpage>.</mixed-citation></ref>
<ref id="pbio.1002578.ref030"><label>30</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rowe</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Hirsh</surname> <given-names>JB</given-names></name>, <name name-style="western"><surname>Anderson</surname> <given-names>AK</given-names></name>. <article-title>Positive affect increases the breadth of attentional selection</article-title>. <source>Proc Natl Acad Sci</source>. <year>2007</year>; <volume>104</volume>: <fpage>383</fpage>–<lpage>388</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.0605198104" xlink:type="simple">10.1073/pnas.0605198104</ext-link></comment> <object-id pub-id-type="pmid">17182749</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref031"><label>31</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schmitz</surname> <given-names>TW</given-names></name>, <name name-style="western"><surname>De Rosa</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Anderson</surname> <given-names>AK</given-names></name>. <article-title>Opposing influences of emotional state valence on visual cortical encoding</article-title>. <source>J Neurosci</source>. <year>2009</year>; <volume>29</volume>: <fpage>7199</fpage>–<lpage>7207</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.5387-08.2009" xlink:type="simple">10.1523/JNEUROSCI.5387-08.2009</ext-link></comment> <object-id pub-id-type="pmid">19494142</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref032"><label>32</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Christianson</surname> <given-names>SA</given-names></name>. <article-title>Emotional stress and eyewitness memory: a critical review</article-title>. <source>Psychol Bull</source>. <year>1992</year>; <volume>112</volume>: <fpage>284</fpage>–<lpage>309</lpage>.</mixed-citation></ref>
<ref id="pbio.1002578.ref033"><label>33</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gasper</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Clore</surname> <given-names>GL</given-names></name>. <article-title>Attending to the big picture: mood and global versus local processing of visual information</article-title>. <source>Psychol Sci</source>. <year>2002</year>; <volume>13</volume>: <fpage>34</fpage>–<lpage>40</lpage>. <object-id pub-id-type="pmid">11892776</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref034"><label>34</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fredrickson</surname> <given-names>BL</given-names></name>, <name name-style="western"><surname>Branigan</surname> <given-names>C</given-names></name>. <article-title>Positive emotions broaden the scope of attention and thought-action repertoires</article-title>. <source>Cogn Emot</source>. <year>2005</year>; <volume>19</volume>: <fpage>313</fpage>–<lpage>332</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1080/02699930441000238" xlink:type="simple">10.1080/02699930441000238</ext-link></comment> <object-id pub-id-type="pmid">21852891</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref035"><label>35</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zhang</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Zhaoping</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Zhou</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Fang</surname> <given-names>F</given-names></name>. <article-title>Neural activities in V1 create a bottom-up saliency map</article-title>. <source>Neuron</source>. <year>2012</year>; <volume>73</volume>: <fpage>183</fpage>–<lpage>192</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2011.10.035" xlink:type="simple">10.1016/j.neuron.2011.10.035</ext-link></comment> <object-id pub-id-type="pmid">22243756</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref036"><label>36</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tottenham</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Tanaka</surname> <given-names>JW</given-names></name>, <name name-style="western"><surname>Leon</surname> <given-names>AC</given-names></name>, <name name-style="western"><surname>McCarry</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Nurse</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Hare</surname> <given-names>TA</given-names></name>, <name name-style="western"><surname>Marcus</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Westerlund</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Casey</surname> <given-names>BJ</given-names></name>, <name name-style="western"><surname>Nelson</surname> <given-names>C</given-names></name>. <article-title>The NimStim set of facial expressions: judgments from untrained research participants</article-title>. <source>Psychiatry Res</source>. <year>2009</year>; <volume>168</volume>: <fpage>242</fpage>–<lpage>249</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.psychres.2008.05.006" xlink:type="simple">10.1016/j.psychres.2008.05.006</ext-link></comment> <object-id pub-id-type="pmid">19564050</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref037"><label>37</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Naka</surname> <given-names>KI</given-names></name>, <name name-style="western"><surname>Rushton</surname> <given-names>WA</given-names></name>. <article-title>S-potentials from colour units in the retina of fish (Cyprinidae)</article-title>. <source>J Physiol (London)</source>. <year>1966</year>; <volume>185</volume>: <fpage>536</fpage>–<lpage>555</lpage>. <object-id pub-id-type="pmid">5918058</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref038"><label>38</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Carandini</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Heeger</surname> <given-names>DJ</given-names></name>. <article-title>Normalization as a canonical neural computation</article-title>. <source>Nat Rev Neurosci</source>. <year>2012</year>; <volume>13</volume>: <fpage>51</fpage>–<lpage>62</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nrn3136" xlink:type="simple">10.1038/nrn3136</ext-link></comment> <object-id pub-id-type="pmid">22108672</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref039"><label>39</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Friston</surname> <given-names>KJ</given-names></name>. <chapter-title>Dynamic causal models for fMRI</chapter-title>. In: <source>Statistical parametric mapping: the analysis of functional brain images</source> (<name name-style="western"><surname>Friston</surname> <given-names>KJ</given-names></name>, ed). <year>2006</year>; pp. <fpage>541</fpage>–<lpage>560</lpage>. <publisher-loc>Amsterdam</publisher-loc>: <publisher-name>Elsevier</publisher-name>.</mixed-citation></ref>
<ref id="pbio.1002578.ref040"><label>40</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jazayeri</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Movshon</surname> <given-names>JA</given-names></name>. <article-title>Optimal representation of sensory information by neural populations</article-title>. <source>Nat Neurosci</source>. <year>2006</year>; <volume>9</volume>: <fpage>690</fpage>–<lpage>696</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn1691" xlink:type="simple">10.1038/nn1691</ext-link></comment> <object-id pub-id-type="pmid">16617339</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref041"><label>41</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fenske</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Eastwood</surname> <given-names>JD</given-names></name>. <article-title>Modulation of focused attention by faces expressing emotion: evidence from flanker tasks</article-title>. <source>Emotion</source>. <year>2003</year>; <volume>3</volume>: <fpage>327</fpage>–<lpage>343</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/1528-3542.3.4.327" xlink:type="simple">10.1037/1528-3542.3.4.327</ext-link></comment> <object-id pub-id-type="pmid">14674827</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref042"><label>42</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Soto</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Funes</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Guzmán-García</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Warbrick</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Rotshtein</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Humphreys</surname> <given-names>GW</given-names></name>. <article-title>Pleasant music overcomes the loss of awareness in patients with visual neglect</article-title>. <source>Proc Natl Acad Sci</source>. <year>2009</year>; <volume>106</volume>: <fpage>6011</fpage>–<lpage>6016</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.0811681106" xlink:type="simple">10.1073/pnas.0811681106</ext-link></comment> <object-id pub-id-type="pmid">19307566</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref043"><label>43</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Heeger</surname> <given-names>DJ</given-names></name>. <article-title>Normalization of cell responses in cat striate cortex</article-title>. <source>Vis Neurosci</source>. <year>1992</year>; <volume>9</volume>: <fpage>181</fpage>–<lpage>197</lpage>. <object-id pub-id-type="pmid">1504027</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref044"><label>44</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ray</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Ni</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Maunsell</surname> <given-names>JH</given-names></name>. <article-title>Strength of gamma rhythm depends on normalization</article-title>. <source>PLoS Biol</source>. <year>2013</year>; <volume>11</volume>: <fpage>e1001477</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pbio.1001477" xlink:type="simple">10.1371/journal.pbio.1001477</ext-link></comment> <object-id pub-id-type="pmid">23393427</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref045"><label>45</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hasegawa</surname> <given-names>RP</given-names></name>, <name name-style="western"><surname>Peterson</surname> <given-names>BW</given-names></name>, <name name-style="western"><surname>Goldberg</surname> <given-names>ME</given-names></name>. <article-title>Prefrontal neurons coding suppression of specific saccades</article-title>. <source>Neuron</source>. <year>2004</year>; <volume>43</volume>: <fpage>415</fpage>–<lpage>425</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2004.07.013" xlink:type="simple">10.1016/j.neuron.2004.07.013</ext-link></comment> <object-id pub-id-type="pmid">15294148</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref046"><label>46</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Geng</surname> <given-names>JJ</given-names></name>. <article-title>Attentional mechanisms of distractor suppression</article-title>. <source>Curr Direct Psychol Sci</source>. <year>2014</year>; <volume>23</volume>: <fpage>147</fpage>–<lpage>153</lpage>.</mixed-citation></ref>
<ref id="pbio.1002578.ref047"><label>47</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lennert</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Martinez-Trujillo</surname> <given-names>J</given-names></name>. <article-title>Strength of response suppression to distracter stimuli determines attentional-filtering performance in primate prefrontal neurons</article-title>. <source>Neuron</source>. <year>2011</year>; <volume>70</volume>: <fpage>141</fpage>–<lpage>152</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2011.02.041" xlink:type="simple">10.1016/j.neuron.2011.02.041</ext-link></comment> <object-id pub-id-type="pmid">21482363</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref048"><label>48</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>MacDonald</surname> <given-names>AW</given-names></name>, <name name-style="western"><surname>Cohen</surname> <given-names>JD</given-names></name>, <name name-style="western"><surname>Stenger</surname> <given-names>VA</given-names></name>, <name name-style="western"><surname>Carter</surname> <given-names>CS</given-names></name>. <article-title>Dissociating the role of the dorsolateral prefrontal and anterior cingulate cortex in cognitive control</article-title>. <source>Science</source>. <year>2000</year>; <volume>288</volume>: <fpage>1835</fpage>–<lpage>1838</lpage>. <object-id pub-id-type="pmid">10846167</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref049"><label>49</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Squire</surname> <given-names>RF</given-names></name>, <name name-style="western"><surname>Noudoost</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Schafer</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Moore</surname> <given-names>T</given-names></name>. <article-title>Prefrontal contributions to visual selective attention</article-title>. <source>Annu Rev Neurosci</source>. <year>2013</year>; <volume>36</volume>: <fpage>451</fpage>–<lpage>466</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1146/annurev-neuro-062111-150439" xlink:type="simple">10.1146/annurev-neuro-062111-150439</ext-link></comment> <object-id pub-id-type="pmid">23841841</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref050"><label>50</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Marshall</surname> <given-names>TR</given-names></name>, <name name-style="western"><surname>Bergmann</surname> <given-names>TO</given-names></name>, <name name-style="western"><surname>Jensen</surname> <given-names>O</given-names></name>. <article-title>Frontoparietal Structural Connectivity Mediates the Top-Down Control of Neuronal Synchronization Associated with Selective Attention</article-title>. <source>PLoS Biol</source>. <year>2015</year>; <volume>13</volume>: <fpage>e1002272</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pbio.1002272" xlink:type="simple">10.1371/journal.pbio.1002272</ext-link></comment> <object-id pub-id-type="pmid">26441286</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref051"><label>51</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Suzuki</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Gottlieb</surname> <given-names>J</given-names></name>. <article-title>Distinct neural mechanisms of distractor suppression in the frontal and parietal lobe</article-title>. <source>Nat Neurosci</source>. <year>2013</year>; <volume>16</volume>: <fpage>98</fpage>–<lpage>104</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.3282" xlink:type="simple">10.1038/nn.3282</ext-link></comment> <object-id pub-id-type="pmid">23242309</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref052"><label>52</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Toepper</surname> <given-names>M</given-names></name>, <etal>et al</etal>. <article-title>Functional correlates of distractor suppression during spatial working memory encoding</article-title>. <source>Neuroscience</source>. <year>2010</year>; <volume>165</volume>: <fpage>1244</fpage>–<lpage>1253</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuroscience.2009.11.019" xlink:type="simple">10.1016/j.neuroscience.2009.11.019</ext-link></comment> <object-id pub-id-type="pmid">19925856</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref053"><label>53</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Friedman</surname> <given-names>NP</given-names></name>, <name name-style="western"><surname>Miyake</surname> <given-names>A</given-names></name>. <article-title>The relations among inhibition and interference control functions: a latent-variable analysis</article-title>. <source>J Exp Psychol Gen</source>. <year>2004</year>; <volume>133</volume>: <fpage>101</fpage>–<lpage>135</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/0096-3445.133.1.101" xlink:type="simple">10.1037/0096-3445.133.1.101</ext-link></comment> <object-id pub-id-type="pmid">14979754</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref054"><label>54</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Snow</surname> <given-names>JC</given-names></name>, <name name-style="western"><surname>Allen</surname> <given-names>HA</given-names></name>, <name name-style="western"><surname>Rafal</surname> <given-names>RD</given-names></name>, <name name-style="western"><surname>Humphreys</surname> <given-names>GW</given-names></name>. <article-title>Impaired attentional selection following lesions to human pulvinar: evidence for homology between human and monkey</article-title>. <source>Proc Natl Acad Sci</source>. <year>2009</year>; <volume>106</volume>: <fpage>4054</fpage>–<lpage>4059</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.0810086106" xlink:type="simple">10.1073/pnas.0810086106</ext-link></comment> <object-id pub-id-type="pmid">19237580</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref055"><label>55</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Desimone</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Wessinger</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Thomas</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Schneider</surname> <given-names>W</given-names></name>. <article-title>Attentional control of visual perception: Cortical and subcortical mechanisms</article-title>. <source>Cold Spr Harb Symp Quant Biol</source>. <year>1990</year>; <volume>55</volume>: <fpage>963</fpage>–<lpage>971</lpage>. <object-id pub-id-type="pmid">2132873</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref056"><label>56</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kastner</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>O’Connor</surname> <given-names>DH</given-names></name>, <name name-style="western"><surname>Fukui</surname> <given-names>MM</given-names></name>, <name name-style="western"><surname>Fehd</surname> <given-names>HM</given-names></name>, <name name-style="western"><surname>Herwig</surname> <given-names>U</given-names></name>, <name name-style="western"><surname>Pinsk</surname> <given-names>MA</given-names></name>. <article-title>Functional imaging of the human lateral geniculate nucleus and pulvinar</article-title>. <source>J Neurophysiol</source>. <year>2004</year>; <volume>91</volume>: <fpage>438</fpage>–<lpage>448</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.00553.2003" xlink:type="simple">10.1152/jn.00553.2003</ext-link></comment> <object-id pub-id-type="pmid">13679404</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref057"><label>57</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Asanuma</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Andersen</surname> <given-names>RA</given-names></name>, <name name-style="western"><surname>Cowan</surname> <given-names>WM</given-names></name>. <article-title>The thalamic relations of the caudal inferior parietal lobule and the lateral prefrontal cortex in monkeys: divergent cortical projections from cell clusters in the medial pulvinar nucleus</article-title>. <source>J Comp Neurol</source>. <year>1985</year>; <volume>241</volume>: <fpage>357</fpage>–<lpage>381</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/cne.902410309" xlink:type="simple">10.1002/cne.902410309</ext-link></comment> <object-id pub-id-type="pmid">4086661</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref058"><label>58</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Saalmann</surname> <given-names>YB</given-names></name>, <name name-style="western"><surname>Kastner</surname> <given-names>S</given-names></name>. <article-title>Cognitive and perceptual functions of the visual thalamus</article-title>. <source>Neuron</source>. <year>2011</year>; <volume>71</volume>: <fpage>209</fpage>–<lpage>223</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2011.06.027" xlink:type="simple">10.1016/j.neuron.2011.06.027</ext-link></comment> <object-id pub-id-type="pmid">21791281</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref059"><label>59</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Webster</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Bachevalier</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Ungerleider</surname> <given-names>LG</given-names></name>. <article-title>Connections of inferior temporal areas TEO and TE with parietal and frontal cortex in macaque monkeys</article-title>. <source>Cereb Cortex</source>. <year>1994</year>; <volume>4</volume>: <fpage>470</fpage>–<lpage>483</lpage>. <object-id pub-id-type="pmid">7530521</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref060"><label>60</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Eckstein</surname> <given-names>MP</given-names></name>, <name name-style="western"><surname>Mack</surname> <given-names>SC</given-names></name>, <name name-style="western"><surname>Liston</surname> <given-names>DB</given-names></name>, <name name-style="western"><surname>Bogush</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Menzel</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Krauzlis</surname> <given-names>RJ</given-names></name>. <article-title>Rethinking human visual attention: Spatial cueing effects and optimality of decisions by honeybees, monkeys and humans</article-title>. <source>Vision Res</source>. <year>2013</year>; <volume>85</volume>: <fpage>5</fpage>–<lpage>19</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.visres.2012.12.011" xlink:type="simple">10.1016/j.visres.2012.12.011</ext-link></comment> <object-id pub-id-type="pmid">23298793</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref061"><label>61</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sergent</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Ruff</surname> <given-names>CC</given-names></name>, <name name-style="western"><surname>Barbot</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Driver</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Rees</surname> <given-names>G</given-names></name>. <article-title>Top-down modulation of human early visual cortex after stimulus offset supports successful postcued report</article-title>. <source>J Cogn Neurosci</source>. <year>2011</year>; <volume>23</volume>: <fpage>1921</fpage>–<lpage>1934</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/jocn.2010.21553" xlink:type="simple">10.1162/jocn.2010.21553</ext-link></comment> <object-id pub-id-type="pmid">20715902</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref062"><label>62</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sergent</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Wyart</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Babo-Rebelo</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Cohen</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Naccache</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Tallon-Baudry</surname> <given-names>C</given-names></name>. <article-title>Cueing attention after the stimulus is gone can retrospectively trigger conscious perception</article-title>. <source>Curr Biol</source>. <year>2013</year>; <volume>23</volume>: <fpage>150</fpage>–<lpage>155</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.cub.2012.11.047" xlink:type="simple">10.1016/j.cub.2012.11.047</ext-link></comment> <object-id pub-id-type="pmid">23246406</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref063"><label>63</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bechara</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Damasio</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Damasio</surname> <given-names>AR</given-names></name>. <article-title>Emotion, decision making and the orbitofrontal cortex</article-title>. <source>Cereb Cortex</source>. <year>2000</year>; <volume>10</volume>: <fpage>295</fpage>–<lpage>307</lpage>. <object-id pub-id-type="pmid">10731224</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref064"><label>64</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wallis</surname> <given-names>JD</given-names></name>. <article-title>Orbitofrontal cortex and its contribution to decision-making</article-title>. <source>Annu Rev Neurosci</source>. <year>2007</year>; <volume>30</volume>: <fpage>31</fpage>–<lpage>56</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1146/annurev.neuro.30.051606.094334" xlink:type="simple">10.1146/annurev.neuro.30.051606.094334</ext-link></comment> <object-id pub-id-type="pmid">17417936</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref065"><label>65</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Corbetta</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Shulman</surname> <given-names>GL</given-names></name>. <article-title>Control of goal-directed and stimulus-driven attention in the brain</article-title>. <source>Nat Rev Neurosci</source>. <year>2002</year>; <volume>3</volume>: <fpage>201</fpage>–<lpage>215</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nrn755" xlink:type="simple">10.1038/nrn755</ext-link></comment> <object-id pub-id-type="pmid">11994752</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref066"><label>66</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Katsuki</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Constantinidis</surname> <given-names>C</given-names></name>. <article-title>Early involvement of prefrontal cortex in visual bottom-up attention</article-title>. <source>Nat Neurosci</source>. <year>2012</year>; <volume>15</volume>: <fpage>1160</fpage>–<lpage>1166</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.3164" xlink:type="simple">10.1038/nn.3164</ext-link></comment> <object-id pub-id-type="pmid">22820465</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref067"><label>67</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sereno</surname> <given-names>MI</given-names></name>, <name name-style="western"><surname>Dale</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Reppas</surname> <given-names>JB</given-names></name>, <name name-style="western"><surname>Kwong</surname> <given-names>KK</given-names></name>, <name name-style="western"><surname>Belliveau</surname> <given-names>JW</given-names></name>, <name name-style="western"><surname>Brady</surname> <given-names>TJ</given-names></name>, <name name-style="western"><surname>Rosen</surname> <given-names>BR</given-names></name>, <name name-style="western"><surname>Tootell</surname> <given-names>RBH</given-names></name>. <article-title>Borders of multiple visual areas in humans revealed by functional magnetic resonance imaging</article-title>. <source>Science</source>. <year>1995</year>; <volume>268</volume>: <fpage>889</fpage>–<lpage>893</lpage>. <object-id pub-id-type="pmid">7754376</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref068"><label>68</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Engel</surname> <given-names>SA</given-names></name>, <name name-style="western"><surname>Glover</surname> <given-names>GH</given-names></name>, <name name-style="western"><surname>Wandell</surname> <given-names>BA</given-names></name>. <article-title>Retinotopic organization in human visual cortex and the spatial precision of functional MRI</article-title>. <source>Cereb Cortex</source>. <year>1997</year>; <volume>7</volume>: <fpage>181</fpage>–<lpage>192</lpage>. <object-id pub-id-type="pmid">9087826</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref069"><label>69</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Talairach</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Tournoux</surname> <given-names>P</given-names></name>. <source>Co-Planar Stereotaxic Atlas of the Human Brain: 3-Dimensional Proportional System: an Approach to Cerebral Imaging</source> (<publisher-loc>New York</publisher-loc>: <publisher-name>Thieme</publisher-name>); <year>1988</year>.</mixed-citation></ref>
<ref id="pbio.1002578.ref070"><label>70</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Smith</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Lewis</surname> <given-names>BK</given-names></name>, <name name-style="western"><surname>Ruttimann</surname> <given-names>UE</given-names></name>, <name name-style="western"><surname>Ye</surname> <given-names>FQ</given-names></name>, <name name-style="western"><surname>Sinnwell</surname> <given-names>TM</given-names></name>, <name name-style="western"><surname>Yang</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Duyn</surname> <given-names>JH</given-names></name>, <name name-style="western"><surname>Frank</surname> <given-names>JA</given-names></name>. <article-title>Investigation of low frequency drift in fMRI signal</article-title>. <source>NeuroImage</source>. <year>1999</year>; <volume>9</volume>: <fpage>526</fpage>–<lpage>533</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1006/nimg.1999.0435" xlink:type="simple">10.1006/nimg.1999.0435</ext-link></comment> <object-id pub-id-type="pmid">10329292</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref071"><label>71</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zhang</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Qiu</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Zhang</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Han</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Fang</surname> <given-names>F</given-names></name>. <article-title>Misbinding of color and motion in human visual cortex</article-title>. <source>Curr Biol</source>. <year>2014</year>; <volume>24</volume>: <fpage>1354</fpage>–<lpage>1360</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.cub.2014.04.045" xlink:type="simple">10.1016/j.cub.2014.04.045</ext-link></comment> <object-id pub-id-type="pmid">24856212</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref072"><label>72</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chen</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Bi</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Zhou</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Li</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Liu</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Fang</surname> <given-names>F</given-names></name>. <article-title>Sharpened cortical tuning and enhanced cortico-cortical communication contribute to the long-term neural mechanisms of visual motion perceptual learning</article-title>. <source>NeuroImage</source>. <year>2015</year>; <volume>115</volume>: <fpage>17</fpage>–<lpage>29</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuroimage.2015.04.041" xlink:type="simple">10.1016/j.neuroimage.2015.04.041</ext-link></comment> <object-id pub-id-type="pmid">25921327</object-id></mixed-citation></ref>
<ref id="pbio.1002578.ref073"><label>73</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Penny</surname> <given-names>WD</given-names></name>, <name name-style="western"><surname>Stephan</surname> <given-names>KE</given-names></name>, <name name-style="western"><surname>Mechelli</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Friston</surname> <given-names>KJ</given-names></name>. <article-title>Comparing dynamic causal models</article-title>. <source>NeuroImage</source>. <year>2004</year>; <volume>22</volume>: <fpage>1157</fpage>–<lpage>1172</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuroimage.2004.03.026" xlink:type="simple">10.1016/j.neuroimage.2004.03.026</ext-link></comment> <object-id pub-id-type="pmid">15219588</object-id></mixed-citation></ref>
</ref-list>
</back>
</article>